{"0": {
    "doc": "Postgresql HA & Loadblance - pgpool II",
    "title": "Optional Solution",
    "content": ". | corosync &amp; pacemaker &amp; heartbeat script POC failed, centos 7.2 x64 . | pgpool II (middleware) &amp; failover script &amp; recovery script POC … processing . | . ",
    "url": "/docs/archives/2018/2018-10-23-Postgresql-pgpool/#optional-solution",
    
    "relUrl": "/docs/archives/2018/2018-10-23-Postgresql-pgpool/#optional-solution"
  },"1": {
    "doc": "Postgresql HA & Loadblance - pgpool II",
    "title": "POC",
    "content": "Env . CentOS 7.2 x64 . Installation . | postgresql 9.6 | pgpool II 96 v3.6.12 | . Version . 9.6 &amp; 3.6 . Config . Hot-standby . | backup command pg_basebackup -D .././. -F p -x -h primary_node -p 5432 -U postgres -P -v . | . Check pool node status . psql -h primary_node -p9999 -U postgres postgres . Pg_rewind command . su - postgres pg_rewind --target-pgdata='/../../..' --source-server='host= port= dbname= user= password=' -P . note: the target server must be primary server, postgresql won’t let server to synchronize from standby server. ",
    "url": "/docs/archives/2018/2018-10-23-Postgresql-pgpool/#poc",
    
    "relUrl": "/docs/archives/2018/2018-10-23-Postgresql-pgpool/#poc"
  },"2": {
    "doc": "Postgresql HA & Loadblance - pgpool II",
    "title": "issue",
    "content": ". | watchdog reject issue, correct Other pgpool Connection Settings pgpool_port and wd_port, default is 9999 and 9000. This issue will lead watchdog process down, watchdog heartbeat signal will be rejected. | correct the rwx permission for root and postgres user. | recovery issue . | pg_rewind command for base time line synchronize | . ",
    "url": "/docs/archives/2018/2018-10-23-Postgresql-pgpool/#issue",
    
    "relUrl": "/docs/archives/2018/2018-10-23-Postgresql-pgpool/#issue"
  },"3": {
    "doc": "Postgresql HA & Loadblance - pgpool II",
    "title": "Postgresql HA & Loadblance - pgpool II",
    "content": "Postgresql . Pgpool . 2018-10-23 19:00:00 +0800 . ",
    "url": "/docs/archives/2018/2018-10-23-Postgresql-pgpool/",
    
    "relUrl": "/docs/archives/2018/2018-10-23-Postgresql-pgpool/"
  },"4": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "What is",
    "content": ". | object-ralational database management system - aka ORDMS | SQL standard database | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#what-is",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#what-is"
  },"5": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "features:",
    "content": ". | complex queries | foreign keys | triggers | updatable views | transactional integrity | multiversion concurrency control | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#features",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#features"
  },"6": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "extended features:",
    "content": ". | data types | functions | operators | aggregate functions | index methods | procedural languages | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#extended-features",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#extended-features"
  },"7": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Basic Command",
    "content": ". | \\h: help for SQL syntax | \\?: PG command-line options | \\l: list all databases | \\c: connect another database | \\d: list all tables for database | \\d + &lt;”table_name”&gt;: describe table, view, sequence, or index | \\du: list all uesr | \\e: editor | \\conninfo: list current connection info | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#basic-command",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#basic-command"
  },"8": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Data type",
    "content": " ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#data-type",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#data-type"
  },"9": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "number",
    "content": "| type | size | range | . | smallint | 2byte | -32768 ~ +32767 | . | integer | 4byte | -2147483648 ~ +2147483647 | . | bigint | 8byte | -9223372036854775808 ~ 9223372036854775807 | . | decimal | var | *131072.*16383 | . | numeric | var | *131072.*16383 | . | real | 4byte | *6 | . | double | 8byte | *15 | . | serial | 4byte | 1 ~ 2147483647 | . | bigserial | 8byte | 1 ~ 922337203685477580 * | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#number",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#number"
  },"10": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "String",
    "content": "| type | . | char(size) | . | character(size) | . | varchar(size) | . | character varying(size) | . | text | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#string",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#string"
  },"11": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Date &amp; Time",
    "content": "| type | . | timestamp | . | timestamp[utc] | . | date | . | time | . | time[utc] | . | interval | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#date--time",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#date--time"
  },"12": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Boolean",
    "content": "| type | value | size | . | boolean | true/false | 1byte | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#boolean",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#boolean"
  },"13": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Json",
    "content": "| type | desc | . | json | textual JOSN data | . | jsonb | binary JOSN data | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#json",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#json"
  },"14": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "other",
    "content": "| type | . | uuid | . | xml | . | … | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#other",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#other"
  },"15": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Database",
    "content": "CREATE DATABASE db_name DROP DATABASE db_name . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#database",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#database"
  },"16": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Table",
    "content": "CREATE TABLE table_name( column1 datatype, column2 datatype, column3 datatype, ..... columnN datatype, PRIMARY KEY( one or more columns ) ); DROP TABLE table_name; . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#table",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#table"
  },"17": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Schema",
    "content": "A database contains one or more named schemas, which in turn contain tables. Schema contains other object like data types, functions, and operators. Schemas are not rigidly separated, a user can access objects in any of the schemas in the database they are connected to. ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#schema",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#schema"
  },"18": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Contaion",
    "content": ". | tables | data types | functions | operators | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#contaion",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#contaion"
  },"19": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "SQL syntax",
    "content": "1. INSERT . INSERT INTO TABLE_NAME (column1,...) VALUES (value1,...); . 2. SELECT . SELECT \"column1\",... FROM \"table_name\"; . 3. UPDATE . UPDATE table_name SET column1 = value1, ... WHERE [condition] UPDATE \"table_name\" set column1 = value1, ... WHERE condition = con_value; . 4. DELETE . DELETE FROM \"table_name\" WHERE condition = con_value; . 5. ORDER BY . ORDER BY WHERE ORDER BY column1 ASC ORDER BY column1 DESC . 6. GROUP BY . GROUP BY sel_column1, ... 7. HAVING . GROUP BY sel_column1, ... HAVING [condition] . use HAVING with GROUP BY syntax . 8. Condition . AND, OR, AND &amp; OR, NOT, LIKE, IN, NOT IN, BETWEEN . 9. AND . SELECT column1, ... FROM table_name WHERE [search_condition] AND [search_condition] . 10. OR . SELECT column1, ... FROM table_name WHERE [search_condition] OR [search_condition] . 11. AND &amp; OR . SELECT column1, ... FROM table_name WHERE ([search_condition] AND [search_condition]) OR ([search_condition]) . 12. NOT . SELECT column1, ... FROM table_name WHERE [search_condition] NOT [condition] SELECT column1, ... FROM table_name WHERE NOT [search_condition] . 13. LIKE . SELECT column1, ... FROM table_name WHERE [search_condition] LIKE [condition] . Wildcard: % . 14. IN . SELECT column1, ... FROM table_name WHERE [search_condition] IN [condition] . 15. NOT IN . SELECT column1, ... FROM table_name WHERE [search_condition] NOT IN [condition] . 16. BETWEEN . SELECT column1, ... FROM table_name WHERE [search_condition] NOT BETWEEN [condition] . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#sql-syntax",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#sql-syntax"
  },"20": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "Join",
    "content": ". | INNER JOIN | LEFT OUTER JOIN | RIGHT OUTER JOIN | FULL OUTER JOIN | CROSS JOIN | . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/#join",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/#join"
  },"21": {
    "doc": "PostgreSQL fundamental and operation",
    "title": "PostgreSQL fundamental and operation",
    "content": "Postgresql . 2018-10-23 19:00:00 +0800 . ",
    "url": "/docs/archives/2018/2018-10-25-PostgreSQL/",
    
    "relUrl": "/docs/archives/2018/2018-10-25-PostgreSQL/"
  },"22": {
    "doc": "Algorithm Matrix",
    "title": "Algorithm requeirment",
    "content": ". | get shortest distance from 0 node for every non 0 node, save the value to the index of non 0 node, generate new matrix. | . ",
    "url": "/docs/archives/2018/2018-10-26-Algorithm-matrix/#algorithm-requeirment",
    
    "relUrl": "/docs/archives/2018/2018-10-26-Algorithm-matrix/#algorithm-requeirment"
  },"23": {
    "doc": "Algorithm Matrix",
    "title": "Implementation",
    "content": "#!/usr/bin/python import random def matrix_distance(origin_matrix): one_list = [] zero_list = [] m_edge = len(origin_matrix[0]) n_edge = len(origin_matrix) for i, v_list in enumerate(origin_matrix): for j, v in enumerate(v_list): if v &gt; 0: one_list.append((i, j)) else: zero_list.append((i, j)) matrix_plus_one(origin_matrix, zero_list, one_list, m_edge, n_edge) def matrix_plus_one(origin_matrix, outter_node_list, inner_node_list, m_edge, n_edge): n_outter_list = [] n_inner_list = [] for i, j in inner_node_list: if 0 &lt;= i - 1 &lt; n_edge and (i - 1, j) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= i + 1 &lt; n_edge and (i + 1, j) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= j - 1 &lt; m_edge and (i, j - 1) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= j + 1 &lt; m_edge and (i, j + 1) in outter_node_list: n_outter_list.append((i, j)) else: n_inner_list.append((i, j)) for i, j in n_inner_list: origin_matrix[i][j] += 1 if len(n_inner_list) &gt; 0: matrix_plus_one(origin_matrix, n_outter_list, n_inner_list, m_edge, n_edge) else: print_matrix(origin_matrix) def print_matrix(matrix): for v in matrix: print v def generate_random_number(): # return random.randint(0, 1) if random.randint(0,100) &gt; 1: return 1 else: return 0 def main(): matrix_size = 30 matrix = [] for _ in range(matrix_size): tmp_list = [] for _ in range(matrix_size): tmp_list.append(generate_random_number()) matrix.append(tmp_list) print_matrix(matrix) print \"result:\" matrix_distance(matrix) if __name__ == '__main__': main() . ",
    "url": "/docs/archives/2018/2018-10-26-Algorithm-matrix/#implementation",
    
    "relUrl": "/docs/archives/2018/2018-10-26-Algorithm-matrix/#implementation"
  },"24": {
    "doc": "Algorithm Matrix",
    "title": "Draft",
    "content": "#!/usr/bin/python # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # get shortest distance from 0 node for every node # map # # m = range(origin_matrix) # n = range(v_list) # if (i-1) in m and origin_matrix[i-1][j] == 0: # z_list.append((i,j)) # elif (i+1) in m and origin_matrix[i+1][j] == 0: # z_list.append((i,j)) # elif (j-1) in n and v_list[j-1] == 0: # z_list.append((i,j)) # elif (j+1) in n and v_list[j+1] == 0: # z_list.append((i,j)) # else import random def matrix_distance(origin_matrix): print_matrix(origin_matrix) # find all 1 one_list = [] zero_list = [] m_edge = len(origin_matrix[0]) n_edge = len(origin_matrix) print m_edge print n_edge for i, v_list in enumerate(origin_matrix): for j, v in enumerate(v_list): if v &gt; 0: one_list.append((i, j)) else: zero_list.append((i, j)) matrix_plus_one(origin_matrix, zero_list, one_list, m_edge, n_edge) def matrix_plus_one(origin_matrix, outter_node_list, inner_node_list, m_edge, n_edge): n_outter_list = [] n_inner_list = [] for i, j in inner_node_list: # print i, j # print m_edge # if 0 &lt;= j-1 &lt; m_edge: # print i, j # if (i, j-1) in outter_node_list: # print \"============================\" # print i, j-1 if 0 &lt;= i - 1 &lt; n_edge and (i - 1, j) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= i + 1 &lt; n_edge and (i + 1, j) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= j - 1 &lt; m_edge and (i, j - 1) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= j + 1 &lt; m_edge and (i, j + 1) in outter_node_list: n_outter_list.append((i, j)) else: n_inner_list.append((i, j)) # print \"OUTTER:\" # print n_outter_list # print \"INNER:\" # print n_inner_list # print n_outter_list # tmp_i, tmp_j = outter_node_list[0] # print tmp_i, tmp_j # if origin_matrix[tmp_i, tmp_j] &gt; 0: print \"========================================\" print_matrix(origin_matrix) print \"========================================\" for i, j in n_inner_list: origin_matrix[i][j] += 1 print_matrix(origin_matrix) if len(n_inner_list) &gt; 0: matrix_plus_one(origin_matrix, n_outter_list, n_inner_list, m_edge, n_edge) else: print \"--------------------------------------------------------------------\" print_matrix(origin_matrix) def print_matrix(matrix): # print \"-\".join(map(str,range(len(matrix[0])))) # for v in matrix: # # separate = \" , \" # print v # for sub_v in v: # print sub_v for i, v_list in enumerate(matrix): for j, v in enumerate(v_list): print matrix[i][j] if matrix[i][j] == 2: print \"&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;\" print i, j matrix[i][j] += 1 for v in matrix: print v def generate_random_number(): return random.randint(0, 1) def main(): # m = len(list_1) list_1 = [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_2 = [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_3 = [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_4 = [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_5 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_6 = [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_7 = [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_8 = [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_9 = [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_10 = [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_11 = [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_12 = [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_13 = [0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_14 = [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_15 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_16 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_17 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_18 = [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] # v = len(v_list) list_1.extend(list_1) list_2.extend(list_2) list_3.extend(list_3) list_4.extend(list_4) list_5.extend(list_5) list_6.extend(list_6) list_7.extend(list_7) list_8.extend(list_8) list_9.extend(list_9) list_10.extend(list_10) list_11.extend(list_11) list_12.extend(list_12) list_13.extend(list_13) list_14.extend(list_14) list_15.extend(list_15) list_16.extend(list_16) list_17.extend(list_17) list_18.extend(list_18) v_list = [list_1, list_2, list_3, list_4, list_5, list_6, list_7, list_8, list_9, list_10, list_11, list_12, list_13, list_14, list_15, list_16, list_17, list_18] # v_list = [list_1, list_2, list_3, list_4, list_5, list_6, list_7, list_8, list_9, list_10, list_11, list_12, list_13, list_14, list_15, list_16, list_17, list_18,] # matrix_distance(v_list) # print_matrix(v_list) # v_list_n = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1] input_list = [] for i in range(16): tmp_list = [] for i in range(16): tmp_list.append(generate_random_number()) input_list.append(tmp_list) print_matrix(input_list) print generate_random_number() if __name__ == '__main__': main() # !/usr/bin/python # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # | 1, 0, 1, 0, 0 | # get shortest distance from 0 node for every node # map # # m = range(origin_matrix) # n = range(v_list) # if (i-1) in m and origin_matrix[i-1][j] == 0: # z_list.append((i,j)) # elif (i+1) in m and origin_matrix[i+1][j] == 0: # z_list.append((i,j)) # elif (j-1) in n and v_list[j-1] == 0: # z_list.append((i,j)) # elif (j+1) in n and v_list[j+1] == 0: # z_list.append((i,j)) # else import random def matrix_distance(origin_matrix): print_matrix(origin_matrix) # find all 1 one_list = [] zero_list = [] m_edge = len(origin_matrix[0]) n_edge = len(origin_matrix) print m_edge print n_edge for i, v_list in enumerate(origin_matrix): for j, v in enumerate(v_list): if v &gt; 0: one_list.append((i, j)) else: zero_list.append((i, j)) matrix_plus_one(origin_matrix, zero_list, one_list, m_edge, n_edge) def matrix_plus_one(origin_matrix, outter_node_list, inner_node_list, m_edge, n_edge): n_outter_list = [] n_inner_list = [] for i, j in inner_node_list: # print i, j # print m_edge # if 0 &lt;= j-1 &lt; m_edge: # print i, j # if (i, j-1) in outter_node_list: # print \"============================\" # print i, j-1 if 0 &lt;= i - 1 &lt; n_edge and (i - 1, j) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= i + 1 &lt; n_edge and (i + 1, j) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= j - 1 &lt; m_edge and (i, j - 1) in outter_node_list: n_outter_list.append((i, j)) elif 0 &lt;= j + 1 &lt; m_edge and (i, j + 1) in outter_node_list: n_outter_list.append((i, j)) else: n_inner_list.append((i, j)) # print \"OUTTER:\" # print n_outter_list # print \"INNER:\" # print n_inner_list # print n_outter_list # tmp_i, tmp_j = outter_node_list[0] # print tmp_i, tmp_j # if origin_matrix[tmp_i, tmp_j] &gt; 0: print \"========================================\" print_matrix(origin_matrix) print \"========================================\" for i, j in n_inner_list: origin_matrix[i][j] += 1 print_matrix(origin_matrix) if len(n_inner_list) &gt; 0: matrix_plus_one(origin_matrix, n_outter_list, n_inner_list, m_edge, n_edge) else: print \"--------------------------------------------------------------------\" print_matrix(origin_matrix) def print_matrix(matrix): # print \"-\".join(map(str,range(len(matrix[0])))) # for v in matrix: # # separate = \" , \" # print v # for sub_v in v: # print sub_v for i, v_list in enumerate(matrix): for j, v in enumerate(v_list): print matrix[i][j] if matrix[i][j] == 2: print \"&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;\" print i, j matrix[i][j] += 1 for v in matrix: print v def generate_random_number(): return random.randint(0, 1) def main(): # m = len(list_1) list_1 = [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_2 = [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_3 = [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_4 = [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_5 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_6 = [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_7 = [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_8 = [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_9 = [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_10 = [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_11 = [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_12 = [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_13 = [0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_14 = [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_15 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_16 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_17 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] list_18 = [1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1] # v = len(v_list) list_1.extend(list_1) list_2.extend(list_2) list_3.extend(list_3) list_4.extend(list_4) list_5.extend(list_5) list_6.extend(list_6) list_7.extend(list_7) list_8.extend(list_8) list_9.extend(list_9) list_10.extend(list_10) list_11.extend(list_11) list_12.extend(list_12) list_13.extend(list_13) list_14.extend(list_14) list_15.extend(list_15) list_16.extend(list_16) list_17.extend(list_17) list_18.extend(list_18) v_list = [list_1, list_2, list_3, list_4, list_5, list_6, list_7, list_8, list_9, list_10, list_11, list_12, list_13, list_14, list_15, list_16, list_17, list_18] # v_list = [list_1, list_2, list_3, list_4, list_5, list_6, list_7, list_8, list_9, list_10, list_11, list_12, list_13, list_14, list_15, list_16, list_17, list_18,] # matrix_distance(v_list) # print_matrix(v_list) # v_list_n = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1] input_list = [] for i in range(16): tmp_list = [] for i in range(16): tmp_list.append(generate_random_number()) input_list.append(tmp_list) print_matrix(input_list) print generate_random_number() def fib_alg(): pass if __name__ == '__main__': main() . ",
    "url": "/docs/archives/2018/2018-10-26-Algorithm-matrix/#draft",
    
    "relUrl": "/docs/archives/2018/2018-10-26-Algorithm-matrix/#draft"
  },"25": {
    "doc": "Algorithm Matrix",
    "title": "Algorithm Matrix",
    "content": "Algorithm . 2018-10-26 18:00:00 +0800 . ",
    "url": "/docs/archives/2018/2018-10-26-Algorithm-matrix/",
    
    "relUrl": "/docs/archives/2018/2018-10-26-Algorithm-matrix/"
  },"26": {
    "doc": "通过 ulimit 改善系统性能",
    "title": "通过 ulimit 改善系统性能",
    "content": " ",
    "url": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#%E9%80%9A%E8%BF%87-ulimit-%E6%94%B9%E5%96%84%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD",
    
    "relUrl": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#通过-ulimit-改善系统性能"
  },"27": {
    "doc": "通过 ulimit 改善系统性能",
    "title": "ulimit:",
    "content": " ",
    "url": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#ulimit",
    
    "relUrl": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#ulimit"
  },"28": {
    "doc": "通过 ulimit 改善系统性能",
    "title": "ulimit用于限制shell启动进程所占用的资源",
    "content": ". | 所创建的内核文件的大小 | 进程数据快的大小 | shell进程创建文件的大小 | 内存锁住的大小 | 常驻内存集的大小 | 打开文件描述符的数量 | 分配堆栈的最大大小 | CPU时间 | 单个用户最大线程数 | shell进程所能使用的最大虚拟内存 硬资源和软资源的限制 . | . ",
    "url": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#ulimit%E7%94%A8%E4%BA%8E%E9%99%90%E5%88%B6shell%E5%90%AF%E5%8A%A8%E8%BF%9B%E7%A8%8B%E6%89%80%E5%8D%A0%E7%94%A8%E7%9A%84%E8%B5%84%E6%BA%90",
    
    "relUrl": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#ulimit用于限制shell启动进程所占用的资源"
  },"29": {
    "doc": "通过 ulimit 改善系统性能",
    "title": "使用方式",
    "content": ". | 登录shell到终止会话之间，对资源进行限制 | 写入文件，可以针对特定用户，进行长期固定的限制 | . | ulimit –help | . ",
    "url": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F",
    
    "relUrl": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#使用方式"
  },"30": {
    "doc": "通过 ulimit 改善系统性能",
    "title": "有效范围",
    "content": ". | 作用范围：作用于用户当前shell进程派生的子进程 | . ",
    "url": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#%E6%9C%89%E6%95%88%E8%8C%83%E5%9B%B4",
    
    "relUrl": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#有效范围"
  },"31": {
    "doc": "通过 ulimit 改善系统性能",
    "title": "修改系统文件",
    "content": ". | 修改单一用户限制 /etc/security/limits.conf | . 文件格式： domain type item value . domain: user and group &amp; * stand for all type: “soft” or “hard” item: “cpu,stack,nofile,….” value: just value . | 修改应用对整个系统的限制 /proc/* | . | /proc 目录下包含很多linux系统当前状态参数 | . /proc/sys/kernel/pid_max 内核态进程最大进程数 /proc/sys/net/ipv4/ip_local_post_range ipv4本地端口范围 … . 由文件名称进行配置参数状态的判断即可 . ",
    "url": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#%E4%BF%AE%E6%94%B9%E7%B3%BB%E7%BB%9F%E6%96%87%E4%BB%B6",
    
    "relUrl": "/docs/archives/2018/2018-12-05-Linux-Ulimit/#修改系统文件"
  },"32": {
    "doc": "通过 ulimit 改善系统性能",
    "title": "通过 ulimit 改善系统性能",
    "content": "Linux . 2018-10-22 12:00:00 +0800 . ",
    "url": "/docs/archives/2018/2018-12-05-Linux-Ulimit/",
    
    "relUrl": "/docs/archives/2018/2018-12-05-Linux-Ulimit/"
  },"33": {
    "doc": "V2ray Nginx 配置",
    "title": "V2ray Nginx 配置",
    "content": "“Nginx内网转发，https证书配置，V2ray代理配置” . ",
    "url": "/docs/archives/2018/2018-12-05-V2ray-Websocket-Nginx/#v2ray-nginx-%E9%85%8D%E7%BD%AE",
    
    "relUrl": "/docs/archives/2018/2018-12-05-V2ray-Websocket-Nginx/#v2ray-nginx-配置"
  },"34": {
    "doc": "V2ray Nginx 配置",
    "title": "V2ray installation and nginx setup",
    "content": "Simple Installation process . | 配置一个域名，提前配置DNS解析 domain=\"\" . | 安装V2ray二进制，提前配置YUM源，makecache，安装wget, nginx, socat wget https://install.direct/go.sh &amp;&amp; bash go.sh . | 生成https证书，certificate curl https://get.acme.sh | sh ~/.acme.sh/acme.sh --issue -d www.maclabx.ml --standalone -k ec-256 ~/.acme.sh/acme.sh --installcert -d www.maclabx.ml --fullchainpath /etc/v2ray/v2ray.crt --keypath /etc/v2ray/v2ray.key --ecc . | 开启内网转发，selinux inner forwarding setsebool -P httpd_can_network_connect 1 . | . Config file . | v2ray service config.json { \"inbound\": { \"port\": 12057, \"listen\":\"127.0.0.1\", \"protocol\": \"vmess\", \"settings\": { \"clients\": [ { \"id\": \"&lt;uuidgen&gt;\", \"alterId\": 64 } ] }, \"streamSettings\": { \"network\": \"ws\", \"wsSettings\": { \"path\": \"/&lt;path&gt;\" } } }, \"outbound\": { \"protocol\": \"freedom\", \"settings\": {} } } . | nginx config server { listen 443 ssl; ssl on; ssl_certificate /etc/v2ray/v2ray.crt; ssl_certificate_key /etc/v2ray/v2ray.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; server_name &lt;my.domain.name&gt;; location /&lt;path&gt; { proxy_redirect off; proxy_pass http://127.0.0.1:&lt;forwording_port&gt;; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; proxy_set_header Host $http_host; } } . | . ",
    "url": "/docs/archives/2018/2018-12-05-V2ray-Websocket-Nginx/#v2ray-installation-and-nginx-setup",
    
    "relUrl": "/docs/archives/2018/2018-12-05-V2ray-Websocket-Nginx/#v2ray-installation-and-nginx-setup"
  },"35": {
    "doc": "V2ray Nginx 配置",
    "title": "Cloud services",
    "content": ". | AWS &amp; AWS lightsail . | Google cloud . | . POC 如果想获取做好的体验，在Google cloud上开启一个ipv6的负载均衡，配置负载均衡的https转发到TW或者HK的同一AZ的两台以上实例 Google cloud 30.35 网段每天有很多时间段无法访问，拜GFW所赐 . ",
    "url": "/docs/archives/2018/2018-12-05-V2ray-Websocket-Nginx/#cloud-services",
    
    "relUrl": "/docs/archives/2018/2018-12-05-V2ray-Websocket-Nginx/#cloud-services"
  },"36": {
    "doc": "V2ray Nginx 配置",
    "title": "V2ray Nginx 配置",
    "content": "V2ray . 2018-12-05 12:00:00 +0800 . ",
    "url": "/docs/archives/2018/2018-12-05-V2ray-Websocket-Nginx/",
    
    "relUrl": "/docs/archives/2018/2018-12-05-V2ray-Websocket-Nginx/"
  },"37": {
    "doc": 2018,
    "title": "2018",
    "content": " ",
    "url": "/docs/archives/2018/2018/#2018",
    
    "relUrl": "/docs/archives/2018/2018/#2018"
  },"38": {
    "doc": 2018,
    "title": 2018,
    "content": " ",
    "url": "/docs/archives/2018/2018/",
    
    "relUrl": "/docs/archives/2018/2018/"
  },"39": {
    "doc": "RabbitMQ & AMQP",
    "title": "RabbitMQ",
    "content": ". ",
    "url": "/docs/archives/2019/2019-02-20-RabbitMQ-pub-sub/#rabbitmq",
    
    "relUrl": "/docs/archives/2019/2019-02-20-RabbitMQ-pub-sub/#rabbitmq"
  },"40": {
    "doc": "RabbitMQ & AMQP",
    "title": "RabbitMQ & AMQP",
    "content": "RabbitMQ . 2019-02-20 10:00:00 +0800 . ",
    "url": "/docs/archives/2019/2019-02-20-RabbitMQ-pub-sub/",
    
    "relUrl": "/docs/archives/2019/2019-02-20-RabbitMQ-pub-sub/"
  },"41": {
    "doc": 2019,
    "title": "2019",
    "content": " ",
    "url": "/docs/archives/2019/2019/#2019",
    
    "relUrl": "/docs/archives/2019/2019/#2019"
  },"42": {
    "doc": 2019,
    "title": 2019,
    "content": " ",
    "url": "/docs/archives/2019/2019/",
    
    "relUrl": "/docs/archives/2019/2019/"
  },"43": {
    "doc": "体系结构-树",
    "title": "体系结构-树",
    "content": "├── 体系结构 │   ├── 基础 │   │   ├── 深入理解计算机系统[CSAPP] │   │   │   ├── 存储结构 │   │   │   ├── 虚拟内存 │   │   │   ├── 链接 │   │   │   ├── 并发 │   │   │   └── 网络 │   │   ├── 计算机网络 │   │   │   └── 链路 │   │   ├── 现代操作系统 │   │   ├── 算法导论 │   │   ├── 自动机导论 │   │   ├── 图灵可计算理论 │   │   ├── 编译原理 │   │   ├── 数据库系统概念 │   ├── 底层 │   │   ├── Linux内核实现&amp;源代码 │   │   │   ├── 线程调度算法 │   │   │   ├── 多路复用算法 │   │   │   ├── 内存管理&amp;mmap │   │   │   ├── 内核网络&amp;socket管理 │   │   │   └── 进程/线程状态表 │   │   ├── CPython虚拟机原理&amp;源代码 │   ├── 应用 │   │   ├── 云计算 │   │   ├── 分布式 │   │   ├── 中间件 │   │   ├── 数据存储 │   │   ├── 消息队列 │   │   ├── 网络应用 │   │   ├── 监控系统 │   │   ├── 理论实践 │   │   │   ├── 远端过程调用[RPC] │   │   ├── 工具 │   │   │   ├── Git │   │   │   ├── VIM │   │   │   ├── Latex │   ├── 语言 │   │   ├── C/C++ │   │   ├── Python │   │   ├── Go │   │   ├── Rust │   ├── 理论 │   │   ├── 论文期刊 │   │   │   ├── 算法[KMP] │   │   │   ├── 远端过程调用计算机系统[RPC] ├── 实践 │   ├── 问题分析 │   │   ├── 网络 │   │   ├── 数据库 │   ├── 需求实现 │   ├── 学习总结 │   ├── 实践记录 │   ├── 面试总结 │   │   ├── 算法 . ",
    "url": "/docs/archives/2020/2020-01-01-cs-communication-physical-architecture/#%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-%E6%A0%91",
    
    "relUrl": "/docs/archives/2020/2020-01-01-cs-communication-physical-architecture/#体系结构-树"
  },"44": {
    "doc": "体系结构-树",
    "title": "体系结构-知识树",
    "content": ". ",
    "url": "/docs/archives/2020/2020-01-01-cs-communication-physical-architecture/#%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-%E7%9F%A5%E8%AF%86%E6%A0%91",
    
    "relUrl": "/docs/archives/2020/2020-01-01-cs-communication-physical-architecture/#体系结构-知识树"
  },"45": {
    "doc": "体系结构-树",
    "title": "体系结构-树",
    "content": "体系结构 . 2020-01-01 00:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-01-01-cs-communication-physical-architecture/",
    
    "relUrl": "/docs/archives/2020/2020-01-01-cs-communication-physical-architecture/"
  },"46": {
    "doc": "BeginningOf2020 - Algorithm",
    "title": "BeginningOf2020 - Algorithm",
    "content": "BeginningOf2020 . Algorithm . 2020-01-20 10:00:00 +0800 . # [47] 全排列 II # # @lc code=start class Solution(object): def permuteUnique(self, nums): \"\"\" :type nums: List[int] :rtype: List[List[int]] \"\"\" def do_swap(l, start, end): for i in range(start, end): if l[end] == l[i]: return False return True def backtrack(start=0): if start == n: result.append(nums[:]) for i in range(start, n): # if i &gt; 0 and nums[i] == nums[i - 1] and pre[i] == 0: # continue if do_swap(nums, start, i): nums[i], nums[start] = nums[start], nums[i] backtrack(start + 1) nums[i], nums[start] = nums[start], nums[i] nums.sort() n = len(nums) result = [] backtrack() return result . # [1] 两数之和 # # @lc code=start class Solution(object): def twoSum(self, nums, target): \"\"\" :type nums: List[int] :type target: int :rtype: List[int] \"\"\" # Golang # func twoSum(nums []int, target int) []int { # tmp_map := make(map [int]int) # for i, n := range nums { # t := target - n # if resultI, ok := tmp_map[t]; ok { # return []int{i, resultI} # } # tmp_map[n] = i # } # return []int{0, 0} # } . # [2] 两数相加 # # @lc code=start # Definition for singly-linked list. # class ListNode(object): # def __init__(self, x): # self.val = x # self.next = None class Solution(object): r = None def addTwoNumbers(self, l1, l2): \"\"\" :type l1: ListNode :type l2: ListNode :rtype: ListNode \"\"\" result = ListNode(0) Solution.r = result while True: if l1 and l2: t_sum = l1.val + l2.val l1 = l1.next l2 = l2.next elif not l1 and l2: t_sum = l2.val l2 = l2.next elif not l2 and l1: t_sum = l1.val l1 = l1.next else: t_sum = 0 Solution.r.next = ListNode(0) if Solution.r.val != 0: t_sum = t_sum + Solution.r.val if t_sum &gt;= 10: t_sum = t_sum - 10 Solution.r.next.val = 1 else: Solution.r.next.val = 0 Solution.r.val = t_sum if not l1 and not l2: if Solution.r.next.val == 0: Solution.r.next = None break Solution.r = Solution.r.next print result return result . # [4] 寻找两个有序数组的中位数 # # @lc code=start class Solution(object): def findMedianSortedArrays(self, nums1, nums2): \"\"\" :type nums1: List[int] :type nums2: List[int] :rtype: float \"\"\" p = 0 if nums1: for n2 in nums2: n = p m = len(nums1) - 1 while True: i = int((m - n) / 2) + n if n == m: if n2 &gt; nums1[n]: p = n + 1 break else: p = n break if n == m - 1: if nums1[n] &lt;= n2 &lt;= nums1[m]: p = n + 1 break elif n2 &lt; nums1[n]: p = n break elif n2 &gt; nums1[m]: p = m + 1 break else: break if n2 == nums1[i]: p = i break elif n2 &lt; nums1[i]: m = i else: n = i nums1.insert(p, n2) else: nums1 = nums2 if len(nums1) % 2 &gt; 0: return nums1[int(len(nums1) - 1) / 2] else: return float((nums1[int(len(nums1) /2)] + (nums1[int(len(nums1) /2 - 1)])) / 2.0) # TODO need to do another alternative . # [5] 最长回文子串 # # @lc code=start class Solution(object): def longestPalindrome(self, s): \"\"\" :type s: str :rtype: str \"\"\" # A: find the same from start to end as start of iterable result = {} for i in range(len(s)): r = \"\" k = 0 j = 0 if i + 1 &gt;= len(s): continue if s[i] == s[i+1]: j = i k = i + 1 while j &gt;= 0 and k &lt; len(s) and s[j] == s[k]: r = s[j] + r r += s[k] j -= 1 k += 1 if r: result.update({len(r): r}) if i - 1 &gt;= 0 and i + 1 &lt; len(s) and s[i-1] == s[i+1]: r = s[i] j = i - 1 k = i + 1 while j &gt;= 0 and k &lt; len(s) and s[j] == s[k]: r = s[j] + r r += s[k] j -= 1 k += 1 if r: result.update({len(r): r}) print result if result: return result[max(result.keys())] elif s: return s[0] else: return \"\" # last_i = len(s) -1 # result = \"\" # for i in range(len(s)): # if s[i] == s[last_i] # last_i = last_i - 1 # result += s[i] # else: # if s[i + 1] == s[last_i]: # continue # elif s[i] == s[last_i -1]: # last_i = last_i -1 # else: # last_i = last_i -1 # reutrn result . # [8] 字符串转换整数 (atoi) # # @lc code=star class Solution(object): def myAtoi(self, string): \"\"\" :type str: str :rtype: int \"\"\" # Anylize # special: return 0 # int32 # string = string.strip() if not string: return 0 l = [str(i) for i in xrange(10)] o = [\"-\", \"+\"] result = \"\" for v in string: if v in o and not result: result += v elif v in l: result += v elif not result: return 0 else: break if result == \"+\" or result == \"-\": return 0 if not (-2 **31 &lt;= int(result) &lt;= 2**31 -1): if int(result) &lt; 0: return -2 ** 31 else: return 2 ** 31 -1 return int(result) . # [13] 罗马数字转整数 # # @lc code=start class Solution(object): def romanToInt(self, s): \"\"\" :type s: str :rtype: int \"\"\" # Anylize: # 1. put cha and number into dict # 2. for the s and handle special case and get number result = [] r_d = { \"I\" : 1, \"V\" : 5, \"X\" : 10, \"L\" : 50, \"C\" : 100, \"D\" : 500, \"M\" : 1000, } for i in s: m = 0 if i in [\"V\", \"X\"] and result and result[len(result) - 1] == 1: m = 1 elif i in [\"L\", \"C\"] and result and result[len(result) - 1] == 10: m = 10 elif i in [\"D\", \"M\"] and result and result[len(result) - 1] == 100: m = 100 else: pass if m != 0: result = result[:len(result) -1] v = r_d[i] - m result.append(v) sum = 0 if not result: return 0 else: for v in result: sum += int(v) return sum . # [15] 三数之和 # # @lc code=start class Solution(object): def threeSum(self, nums): \"\"\" :type nums: List[int] :rtype: List[List[int]] \"\"\" # Anylize # 1. use set # 2. minimize the time # result = set() # result_dict = {} # for a in nums: # result_dict.update({[a]: a}) # for b in nums: # for i in result_dict.iterkeys(): # result_dict[i] += b # i.append(b) # for c in nums: # for i in result_dict.iterkeys(): # result_dict[i] += c # i.append(c) # print result_dict # for k, v in result_dict.iteritems(): # if v == 0: # result.add(tuple(k)) # return result # sort and 2 points result = [] nums.sort() k = 0 while nums and len(nums) &gt; 2 and nums[k] &lt;= 0 and k &lt; len(nums) -1: if nums[k] &gt; 0: break if k != 0 and nums[k] == nums[k-1]: k+=1; continue i = k + 1 j = len(nums) -1 while i &lt; j: s = nums[i] + nums[k] + nums[j] if s &lt; 0: i += 1 while i &lt;j and nums[i] == nums[i - 1]: i += 1 elif s &gt; 0: j -= 1 while i &lt; j and nums[j] == nums[j + 1]: j -= 1 else: t = [nums[i], nums[k], nums[j]] result.append(t) i += 1 j -= 1 while i &lt; j and nums[i] == nums[i - 1]: i += 1 while i &lt; j and nums[j] == nums[j + 1]: j -= 1 k += 1 return result . # [20] 有效的括号 # # @lc code=start class Solution(object): def isValid(self, s): \"\"\" :type s: str :rtype: bool \"\"\" # 1. from 0 to n &gt; and find it's pair X # 1. L, R # 2. 1,2,3 reverse 3,2,1 stack = [] q_dict = { \"(\": (1, \"L\"), \")\": (1, \"R\"), \"[\": (2, \"L\"), \"]\": (2, \"R\"), \"{\": (3, \"L\"), \"}\": (3, \"R\") } for v in s: if q_dict[v][1] == \"R\": if not stack: return False else: if q_dict[v][0] == stack[-1:][0][0]: stack.pop(len(stack) - 1) else: return False else: stack.append(q_dict[v]) if not stack: return True return False . # [21] 合并两个有序链表 # # @lc code=start # Definition for singly-linked list. # class ListNode(object): # def __init__(self, x): # self.val = x # self.next = None class Solution(object): def mergeTwoLists(self, l1, l2): \"\"\" :type l1: ListNode :type l2: ListNode :rtype: ListNode \"\"\" # recontect len n m # method1 : read all and sort time- fuckedup # method2 : sort insert into long # 1. l1 between l2 # 2. l1 head of l2 # 3. l1 tail of l2 # l1 --------- # l2 ------ if not l1 and not l2: return None elif not l1 and l2: return l2 elif l1 and not l2: return l1 else: pass if l1.val &lt; l2.val: head = l1 tail = l2 else: head = l2 tail = l1 result = head while head: if not head or not tail: break if not head.next and tail: head.next = tail break while head.next.val &gt;= tail.val: tmp = ListNode(tail.val) tmp.next = head.next head.next = tmp tail = tail.next if not tail and head: break head = head.next return result . # [23] 合并K个排序链表 # # @lc code=start # Definition for singly-linked list. # class ListNode(object): # def __init__(self, x): # self.val = x # self.next = None class Solution(object): def mergeKLists(self, lists): \"\"\" :type lists: List[ListNode] :rtype: ListNode \"\"\" if not lists: return None l_merge = [] for l in lists: if l: l_merge.append((l.val, l)) if not l_merge: return None l_merge = sorted(l_merge, key=lambda k: k[0]) print l_merge while len(l_merge) &gt; 1: i = 0 new_l_merge = [] while i &lt; len(l_merge) / 2: new_l = self.mergeTwoLists(l_merge[i][1], l_merge[len(l_merge) - 1 -i][1]) l_merge.pop(i) l_merge.pop(len(l_merge) - 1 -i) new_l_merge.append((new_l.val, new_l)) if l_merge: new_l_merge.extend(l_merge) l_merge = new_l_merge return l_merge[0][1] def mergeTwoLists(self, l1, l2): if not l1 and not l2: return None elif not l1 and l2: return l2 elif l1 and not l2: return l1 else: pass if l1.val &lt; l2.val: head = l1 tail = l2 else: head = l2 tail = l1 result = head while head: if not head or not tail: break if not head.next and tail: head.next = tail break while head.next.val &gt;= tail.val: tmp = ListNode(tail.val) tmp.next = head.next head.next = tmp tail = tail.next if not tail and head: break head = head.next return result . # [24] 两两交换链表中的节点 # # @lc code=start # Definition for singly-linked list. # class ListNode(object): # def __init__(self, x): # self.val = x # self.next = None class Solution(object): def swapPairs(self, head): \"\"\" :type head: ListNode :rtype: ListNode \"\"\" # recursive # # # if head == None or head.next == None: return head read_p = ListNode(0) read_p = head.next head.next = self.swapPairs(read_p.next) read_p.next = head return read_p . # [25] K 个一组翻转链表 # # @lc code=start # Definition for singly-linked list. # class ListNode(object): # def __init__(self, x): # self.val = x # self.next = None class Solution(object): def reverseKGroup(self, head, k): \"\"\" :type head: ListNode :type k: int :rtype: ListNode \"\"\" if k == 0: return head if head == None or head.next == None: return head stack = [] first = None last = None while True: if not head and len(stack) &lt; k: if not first: return stack[0] last.next = stack[0] return first if len(stack) == k: i = k - 1 while i &gt; 0: stack[i].next = stack[i - 1] if i -1 == 0: stack[i -1].next = None i -= 1 if not last and not first: first = stack[k - 1] else: last.next = stack[k - 1] last = stack[0] stack = [] if not head and not stack: return first stack.append(head) head = head.next . # [26] 删除排序数组中的重复项 # # @lc code=start class Solution(object): def removeDuplicates(self, nums): \"\"\" :type nums: List[int] :rtype: int \"\"\" # if not nums: return 0 if len(nums) == 1: return 1 i , c = 0, 0 while i &lt; len(nums) - 1: i += 1 if nums[i] != nums[c]: if nums[c] == nums[c -1]: nums[c:i + 1] = [nums[i] for _ in range(c, i + 1)] c += 1 else: if nums[c] != nums[c -1]: c = i if c == len(nums) - 1 and nums[c -1] != nums[len(nums) - 1]: return len(nums) if c == 0: return 1 return c # Double pointer # @Time complexity: O(n) # @Space complexity: O(1) . # [28] 实现 strStr() # # @lc code=start class Solution(object): def strStr(self, haystack, needle): \"\"\" :type haystack: str :type needle: str :rtype: int \"\"\" if not needle: return 0 i, c = 0, -1 while i &lt; len(haystack): if haystack[i] == needle[0] and c == -1: c = i continue if c != -1: if len(needle) &gt; len(haystack) - c: c = -1 break if i - c == len(needle): break if haystack[i] != needle[i-c]: i = c c = -1 i += 1 return c . # [33] 搜索旋转排序数组 # # @lc code=start class Solution(object): def search(self, nums, target): \"\"\" :type nums: List[int] :type target: int :rtype: int \"\"\" # time complexity logN # length = len(nums) # if target &gt; nums[0]: # i, j = 0, length / 4 # while j &lt; length: # if target == nums[j]: # return j # elif target &lt; nums[j]: # if j == i + 1 or i == j + 1: # return -1 # i = j # j = j / 2 # else: # if j == i + 1 or i == j + 1: # return -1 # i = j # j = (length - 1 - j) / 2 + j # elif target &lt; nums[length - 1]: # i, j = 0, 3* length / 4 # while j &lt; length: # if target == nums[j]: # return j # elif target &lt; nums[j]: # if j == i + 1 or i == j + 1: # return -1 # i = j # j = j / 2 # else: # if j == i + 1 or i == j + 1: # return -1 # i = j # j = (length - 1 - j) / 2 + j # elif target == nums[length - 1]: # return length - 1 # elif target == nums[0]: # return 0 # else: # return -1 length = len(nums) if not nums: return -1 elif target == nums[length - 1]: return length - 1 elif target == nums[0]: return 0 elif nums[length - 1] &lt; nums[0] and nums[length - 1] &lt; target &lt; nums[0]: return -1 else: pass i, j = 0, length -1 while i &lt;= j: m = i + (j - i) / 2 mt= target mV= \"M %s\" % nums[m] mI= \"I %s\" % nums[i] mJ= \"J %s\" % nums[j] if target == nums[m]: return m elif target == nums[i]: return i elif target == nums[j]: return j elif i == j: return -1 if nums[length - 1] &gt; nums[0]: # not rotated if target &lt; nums[m]: j = m -1 else: i = m + 1 else: # rotated if nums[m] &gt; nums[length -1]: # middle in the left side if target &lt; nums[m] and target &lt; nums[0]: i = m + 1 elif target &lt; nums[m] and target &gt; nums[0]: j = m - 1 elif target &gt; nums[m]: i = m + 1 else: return -1 elif nums[m] &lt; nums[length -1]: # middle in the right side # or nums are not rotated if target &lt; nums[m]: j = m - 1 elif target &gt; nums[m] and target &gt; nums[0]: j = m - 1 elif target &gt; nums[m] and target &lt; nums[0]: i = m + 1 else: return -1 return -1 . # [46] 全排列 # # @lc code=start class Solution(object): def permute(self, nums): \"\"\" :type nums: List[int] :rtype: List[List[int]] \"\"\" def backtrack(first=0): if first == n: result.append(nums[:]) for i in range(first, n): nums[first], nums[i] = nums[i], nums[first] backtrack(first + 1) nums[first], nums[i] = nums[i], nums[first] n = len(nums) result = [] backtrack() return result . # [47] 全排列 II # # @lc code=start class Solution(object): def permuteUnique(self, nums): \"\"\" :type nums: List[int] :rtype: List[List[int]] \"\"\" def do_swap(l, start, end): for i in range(start, end): if l[end] == l[i]: return False return True def backtrack(start=0): if start == n: result.append(nums[:]) for i in range(start, n): # if i &gt; 0 and nums[i] == nums[i - 1] and pre[i] == 0: # continue if do_swap(nums, start, i): nums[i], nums[start] = nums[start], nums[i] backtrack(start + 1) nums[i], nums[start] = nums[start], nums[i] nums.sort() n = len(nums) result = [] backtrack() return result # def backtrack(start=0): # if start == n: # # if nums not in result: # result.append(nums[:]) # for i in range(start, n): # if i + 1 &lt; n and nums[i] == nums[i + 1]: # continue # if i==start and pre.get(i) and nums[:start] in pre.get(i): # continue # nums[i], nums[start] = nums[start], nums[i] # if start ==i: # if not pre.get(i): # pre[i] = [nums[:start]] # else: # pre[i].append(nums[:start]) # backtrack(start + 1) # nums[i], nums[start] = nums[start], nums[i] # pre = {} # n = len(nums) # result = [] # backtrack() # return result # Python 3 time complexity great # class Solution: # def permuteUnique(self, nums: List[int]) -&gt; List[List[int]]: # nums.sort() # self.res = [] # check = [0 for i in range(len(nums))] # self.backtrack([], nums, check) # return self.res # def backtrack(self, sol, nums, check): # if len(sol) == len(nums): # self.res.append(sol) # return # for i in range(len(nums)): # if check[i] == 1: # continue # if i &gt; 0 and nums[i] == nums[i-1] and check[i-1] == 0: # continue # check[i] = 1 # self.backtrack(sol+[nums[i]], nums, check) # check[i] = 0 # def permuteUnique(self, nums): # nums.sort() # self.res = [] # check = [0 for _ in range(len(nums))] # self.backtrack([], nums, check) # return self.res # def backtrack(self, sol, nums, check): # if len(sol) == len(nums): # self.res.append(sol) # return # for i in range(len(nums)): # if check[i] == 1: ## continue # if i &gt; 0 and nums[i] == nums[i - 1] and check[i - 1] == 0: # continue # check[i] = 1 # self.backtrack(sol + [nums[i]], nums, check) # check[i] = 0 . # TODO - mark fix # [672] 灯泡开关 Ⅱ # # @lc code=start class Solution(object): def flipLights(self, n, m): \"\"\" :type n: int :type m: int :rtype: int \"\"\" lights = [1 for i in range(n)] result = [] p = [] for m1 in range(m + 1): m234 = m - m1 for m2 in range(m234 +1): m34 = m234 - m2 for m3 in range(m34 +1): m4 = m34 - m3 if m1 % 2 &gt; 0: lights = [0 for i in range(n)] if m2 % 2 &gt; 0: for i in range(0, n): if (i+1) % 2 == 0: if lights[i] == 0: lights[i] = 1 else: lights[i] = 0 if m3 % 2 &gt; 0: for i in range(0, n): if (i + 1) % 2 == 1: if lights[i] == 0: lights[i] = 1 else: lights[i] = 0 if m4 % 2 &gt; 0: if n == 0: continue elif n in [1, 2, 3]: if lights[0] == 0: lights[0] = 1 else: lights[0] = 0 else: for k in range(int((n - 1)/ 3) + 1): if lights[3 *k] == 0: lights[3 * k] = 1 else: lights[3 * k] = 0 r_l = \",\".join([str(a) for a in lights]) print m1, m2, m3, m4 p.append([m1, m2, m3, m4]) print \"LIGHTS: %s\" % lights result.append(r_l) lights = [1 for i in range(n)] print len(result) result = set(result) print len(result) print \"P %s\" % len(p) print result return len(result) . ",
    "url": "/docs/archives/2020/2020-01-08-%5BBeginning-of-2020--Algorithm%5D/",
    
    "relUrl": "/docs/archives/2020/2020-01-08-%5BBeginning-of-2020--Algorithm%5D/"
  },"47": {
    "doc": "SumOf2019 - DataInfluxPatrol",
    "title": "DataInfluxPatrol-Golang",
    "content": "Q: What is the method of analyzing high influx data coverage ? . ",
    "url": "/docs/archives/2020/2020-01-08-%5BSum-of-2019--DataInfluxPatrol-Golang%5D/#datainfluxpatrol-golang",
    
    "relUrl": "/docs/archives/2020/2020-01-08-%5BSum-of-2019--DataInfluxPatrol-Golang%5D/#datainfluxpatrol-golang"
  },"48": {
    "doc": "SumOf2019 - DataInfluxPatrol",
    "title": "The implementation of high influx data coverage analyzer",
    "content": "1. Foundament of Architecture . ",
    "url": "/docs/archives/2020/2020-01-08-%5BSum-of-2019--DataInfluxPatrol-Golang%5D/#the-implementation-of-high-influx-data-coverage-analyzer",
    
    "relUrl": "/docs/archives/2020/2020-01-08-%5BSum-of-2019--DataInfluxPatrol-Golang%5D/#the-implementation-of-high-influx-data-coverage-analyzer"
  },"49": {
    "doc": "SumOf2019 - DataInfluxPatrol",
    "title": "SumOf2019 - DataInfluxPatrol",
    "content": "SumOf2019 . DataInfluxPatrol-Golang . 2019-12-01 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-01-08-%5BSum-of-2019--DataInfluxPatrol-Golang%5D/",
    
    "relUrl": "/docs/archives/2020/2020-01-08-%5BSum-of-2019--DataInfluxPatrol-Golang%5D/"
  },"50": {
    "doc": "Algorithm Everything",
    "title": "经验",
    "content": " ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E7%BB%8F%E9%AA%8C",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#经验"
  },"51": {
    "doc": "Algorithm Everything",
    "title": "1. 提问",
    "content": ". | 主要负责内容 云网络监控 . | 具体项目描述 | 什么样的架构 server+agent的分布式架构，每个可用去会规划两台裸金属的物理机作为监控agent节点，每台物理机会启动多个agent将采集压力负载到每个agent上，并且agent采用了心跳模式的高可用和监控； . | 用了什么框架 server使用的是python2的tornado框架 tornado框架和核心是什么 . | . epoll epoll linux: linux多路复用技术可以处理数以百万计的socket句柄 poll和select epoll的提升和区别 多路复用IO(I/O Multiplexing) . 多路复用模型 select epoll . 句柄与普通指针的区别在于，指针包含的是引用对象的内存地址，而句柄则是由系统所管理的引用标识，该标识可以被系统重新定位到一个内存地址上。这种间接访问对象的模式增强了系统对引用对象的控制。（参见封装）。通俗的说就是我们调用句柄就是调用句柄所提供的服务，即句柄已经把它能做的操作都设定好了，我们只能在句柄所提供的操作范围内进行操作，但是普通指针的操作却多种多样，不受限制。 . # https://www.jiqizhixin.com/articles/2019-04-10-15 # 前面一部分Torando.ioloop是Tornado的核心模块ioloop模块，IOLoop是ioloop模块的一个类，current()是IOLoop类的一个方法，结果是返回一个当前线程的IOLoop的实例，start()也是IOLoop的方法，调用后开启循环。 tornado.ioloop.IOLoop.current().start() . | 数据处理的模式 . | 负载均衡用了什么 . | . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#1-%E6%8F%90%E9%97%AE",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#1-提问"
  },"52": {
    "doc": "Algorithm Everything",
    "title": "基础",
    "content": " ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%9F%BA%E7%A1%80",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#基础"
  },"53": {
    "doc": "Algorithm Everything",
    "title": "各种排序算法和查找算法",
    "content": ". | 快速排序 | 冒泡排序 | 选择排序 | 直接插入排序 | 归并排序 | 堆排序 | 希尔排序 | 基数排序 | 二叉树排序 | 计数排序 . | 二分查找 | . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%90%84%E7%A7%8D%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%92%8C%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#各种排序算法和查找算法"
  },"54": {
    "doc": "Algorithm Everything",
    "title": "数据结构基础",
    "content": ". | 队列 | 栈 | 链表 单向链表，双向链表，单向链表存储当前值和下一个节点的指针或着引用，双向链表会多存储一个前一个节点的指针或着引用。 . | 哈希表 | 二分查找 | 二叉树 二叉树搜索， 任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低。为O(log n)。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、multiset、关联数组等。 . | 图 图、连通图、图的基本算法： 数据结构中有三种关系，一对一，一对多，多对多 一对一： 线性结构数组、栈、队列、链表、哈希表 一对多：树结构，二叉树、三叉树 多对多：图 | . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%9F%BA%E7%A1%80",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#数据结构基础"
  },"55": {
    "doc": "Algorithm Everything",
    "title": "TODO",
    "content": "二叉树的数据结构的实现和各种遍历方式 . | 二叉搜索树 | N叉树 | . https://leetcode-cn.com/explore/ . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#todo",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#todo"
  },"56": {
    "doc": "Algorithm Everything",
    "title": "数据库",
    "content": " ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E6%95%B0%E6%8D%AE%E5%BA%93",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#数据库"
  },"57": {
    "doc": "Algorithm Everything",
    "title": "shell",
    "content": " ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#shell",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#shell"
  },"58": {
    "doc": "Algorithm Everything",
    "title": "多线程",
    "content": " ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%A4%9A%E7%BA%BF%E7%A8%8B",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#多线程"
  },"59": {
    "doc": "Algorithm Everything",
    "title": "递归",
    "content": " ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E9%80%92%E5%BD%92",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#递归"
  },"60": {
    "doc": "Algorithm Everything",
    "title": "机器学习",
    "content": " ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#机器学习"
  },"61": {
    "doc": "Algorithm Everything",
    "title": "动手",
    "content": "https://teddygoodman.github.io/ . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%8A%A8%E6%89%8B",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#动手"
  },"62": {
    "doc": "Algorithm Everything",
    "title": "进阶",
    "content": ". | 动态规划 https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/solution/yi-ge-fang-fa-tuan-mie-6-dao-gu-piao-wen-ti-by-l-2/ . | 递归：画出递归树 递归树 | | . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E8%BF%9B%E9%98%B6",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#进阶"
  },"63": {
    "doc": "Algorithm Everything",
    "title": "算法学习总结",
    "content": "常用方法总结： 贪心算法 贪心算法的思想是每一步都选择最佳解决方案，最终获得全局最佳的解决方案。 . 常用时间复杂度：O(n log(n)) O(n^2) O(n) O(1) O(n^2) O(n+k) O(nk) O(n!) O(max(m, n)) O(log(m + n)) O(max(m, n)) . Company - Microsoft . | 两数之和，给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 Solution: 一次遍历 1. 初始化一个字典 2. 一次遍历 numns 并获取 target 与每个遍历值的差值 3. 检查差值是否在已经初始化的目标字典中，存在则返回字典值 &gt; T: O(n) S: O(n) . | 两数相加，给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。两个数相加起来，则会返回一个新的链表来表示它们的和。(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) 输出：7 -&gt; 0 -&gt; 8 &gt; Solution: 一次遍历，遍历次数为最长链表 1. 初始化一个结果链表 2. 使用while循环，操作两个链表（假设输入链表为m n），m和n都存在时，与结果非0相加，如果相加值大于10，则将结果的next设置为1，如果其中一个链表为空，则循环非空链表，并将值加到结果链表上 &gt; T: O(max(m, n)) S: O(max(m, n)) . | 寻找两个有序数组的中位数, 给定两个大小为 m 和 n 的有序数组 nums1 和 nums2。请你找出这两个有序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n)) 你可以假设 nums1 和 nums2 不会同时为空。(中位数，统计学，将一个集合划分为两个长度相等的子集，其中一个子集中的元素总是大于另一个子集中的元素。) &gt; Solution: 二叉树搜索算法，对num1和nums2生成两个排序树，并且对较短的排序树进行搜索，较短的树为m，比较树根的大小，如果m树小于n左子树树根，则m重新定义为m的又子树树根，反之亦然。算法实现方式类似于二分查找，最近结果时间复杂度接近O(log(max(m, n))),需要考虑边界条件，包括两个数组各自或者都为空的情况，和一个数组最大值小于另一个数组0索引值的情况。还需要考虑奇偶情况； &gt; T: O(log(max(m, n))) S: O(1) 存储静态变量，无需过多空间； . | 买卖股票的最佳时机，给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。注意你不能在买入股票前卖出股票。如果最多可以完成两笔交易呢？？？ 最大收益，最佳时机，一次交易机会 最大收益，最佳时机，最多两次交易机会 最大收益，最佳时机，无限次交易机会 买卖股票的最佳时机，交易k次，且 k &lt; n /2 最佳买卖股票时机含冷冻期 买卖股票的最佳时机含手续费 ``` Solution: 简单动态规划，画图分析，将每天的股票价格表示在折线图中，所要求的结果就是峰值和谷值的差，一次交易为一次最大差值，两次交易为两次最大差值的和或者一次最大差值。解法：1. 初始化两个变量，来存储当前最低值和最大收益（最大差），一次遍历该数组，每次遇到小于最低值的就更新最低值，每次遇到与最低值差值大于变量值的就更新最大差值，最终得到最大收益；2. 如果最多有两次交易机会则，仿照方法1初始化两个最小值和最大值变量，分别代表第一次和第二次最低交易值和最大收益，第二次的最低交易值需要用最低值减去第一次的收入。 Solution: 真正的动态规划，使用dp table(dynamic programming table)，动态规划表，首先使用状态表穷举所有可能性，例如此题中为每一天的状态，包含三个可变参数天数、到当前剩余交易次数、当前是否持有股票，该表中的最终参数为当天利润；完成穷举框架后定义出所有状态转移方程，根据状态转移方程求得最终的最大利润，最终需要做好base case和特殊情况的处理； 用状态的转移跟踪动态的变化： 状态穷举： dp[i][k][0]: 表示第i天剩余k次交易的时候，没持有股票时手上的利润，两种可能延续了前一天没有股票，今天刚刚卖出股票，在这两种可能中找出最大值 dp[i][k][1]: 表示第i天剩余k次交易的时候，持有股票时手上的利润，两种可能延续了前一天持有的股票，今天刚买进股票，在这两种可能中找出最大值 . | . base case： dp[-1][k][0] = dp[i][0][0] = 0 dp[-1][k][1] = dp[i][0][1] = -infinity . 状态转移方程： dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]) dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]) . III: 题目三根据穷举状态可得到，需要对无法消除的影响变量k进行穷举，表现在算法中就是遍历，最终的算法结果可以进一步进行化简，从而实现4个变量保存状态的最大利润； T:O(n) S: O(1) . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#算法学习总结"
  },"64": {
    "doc": "Algorithm Everything",
    "title": "Python 实现题目III 状态方程化简前",
    "content": " ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python-%E5%AE%9E%E7%8E%B0%E9%A2%98%E7%9B%AEiii-%E7%8A%B6%E6%80%81%E6%96%B9%E7%A8%8B%E5%8C%96%E7%AE%80%E5%89%8D",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python-实现题目iii-状态方程化简前"
  },"65": {
    "doc": "Algorithm Everything",
    "title": "此时必须要考虑k对整体状态转移的影响，也就是k的次数会随着交易的次数降低，但是k也有可能出现还剩一次的情况但是已经得到了最大的收益了o",
    "content": "int max_k = 2; int[][][] dp = new int[n][max_k + 1][2]; for (int i = 0; i &lt; n; i++) { for (int k = max_k; k &gt;= 1; k–) { if (i - 1 == -1) { /* 处理 base case / dp[i][k][0] = 0; dp[i][k][1] = -prices[i]; continue; /处理 base case */ } dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]); dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]); } } // 穷举了 n × max_k × 2 个状态，正确。 return dp[n - 1][max_k][0]; . mindnode . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E6%AD%A4%E6%97%B6%E5%BF%85%E9%A1%BB%E8%A6%81%E8%80%83%E8%99%91k%E5%AF%B9%E6%95%B4%E4%BD%93%E7%8A%B6%E6%80%81%E8%BD%AC%E7%A7%BB%E7%9A%84%E5%BD%B1%E5%93%8D%E4%B9%9F%E5%B0%B1%E6%98%AFk%E7%9A%84%E6%AC%A1%E6%95%B0%E4%BC%9A%E9%9A%8F%E7%9D%80%E4%BA%A4%E6%98%93%E7%9A%84%E6%AC%A1%E6%95%B0%E9%99%8D%E4%BD%8E%E4%BD%86%E6%98%AFk%E4%B9%9F%E6%9C%89%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E8%BF%98%E5%89%A9%E4%B8%80%E6%AC%A1%E7%9A%84%E6%83%85%E5%86%B5%E4%BD%86%E6%98%AF%E5%B7%B2%E7%BB%8F%E5%BE%97%E5%88%B0%E4%BA%86%E6%9C%80%E5%A4%A7%E7%9A%84%E6%94%B6%E7%9B%8A%E4%BA%86o",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#此时必须要考虑k对整体状态转移的影响也就是k的次数会随着交易的次数降低但是k也有可能出现还剩一次的情况但是已经得到了最大的收益了o"
  },"66": {
    "doc": "Algorithm Everything",
    "title": "Python 实现题目III 状态方程化简后",
    "content": "fst_lower, sec_lower, fst_max, sec_max = sys.maxint, sys.maxint, 0, 0 . for i in prices: if i &lt; fst_lower: fst_lower = i if i - fst_lower &gt; fst_max: fst_max = i - fst_lower . if i - fst_max &lt; sec_lower: sec_lower = i - fst_max if i - sec_lower &gt; sec_max: sec_max = i - sec_lower . return sec_max . 5. 给一个 C++ 程序，删除程序中的注释。在 C++ 中有两种注释风格，行内注释和块注释。 . Solution: 逐行考虑当前这一行会出现的情况有哪些： 我们需要逐行分析源代码。有两种情况，要么在一个注释内或者不在。 如果我们遇到注释块符号，而我们不在注释中，那么我们将跳过接下来的两个字符，并将状态更改为在注释中。 如果我们遇到注释块符号并且我们在注释中，那么我们将跳过接下来的两个字符并将状态更改为不在注释中。 如果我们遇到一个行注释且我们不在注释中，那么我们将忽略该行的其余部分。 如果我们不在注释中（并且它不是注释的开头），我们将记录所遇到的字符。 在每行的末尾，如果我们不在注释中，我们将记录该行。 T: O(S) S: O(S) S表示代码的总字符长度 . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python-%E5%AE%9E%E7%8E%B0%E9%A2%98%E7%9B%AEiii-%E7%8A%B6%E6%80%81%E6%96%B9%E7%A8%8B%E5%8C%96%E7%AE%80%E5%90%8E",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python-实现题目iii-状态方程化简后"
  },"67": {
    "doc": "Algorithm Everything",
    "title": "python",
    "content": "class Solution(object): def removeComments(self, source): in_block = False ans = [] for line in source: i = 0 if not in_block: newline = [] while i &lt; len(line): if line[i:i+2] == ‘/’ and not in_block: in_block = True i += 1 elif line[i:i+2] == ‘/’ and in_block: in_block = False i += 1 elif not in_block and line[i:i+2] == ‘//’: break elif not in_block: newline.append(line[i]) i += 1 if newline and not in_block: ans.append(““.join(newline)) . return ans ``` . | 灯泡开关 Ⅱ 按位与   ( bitwise and of x and y ) &amp;  举例： 5&amp;3 = 1  解释： 101  11 相同位仅为个位1 ，故结果为 1 按位或   ( bitwise or of x and y ) |  举例： 5|3 = 7  解释： 101  11 出现1的位是 1 1 1，故结果为 111 按位异或 ( bitwise exclusive or of x and y ) ^  举例： 5^3 = 6  解释： 101  11 对位相加(不进位)是 1 1 0，故结果为 110 按位反转 (the bits of x inverted ) ~  举例： ~5 = -6  解释： 将二进制数+1之后乘以-1，即~x = -(x+1)，-(101 + 1) = -110 按位反转仅能用在数字前面。所以写成 3+~5 可以得到结果-3，写成3~5就出错了 按位左移 （ x shifted left by n bits ） « 举例:  5«2 = 20 解释：101 向左移动2位得到 10100 ，即右面多出2位用0补 按位右移 （ x shifted right by n bits ） . 举例： 5»2 = 1  解释：101 向右移动2位得到 1，即去掉右面的2位 . Solution: 状态枚举，按位操作 解法，首先列出前6个灯的所有可能性 Light 1 = 1 + a + c + d Light 2 = 1 + a + b Light 3 = 1 + a + c Light 4 = 1 + a + b + d Light 5 = 1 + a + c Light 6 = 1 + a + b 前三个灯已经包含了所有会出现的可能性，第五个和第六个灯的状态和第三个第二个完全一致，第四个灯地状态等于前三种开关状态之和，也就是前三种状态完全决定了第四个灯的状态； 此时由上述分析可知，前三个灯的状态决定了全部灯在序列里状态的可能性，所以只需要分析前三个灯在所有操作次数的可能性所有情况 只需要考虑m分别为0，1，2的三种特殊情况下的前三灯的特殊状态，当m&gt;=3的时候前三个灯将包括他所有可能的亮灭过程，分别为2，4，8； 重点：1.分析前三个灯决定了所有灯的状态，2.分析操作次数大于等于3的情况下前三个灯将包含其所有可能的状态，因为前三个灯最多操作的是三种操作叠加，所以当操作次数为3的情况下，前三灯的所有的情况都可以包括； T: O(1) S: O(1) # python class Solution(object): def flipLights(self, n, m): n = min(n, 3) if m == 0: return 1 if m == 1: return [2, 3, 4][n-1] if m == 2: return [2, 4, 7][n-1] return [2, 4, 8][n-1 ] . | 灯泡开关 I 初始时有 n 个灯泡关闭。 第 1 轮，你打开所有的灯泡。 第 2 轮，每两个灯泡你关闭一次。 第 3 轮，每三个灯泡切换一次开关（如果关闭则开启，如果开启则关闭）。第 i 轮，每 i 个灯泡切换一次开关。 对于第 n 轮，你只切换最后一个灯泡的开关。 找出 n 轮后有多少个亮着的灯泡。 &gt; Solution: 分析方法，画出自定义的n个灯泡的情况，不难发现，每个数字都有奇数个或者偶数个因数，比如9 1 9 3而12为1 12 3 4，从而可以看出只有奇数个因数的序号的灯泡会进行奇数次操作，最终结果为亮着的状态，而判断一个数字的因数是否为奇数个也很简单就是看该数字是否是平方数；答案为返回平方数的个数； &gt; T: S: . | 最大二叉树 给定一个不含重复元素的整数数组。一个以此数组构建的最大二叉树定义如下： 二叉树的根是数组中的最大元素。 左子树是通过数组中最大值左边部分构造出的最大二叉树。 右子树是通过数组中最大值右边部分构造出的最大二叉树。 通过给定的数组构建最大二叉树，并且输出这个树的根节点。 . Solution: 重点： 二叉树 递归 如何表示二叉树的数据结构 Node(elem, lchild, rchild) T: S: . | 只有两个键的键盘 最初在一个记事本上只有一个字符 ‘A’。你每次可以对这个记事本进行两种操作： Copy All (复制全部) : 你可以复制这个记事本中的所有字符(部分的复制是不允许的)。 Paste (粘贴) : 你可以粘贴你上一次复制的字符。 给定一个数字 n 。你需要使用最少的操作次数，在记事本中打印出恰好 n 个 ‘A’。输出能够打印出 n 个 ‘A’ 的最少操作次数。 ``` Solution: 数学，素数分解 素数分解，素数分解的方法，例如一个自然数N，如果要求他的最小因数和且不限制他的因数数量，则将N分解因数且所有因数都为素数，因为x+y&lt;=x*y; 最终所有素数的和就是最小因数和，此题的答案就是最小因数和-因数数量 python求解素数分解: result = 0 pn_start = 2 while n &gt; 1: while n%pn_start == 0: result += pn_start n /= pn_start pn_start += 1 return result . | . 之所以不考虑copy这个无效操作多出来的1个操作数，是因为每次拷贝前已经存在一份拷贝了 a(n) = a(n-1) + [a(n) - 1]a(n-1), n-1次粘贴再加上已经存在的一份，所以每次操作都是n次； . T: O(√n) S: O(1) 这里的最差时间复杂度是当一个数的素数因数正好是他的开方，这时候中间两行代码被执行到的次数最多和最后一行升序被执行的最多，也就是开方次； ``` . | 子串查询，KMP &gt; Solution: &gt; T: S: . | 字符串的排列 给定两个字符串 s1 和 s2，写一个函数来判断 s2 是否包含 s1 的排列。 换句话说，第一个字符串的排列之一是第二个字符串的子串。 ``` Solution: 滑动窗口思想 什么是滑动窗口：它是一个运行在一个大数组上的子列表，该数组是一个底层元素集合。 假设有数组 [a b c d e f g h ]，一个大小为 3 的 滑动窗口 在其上滑动，则有： [a b c] [b c d] [c d e] [d e f] [e f g] [f g h] 一般情况下就是使用这个窗口在数组的 合法区间 内进行滑动，同时 动态地 记录一些有用的数据，很多情况下，能够极大地提高算法地效率。 本题求解思路： 暴力法就是生成s1的所有排列，也就是s1的全排列，在使用KMP法再s2中进行子串搜索； 与kmp类似的方法是滑动窗口，通过子串在目标串的滑动过程中来记录窗口中的关键信息，从而实现算法时间复杂度的最优； . | . 下面两种python的实现，都是根据窗口中现有的字符数目的前后匹配，时间上比较差； . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python"
  },"68": {
    "doc": "Algorithm Everything",
    "title": "python 实现",
    "content": "def checkInclusion(self, s1, s2): \"\"\" :type s1: str :type s2: str :rtype: bool \"\"\" # 解法1: 复杂窗口匹配法 # 1. 在s1中找到所有字符的数量 \"\"\" char_map = {} for v in s1: if v not in char_map.iterkeys(): char_map.update({v: 1}) else: char_map.update({v: char_map[v] + 1}) # 2. 通过滑动窗口匹配s1中的元素数量 w_l= len(s1) i = 0 max_l = [] less_l = [] while i &lt; len(s2) - w_l + 1: if max_l and max_l[1] &gt; 0: if s2[i+w_l-1] != max_l[0] and s2[i-1] == max_l[0]: max_l[1] -= 1 elif s2[i+w_l-1] == max_l[0] and s2[i-1] != max_l[0]: max_l[1] += 1 if max_l[1] &gt; 0: i += 1 continue if less_l and less_l[1] &gt; 0: if s2[i+w_l-1] == less_l[0] and s2[i-1] != less_l[0]: less_l[1] -= 1 elif s2[i+w_l-1] != less_l[0] and s2[i-1] == less_l[0]: less_l[1] += 1 if less_l[1] &gt; 0: i += 1 continue tmp_count = {} j = i while j &lt; w_l + i: if s2[j] not in char_map.iterkeys(): i = j break if s2[j] not in tmp_count.iterkeys(): tmp_count.update({s2[j]: 1}) else: tmp_count.update({s2[j]: tmp_count[s2[j]] + 1}) # # 窗口中元素过多 v = s2[j] if tmp_count[v] &gt; char_map[v]: max_l = [v, tmp_count[v] - char_map[v]] break # 窗口中元素过少(窗口中已经存在的元素数量与s中元素数量的差值大于了当前窗口的剩余长度) if char_map[v] - tmp_count[v] &gt; w_l + i - j: less_l = [v, char_map[v] - tmp_count[v] - (w_l + i - j)] j += 1 i += 1 if tmp_count == char_map: return True return False \"\"\" # 解法2: 窗口前后元素更新比对法 # 1. 在s1中找到所有字符的数量 char_map = {} for v in s1: if v not in char_map.iterkeys(): char_map.update({v: 1}) else: char_map.update({v: char_map[v] + 1}) window_size = len(s1) window_map = {} window_left = 0 window_right = 0 while window_right &lt; len(s2): if s2[window_right] not in char_map.iterkeys(): window_map = {} window_left = window_right + 1 window_right = window_right + 1 continue if s2[window_right] not in window_map.iterkeys(): window_map.update({s2[window_right]: 1}) else: window_map.update({s2[window_right]: window_map[s2[window_right]] + 1}) window_right += 1 if window_right - window_left &gt; window_size: window_map[s2[window_left]] -= 1 if window_map[s2[window_left]] == 0: window_map.pop(s2[window_left]) window_left += 1 if window_map == char_map: return True return False &gt; T: S: #TODO 后续分析 ``` . | 找树左下角的值 tree | depth-first-search | breadth-first-search 给定一个二叉树，在树的最后一行找到最左边的值。 ``` TODO： 二叉树的各种遍历方式： 广度优先 队列 深度优先 栈 前序遍历 中序遍历 后序遍历 Solution: 广度优先，深度优先； 二叉树的各种遍历方式：广度优先、深度优先、前序遍历、中序遍历、后序遍历 深度优先遍历：从根节点出发，沿着左子树方向进行纵向遍历，直到找到叶子节点为止。然后回溯到前一个节点，进行右子树节点的遍历，直到遍历完所有可达节点为止。 广度优先遍历：从根节点出发，在横向遍历二叉树层段节点的基础上纵向遍历二叉树的层次。 DFS实现： 数据结构：栈 父节点入栈，父节点出栈，先右子节点入栈，后左子节点入栈。递归遍历全部节点即可 . | . BFS实现： 数据结构：队列 父节点入队，父节点出队列，先左子节点入队，后右子节点入队。递归遍历全部节点即可 . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python-%E5%AE%9E%E7%8E%B0",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python-实现"
  },"69": {
    "doc": "Algorithm Everything",
    "title": "python 使用队列从右往左广度优先遍历，使用栈实现深度优先遍历并暂存长度",
    "content": "def findBottomLeftValue(self, root): \"\"\" :type root: TreeNode :rtype: int \"\"\" # 使用队列从右往左广度优先遍历整个树，输出最后一个元素就是最后一行最左边的元素 queue_l = [] queue_l.append(root) while queue_l: node = queue_l.pop(0) if node.right: queue_l.append(node.right) if node.left: queue_l.append(node.left) if not queue_l: return node.val # 使用栈实现深度优先遍历 &gt; T: S: ``` . | 用最少数量的箭引爆气球 xstart ≤ x ≤ xend，则该气球会被引爆 输入:[[10,16], [2,8], [1,6], [7,12]] 输出:2 &gt; Solution: 考虑使用局部最优解或者说每一步都是最优解的贪心算法 &gt; 常用方法总结： &gt; 贪心算法 贪心算法的思想是每一步都选择最佳解决方案，最终获得全局最佳的解决方案。 &gt; 对于此题来说所有气球坐标最小和坐标最大的之间尽量使用最少的箭来引爆 对于每一个气球来说最好能找到与其坐标香蕉的气球，对每一个气球来说都是找到该气球下的最优解； # python if not points: return 0 points = sorted(points, key= lambda x:x[1]) arr_n = 1 end = points[0][1] for v1, v2 in points: if v1 &gt; end: arr_n += 1 end = v2 return arr_n # 在不使用排序的情况下，无法解决边界问题，因为全部气球的最左边或者最右边是整体的边界，如果遍历顺序导致边界情况在后来才被考虑到，可能就会导致边界被孤立，从而无法获得最优解： # 此题目 不排序情况下的实现方式 # TODO # if not points: # return 0 # arr_range = [[points[0][0],points[0][1]]] # for v1, v2 in points: # update = False # for rv in arr_range: # if rv[0] &lt;= v1 &lt;= rv[1] or rv[0] &lt;= v2 &lt;= rv[1] or v1 &lt;= rv[0] &lt;= v2 or v1 &lt;= rv[1] &lt;= v2: # rv[0] = max(rv[0], v1) # rv[1] = min(rv[1], v2) # update = True # break # if not update: arr_range.append([v1, v2]) # return len(arr_range) 无法满足的case： [[3,9],[7,12],[3,8],[6,8],[9,10],[2,9],[0,9],[3,9],[0,6],[2,8]] [!image]() &gt; T: S: . | 两数相加 II 给定两个非空链表来代表两个非负整数。数字最高位位于链表开始位置。它们的每个节点只存储单个数字。将这两数相加会返回一个新的链表。 &gt; Solution: 此次的两数相加中不知道链表长度而且不能对链表进行直接反转之后进位相加，所有需要考虑从高位开始向低位对目的链表进行相加的情况： 解法1: 思想：暂存栈，存储之后pop相加 对L1 L2两个链表进行暂存存储在栈中，因为栈的push和pop操作又后进先出的特点，所以对两个栈进行相加并生成新的链表，就可以得到最终L1 L2之和的链表的结果； 解法2: 获取长度，对同位部分使用递归的方式相加，递归的return可以返回相加的进位，如此就可以处理进位的问题； # pyothon 解法2 # TODO # Mark - this is a python 3 implementation # finish python2 version and rewrite with stack push pop def addTwoNumbers(self, l1, l2): def add(num1, num2, i, j): if not i or not j: return 0 if num1 &gt; num2: temp = i.val + add(num1 - 1, num2, i.next, j) else: temp = i.val + j.val + add(num1, num2, i.next, j.next) i.val = temp % 10 return temp // 10 num1 = num2 = 0 cur = l2 while cur: num2 += 1 cur = cur.next cur = l1 while cur: num1 += 1 cur = cur.next if num2 &gt; num1: l1, l2 = l2, l1 num2, num1 = num1, num2 if add(num1,num2,l1, l2): l2 = ListNode(1) l2.next = l1 l1 = l2 return l1 &gt; T: S: . | 压缩字符串 | . 给定一组字符，使用原地算法将其压缩。 压缩后的长度必须始终小于或等于原数组长度。 数组的每个元素应该是长度为1 的字符（不是 int 整数类型）。 在完成原地修改输入数组后，返回数组的新长度。 使用O(1) 空间解决 . 原地算法： . 在计算机科学中，一个原地算法（in-place algorithm）是一种使用小的，固定数量的额外之空间来转换资料的算法。当算法执行时，输入的资料通常会被要输出的部份覆盖掉。不是原地算法有时候称为非原地（not-in-place）或不得其所（out-of-place）。 . 在计算复杂性理论中，原地算法包含使用O(1)空间复杂度的所有算法，DSPACE(1)类型。这个类型是非常有限的；它与正规语言1相等。事实上，它甚至不包含上面所列的任何范例。 . 示例： . 输入： [\"a\",\"b\",\"b\",\"b\",\"b\",\"b\",\"b\",\"b\",\"b\",\"b\",\"b\",\"b\",\"b\"] 输出： 返回4，输入数组的前4个字符应该是：[\"a\",\"b\",\"1\",\"2\"]。 . &gt; Solution: 解法1: 1. 实现空间复杂度为1的原地算法 # python 使用暂存值存储索引值和重复字符的索引，并存储重复字符的字符 # 实现空间复杂度为1的原地算法 # 在python中使用切片无法实现原地算法，原地算法需要对原数组中的值进行修改，例如直接替换、pop、insert # count, j, i = 1, 0, 0 # while i &lt; len(chars) - 1: # i += 1 # if chars[i] == chars[i - 1]: # count += 1 # if j == 0: j = i # if i == len(chars) - 1 and count &gt; 1: # count_l = str(count).split(\",\") # chars = chars[0:j] + count_l # else: # if count &gt; 1: # count_l = str(count).split(\",\") # chars = chars[0:j] + count_l + chars[i:] # j = 0 # count = 1 # i = i - (i - j) + len(count_l) # print chars # return len(chars) # 实现空间复杂度为1的原地算法 count, i = 1, 0 while i &lt; len(chars) - 1: i += 1 if chars[i] == chars[i - 1]: chars.pop(i) i -= 1 count += 1 if i == len(chars) - 1 and count &gt; 1: chars.extend(list(str(count))) break else: if count &gt; 1: count_l = list(str(count)) for v in count_l: chars.insert(i, v) i += 1 count = 1 return len(chars) # 空间复杂度O(1) 使用3个常量存储 # 时间复杂度O(N) &gt; T: S: . | 甲板上的战舰 | . 给定一个二维的甲板， 请计算其中有多少艘战舰。 战舰用 'X'表示，空位用 '.'表示。 你需要遵守以下规则： . | 给你一个有效的甲板，仅由战舰或者空位组成。 | 战舰只能水平或者垂直放置。换句话说,战舰只能由 1xN (1 行, N 列)组成，或者 Nx1 (N 行, 1 列)组成，其中N可以是任意大小。 | 两艘战舰之间至少有一个水平或垂直的空位分隔 - 即没有相邻的战舰。 类似题目：岛屿数量 | . &gt; Solution: 图，图的搜索，DFS，BFS搜索算法 此题为在二维数组中寻找特殊条件的连通图（所有顶点都联通）的个数； 重点： 在一个无向图中找特殊条件的连通图 一次扫描整个二维数组，且使用静态变量存储返回值： # Python count = 0 for i in range(len(board)): for j in range(len(board[0])): if board[i][j] == \"X\": if (i &gt; 0 and board[i - 1][j] == \"X\") or (j &gt; 0 and board[i][j - 1] == \"X\"): continue count += 1 return count &gt; T: O(m*n) S: O(1) . | 水壶问题 | . 有两个容量分别为 x升 和 y升 的水壶以及无限多的水。请判断能否通过使用这两个水壶，从而可以得到恰好 z升 的水？ . 如果可以，最后请用以上水壶中的一或两个来盛放取得的 z升 水。 . 你允许： . | 装满任意一个水壶 | 清空任意一个水壶 | 从一个水壶向另外一个水壶倒水，直到装满或者倒空 | . &gt; Solution: 数学问题， 类似3加仑和4加仑的桶到处5加仑水的问题： 数学问题 裴蜀定理 任意两个正整数a，b的公约数d，有xa+yb = d的倍数，也就是此题中结果想要得到的水的容量需要满足他是两个水壶容量的公约数的倍数； # python def _gcd(x, y): if y == 0: return x z = x % y return _gcd(y, z) if (x == y != z and z!= 0) or (z &gt; x + y): return False if z == 0 or z % _gcd(x, y) == 0: return True &gt; T: S: . | 最长上升子序列 给定一个无序的整数数组，找到其中最长上升子序列的长度。 | . 示例: . 输入: [10,9,2,5,3,7,101,18] 输出: 4 解释: 最长的上升子序列是 [2,3,7,101]，它的长度是 4。 说明: . 可能会有多种最长上升子序列的组合，你只需要输出对应的长度即可。 你算法的时间复杂度应该为 O(n2) 。 将算法的时间复杂度降低到 O(n log n) . &gt; Solution: n log n表示什么：首先logn的算法涉及到二分法，例如二分查找和二分搜索 解法： 使用dp，dynamic programming，动态规划的基本步骤是 1.定义当前动态需求的状态并建立状态方程 2.状态方程的建立需要考虑所有穷举的可能性 3. 考虑状态随变量变化的转移情况，建立状态转移方程； 解法1: 使用动态规划： 1. 状态定义： dp[i] 表示到索引i为止的最长升序序列的长度值 2. 状态转移：转移条件：序列索引上升，这时候需要考虑此索引前面每一个状态长度和当前值的关系得到最佳结果，如：比较当前值和该索引i前的每一个值的大小，如果出现大于前面索引值dp[j]的情况需要考虑在当前值和dp[j] + 1 中获取最大值，即表示最长升序 解法2 动态规划 + 二分查找 1. 对解法1中的状态定义换一个角度，解法1中的状态定义的长度为dp[i]的值，这里的状态定义将换成保存到i为止的升序（严格来说不是i-1处的真正的升序序列）序列，而1中的dp值就是现在的dp序列的长度；这样就可以在此dp序列上进行目标元素的替换从而不影响上一个序列的长度； 例如：2， 3， 4， 7， 10， 11， 6， 8， 9 ，10 i = 5， dp = 2，3，4，7，10，11 i = 6， dp = 2，3，4，6，10，11 这里状态的转移是将7替换成了6从而能够在目标序列中继续找升序序列，但是并没有影响当前找到的最大升序序列的长度，最终如果找到了新最小值（7被6替换表示，6替换了dp中第一个大于它自身的数字）从而得到了一个更长的序列例如找到最大数后append操作，最终新的长度也覆盖了上一次最长上升长度，而替换和append操作则可以使用二分查找的方式来实现； 这里的难点在于： dp数组会对当前最长的长度进行保留并且也会在每个索引的位置上讲后续升序的潜在可能性提高到最高，比如大于6的正整数比大于7的正整数多； 重点： dp数组，1. 保存了到当前索引的最大升序长度 2. 保存了当前索引前替换发生前的dp状态和替换后的双重状态； 2， 3， 4， 7， 10， 12， 6， 8， 9 ，11 1， 2， 3， 4， 5， 6， 4， 5， 6， 7 解法1中的dp状态 解法2中 2， 3， 4， 7， 10， 12 -》 2， 3， 4， 6， 10， 12 将7替换为6表示： 1. 等于解法1中7和7前面的长度还有参考价值，但是7本身没有参考价值，6处长度的更新（更新为4）就等于解法2中的替换； 2. 替换等效于解法1中的状态随着索引的不断转移，即使已经有大于自己的最长升序依然还在计算升序值，因为越小的值后面出现大于它的值的数量的概率越高； # python # DP + BS # dynamic programming + binary search dp = [] for v in nums: if not dp or v &gt; dp[-1]: dp.append(v) continue i, j = 0, len(dp) # 二分查找找到第一个最大的，也就是大小最接近v而且大于v的数 while i &lt; j: m = (i + j) // 2 # // 表示对商向下取整 if dp[m] &lt; v: i = m + 1 else: j = m #既保留前者状态又更新最新状态的替换 dp[i] = v return len(dp) &gt; T: S: . | 缺失数字 . 给定一个包含 0, 1, 2, …, n 中 n 个数的序列，找出 0 .. n 中没有出现在序列中的那个数。 . | . &gt; Solution: 位运算，位运算中相同数字经过^异或运算后得到0，所以对整个序列好正常序列经过异或后的到的就是： 缺失值^目标序列最大值 而目标序列最大值正好就是目标序列的长度 傻瓜式解法： 1. 先排序然后在遍历，最差时间复杂度为 nlogn + n 所以就是nlogn 2. 使用一个哈希表，将检查出来的数字存储到哈希表中，因为哈希表的查询时间复杂度为1，所以最终结果的时间复杂度为n # python 位运算 def missingNumber(self, nums): \"\"\" :type nums: List[int] :rtype: int \"\"\" # 位运算 # 异或，两个相同的数异或得到的结果为0 miss_n = len(nums) for i in range(len(nums)): miss_n ^= i ^ nums[i] return miss_n &gt; T: O(n) S: O(1) 一个常量存储缺失值的异或结果 . | 二叉树的序列化与反序列化 | . 序列化是将一个数据结构或者对象转换为连续的比特位的操作，进而可以将转换后的数据存储在一个文件或者内存中，同时也可以通过网络传输到另一个计算机环境，采取相反方式重构得到原数据。 . 请设计一个算法来实现二叉树的序列化与反序列化。这里不限定你的序列 / 反序列化算法执行逻辑，你只需要保证一个二叉树可以被序列化为一个字符串并且将这个字符串反序列化为原始的树结构。 . 示例: . 你可以将以下二叉树： 1 / \\ 2 3 / \\ 4 5 序列化为 \"[1,2,3,null,null,4,5]\" . &gt; Solution: # python class Codec: # 对二叉树使用深度优先遍历 # 二叉树的DFS BFS # BFS: # queue_l = [] # queue_l.append(root) # while queue_l: # node = queue_l.pop(0) # if node.right: # queue_l.append(node.right) # if node.left: # queue_l.append(node.left) # if not queue_l: # return node.val # 深度遍历 # 不使用静态变量 使用递归 def serialize(self, root): \"\"\"Encodes a tree to a single string. :type root: TreeNode :rtype: str \"\"\" def recursive_serializer(node, string): if node is None: string += \"None,\" else: string += str(node.val) + \",\" string = recursive_serializer(node.left, string) string = recursive_serializer(node.right, string) return string return recursive_serializer(root, '') # 反序列化，将数组转化成二叉树 # 使用了递归实现了序列化，侧同理反序列化也使用递归 def deserialize(self, data): \"\"\"Decodes your encoded data to tree. :type data: str :rtype: TreeNode \"\"\" def recursive_serializer(data): if data[0] == \"None\": data.pop(0) return None node = TreeNode(data[0]) data.pop(0) node.left = recursive_serializer(data) node.right = recursive_serializer(data) return node return recursive_serializer(data.split(',')) &gt; T: S: . | 整数转换英文表示 | . 将非负整数转换为其对应的英文表示。可以保证给定输入小于 231 - 1 。 . 示例 1: . 输入: 123 输出: \"One Hundred Twenty Three\" . 示例 2: . 输入: 12345 输出: \"Twelve Thousand Three Hundred Forty Five\" . 示例 3: . 输入: 1234567 输出: \"One Million Two Hundred Thirty Four Thousand Five Hundred Sixty Seven\" . 示例 4: . 输入: 1234567891 输出: \"One Billion Two Hundred Thirty Four Million Five Hundred Sixty Seven Thousand Eight Hundred Ninety One\" . &gt; Solution: 分治 所有数字的英文表示： 1- 10 1: 'One', 2: 'Two', 3: 'Three', 4: 'Four', 5: 'Five', 6: 'Six', 7: 'Seven', 8: 'Eight', 9: 'Nine' 10 - 20 10: 'Ten', 11: 'Eleven', 12: 'Twelve', 13: 'Thirteen', 14: 'Fourteen', 15: 'Fifteen', 16: 'Sixteen', 17: 'Seventeen', 18: 'Eighteen', 19: 'Nineteen' 20 - 90 2: 'Twenty', 3: 'Thirty', 4: 'Forty', 5: 'Fifty', 6: 'Sixty', 7: 'Seventy', 8: 'Eighty', 9: 'Ninety' billion = 1，000，000，000 million = 1，000，000 thousand = 1，000 # python 实现，使用分而治之的方式，将数字按照英制的阿拉伯数字的划分方式，将其划分成每3个一组的方式在进一步划分； 分治具体的方法实现； 1. 每三位分出当前总数，题目要求是小于2**31 -1 = 1024 * 1024 * 1024 -1 所以可以确定需要转换的数在百万以内，确定数字的 bilion million thousand 2. 将每个3位的单位数前面的数字转换成因为，有三种转换方式第一10以内，第二100以内，第三999以内，并且不重复； 3. 将三种方法的函数实现并将进位的函数实现，题目就可以解出； class Solution: def numberToWords(self, num): \"\"\" :type num: int :rtype: str \"\"\" def one(num): switcher = { 1: 'One', 2: 'Two', 3: 'Three', 4: 'Four', 5: 'Five', 6: 'Six', 7: 'Seven', 8: 'Eight', 9: 'Nine' } return switcher.get(num) def two_less_20(num): switcher = { 10: 'Ten', 11: 'Eleven', 12: 'Twelve', 13: 'Thirteen', 14: 'Fourteen', 15: 'Fifteen', 16: 'Sixteen', 17: 'Seventeen', 18: 'Eighteen', 19: 'Nineteen' } return switcher.get(num) def ten(num): switcher = { 2: 'Twenty', 3: 'Thirty', 4: 'Forty', 5: 'Fifty', 6: 'Sixty', 7: 'Seventy', 8: 'Eighty', 9: 'Ninety' } return switcher.get(num) # 返回小于20的数字的英文表示 def two(num): if not num: return '' elif num &lt; 10: return one(num) elif num &lt; 20: return two_less_20(num) else: tenner = num // 10 rest = num - tenner * 10 return ten(tenner) + ' ' + one(rest) if rest else ten(tenner) # 返回小于999的数字的英文表示，需要使用到hundred def three(num): hundred = num // 100 rest = num - hundred * 100 if hundred and rest: return one(hundred) + ' Hundred ' + two(rest) elif not hundred and rest: return two(rest) elif hundred and not rest: return one(hundred) + ' Hundred' # 按照进位划分当前的数字 billion = num // 1000000000 million = (num - billion * 1000000000) // 1000000 thousand = (num - billion * 1000000000 - million * 1000000) // 1000 rest = num - billion * 1000000000 - million * 1000000 - thousand * 1000 if not num: return 'Zero' result = '' if billion: result = three(billion) + ' Billion' if million: result += ' ' if result else '' result += three(million) + ' Million' if thousand: result += ' ' if result else '' result += three(thousand) + ' Thousand' if rest: result += ' ' if result else '' result += three(rest) return result &gt; T: S: . | 各位相加 | . &gt; Solution: 数学问题，只需要在草纸上进行退到即可得到答案 10x + y = z x + y = z - 9x a + b + c = z - (99a + 9b) = z - 9(11a + b) e + f = z - 9(11a + b) - 9e = z - 9(11a + b + e) 由此可见，因为十进制总是9 + 1才进位，所以各位相加就是对9取余数； 但是由于9的倍数对9取余数为0，但是更具题目条件，所以需要返回9； # python class Solution(object): def addDigits(self, num): \"\"\" :type num: int :rtype: int \"\"\" if num == 0: return 0 return num % 9 if num % 9 &gt; 0 else 9 &gt; T: O(1) S: O(1) . | 除自身以外数组的乘积 | . 给定长度为 n 的整数数组 nums，其中 n &gt; 1，返回输出数组 output ，其中 output[i] 等于 nums 中除 nums[i] 之外其余各元素的乘积。 . 示例: . 输入: [1,2,3,4] 输出: [24,12,8,6] . 说明: 请不要使用除法，且在 O(n) 时间复杂度内完成此题。 . 进阶： 你可以在常数空间复杂度内完成这个题目吗？（ 出于对空间复杂度分析的目的，输出数组不被视为额外空间。） . &gt; Solution: 逻辑思维 数学 此题的解决方法需要考虑 1. 只能使用相乘 2. 需要在线性的时间和空间内解决 3. 要考虑遇到0的情况; 考虑： a1, a2, a3, a4 1, 1*a1, 1*a1*a2, 1*a1*a2*a3 a1, a2, a3, a4 a4*1*a3*a1, a4*1*a3 a4*1, 1 由于数组是线性结构，从两端同时分别遍历，最终的即可得到答案； # python # a1, a2, a3, a4 # 1, 1*a1, 1*a1*a2, 1*a1*a2*a3 # a1, a2, a3, a4 # a4*1*a3*a1, a4*1*a3, a4*1, 1 # 由于数组是线性结构，从两端同时分别遍历，最终的即可得到答案； l = len(nums) i = 0 j = l - 1 result = [1]*l while i != l -1: result[i+1] = result[i] * nums[i] i += 1 p = 1 while j != 0: p = nums[j] * p result[j -1] *= p j -= 1 return result &gt; T: S: . | 删除链表中的节点 | . &gt; Solution: t = node.next node.val = t.val node.next = t.next t = None &gt; T: S: . | 二叉树的最近公共祖先 | . &gt; Solution: 递归，回溯 解法： 1. 对二叉树进行深度优先遍历并将每一个非叶子节点添加到缓存栈中 2. 当找到第一个匹配后，立即停止再向缓存栈中添加节点，因为此时的答案已经在栈中了 3. 递归回溯，将没有匹配的节点从缓存栈中移除 4. 找到第二个匹配项后，返回栈顶节点 @@ 需要考虑跟节点就是匹配节点的情况，需要考虑叶子节点的情况，需要考虑匹配节点本身就是答案的情况； # Python class Solution(object): def lowestCommonAncestor(self, root, p, q): \"\"\" :type root: TreeNode :type p: TreeNode :type q: TreeNode :rtype: TreeNode \"\"\" # BFS - Breadth first search while loop # DFS - depth first search recursive # recursive tree # a # b z # c f # d e stack = [] find = [] # 返回根结点 if root == q or root == p: return root def depth_search(node, p, q): if node.val == p.val or node.val == q.val: # 找到第二个元素返回True，这时候整个递归都会返回，并且不再修改结果 if find: return True # 找到第一个元素后在find数组中标记 # 并且将第一个找到的元素也考虑在可能的答案根结点上 find.append(True) stack.append(node) # 考虑末尾节点，当节点为叶子节点时，直接对该节点返回False # 如果当前匹配第一次的节点就是叶子节点，需要将该节点移除缓存栈 if node.left == None and node.right == None: if stack[-1] == node: stack.pop(-1) return False # 没有匹配的情况下，需要将每个非叶子节点加入缓存栈 if not find: stack.append(node) # 对左右子树递归 if node.left: if depth_search(node.left, p, q): return True if node.right: if depth_search(node.right, p ,q): return True # 如果没有一次匹配则回溯到本节点后从缓存栈移除 # 如果当前节点就是缓存栈顶部节点，则移除，因为上面的左右子树递归没有找到第二个匹配项 if not find or stack[-1] == node: stack.pop(-1) depth_search(root, p, q) return stack[-1] &gt; T: N S: N/2 . | 二叉搜索树的最近公共祖先 | . &gt; Solution: 二叉树，完全二叉树，满二叉树、二叉搜索树（二叉查找树） # 对于找到二搜索树的最近祖先，只需要考虑大于、小于、等于、包含跟节点四种情况即可，大于和小于需要更新跟节点 # python class Solution(object): def lowestCommonAncestor(self, root, p, q): \"\"\" :type root: TreeNode :type p: TreeNode :type q: TreeNode :rtype: TreeNode \"\"\" while root: if p.val == root.val or q.val == root.val: return root elif p.val &lt; root.val &lt; q.val or q.val &lt; root.val &lt; p.val: return root elif p.val &lt; root.val and q.val &lt; root.val: root = root.left elif p.val &gt; root.val and q.val &gt; root.val: root = root.right else: pass &gt; T: 1 S: 1 . TODO: read and understand the meaning . | 标签验证器 栈 ``` Solution: html 代码验证工具，对于这样的特殊匹配的题目，需要注意栈和队列的使用 解法： . | 遍历整段代码，将遇到的html标签放入栈中，如果遇到结束标签就可以对比栈定的开始标签元素； | 对于开始字符”&lt;”，如果后面接的是！则为cdata的开始，如果不是那一定是一个开始标签或者结束标签 | 对入栈和出栈的元素的对比的同时需要检查tag_name的合法性； | 结束时，检查栈是否为空，代码必须在栈不为空的时候出现，因为代码必须在标签的包裹中，最后一个标签之后不能有其他代码；以上条件都符合则就视为True | . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python-%E4%BD%BF%E7%94%A8%E9%98%9F%E5%88%97%E4%BB%8E%E5%8F%B3%E5%BE%80%E5%B7%A6%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E9%81%8D%E5%8E%86%E4%BD%BF%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E9%81%8D%E5%8E%86%E5%B9%B6%E6%9A%82%E5%AD%98%E9%95%BF%E5%BA%A6",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#python-使用队列从右往左广度优先遍历使用栈实现深度优先遍历并暂存长度"
  },"70": {
    "doc": "Algorithm Everything",
    "title": "java",
    "content": "public class Solution { Stack &lt; String &gt; stack = new Stack &lt; &gt; (); boolean contains_tag = false; public boolean isValidTagName(String s, boolean ending) { if (s.length() &lt; 1 || s.length() &gt; 9) return false; for (int i = 0; i &lt; s.length(); i++) { if (!Character.isUpperCase(s.charAt(i))) return false; } if (ending) { if (!stack.isEmpty() &amp;&amp; stack.peek().equals(s)) stack.pop(); else return false; } else { contains_tag = true; stack.push(s); } return true; } public boolean isValidCdata(String s) { return s.indexOf(“[CDATA[”) == 0; } public boolean isValid(String code) { if (code.charAt(0) != ‘&lt;’ || code.charAt(code.length() - 1) != ‘&gt;’) return false; for (int i = 0; i &lt; code.length(); i++) { boolean ending = false; int closeindex; if(stack.isEmpty() &amp;&amp; contains_tag) return false; if (code.charAt(i) == ‘&lt;’) { if (!stack.isEmpty() &amp;&amp; code.charAt(i + 1) == ‘!’) { closeindex = code.indexOf(“]]&gt;”, i + 1); if (closeindex &lt; 0 || !isValidCdata(code.substring(i + 2, closeindex))) return false; } else { if (code.charAt(i + 1) == ‘/’) { i++; ending = true; } closeindex = code.indexOf(‘&gt;’, i + 1); if (closeindex &lt; 0 || !isValidTagName(code.substring(i + 1, closeindex), ending)) return false; } i = closeindex; } } return stack.isEmpty() &amp;&amp; contains_tag; } } . T: N S: N ``` . | 用栈实现队列 ``` Solution: Queue, Stack 一进一出两个栈实现队列，栈和队列的基础知识 . | . Stack: push to top, peek/pop from top, size,is empty Queue: push, pop, peek, empty . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#java",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#java"
  },"71": {
    "doc": "Algorithm Everything",
    "title": "[232] 用栈实现队列",
    "content": "# . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#232-%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#232-用栈实现队列"
  },"72": {
    "doc": "Algorithm Everything",
    "title": "@lc code=start",
    "content": "class MyQueue(object): . # stack # bottom [x, x, x, x] top # queue # top [x, x, x, x] bottom def __init__(self): \"\"\" Initialize your data structure here. \"\"\" self.stack_in = [] self.stack_out = [] def push(self, x): \"\"\" Push element x to the back of queue. :type x: int :rtype: None \"\"\" self.stack_in.append(x) print \"IN %s\" % self.stack_in print \"OUT %s\" % self.stack_out def pop(self): \"\"\" Removes the element from in front of queue and returns that element. :rtype: int \"\"\" while self.stack_in: self.stack_out.append(self.stack_in.pop(-1)) result = self.stack_out.pop(-1) while self.stack_out: self.stack_in.append(self.stack_out.pop(-1)) print \"IN %s\" % self.stack_in print \"OUT %s\" % self.stack_out return result def peek(self): \"\"\" Get the front element. :rtype: int \"\"\" while self.stack_in: self.stack_out.append(self.stack_in.pop(-1)) result = self.stack_out[-1] while self.stack_out: self.stack_in.append(self.stack_out.pop(-1)) print \"IN %s\" % self.stack_in print \"OUT %s\" % self.stack_out return result def empty(self): \"\"\" Returns whether the queue is empty. :rtype: bool \"\"\" print \"IN %s\" % self.stack_in print \"OUT %s\" % self.stack_out if len(self.stack_in) &gt; 0: return False else: return True . T: S: ``` . | 旋转图像 | . TODO . 给定 matrix = [ [1,2,3], [4,5,6], [7,8,9] ], . &gt; Solution: 90度顺时针旋转矩阵，不能使用另外的空间，原地进行计算 解法： 1. 转置矩阵，然后左右翻转 2. 矩型转动； 1 2 3 4 5 6 7 8 9 # 方法2的python实现 # @lc code=start quanshu &gt; T: N**2 S: . | 最大子序和 TODO 分治法 | . &gt; Solution: 本题是分治算法的典型例子 # 贪心算法也可以求解，局部最优解，需要两个变量1存储当前窗口移动到的位置的最大值，第二个存储到当前节点为止的最大值； -2 1 -3 索引为2: 当前点最大值 1-3 到该点为止最大值 1 # 贪心 # 滑动窗口 # 分治 window = 0 result_max = - sys.maxint -1 for v in nums: window += v window = max(window, v) result_max = max(window, result_max) return result_max # 动态规划也可以求解 Kadane 算法 有两种标准 DP 方法适用于数组： 常数空间，沿数组移动并在原数组修改。 线性空间，首先沿 left-&gt;right 方向移动，然后再沿 right-&gt;left 方向移动。 合并结果。 1. 原地修改 2. 左右滑动窗口合并结果 使用原地修改，参考贪心算法，就是将当前窗口的最大值放在数组内，并且可以直接使用； 动态规划： 1. 定义状态，建立基本的状态 2. 更具变量的变化，建立状态转移方程 3. 根据状态转移方程求解 标准动态规划的代码如下： class Solution { // 动态规划 public int maxSubArray(int[] nums) { if (nums == null || nums.length == 0) return 0; int ans = 0; // 1. 状态定义 // dp[i] 表示前 i 个元素的最大连续子数组的和 int[] dp = new int[nums.length]; // 2. 状态初始化，数组中第一个元素的最大和就是第一个元素值 dp[0] = nums[0]; ans = nums[0]; // 3. 状态转移 // 转移方程：dp[i] = max(dp[i - 1], 0) + nums[i] // dp 当前元素的值等于前一个元素值和 0 的最大值再加上 nums[i] for (int i = 1; i &lt; nums.length; i++) { dp[i] = Math.max(dp[i - 1], 0) + nums[i]; // 更新最大和 ans = Math.max(ans, dp[i]); } return ans; } } 以上代码的时间复杂度是 O(N)，空间复杂度也是 O(N)，实际上我们可以降低空间复杂度到 O(1)。 从上面的状态转移方程 dp[i] = max(dp[i - 1], 0) + nums[i] 看出，当前的状态的值只取决于前一个状态值，所以我们可以使用一个变量来代替 dp[i] 和 dp[i - 1]，如下代码： class Solution { // 动态规划 public int maxSubArray(int[] nums) { if (nums == null || nums.length == 0) return 0; int ans = 0; // 使用 currSum 代替 dp[i] int currSum = nums[0]; ans = nums[0]; for (int i = 1; i &lt; nums.length; i++) { currSum = Math.max(currSum, 0) + nums[i]; // 更新最大和 ans = Math.max(ans, currSum); } return ans; } } 以上代码的时间复杂度是 O(N)，空间复杂度也是 O(1) &gt; T: N S: 1 . | 螺旋矩阵 | . &gt; Solution: # python # 模拟旋转 # TODO result = [] while matrix: if not result: result = matrix.pop(0) else: result.extend(matrix.pop(0)) if not matrix: return result for s in range(len(matrix)): result.append(matrix[s][-1]) matrix[s].pop(-1) for _ in range(len(matrix[-1])): result.append(matrix[-1][-1]) matrix[-1].pop(-1) while matrix and not matrix[-1]: matrix.pop(-1) for j in range(len(matrix)): result.append(matrix[len(matrix) - 1 - j][0]) matrix[len(matrix) - 1 - j].pop(0) while matrix and not matrix[-1]: matrix.pop(-1) return result &gt; T: S: . | 跳跃游戏 TODO | . &gt; Solution: 解法： 反向思考，只要前面的任意一个点能到达终点，则这个点就是终点，继续向前寻找能到达终点的点，知道最终找完整个数组，如果此时终点在起点上，则返回True； # 动态规划，自底向上，自顶向下 # 贪心 # python # @lc code=start class Solution(object): def canJump(self, nums): \"\"\" :type nums: List[int] :rtype: bool \"\"\" # l = len(nums) # if l == 1: # return True # for i in range(0, l): # if i != l - 1 and nums[i] == 0: # return False # i = i + nums[i] # if i == l - 1: # return True # if i &gt; l -1: # return False # 题目中指出数组中的元素代表能跳跃的最大长度 最大 最大 最大 # 动态规划，自底向上，自顶向下 # 贪心 l = len(nums) position = l - 1 if l == 1: return True for i in range(1, l): j = l - 1 - i if j + nums[j] &gt;= position: position = j if position == 0: return True else: return False &gt; T: S: . | 合并区间 | . 箭射气球 . &gt; Solution: # python if not intervals: return [] intervals.sort(key=lambda x: x[0]) result = [] tmp = intervals[0] for v in intervals: if tmp[0] &lt;= v[0] &lt;= tmp[1]: tmp[1] = max(tmp[1], v[1]) else: result.append(tmp) tmp = v result.append(tmp) return result # 先排序在合并区间，此题目类似箭射气球 &gt; T: S: . | 最长回文子串 TODO： 终极方法为Manacher 算法时间复杂度为 O(n) Manacher 算法 Solution: 中心扩展发，回文子串是 aba 或者 bb 这样正反都相同的字符串，所以从找到这些的两种情况从中心向外扩展，直到中不再有相同元素为止，这样算法的最差时间复杂度就是N**2 T: S: ```python # A: find the same from start to end as start of iterable result = {} . for i in range(len(s)): r = \"\" k = 0 j = 0 if i + 1 &gt;= len(s): continue if s[i] == s[i+1]: j = i k = i + 1 while j &gt;= 0 and k &lt; len(s) and s[j] == s[k]: r = s[j] + r r += s[k] j -= 1 k += 1 if r: result.update({len(r): r}) if i - 1 &gt;= 0 and i + 1 &lt; len(s) and s[i-1] == s[i+1]: r = s[i] j = i - 1 k = i + 1 while j &gt;= 0 and k &lt; len(s) and s[j] == s[k]: r = s[j] + r r += s[k] j -= 1 k += 1 if r: result.update({len(r): r}) print result if result: return result[max(result.keys())] elif s: return s[0] else: return \"\" ``` . | 字符串转换整数 (atoi) | . Solution: 两种解法，第一直接根据条件做一次遍历得到答案，且需要考虑特殊情况； 第二可以考虑使用正则表达式进行匹配获取答案 . T: N S: 1 ```python # Anylize # special: return 0 # int32 # . string = string.strip() if not string: return 0 l = [str(i) for i in xrange(10)] o = [\"-\", \"+\"] result = \"\" for v in string: if v in o and not result: result += v elif v in l: result += v elif not result: return 0 else: break if result == \"+\" or result == \"-\": return 0 if not (-2 **31 &lt;= int(result) &lt;= 2**31 -1): if int(result) &lt; 0: return -2 ** 31 else: return 2 ** 31 -1 return int(result) . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#lc-codestart",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#lc-codestart"
  },"73": {
    "doc": "Algorithm Everything",
    "title": "regular expresion",
    "content": "class Solution: def myAtoi(self, s: str) -&gt; int: return max(min(int(*re.findall(‘^[+-]?\\d+’, s.lstrip())), 231 - 1), -231) . 35. [罗马数字转整数](https://leetcode-cn.com/problems/roman-to-integer/description/) &gt; Solution: &gt; T: S: ```python # Anylize: # 1. put cha and number into dict # 2. for the s and handle special case and get number result = [] r_d = { \"I\" : 1, \"V\" : 5, \"X\" : 10, \"L\" : 50, \"C\" : 100, \"D\" : 500, \"M\" : 1000, } for i in s: m = 0 if i in [\"V\", \"X\"] and result and result[len(result) - 1] == 1: m = 1 elif i in [\"L\", \"C\"] and result and result[len(result) - 1] == 10: m = 10 elif i in [\"D\", \"M\"] and result and result[len(result) - 1] == 100: m = 100 else: pass if m != 0: result = result[:len(result) -1] v = r_d[i] - m result.append(v) sum = 0 if not result: return 0 else: for v in result: sum += int(v) return sum . | 三数之和 | . Solution: 排序后，选定一个负值，使用双指针从选定值的后一个值和末尾元素开始，如果三数之和小于0则表示末尾值太大需要前移，同理大于0指针后移，最终将两个指针相遇前的所以满足结果保存在列表里； T: N**2 S: 1 ```python . # sort and 2 points result = [] nums.sort() #nlog(n) k = 0 while nums and len(nums) &gt; 2 and nums[k] &lt;= 0 and k &lt; len(nums) -1: # n if nums[k] &gt; 0: break # 最外层循环只遍历小于等于0的值，如果遇到大于0的值直接跳出 # # 遇到重复直接前移一个元素，去除重复答案 if k != 0 and nums[k] == nums[k-1]: k+=1; continue i = k + 1 j = len(nums) -1 # 循环n次 while i &lt; j: s = nums[i] + nums[k] + nums[j] if s &lt; 0: i += 1 while i &lt;j and nums[i] == nums[i - 1]: i += 1 # 去重 elif s &gt; 0: j -= 1 while i &lt; j and nums[j] == nums[j + 1]: j -= 1 # 去重 else: t = [nums[i], nums[k], nums[j]] result.append(t) i += 1 j -= 1 while i &lt; j and nums[i] == nums[i - 1]: i += 1 while i &lt; j and nums[j] == nums[j + 1]: j -= 1 k += 1 return result # T: nlog(n) + n**2 == n**2 ``` . | 有效的括号 | . Solution: T: S: ```python . 38. [合并两个有序链表](https://leetcode-cn.com/problems/merge-two-sorted-lists/description/) &gt; Solution: &gt; T: S: ```python . | 合并K个排序链表 | . Solution: T: S: ```python . 40. [两两交换链表中的节点](https://leetcode-cn.com/problems/swap-nodes-in-pairs/description/) &gt; Solution: &gt; T: S: ```python . | K 个一组翻转链表 | . Solution: T: S: ```python . 42. [删除排序数组中的重复项](https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array/description/) &gt; Solution: &gt; T: S: ```python . | 实现 strStr() | . Solution: T: S: ```python . 44. [搜索旋转排序数组](https://leetcode-cn.com/problems/search-in-rotated-sorted-array/description/) &gt; Solution: &gt; T: S: ```python . | 全排列 | . Solution: T: S: ```python . 46. [全排列 II](https://leetcode-cn.com/problems/permutations-ii/description/) &gt; Solution: &gt; T: S: ```python . | ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#regular-expresion",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#regular-expresion"
  },"74": {
    "doc": "Algorithm Everything",
    "title": "简化路径",
    "content": "| . Solution: 切忌切忌切忌 不能一上来就按照条件开始coding 在使用split和栈做存储的情况下，本题的效率和代码数量提高了一个量级，遇到这样的字符串分割的问题千万不能一个字符一个字符去过 T: N S: N ```python # ❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌ # path = list(path) # slash = [0] if path[0] == “/” else [] # i = 0 # while i &lt; len(path): # # 遇到//不处理 # i += 1 # if not (i +1 &lt; len(path)): break # if (path[i] == path[i-1] == “/”): # path.pop(i) # i -= 1 # continue # elif path[i] == “/” and path[i-1] != “/”: # slash.append(i) # continue # if path[i] == “.” and path[i + 1] == “.”: # if i + 2 &lt; len(path): # if len(slash) &lt; 2: # path = path[i + 2:] # i = 0 # else: # path = path[:slash[-2]] + path[i + 2:] # i = slash[-2] # slash.pop(-1) # elif i + 2 == len(path): # if len(slash) &lt; 2: # path = path[:i] # else: # path = path[:slash[-2]] + path[i + 2:] # elif path[i] == “.” and path[i + 1] != “.”: # path.pop(i) # path.pop(i) # i -= 1 # while path[-1] == “.”: path.pop(-1) # while len(path) &gt; 1 and path[-1] == “/”: path.pop(-1) # return ““.join(path) # ❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌❌TRASH . #解决方案： 栈 split(\"/\") # 遇到这样的字符过滤的问题，一定要想到栈 stack = [] l = path.split(\"/\") for v in l: # case if not v: pass elif v == \".\": pass elif v == '..': if stack: stack.pop(-1) else: stack.append(v) return \"/\" + \"/\".join(stack) ``` . | 矩阵置零 | . Solution: 此题目的关键在于如何记录是那些行那些列需要全部置0，所有使用m+n的空间记录所有需要置0的行列，更加简单的方式是直接在第一行第一列记录 m n 所有要置0的行列，对第一行第一列只需要在最开始用两个常数或者布尔值记录是否含有0就可以 T: m*n S: 1 ```python # 常数空间 # 以第一行第一列为标记点，先判断第一行第一列的情况，记录0的数量 # 将其他数据中的0放在第一行第一列相应位置 # 修改全部数据 # 1 0 0 0 # 0 1 0 1 # 1 1 1 1 # 0 1 1 0 . f_row = False f_column = False if 0 in matrix[0]: f_row = True for i in range(len(matrix)): if matrix[i][0] == 0: f_column = True for m in range(1, len(matrix)): for n in range(1, len(matrix[0])): if matrix[m][n] == 0: matrix[0][n] = 0 matrix[m][0] = 0 for x in range(1, len(matrix)): if matrix[x][0] == 0: for t in range(1, len(matrix[x])): matrix[x][t] = 0 for y in range(1, len(matrix[0])): if matrix[0][y] == 0: for t in range(1, len(matrix)): matrix[t][y] = 0 if f_row: for t in range(0, len(matrix[0])): matrix[0][t] = 0 if f_column: for t in range(0, len(matrix)): matrix[t][0] = 0 return matrix ``` . | 颜色分类 | . 本问题被称为 荷兰国旗问题 . Solution: 不要使用insert和pop的方式，特殊情况难以处理； T: S: ```python # 因为是线性数组，一次遍历使用双指针最为高效 # 因为该题目为三中类型的元素 # 所以需要双指针来跟踪边缘 # 增加一个循环指针 . p = 0 edge_l = 0 edge_r = len(nums) - 1 while p &lt;= edge_r: if nums[p] == 0: #左边缘右移 nums[p], nums[edge_l] = nums[edge_l], nums[p] edge_l += 1 p += 1 elif nums[p] == 2: #和右边缘护环 nums[p], nums[edge_r] = nums[edge_r], nums[p] edge_r -= 1 elif nums[p] == 1: p += 1 return nums # 使用insert和pop方式 if (1 not in nums and 2 not in nums) or (1 not in nums and 0 not in nums) or (0 not in nums and 2 not in nums): return nums i = 0 count = 0 while i &lt; len(nums) and len(nums) &gt; 1: if nums[i] == 0: nums.insert(0, 0) nums.pop(i + 1) i += 1 if count: count = 0 elif nums[i] == 2: if count &gt;= len(nums) - i: break nums.append(2) nums.pop(i) count += 1 else: i += 1 if count: count = 0 return nums ``` . | 单词搜索 TODO Solution: 在一个二维数组中找到一个单词，与前一个字母上下左右相邻的都可以做下一个元素；上下左右，只能是从这四个里面找下一个元素； . 解法：类似图的深度优先遍历，一次找到和单词中第一个字母相同的字母，从第一个开始就开始用“递归”遍历，当未找到某个字母的时候，回溯在前一个字母，直到回溯回第一个字母还是没有找到结果，就开始对第二个找到的字母做同样的递归，递归需要注意：边界条件和return点，return决定了回溯的情况；对于已经找到的结果可以存储在栈中，python使用list来模拟栈； . T: M*N S: . board = [ ['A','B','C','E'], ['S','F','C','S'], ['A','D','E','E'] ] 给定 word = \"ABCCED\", 返回 true. 给定 word = \"SEE\", 返回 true. 给定 word = \"ABCB\", 返回 false. ```python class Solution(object): . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E7%AE%80%E5%8C%96%E8%B7%AF%E5%BE%84",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#简化路径"
  },"75": {
    "doc": "Algorithm Everything",
    "title": "定义上下左右四个行走方向",
    "content": "directs = [(0, 1), (0, -1), (1, 0), (-1, 0)] . def exist(self, board, word): “”” :type board: List[List[str]] :type word: str :rtype: bool “”” m = len(board) if m == 0: return False n = len(board[0]) mark = [[0 for _ in range(n)] for _ in range(m)] . for i in range(len(board)): for j in range(len(board[0])): if board[i][j] == word[0]: # 将该元素标记为已使用 mark[i][j] = 1 if self.backtrack(i, j, mark, board, word[1:]) == True: return True else: # 回溯 mark[i][j] = 0 return False . def backtrack(self, i, j, mark, board, word): if len(word) == 0: return True . for direct in self.directs: cur_i = i + direct[0] cur_j = j + direct[1] if cur_i &gt;= 0 and cur_i &lt; len(board) and cur_j &gt;= 0 and cur_j &lt; len(board[0]) and board[cur_i][cur_j] == word[0]: # 如果是已经使用过的元素，忽略 if mark[cur_i][cur_j] == 1: continue # 将该元素标记为已使用 mark[cur_i][cur_j] = 1 if self.backtrack(cur_i, cur_j, mark, board, word[1:]) == True: return True else: # 回溯 mark[cur_i][cur_j] = 0 return False ``` . | 解码方法 | . Solution: 本题的求解方式是动态规划，题目中没有明确指出对于0的处理情况， 所以需要考虑0值的处理问题，尤其是不符合规则出现的0； . 动态规划： . | dp保存到点i为止出现的所有可能之和 | 通过21～26和11～19可知，对于这种情况的i处的状态就是 dp[i] = dp[i -1] + dp[i-2], 其他情况就是 dp[i] = dp[i - 1] | 一次遍历并将条件带入状态转移方程，最终得到结果，特殊情况是0值的考虑 | . T: S: ```python . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%AE%9A%E4%B9%89%E4%B8%8A%E4%B8%8B%E5%B7%A6%E5%8F%B3%E5%9B%9B%E4%B8%AA%E8%A1%8C%E8%B5%B0%E6%96%B9%E5%90%91",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#定义上下左右四个行走方向"
  },"76": {
    "doc": "Algorithm Everything",
    "title": "动态规划，找出dp[i] dp[i-1] dp[i-2] 之间的关系",
    "content": "# 1 ~ 9 # 10 ~ 19 # 20 ~ 26 # 226 # i = 0: dp[0] = 1 # i = 1: dp[1] = dp[0] + (if 2 &lt; 6) # i = 2: dp[2] = dp[1] + () . # if s[0] == \"0\": return 0 # 22619 dp = [] for i in range(len(s)): if i == 0: if s[0] != \"0\": dp.append(1) else: return 0 continue if s[i] == \"0\": if s[i-1] == \"1\" or s[i-1] == \"2\": if i == 1: dp.append(dp[i-1]) continue dp.append(dp[-2]) continue else: return 0 if s[i - 1] == \"0\": dp.append(dp[-1]) continue if (s[i - 1] == \"2\" and s[i] &lt;= \"6\") or (s[i - 1] == \"1\"): if i == 1: dp.append(dp[i-1] + 1) continue if dp[i -2] == \"0\": dp.append(dp[i - 1] + 1) else: dp.append(dp[i -1] + dp[i - 2]) else: dp.append(dp[-1]) print dp return dp[-1] ``` . | 二叉树的中序遍历 | . Solution: 二叉树的五种遍历方式，其中和跟节点在三点见顺序有关系的是中序遍历、前序遍历、后序遍历、BFS、DFS . 前序遍历： 跟节点 〉左子树 〉右子树 . 中序遍历： 左子树 〉跟节点 〉右子树 . 后序遍历： 左子树 〉右子树 〉跟节点 . 本题目要求用迭代的方式求中序遍历 . T: S: ```python # 在不使用递归的方式的情况下，使用栈来记录数据，完成中序 # public class Solution { # public List &lt; Integer &gt; inorderTraversal(TreeNode root) { # List &lt; Integer &gt; res = new ArrayList &lt; &gt; (); # Stack &lt; TreeNode &gt; stack = new Stack &lt; &gt; (); # TreeNode curr = root; # while (curr != null || !stack.isEmpty()) { # while (curr != null) { # stack.push(curr); # curr = curr.left; # } # curr = stack.pop(); # res.add(curr.val); # curr = curr.right; # } # return res; # } # 递归的方式 # class Solution { # public List &lt; Integer &gt; inorderTraversal(TreeNode root) { # List &lt; Integer &gt; res = new ArrayList &lt; &gt; (); # helper(root, res); # return res; # } . # public void helper(TreeNode root, List &lt; Integer &gt; res) { # if (root != null) { # if (root.left != null) { # helper(root.left, res); # } # res.add(root.val); # if (root.right != null) { # helper(root.right, res); # } # } # } # } #时间复杂度：O(n)O(n)。递归函数 T(n)=2⋅T(n/2)+1T(n)=2⋅T(n/2)+1。 # 空间复杂度：最坏情况下需要空间O(n)O(n)，平均情况为O(log⁡n)O(logn)。 stack = [] result = [] current = root while current or stack: # 找到当前节点的最左 while current: stack.append(current) current = current.left # 当前节点的最左应该是遍历的第一个值 # 外层循环将没有找到right的节点,将继续吧目标值更新为栈顶的值 current = stack.pop(-1) result.append(current.val) # 寻找当前节点的第一个right，找到right后再对right做同样的一直找左子树的操作 current = current.right return result # 时间复杂度： 假设结果长度为n，那么时间复杂度为n 空间复杂度 n . 53. [验证二叉搜索树](https://leetcode-cn.com/problems/validate-binary-search-tree/description/) 给定一个二叉树，判断其是否是一个有效的二叉搜索树。 &gt; Solution: 验证二叉搜索树，使用递归或者迭代的中序遍历，对遍历结果进行实时判断如果一点出现非升序元素则不是二叉搜索树 &gt; &gt; 对于递归处理的方式，一定要考虑return的使用方式 &gt; &gt; T: S: ```python # 验证二叉搜索树 # 解法：对二叉树做中序遍历，判断每次新加的值是否比前一个值大 # 重要重要重要 ： 两个数相等也是不符合搜索二叉树的条件的 # stack = [] # result = [] # current = root # while current or stack: # # 找到当前节点的最左 # while current: # stack.append(current) # current = current.left # # 当前节点的最左应该是遍历的第一个值 # # 外层循环将没有找到right的节点,将继续吧目标值更新为栈顶的值 # current = stack.pop(-1) # if result and current.val &lt;= result[-1]: return False # result.append(current.val) # # 寻找当前节点的第一个right，找到right后再对right做同样的一直找左子树的操作 # current = current.right # return True # 递归的方式实现 # 使用递归对二叉树进行中序遍历，遍历的结果必须有序才符合条件 # 遍历的每一次操作都需要对比 def middle(node, res): if not node: return True if res and node.val &lt;= res[-1]: return False if node.left: if not middle(node.left, res): return False if res and node.val &lt;= res[-1]: return False res.append(node.val) if node.right: if not middle(node.right, res): return False return True res = [] return middle(root, res) # 递归分析 # 1. append + left # 2. append + left # x. 最左的所有节点都放在栈中了，拿出栈顶元素（栈顶元素就是树的左叶子节点）,将值放入结果中 # x + 1. 回溯找到将右边的第一个节点，左同样的1到n的递归 . | 二叉树的层次遍历 | . Solution: . 本题解法为广度优先遍历 广度优先遍历需要使用到队列 如何控制分界线 . 控制分界线的方式是追踪当前每层实时的节点总数，2**n - last_nll * 2 - current_null . 每层在满树的情况下的总数2的n次方 - 上一层为空的节点数*2 - 当前节点为空的数量 . 如果queue中有相同数目的元素则拷贝一份到答案数组； . 分解条件的数学原因为： n &gt; 1时候 总有： n - 1+ 2 &lt; 2 * n n -1 + 1 &lt; 2 *n -1 . T: S: ```python # 本题解法为广度优先遍历 # 广度优先遍历需要使用到队列 # 如何控制分界线 . queue = [root] result = [] last_null = 0 current_null = 0 while queue and root: if len(queue) == 2**len(result) - last_null * 2 - current_null: last_null = last_null * 2 + current_null current_null = 0 result.append([n.val for n in queue]) node = queue.pop(0) if node.left: queue.append(node.left) else: current_null += 1 if node.right: queue.append(node.right) else: current_null += 1 return result ``` . | 二叉树的锯齿形层次遍历 | . Solution: 本题和上一题基本完全一致，每层遍历顺序相反的二叉树BFS遍历为二维数组，只需要将读取队列中的值的步骤依赖当前层次的奇偶性就可以完成； T: S: ```python # def findBottomLeftValue(self, root): # “”” # :type root: TreeNode # :rtype: int # “”” # # 使用队列从右往左广度优先遍历整个树，输出最后一个元素就是最后一行最左边的元素 # queue_l = [] # queue_l.append(root) . # while queue_l: # node = queue_l.pop(0) # if node.right: # queue_l.append(node.right) # if node.left: # queue_l.append(node.left) # if not queue_l: # return node.val # 本题解法为广度优先遍历 # 广度优先遍历需要使用到队列 # 如何控制分界线 queue = [root] result = [] last_null = 0 current_null = 0 while queue and root: if len(queue) == 2**len(result) - last_null * 2 - current_null: last_null = last_null * 2 + current_null current_null = 0 result.append([n.val for n in queue]) node = queue.pop(0) if node.left: queue.append(node.left) else: current_null += 1 if node.right: queue.append(node.right) else: current_null += 1 return result . 56. [从中序与后序遍历序列构造二叉树](https://leetcode-cn.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/description/) &gt; Solution: &gt; T: S: ```python # 解法，从后序遍历中的末尾元素可以找到第一个根结点，找到该节点在中序遍历中的位置 # 此时该位置前的元素为左孩子，后面的元素为又孩子 # 递归继续对前后两个孩子进行同样操作 # 难度： 1. 树的还原 2. 递归返回 # TODO - recoding # 递归函数 def helper(in_left, in_right): # if there is no elements to construct subtrees # 4. 第三步中的 index+1 in_right 当到达同一个点时也就是不可再分割是，就是index+1 &gt; in_right，所以返回空 if in_left &gt; in_right: return None # pick up the last element as a root # 1. 从后序遍历中获取根结点，并生成根结点TreeNode val = postorder.pop() root = TreeNode(val) # root splits inorder list # into left and right subtrees # 2. 在中序遍历中找到根节点的索引值 index = idx_map[val] # 3. 将根节点左右两边的值进行递归生成新的根节点和子树 # 因为后续遍历找到根节点是从右边子树开始所以，先对右边左递归 # 这里传入的参数有两个作用，第一用来限定递归次数也就是分割次数，第二使用来判断是否已经到达叶子节点 # build right subtree root.right = helper(index + 1, in_right) # build left subtree root.left = helper(in_left, index - 1) return root # 最终递归结束后返回给第一次调用的根节点 # build a hashmap value -&gt; its index # 将list列表转换为哈希表，方便定位元素 idx_map = {val:idx for idx, val in enumerate(inorder)} return helper(0, len(inorder) - 1) # 时间复杂度分析： # 递归树分析 # 时间复杂度： # 由主定理考虑： # T(n) = aT(n/b) + f(n) 表示将 T(n) 的问题分解为a个 T(n/b)， # 在每次递归中二叉树涉及到的规模为初始问题的两个子问题a=2，因为左右子树在递归中每次各计算一次所以这里b=2, # logb(a) log以b为底的a表示问题被分解为a个子问题规模, O(n**logb(a)) # f(n) # 空间复杂度：O(N)存储整棵树。 . | 路径总和 | . Solution: T: S: ```python # 二叉树的两种基本遍历 # BFS 使用队列 # DFS 使用栈 . # DFS 迭代 栈 # 栈中的每一个元素都存储了到该元素位置的总和，所以迭代在不满足条件的情况下，深度遍历继续进行可以继续找目标值 if not root: return False de = [(root, sum - root.val), ] while de: node, curr_sum = de.pop() if not node.left and not node.right and curr_sum == 0: return True if node.right: de.append((node.right, curr_sum - node.right.val)) if node.left: de.append((node.left, curr_sum - node.left.val)) return False ``` . | 复制带随机指针的链表 | . Solution: 用递归回溯的方式扫描整个链表，并存储已经创建的拷贝 T: N S: N ```python # 用来保存当前访问的节点深拷贝出来的新节点 self.hash_map = {} . def recursive_copy(head_node): if not head_node: return None # 1. hash_map 中保存了当前访问节点和初始化的拷贝节点 # 如果不存在则证明该节点还没创建 new_node = self.hash_map.get(head_node) if not new_node: # 1. 拷贝值创建新节点， 并存入hash_map new_node = Node(head_node.val, None, None) self.hash_map.update({head_node: new_node}) else: # 2. 在已经拷贝过的node里找到了已经新建的node就要直接返回，否则会导致循环递归，最终达到递归上限 return new_node # 3. 拷贝自己的next，如果存在直接返回 new_node.next = recursive_copy(head_node.next) # 4. 拷贝自己的random，如果存在直接返回 new_node.random = recursive_copy(head_node.random) return new_node return recursive_copy(head) . 59. [二叉树展开为链表](https://leetcode-cn.com/problems/flatten-binary-tree-to-linked-list/description/) &gt; Solution: &gt; T: S: ```python # 94题 mirrors # 原地算法，直接将所有值接到节点的右子树 # 使用后序遍历 # 1 # / \\ # 2 5 # / \\ \\ # 3 4 6 # 1 # / \\ # 2 5 # \\ \\ # 3 6 # \\ # 4 # 1 # \\ # 2 # \\ # 3 # \\ # 4 # \\ # 5 # \\ # 6 # 使用后续遍历，将第一个找到的右子树改为第一个找到的左子树的右孩子 # 并递归活迭代 # 递归 # 改变方向的从右向左的后序遍历 self.last_right = None # 上一个已经排到右边的节点，活着说上个已经完成转链表的节点 def recursive_post(node): if not node: return recursive_post(node.right) recursive_post(node.left) node.right = self.last_right node.left = None self.last_right = node return recursive_post(root) # public void flatten(TreeNode root) { # Stack&lt;TreeNode&gt; toVisit = new Stack&lt;&gt;(); # TreeNode cur = root; # TreeNode pre = null; # while (cur != null || !toVisit.isEmpty()) { # while (cur != null) { # toVisit.push(cur); // 添加根节点 # cur = cur.right; // 递归添加右节点 # } # cur = toVisit.peek(); // 已经访问到最右的节点了 # // 在不存在左节点或者右节点已经访问过的情况下，访问根节点 # if (cur.left == null || cur.left == pre) { # toVisit.pop(); # /**************修改的地方***************/ # cur.right = pre; # cur.left = null; # /*************************************/ # pre = cur; # cur = null; # } else { # cur = cur.left; // 左节点还没有访问过就先访问左节点 # } # } # } # de = [(root, sum - root.val), ] # while de: # node, curr_sum = de.pop() # if not node.left and not node.right and curr_sum == 0: # return True # if node.right: # de.append((node.right, curr_sum - node.right.val)) # if node.left: # de.append((node.left, curr_sum - node.left.val)) # return False . | 填充每个节点的下一个右侧节点指针 | . Solution: T: S: ```python def connect(self, root): “”” :type root: Node :rtype: Node “”” . # 层序遍历，从最下层往最上层 queue = [root] level = 0 last_null = 0 current_null = 0 left_node = None while queue and root: if len(queue) == 2**level - last_null * 2 - current_null: last_null = last_null * 2 + current_null current_null = 0 level += 1 # 完全二叉树，不用考虑缺少的左右子树，所以可以忽略last_null和current_null for i in range(len(queue)-1): queue[i].next = queue[i+1] left_node = queue[0] node = queue.pop(0) if node.left: queue.append(node.left) else: current_null += 1 if node.right: queue.append(node.right) else: current_null += 1 node.right = None if node != left_node: node.left = None return root ``` . 61.填充每个节点的下一个右侧节点指针 II . Solution: T: S: ```python def connect(self, root): “”” :type root: Node :rtype: Node “”” queue = [root] level = 0 last_null = 0 current_null = 0 left_node = None while queue and root: if len(queue) == 2**level - last_null * 2 - current_null: last_null = last_null * 2 + current_null current_null = 0 level += 1 . # 完全二叉树，不用考虑缺少的左右子树，所以可以忽略last_null和current_null left_node = queue[-1] for i in range(len(queue)-1): queue[i].next = queue[i+1] if left_node == queue[-1] and (queue[i].left or queue[i].right): left_node = queue[i] node = queue.pop(0) if node.left: queue.append(node.left) else: current_null += 1 if node.right: queue.append(node.right) else: current_null += 1 if node == left_node: if node.left and node.right: node.right = None continue node.left = None node.right = None return root ``` . | 复制带随机指针的链表 | . Solution: T: S: ```python def copyRandomList(self, head): “”” :type head: Node :rtype: Node “”” # 用来保存当前访问的节点深拷贝出来的新节点 self.hash_map = {} . def recursive_copy(head_node): if not head_node: return None # 1. hash_map 中保存了当前访问节点和初始化的拷贝节点 # 如果不存在则证明该节点还没创建 new_node = self.hash_map.get(head_node) if not new_node: # 1. 拷贝值创建新节点， 并存入hash_map new_node = Node(head_node.val, None, None) self.hash_map.update({head_node: new_node}) else: # 2. 在已经拷贝过的node里找到了已经新建的node就要直接返回，否则会导致循环递归，最终达到递归上限 return new_node # 3. 拷贝自己的next，如果存在直接返回 new_node.next = recursive_copy(head_node.next) # 4. 拷贝自己的random，如果存在直接返回 new_node.random = recursive_copy(head_node.random) return new_node return recursive_copy(head) ``` . | 环形链表 | . Solution: T: S: . ```python if not head or not head.next: return False . p1 = head p2 = head.next while p1 != p2: if not p1 or not p2 or not p2.next: return False p1 = p1.next p2 = p2.next.next return True ``` . | LRU缓存机制 | . Solution: T: S: ```python from collections import OrderedDict class LRUCache(OrderedDict): . def __init__(self, capacity): \"\"\" :type capacity: int \"\"\" self.capacity = capacity def get(self, key): \"\"\" :type key: int :rtype: int \"\"\" if key not in self: return - 1 self.move_to_end(key) return self[key] def put(self, key, value): \"\"\" :type key: int :type value: int :rtype: void \"\"\" if key in self: self.move_to_end(key) self[key] = value if len(self) &gt; self.capacity: self.popitem(last = False) ``` . | 翻转字符串里的单词 | . Solution: T: S: . # python # 解法1: 先用strip，然后split，然后反向读取list在转为字符串 # 解法2: 不使用额外n空间，先strip，然后在字符串前加两个空格，然后读取到第一个单词， # 将开始坐标和单词结束坐标的字符加到字符串末尾并删除，依次对所有单词做同样操作，直到找到末尾坐标（后面出现两个连续空格） # 解法3：不使用额外n空间，原地算法，双指针 . 66. Solution: T: S: ```python # 使用迭代的二分查找或者递归的二分搜索的方法 . # 解法： 1. 递归 # 找出二分搜索的中间点 # 比较是否 中间点的值大于其后一个值，如果大于则证明，中间点位于一个局部下降的位置， # 那么它左边肯定有至少一个peek点，那么继续对左边做二分搜索 # 如果，中间点的值小于其后面一个值，那么中间点在一个局部上升位置 # 那么它右边肯定有一个peek，递归 # 最终l r相等就可以得到结果 #public class Solution { # public int findPeakElement(int[] nums) { # return search(nums, 0, nums.length - 1); # } # public int search(int[] nums, int l, int r) { # if (l == r) # return l; # int mid = (l + r) / 2; # if (nums[mid] &gt; nums[mid + 1]) # return search(nums, l, mid); # return search(nums, mid + 1, r); # } # } def search_peek(nums, l, r): if l == r: return l middle = (l + r) /2 # \\ down from middle to middle + 1 if nums[middle] &gt; nums[middle + 1]: return search_peek(nums, l, middle) # / up from middle to middel +1 else: return search_peek(nums, middle + 1, r) return search_peek(nums, 0, len(nums) -1) ``` . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . Solution: T: S: ```python . &gt; Solution: &gt; T: S: ```python . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%89%BE%E5%87%BAdpi-dpi-1-dpi-2-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#动态规划找出dpi-dpi-1-dpi-2-之间的关系"
  },"77": {
    "doc": "Algorithm Everything",
    "title": "所有重点题型",
    "content": ". | ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E6%89%80%E6%9C%89%E9%87%8D%E7%82%B9%E9%A2%98%E5%9E%8B",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#所有重点题型"
  },"78": {
    "doc": "Algorithm Everything",
    "title": "两数相加",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#两数相加"
  },"79": {
    "doc": "Algorithm Everything",
    "title": "最长回文子串",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#最长回文子串"
  },"80": {
    "doc": "Algorithm Everything",
    "title": "字符串转换整数 (atoi)",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%8D%A2%E6%95%B4%E6%95%B0-atoi",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#字符串转换整数-atoi"
  },"81": {
    "doc": "Algorithm Everything",
    "title": "三数之和",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#三数之和"
  },"82": {
    "doc": "Algorithm Everything",
    "title": "合并K个排序链表",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%90%88%E5%B9%B6k%E4%B8%AA%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#合并k个排序链表"
  },"83": {
    "doc": "Algorithm Everything",
    "title": "两两交换链表中的节点",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#两两交换链表中的节点"
  },"84": {
    "doc": "Algorithm Everything",
    "title": "K 个一组翻转链表",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#k-%E4%B8%AA%E4%B8%80%E7%BB%84%E7%BF%BB%E8%BD%AC%E9%93%BE%E8%A1%A8",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#k-个一组翻转链表"
  },"85": {
    "doc": "Algorithm Everything",
    "title": "搜索旋转排序数组",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E6%90%9C%E7%B4%A2%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#搜索旋转排序数组"
  },"86": {
    "doc": "Algorithm Everything",
    "title": "全排列",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%85%A8%E6%8E%92%E5%88%97",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#全排列"
  },"87": {
    "doc": "Algorithm Everything",
    "title": "全排列 II",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%85%A8%E6%8E%92%E5%88%97-ii",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#全排列-ii"
  },"88": {
    "doc": "Algorithm Everything",
    "title": "旋转图像",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E6%97%8B%E8%BD%AC%E5%9B%BE%E5%83%8F",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#旋转图像"
  },"89": {
    "doc": "Algorithm Everything",
    "title": "螺旋矩阵",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E8%9E%BA%E6%97%8B%E7%9F%A9%E9%98%B5",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#螺旋矩阵"
  },"90": {
    "doc": "Algorithm Everything",
    "title": "跳跃游戏",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#跳跃游戏"
  },"91": {
    "doc": "Algorithm Everything",
    "title": "合并区间",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#合并区间"
  },"92": {
    "doc": "Algorithm Everything",
    "title": "简化路径",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E7%AE%80%E5%8C%96%E8%B7%AF%E5%BE%84-1",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#简化路径-1"
  },"93": {
    "doc": "Algorithm Everything",
    "title": "矩阵置零",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E7%9F%A9%E9%98%B5%E7%BD%AE%E9%9B%B6",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#矩阵置零"
  },"94": {
    "doc": "Algorithm Everything",
    "title": "颜色分类",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E9%A2%9C%E8%89%B2%E5%88%86%E7%B1%BB",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#颜色分类"
  },"95": {
    "doc": "Algorithm Everything",
    "title": "单词搜索",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%8D%95%E8%AF%8D%E6%90%9C%E7%B4%A2",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#单词搜索"
  },"96": {
    "doc": "Algorithm Everything",
    "title": "解码方法",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E8%A7%A3%E7%A0%81%E6%96%B9%E6%B3%95",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#解码方法"
  },"97": {
    "doc": "Algorithm Everything",
    "title": "二叉树的中序遍历",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#二叉树的中序遍历"
  },"98": {
    "doc": "Algorithm Everything",
    "title": "验证二叉搜索树",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E9%AA%8C%E8%AF%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#验证二叉搜索树"
  },"99": {
    "doc": "Algorithm Everything",
    "title": "二叉树的层次遍历",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E6%AC%A1%E9%81%8D%E5%8E%86",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#二叉树的层次遍历"
  },"100": {
    "doc": "Algorithm Everything",
    "title": "二叉树的锯齿形层次遍历",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%94%AF%E9%BD%BF%E5%BD%A2%E5%B1%82%E6%AC%A1%E9%81%8D%E5%8E%86",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#二叉树的锯齿形层次遍历"
  },"101": {
    "doc": "Algorithm Everything",
    "title": "从中序与后序遍历序列构造二叉树",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%BB%8E%E4%B8%AD%E5%BA%8F%E4%B8%8E%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86%E5%BA%8F%E5%88%97%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#从中序与后序遍历序列构造二叉树"
  },"102": {
    "doc": "Algorithm Everything",
    "title": "路径总和",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#路径总和"
  },"103": {
    "doc": "Algorithm Everything",
    "title": "二叉树展开为链表",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%BA%8C%E5%8F%89%E6%A0%91%E5%B1%95%E5%BC%80%E4%B8%BA%E9%93%BE%E8%A1%A8",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#二叉树展开为链表"
  },"104": {
    "doc": "Algorithm Everything",
    "title": "填充每个节点的下一个右侧节点指针",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%A1%AB%E5%85%85%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E4%B8%8B%E4%B8%80%E4%B8%AA%E5%8F%B3%E4%BE%A7%E8%8A%82%E7%82%B9%E6%8C%87%E9%92%88",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#填充每个节点的下一个右侧节点指针"
  },"105": {
    "doc": "Algorithm Everything",
    "title": "填充每个节点的下一个右侧节点指针 II",
    "content": "| ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E5%A1%AB%E5%85%85%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84%E4%B8%8B%E4%B8%80%E4%B8%AA%E5%8F%B3%E4%BE%A7%E8%8A%82%E7%82%B9%E6%8C%87%E9%92%88-ii",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#填充每个节点的下一个右侧节点指针-ii"
  },"106": {
    "doc": "Algorithm Everything",
    "title": "买卖股票的最佳时机-全部股票相关题目",
    "content": "| | . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-%E5%85%A8%E9%83%A8%E8%82%A1%E7%A5%A8%E7%9B%B8%E5%85%B3%E9%A2%98%E7%9B%AE",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#买卖股票的最佳时机-全部股票相关题目"
  },"107": {
    "doc": "Algorithm Everything",
    "title": "题目",
    "content": "https://leetcode-cn.com/problems/two-sum/solution/liang-shu-zhi-he-by-leetcode-2/ https://blog.csdn.net/l975764577/article/details/39399077 https://www.cnblogs.com/absfree/p/5463372.html https://leetcode-cn.com/problems/add-two-numbers/solution/liang-shu-xiang-jia-by-leetcode/ https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xun-zhao-liang-ge-you-xu-shu-zu-de-zhong-wei-shu-b/ https://lufficc.com/blog/binary-search-tree https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/solution/mai-mai-gu-piao-de-zui-jia-shi-ji-by-leetcode/ https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/solution/yi-ge-fang-fa-tuan-mie-6-dao-gu-piao-wen-ti-by-l-3/ https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/solution/mai-mai-gu-piao-de-zui-jia-shi-ji-ii-by-leetcode/ https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/solution/java-1ms-100dong-tai-gui-hua-li-yong-si-ge-bian-li/ https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iv/solution/yi-ge-tong-yong-fang-fa-tuan-mie-6-dao-gu-piao-w-5/ https://gitee.com/x3code/algo-book https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-iii/solution/java-1ms-100dong-tai-gui-hua-li-yong-si-ge-bian-li/ https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/ https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/solution/yi-ge-fang-fa-tuan-mie-6-dao-gu-piao-wen-ti-by-l-2/ https://gitee.com/labuladong/algo-book/blob/master/labuladong的算法小抄.pdf https://stackoverflow.com/questions/7604966/maximum-and-minimum-values-for-ints https://leetcode-cn.com/problems/remove-comments/solution/shan-chu-zhu-shi-by-leetcode/ https://leetcode-cn.com/problems/bulb-switcher-ii/solution/deng-pao-kai-guan-ii-by-leetcode/ https://leetcode-cn.com/problems/bulb-switcher/solution/you-jian-dan-li-zi-tui-li-rong-yi-li-jie-by-fall12/ https://www.geeksforgeeks.org/python-math-function-sqrt/ https://leetcode-cn.com/problems/maximum-binary-tree/solution/zui-da-er-cha-shu-by-leetcode/ https://xintiaohuiyi.gitbook.io/jynotebook/shu-ji/shu-ju-jie-gou-yu-suan-fa-zhi-mei/27-di-gui-shu-ff1a-ru-he-jie-zhu-shu-lai-qiu-jie-di-gui-suan-fa-de-shi-jian-fu-za-du-ff1f https://leetcode-cn.com/problems/2-keys-keyboard/solution/zhi-you-liang-ge-jian-de-jian-pan-by-leetcode/ . 素数，指在大於1的自然数中，除了1和該数自身外，無法被其他自然数整除的数 https://leetcode-cn.com/problems/permutation-in-string/solution/chua-dong-chuang-kou-ji-you-hua-by-never_say_never/ https://juejin.im/post/5c74a2e2f265da2dea053355 https://leetcode-cn.com/problems/longest-palindromic-substring/solution/zui-chang-hui-wen-zi-chuan-by-leetcode/ https://leetcode-cn.com/problems/permutations-ii/solution/hui-su-suan-fa-python-dai-ma-java-dai-ma-by-liwe-2/ https://leetcode-cn.com/problems/permutations/solution/quan-pai-lie-by-leetcode/ https://blog.csdn.net/JonsTank2013/article/details/50898473 https://en.wikipedia.org/wiki/Knuth–Morris–Pratt_algorithm https://leetcode-cn.com/problems/find-bottom-left-tree-value/solution/cong-you-dao-zuo-de-ceng-xu-bian-li-bu-xu-ji-lu-zh/ https://blog.csdn.net/mingwanganyu/article/details/72033122 https://leetcode.com/tag/breadth-first-search/ https://leetcode-cn.com/problems/add-two-numbers-ii/solution/python-di-gui-zhi-xing-yong-shi-52-ms-zai-suo-you-/ 用最少数量的箭引爆气球 https://leetcode-cn.com/problems/add-two-numbers-ii/solution/python-di-gui-zhi-xing-yong-shi-52-ms-zai-suo-you-/ https://leetcode-cn.com/problems/string-compression/solution/ya-suo-zi-fu-chuan-by-leetcode/ https://leetcode-cn.com/problems/battleships-in-a-board/solution/cyu-yan-cai-yong-dfsfang-shi-ba-zhao-guo-de-zhan-j/ https://www.jianshu.com/p/70952b51f0c8 https://zhuanlan.zhihu.com/p/24986203 https://leetcode-cn.com/problems/first-unique-character-in-a-string/solution/zi-fu-chuan-zhong-de-di-yi-ge-wei-yi-zi-fu-by-leet/ https://leetcode-cn.com/problems/two-sum/solution/jing-xin-zong-jie-python3-de-san-chong-shi-xian-1b/ https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/solution/yi-ge-fang-fa-tuan-mie-6-dao-gu-piao-wen-ti-by-l-3/ https://leetcode-cn.com/problems/3sum/solution/pai-xu-shuang-zhi-zhen-zhu-xing-jie-shi-python3-by/ https://leetcode-cn.com/problems/string-to-integer-atoi/solution/python-1xing-zheng-ze-biao-da-shi-by-knifezhu/ https://leetcode-cn.com/problems/longest-palindromic-substring/solution/zui-chang-hui-wen-zi-chuan-by-leetcode/ https://leetcode-cn.com/problems/merge-intervals/solution/he-bing-qu-jian-by-leetcode/ https://leetcode-cn.com/problems/jump-game/solution/tiao-yue-you-xi-by-leetcode/ https://leetcode-cn.com/problems/spiral-matrix/solution/luo-xuan-ju-zhen-by-leetcode/ https://leetcode-cn.com/problems/maximum-subarray/solution/zui-da-zi-xu-he-by-leetcode/ https://leetcode-cn.com/problems/rotate-image/solution/xuan-zhuan-tu-xiang-by-leetcode/ https://leetcode-cn.com/problems/implement-queue-using-stacks/solution/ https://leetcode-cn.com/problems/tag-validator/solution/biao-qian-yan-zheng-qi-by-leetcode/ https://leetcode-cn.com/problems/tag-validator/solution/biao-qian-yan-zheng-qi-by-leetcode/ https://leetcode-cn.com/problems/add-digits/solution/java-o1jie-fa-de-ge-ren-li-jie-by-liveforexperienc/ https://blog.csdn.net/xtj332/article/details/6639009 https://leetcode-cn.com/problems/integer-to-english-words/solution/zheng-shu-zhuan-huan-ying-wen-biao-shi-by-leetcode/ https://leetcode-cn.com/problems/serialize-and-deserialize-binary-tree/solution/er-cha-shu-de-xu-lie-hua-yu-fan-xu-lie-hua-by-leet/ https://leetcode-cn.com/problems/missing-number/solution/que-shi-shu-zi-by-leetcode/ https://leetcode-cn.com/problems/longest-increasing-subsequence/solution/zui-chang-shang-sheng-zi-xu-lie-dong-tai-gui-hua-2/ . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E9%A2%98%E7%9B%AE",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#题目"
  },"108": {
    "doc": "Algorithm Everything",
    "title": "知识点",
    "content": "https://leetcode.com/tag/breadth-first-search/ https://www.jianshu.com/p/70952b51f0c8 http://data.biancheng.net/view/200.html http://data.biancheng.net/view/201.html https://wiki.jikexueyuan.com/project/easy-learn-algorithm/fast-sort.html https://blog.csdn.net/Bone_ACE/article/details/46718683 . 基本算法的实现，烂熟于心： . 二分搜索 二叉树的遍历：深度 前后后 广度 左右 基础动态规划 回溯 迭代 递归 图的 BFS、 DFS Fib 分治 主定理 kmp 自动机 . 斐波那契数列的计算 . 主定理时间复杂度分析： T(n)=aT(n/b)+f(n) . 其中a≥1和b&gt;1是常数，f(n)是渐近正函数。这个递推式将规模为n的问题分解为a个子问题，每个子问题的规模为n/b，a个子问题递归地求解，每个花费时间T(n/b)。函数f(n)包含了问题分解和子问题解合并的代价。 . 图，graph： . | 图：表示多对过的关系的数据结构，实现方式由一个数组和一个二维数字表示，二维数组表示图中每一个顶点与其他顶点之间的联通情况，一维数组表示的是图中每个顶点的值，序号和二维数组中的索引值相对应； | . 基本概念： . | 弧头和弧尾 有向图中，无箭头一端的顶点通常被称为”初始点”或”弧尾”，箭头直线的顶点被称为”终端点”或”弧头”。 . | 入度和出度 | . 对于有向图中的一个顶点 V 来说，箭头指向 V 的弧的数量为 V 的入度（InDegree，记为 ID(V)）；箭头远离 V 的弧的数量为 V 的出度（OutDegree，记为OD(V)）。 . | (V1,V2) 和 &lt;V1,V2&gt; 的区别 无向图中描述两顶点（V1 和 V2）之间的关系可以用 (V1,V2) 来表示，而有向图中描述从 V1 到 V2 的”单向”关系用 &lt;V1,V2&gt; 来表示。 . | . 由于图存储结构中顶点之间的关系是用线来表示的，因此 (V1,V2) 还可以用来表示无向图中连接 V1 和 V2 的线，又称为边；同样，&lt;V1,V2&gt; 也可用来表示有向图中从 V1 到 V2 带方向的线，又称为弧。 . | 集合 VR 的含义 | . 并且，图中习惯用 VR 表示图中所有顶点之间关系的集合。例如，图 1 中无向图的集合 VR={(v1,v2),(v1,v4),(v1,v3),(v3,v4)}，图 2 中有向图的集合 VR={&lt;v1,v2&gt;,&lt;v1,v3&gt;,&lt;v3,v4&gt;,&lt;v4,v1&gt;}。 路径和回路 . | 无论是无向图还是有向图，从一个顶点到另一顶点途径的所有顶点组成的序列（包含这两个顶点），称为一条路径。如果路径中第一个顶点和最后一个顶点相同，则此路径称为”回路”（或”环”）。 . | 并且，若路径中各顶点都不重复，此路径又被称为”简单路径”；同样，若回路中的顶点互不重复，此回路被称为”简单回路”（或简单环）。 . | 在有向图中，每条路径或回路都是有方向的。 | 权和网的含义 在某些实际场景中，图中的每条边（或弧）会赋予一个实数来表示一定的含义，这种与边（或弧）相匹配的实数被称为”权”，而带权的图通常称为网。如图 3 所示，就是一个网结构： . | 无向图中，如果任意两个顶点之间都能够连通，则称此无向图为连通图。 | 若无向图不是连通图，但图中存储某个子图符合连通图的性质，则称该子图为连通分量。 | 由图中部分顶点和边构成的图为该图的一个子图，但这里的子图指的是图中”最大”的连通子图（也称”极大连通子图”）。 | . DFS: . DFS_SEARCHED = set() def dfs(graph, start): if start not in DFS_SEARCHED: print(start) DFS_SEARCHED.add(start) for node in graph[start]: if node not in DFS_SEARCHED: dfs(graph, node) print('dfs:') dfs(GRAPH, 'A') # A B C I D G F E H . BFS: . from collections import deque GRAPH = { 'A': ['B', 'F'], 'B': ['C', 'I', 'G'], 'C': ['B', 'I', 'D'], 'D': ['C', 'I', 'G', 'H', 'E'], 'E': ['D', 'H', 'F'], 'F': ['A', 'G', 'E'], 'G': ['B', 'F', 'H', 'D'], 'H': ['G', 'D', 'E'], 'I': ['B', 'C', 'D'], } class Queue(object): def __init__(self): self._deque = deque() def push(self, value): return self._deque.append(value) def pop(self): return self._deque.popleft() def __len__(self): return len(self._deque) def bfs(graph, start): search_queue = Queue() search_queue.push(start) searched = set() while search_queue: # 队列不为空就继续 cur_node = search_queue.pop() if cur_node not in searched: yield cur_node searched.add(cur_node) for node in graph[cur_node]: search_queue.push(node) print('bfs:') bfs(GRAPH, 'A' . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#%E7%9F%A5%E8%AF%86%E7%82%B9",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/#知识点"
  },"109": {
    "doc": "Algorithm Everything",
    "title": "Algorithm Everything",
    "content": "Algorithm . 2020-02-18 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-02-18-Algorithm-Everything/",
    
    "relUrl": "/docs/archives/2020/2020-02-18-Algorithm-Everything/"
  },"110": {
    "doc": "My Algorithm Curve",
    "title": "做题路径-重要算法思想",
    "content": "##EASY： . | 两数之和，目标值是数组中两个数字的和，求这两数字 用dp保存遍历结果，遍历数组，获取目标值和遍历值的差值，在dp中找是否存在该值 =N 排序，双指针不断更新靠近目标值 =NlogN . | 罗马数字转整数 遍历输入串，将罗马数字转化成数字并append到一个暂存list中，下一次判断list最后一位是否和罗马数字相减要求的一致，pop掉，并将新数字减掉1 10 100，最终对list中的int相加 . | n以内所有素数的数量，n是不是素数 埃式筛法，从i**2开始+=i，筛掉，最终留下的就是全素数集合 无重复的欧拉筛法 . | 合并两个有序链表 比对l1和l2的大小，将最小的放在新链表的next上，更新l1或者l2，直到其中一个链表为空 while l1 and l2；最终返回新链表的next。T = M + N . | 删除排序数组中的重复项 快慢双指针，快慢从0 1出发，如果快慢不相等，慢指针每次都更新为快慢不相等的慢的下一个，也就是慢指针前面的数没有相等的，如果相等，停止更新慢指针，直到找到下一个不相等，开始更新慢指针的值，也就是快指针向前移动一次慢指针更新一次 T = N S = 1 . | 实现 strStr() 返回子串开始的索引，空串返回0 一次遍历，更新第一个发现匹配位置的索引，匹配后更新，不匹配更新为-1，一直到剩下长度不足找到needle，或者匹配后i-第一匹配点为len needle . | 最大子序和，找到序列中最大和的自序，N，贪心、滑动窗口、分治 贪心算法也可以求解，局部最优解，需要两个变量1存储当前窗口移动到的位置的最大值，第二个存储到当前节点为止的最大值，每次比较当前值和更新后的窗口值的大小；滑动窗口：窗口在数组上滑动，在滑动的同是，用常量记录一些状态，如当前的窗口值或者当前值，或者其和差等；这里的窗口记录的是到当前窗口处序列和或者重新开始序列的值，另一个变量保存当前最大和； 本题的动态规划其实就是贪心算法，贪心每次记录的window值就是到当前节点的最大子序列和，包括当前节点哦 . | 合并两个有序数组, m个n个元素长度 m数组 &gt; n数组 双指针比对法，从尾部向前每次比对m和n中最大的一个数放在m数组尾部，这样需要第三个指针来记录当前尾部更新的位置，当n数组全部比对完成后，就可以返回答案了 . | 对称二叉树，左右互为镜像 递归或者迭代的广度，然后得到广度的遍历的每一个level的结果后，检查数组是否是镜像的； 递归，从root的左右子树开始，检查左右val是否相等，然后递归在左的左右，和右的左右 . | 路径总和 迭代的广度优先遍历，使用队列存储一个tuple元组，元组的0位置上放广度遍历的记录值，1位置上放当前路径到该点的差值，如root节点存储sum-rootv，当每次到达叶子节点时，判断节点的sum是否为0 . | 广度，队列，记忆 | . | 验证回文串 . | 双指针，将不符合条件的字符都跳过，值比较字母和数字，知道指针相遇或是指针重叠； | . | 相交链表， 两个链表有相交的部分，找到相交点 . | 双指针，分别从两个链表同时出发，先遍历个字节点，完成后从对方节点再开始遍历，如果相遇就是相交起始点，m + k + n = n + k + m | . | Excel表列名称 ASC中A从65开始，a从97开始，python中分别有 ord 和 chr 函数来转换，本题其实就是一个进制问题，将数组转换为字母的进制问题，但是因为本题没有0，所以z和A0都可以表示26的时候要选择Z， . | 始值是字符串，对26取余数，当余数为0的情况下，证明此时必须保留最后一位Z，所以将m改为26用来转Z，更新n为n-26，后续再得到n=n/26，循环开始前要检查n是否大于26，否则直接转n； | . | Excel表列序号 获取每个字母，ord-65+1获取十进制数的大小k，然后k*26**m m次方就是总字母数-1-i for i in range(l): r += (ord(s[i]) - 65 + 1) * (26 ** (l-1-i)) . | 旋转数组， 右移动k步。S 1 原地 . | i i+k交换，记录i，并填充 N N | 原地且空间为1，循环替换，0 - k - 2k - 3k 当替换次数到达数组长度是，证明所有替换完成，记录每次替换的开始点，如nums0，当没有完成所有替换的同时且循环又一次回到了开始点，则下一个开始点更新为cur+1，且下一个cache点也为nums i+1；tmp = nums[cur] nums[cur] = cache cache = tmp | . | 位1的个数 while n &gt; 0: result += 1 n &amp;= n - 1 . | 对于一个二进制来说，最低位的1，一定会因为 n - 1 而变成0，这时候对n和n-1做与操作，，就可以得到去掉最低位1的结果 | . | 计数质数，小于n的所有素数的数量 埃式筛法： 待筛开始数，为2到根号n，每个数开始筛的起始数为i**2，然后每次+i； 时间复杂度：nlognlogn -&gt; 素数分布定理 + 微积分基本定理 求解 . if n &lt; 2: return 0 # visited = [False]*n # ans = n - 2 # i = 2 while i &lt;= n/i: if not visited[i]: j = i * i while j &lt; n: if not visited[j]: ans -= 1 visited[j] = True j += i i += 1 . | 反转链表 # 指针操作，需要留意暂存next和更新last已经current，1. 暂存next 2. 当前的next为cachelast 3. cachelast更新位当前 4. 当前为暂存的next . | 删除链表中的节点 和next交换值，并更新next为next next t = node.next; node.val = t.val; node.next = t.next; t = None . | 字符串中的第一个唯一字符，只有小写字母 第一次遍历n的字符，用哈希表更新count，用一个新的数组保存字母顺序，第二次遍历数组取hash值，当值为1就返回，这样时间是N空间是两个26所以是1 . | 压缩字符串，原地算法 . | 实现空间复杂度为1的原地算法 # python 使用暂存值存储索引值和重复字符的索引，并存储重复字符的字符 一个读一个写指针同时出发，当遇到于前一个字符相同的字符是写指针暂停，读指针继续，当遇到第一个不同字符时，写指针写入压缩长度，读指针+1并写入新值，读指针继续读取和计数，如果没有重复就前移且写指针不断写入并前移，知道再次重复为止；最终的结果就是原地到读指针的位置； | . | . ##MIDDLE： . | 两数相加，逆序数字链表，相加得到新链表 (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) 输出：7 -&gt; 0 -&gt; 8 数学问题，while循环，得出每次相加的和，并更新新的l1，l2，如果发现其中一个链表比另一个短，和为存在值；更新新链表如果有进位下一个next的val就设置为1，下一次也要加上 T = max(m,n) S = m+n . | 最长回文子串，最长回文子串 ABA AA 中心扩展法，n个ABA类中心，n-1个AA中心，顺序遍历字符串，将i i和i i+1分别由中心扩展求其最大会回文长度，然后在外层循环中更现要返回的最大长度和坐标索引，T=N**2 S=1 动态规划法和中心扩展一样T更大S，Manacher极其复杂 . | 字符串转换整数 (atoi)，符合规则，rstrip前面空格，以+-号或者数字开始，只保留数字 直接处理，先rstrip前面空格，遍历读取，+-加到结果串，数字加到结果串，遇到不是数字break，要求要在32位int范围内，所有可以转为64位int做判断，超过就返回边缘 T=N . | 三数之和，找到所以三元组符合他们的总和是目标值=0 先直接排序，这样将时间锁定在nlogn，三个数字和为0，必然有一数字小于等于0，遍历所有小于0的数字，然后参考两数之和排序的做法，从i位置前面的一个位置和最后一个位置各自一个指针，直到相遇，找他们三个数字和为0的数字，（如果遇到相等的数，直接更新指针）；nlogn 排序双指针法 . | 有效的括号，这种左右两个对称元素的题目，一定要想到用栈，栈先进后出，可以判断括号闭合后，直接都出栈 栈顶存储的，就是最新的左括号，如果栈为空来右括号，直接break，如果不为空，比对栈顶元素和遍历元素是否是同一种括号，是就ok，否就break . | 两两交换链表中的节点 指针操作容易出错，使用递归，暂存next指针，递归更新当前指针的next为暂存的next，更新暂存的next为curr 例如：1 - 2 - 3 - 4，暂存2，递归更新1的next为3的递归，2的next设置为1，递归返回2 第一步暂存1.next 也就是2，第二步更新1的next为2的next，这里就是次操作的递归，第三部更新暂存的2的next为1 思考： 先换第一个和第二个，然后在思考后面怎么换 . | 全排列，递归回溯，backtrack 123 -A- 123，213，312 -backtrack- 23 32，13，31，12，21 – Afor循环将start位置和所有位置swap，然后回溯对剩下位置的数做同样的操作（start+1），1次回溯完成后需要将start和swap在换回来，保证下一次swap操作无误 . | 全排列 II，有重复数字的全排列，需要去除重复的排列 和全排列I同样的循环+回溯+归位，只需要在每一次循环前定义一个set，将每个遍历的数字放入set，如果出现重复直接continue . | 旋转图像，matrix顺时针90度旋转，原地算法 转置矩阵，这表示上下和左右调换，然后在左右翻转 每圈旋转，圈数等于n/2,每圈旋转 T n**2 . | 螺旋矩阵，用顺时针螺旋的方式将矩阵输出为数组 模拟旋转，暴力将原矩阵上右下左切除，最终留下的一个元素就是tail . | 跳跃游戏，每个元素代表能够跳的最大步数，求能不能跳到末尾元素 反证法，不论多少种方式，只要能到末尾就是合法，所以从末尾元素往回跳，如果能到起始元素就，那就表示True 回溯，模拟所有可能性，动态规划在回溯的基础上更新每个点能否跳到末尾，记录memo中，这就是记忆法 检查每一坨0是否能被跳过 . | 合并区间，这题和箭射气球异曲同工，都是要把区间进行合并 必须先排序在做合并，因为如果不做排序需要每次都把剩下的所有区间遍历一次做对比，如果排序之后，就可以直接顺序合并区间，排序的key使用区间的左边界； 气球的问题也类似，因为气球是每次寻找最小集合来射箭，如果不做排序那么有可能会无法处理边界的气球，导致无法达到最优解 . | 简化路径 本题，直接用split函数，直接可以忽略所有的多///和空，包括单点.,用stack存储路径字符，如果遇到双点则直接pop出来前一个目录，最后将join . | 矩阵置零，一个点为0将所有行列设置为0，原地算法 不使用m+n的空间而使用常数空间，本题就是要做记录，然后置0，记录0点所在的行和列，最后统一置0，时间上m*n，如果使用常识空间那就直接用第一行第一列进行记录，但是开始前先用常识记录第一行第一列是否自己有0，最后统一置0 . | 颜色分类，国旗颜色问题，只有012的序列原地排序 双指针边缘监控法，前面的指针放在0的下一个左边，后一个指针放在2的前一个左边，也就是保证指针前后符合要求，cur指针遍历数组，遇到0和前指针互换且指针都前移，遇到2和后指针互换且指针都后移，知道cur和2指针相遇； . | 单词搜索，在二维网格中搜索单词，上下左右相邻字母连接 类似图的深度优先遍历，一次找到和单词中第一个字母相同的字母，从第一个开始就开始用“递归”遍历，当未找到某个字母的时候，回溯在前一个字母，直到回溯回第一个字母还是没有找到结果，就开始对第二个找到的字母做同样的递归，递归需要注意：边界条件和return点，return决定了回溯的情况；对于已经找到的结果可以存储在栈中，python使用list来模拟栈；记得要标记已经使用过的点； . | 解码方法 A-Z的字母由1-26编码，给一个只包含数字的非空串，解答出所有可能的解码数；关于0，0只有在前面是1和2的时候才有意义，如果是0分割了前后的数字则，返回0； 动态规划：1. dp保存到点i为止出现的所有可能之和 2. 通过21～26和11～19可知，对于这种情况的i处的状态就是 dp[i] = dp[i -1] + dp[i-2], 其他情况就是 dp[i] = dp[i - 1] 3. 一次遍历并将条件带入状态转移方程，最终得到结果，特殊情况是0值的考虑，如果是不符合条件的0直接返回0，这样的串无法解码 . | 二叉树的中序遍历，涉及知识点：二叉树的广度优先 深度优先-先中后 栈 队列 迭代 递归 二叉树的深度+递归，先：append 左递归 右递归，中：左递归 append 右递归 后：左递归 右递归 append 二叉树的深度+迭代，栈，用栈来保存每次遍历的节点，每次用while循环找到最后一个左节点 . | 先：同理，将获取值放在找左和取右前 while current: stack.append(current); current = current.left \\N current = stack.pop(-1) ###result.append(current.val)### current = current.right | 中：stack不为空：pop，然后while 循环来找到最左节点，全部push入栈，然后pop出第一个，将其值append到结果，再将其右子树push入栈或者用一个变量暂存右子树，为空就直接pop | 后：Append操作在迭代中的位置 | 先：pop出第一个值放入result，然后pop出的存在就是先右后左入栈 | 中：先找最左，全都入栈，出第一个，给result，然后将cur更新为右 | 后：和先相同，但是改为先左后右，最终在reverse结果串 | 二叉树的广度遍历，层次遍历： | 递归法：于深度遍历的情况相似，就是需要传递一个level参数，这样在每次递归的时候只要更新level+1就可以，按照顺序将result[level].append(val) 当前level初始化前，需要先加入一个空串 | 迭代法：用队列的方式保存当前的读取的节点，步骤 1. 从队列pop出第一个元素 2. 将其左右儿子放入队列，如果不存在，则current_null += 1, 维护一个当前为空的数量 那怎么读取呢：0. 检查当前queue中节点数是否=当前level数的二次方 - last_null *2 - current_null, 符合条件的情况下就是可以完整的读取一个level了，当然每次还要更新last_null = last_null *2 + current_null; current_null = 0 | . | 验证二叉搜素数，左边叶子小于根，右边叶子大于根，二叉搜索树的中序遍历就是有序数组 直接左中序遍历，当有小于排序数组最新点的数字时，返回False，如果用递归的话这里的return要特别注意，左右节点都要检查，且每个节点递归如果返回False，也返回False . | 二叉树的层次遍历 二叉树的广度遍历，并用level记录高度 . | 二叉树的锯齿形层次遍历 递归，迭代，与二叉树的广度遍历相同的逻辑，就是检查当前level的奇偶，然后做insert或者append操作 . | 从中序与后序遍历序列构造二叉树 从后序遍历中的末尾元素可以找到第一个根结点，找到该节点在中序遍历中的位置，此时该位置前的元素为左孩子，后面的元素为又孩子，递归继续对前后两个孩子进行同样操作，难度： 1. 树的还原 2. 递归返回 代码实现：1. 从后序遍历中pop给cur，并获取val， 生成新节点node，2.然后在中序中获取cur的index，3. node right先对右子树进行递归，再对左子树进行递归，因为是反后序遍历的顺序，递归时传入左右边界参数， 这里传入的参数有两个作用，第一用来限定递归次数也就是分割次数，第二使用来判断是否已经到达叶子节点； 0 判断方式就是如果左边界比右边大，那就证明左右边界分割到了同一个点； 时间复杂度分析：本题的时间复杂度设计到主定理，每次将问题分为了2个子问题的规模，并且每次划分为左右子树n的规模变成n/2，由于fn是渐进函数，包含分解问题的代价，但是fn是小于 n的，所以时间复杂度为On . | 二叉树展开为链表， 给定一个二叉树，原地将它展开为链表 从右向左的后续遍历 6 5 4 3 2 1，用一个常量记录last值，把last给当前节点的right，并把当前节点左置空，last更新为当前节点 . # 1 # / \\ # 2 5 # / \\ \\ # 3 4 6 . | 填充每个节点的下一个右侧节点指针 – 完全二叉树、二叉树 . | 还是广度遍历，对每个level的节点进行遍历设置next，除了每个level的开始节点为，其他节点都要在pop完成后left right set null，level开始节点如果存在左右子树，就将右置空 | 从右向左的广度遍历，在一个level的list内的就暂存到下一点将其设为next，检查nextOBJ是否为空，为空赋值，不空获取为next，并更新 | . | 二叉树中的最大路径和 在二叉树中，求可能的最大路径和 边界情况：如果节点为空，那么最大权值是 0 。 对该节点的所有孩子递归调用 max_gain，计算从左右子树的最大权值：left_gain = max(max_gain(node.left), 0) 和 right_gain = max(max_gain(node.right), 0)。 检查是维护旧路径还是创建新路径。创建新路径的权值是：price_newpath = node.val + left_gain + right_gain，当新路径更好的时候更新 max_sum。 对于递归返回的到当前节点的一条最大路径，计算结果为：node.val + max(left_gain, right_gain)。 . | 深度遍历计算每个节点的权值 | . | 复制带随机指针的链表 回溯记忆法，用递归回溯的方式扫描整个链表，并存储已经创建的拷贝； . | hash_map用来保存当前访问的节点深拷贝出来的新节点 1. hash_map 中保存了当前访问节点和初始化的拷贝节点，如果不存在则证明该节点还没创建，拷贝值创建新节点， 并存入hash_map 2. 在已经拷贝过的node里找到了已经新建的node就要直接返回，否则会导致循环递归，最终达到递归上限，3. 同样用递归创建新节点的next，和random，如果存在直接返回； | . | 环形链表 给定一个链表，检查是否存在环 快慢指针游戏，快指针一次走两步，慢指针一次走1步，如果快指针的next为慢指针，或两指针再次相遇，则证明有环；没有的话，指针都会指向NULL . | LRU缓存机制 get(key) - 如果(key) 存在于缓存中，则获取密钥的值（总是正数），否则-1。put(key, value) - 如果密钥不存在，则写入其数据值。当缓存容量达到上限时，它应该在写入新数据之前删除最近最少使用的数据值，从而为新的数据值留出空间。 解法1. 使用python标准库中的driectdic有序字典，新add的元素在末尾，每次被访问的也geng更新到末尾，如果超出capacity就pop0 解法2. 需要一个有序数据结构，不需要遍历就可以获取对象，并调整顺序，并且可以直接add del，双向链表，初始化capacity和head tail的双向链表，新添加的元素放在head之后的第一个，get一次的元素直接找到它并更新到head之后第一个，所以约接近尾部的元素就是超出容量时要删除的，也就是tail的pre指针指向的对象； LinkedHashMap . | 翻转字符串里的单词, 按照单词翻转串 解法1: 先用strip，然后split，然后反向读取list在转为字符串 解法2: 不使用额外n空间，先strip，然后在字符串前加两个空格，然后读取到第一个单词，将开始坐标和单词结束坐标的字符加到字符串末尾并删除，依次对所有单词做同样操作，直到找到末尾坐标（后面出现两个连续空格） 解法3：不使用额外n空间，原地算法，ij双指针，交换每一个元素，原地完全翻转字符串，然后开始遍历，将每一个单词翻转成正向的，还是两个指针，第一个记录每个单词的开始位置，第二个到单词的末尾，开始交换；On O1的原地算法，题目之所以要求使用C语言是因为C的字符串是Char数组结构，可以不开辟新的空间而改变值，其他语言可能是静态量无法直接修改； . | 寻找旋转排序数组中的最小值 直接遍历，找到最小值，返回时间是On 复杂度降低到 logn，做法是对数组进行二分搜索，每次搜索只保留之后，将中间点和数组第一个元素比较大小，如果大，那就是最小值在右侧，如果小则在左侧，直到找到第一个小于其前值的元素，因为翻转后的最小值一定在二分查找分出来的两个序列中，时间复杂度可以从n降低到logn 本题和在一个数组中搜索第n大的数相似，也是使用二分搜索，快速选择法，每次可以确定一个第k大的数，只需要判断第m大的数在其左还是右就可以 . | 寻找峰值 - 找到数组中所有波峰，找到一个就可以 logN 把数组看作二维图表，使用迭代的二分查找或者递归的二分搜索的方法，解法： 1. 递，找出二分搜索的中间，比较是否 中间点的值大于其后一个值，如果大于则证明，中间点位于一个局部下降的位置，那么它左边肯定有至少一个peek点，那么继续对左边做二分搜，如果，中间点的值小于其后面一个值，那么中间点在一个局部上升位，那么它右边肯定有一个peek，递，最终l r相等就可以得到结果； . | \\ down from middle to middle + 1 就证明左边绝对有波峰，/ up from middle to middel +1 就证明右边绝对有波峰 -如果找出所有的波峰，那就只能N了 | . | 比较版本号 .分割，可能有前导0 用split从.分割成数组，然后按照max m n遍历，短的数组，初始值为0，转int比大小 T = O(max(m,n)) S = n, 直接用串比较可以降低空间 . | 二叉搜索树迭代器 首先根据题意，要实现的是一个每次取出最小数的操作，所以，对于一个二叉搜索树，只需要进行中序遍历即可得到一个排序序列 但是要求空间复杂度只能小于等于这个树的高度，且取出和查看都是O(1) . | 对于此要求，第一对树只进行中序的遍历的左边，并将值存入一个栈中 | 每次取出的时候需要对pop出来节点，查看其是否存在右子树，如果存在则将其右子树进行递归，找到下一个最小值 | 递归的过程中，将找到的值push入栈 时间复杂度上 next操作的平均时间复杂度近似为1，最差时间复杂度依然为N | . | 岛屿数量 – 二维数组中找到所有的联通的1，图的遍历， 图的基本算法 BFS - 本题为计算图中的联通图的总数，在一个无向图中找连通分量的数量 BFS，遍历数组从第一个点开始找到第一个不为0的点，以该点为广度优先的起始点，广度优先使用queue保存每个符合条件的1的坐标，按照左上右下的顺序，将符合条件坐标add入queue，并将该点的值设置为0，迭代下一次从队列中poll元素继续order &gt; left - up - right - down 如果只再poll元素出来的时候再将其配置为0，会导致，元素重复添加，导致进入死循环；所以记录完成符合条件的坐标后，直接将状态改变； . | 实现 Trie (前缀树) - 字典树 相似题目： . | 添加与搜索单词 - 数据结构设计 | 单词搜索 II HARD | 数组中两个数的最大异或值 实现方式：初始化一个字典，每次有新单词更新字典树并添加末尾元素 for a in word: if a not in tree: tree[a] = {}; tree = tree[a] tree[”#”] = “#”，搜索单词只要能找到结束符就返回true，找前缀无需匹配#，只要能找到就返回true . | . | 打家劫舍 I II III 题目条件I：不能偷相邻的房间 II：环，最后一间房和第一件也是连在一起的 III：二叉树，不能偷相连的两个 I：动态规划 1. dp状态定义， 将nums中的到当前天的最大金额为dp[i]，每次只有偷和不偷的两种情况 2. 根据要求，不能连续获取数字，可以相隔1到n-2个房间获取，dp[i] = max[dp[i-1], dp[i-2] + nums[i]], 每次遍历获取一个max II：需要考虑条件为首元素和末尾元素相连，那么只有三种情况，偷首不偷尾，偷尾不偷首，都不偷，所以沿用I中的方式，计算两次，第一次1到n-1，第二次0到n-2 III：动态规划 + 二叉树的深度遍历: . | . dp dp-pdf . 对于二叉树，满足条件的情况下，必须每次抢劫都隔一层 0 1 1 1 0 0 0 0 0 0都是可以抢的 所以抢了根节点就不能再抢他的字节点 深度遍历，从左下开始，求每个根节点要抢和不抢的大小 dp: [not_r, r] dp[r] = ndoe.val + dp_sub_l[0] + dp_sub_r[0] 必须是其和其子节点不抢的和，抢了自己就不能在抢自己节点 dp[not_r] = max(dp_sub_l[1],dp_sub_l[0]) + max(dp_sub_r[1],dp_sub_r[0]) 如果该点不抢的话， 它自己的字节点可以抢也可以不抢，抢不抢它的左节点取决于，抢的利润和不抢的利润，所以这里右边也一样 . def dp_recursive(node): if not node: return [0,0] dp_sub_l = dp_recursive(node.left) dp_sub_r = dp_recursive(node.right) dp_r = node.val + dp_sub_l[0] + dp_sub_r[0] dp_not_r = max(dp_sub_l[1],dp_sub_l[0]) + max(dp_sub_r[1],dp_sub_r[0]) return [dp_not_r, dp_r] return max(dp_recursive(root)) . | 数组中的第K个最大元素，找到未排序数组总第k个最大的数 一次快排，最终达成的目的就是在序列的n-k的位置， 快速选择，与快速排序类似，快速选择算法在平均状况下有着不错的表现，但是对于基准值的选择十分敏感。如果基准值选择上佳，搜索范围每次能够指数级减少，，这样一来所耗时间是线性的(即O(n))。但如果基准值选择非常不好， 实现，找到基准值，完成第一次排序，检查当前基准值的坐标和n-k的大小，如果小，在左侧继续排序，右侧同理，左右选择函数和排序函数可以分开写；排序可以双指针替换或者单指针比较； . | 最坏时间复杂度 О(n2) 最优时间复杂度 О(n) 平均时间复杂度 O(n) 最坏空间复杂度 O(1) | . | 用栈实现队列 Queue, Stack 一进一出两个栈实现队列，in用来add新元素，peek和pop操作，把in中的全部pop出来然后取最后一个剩下的push入out，获取到值后，在把out中的push入in . | Stack: push to top, peek/pop from top, size,is empty | Queue: push, pop, peek, empty | . | 二叉搜索树的最近公共祖先 对于找到二搜索树的最近祖先，考虑四种情况，1.p或者q就是root 2.root在p q之间，直接返回root 3. p q都在root左边，更新root left 3. p q都在root右边，更新root right . | 二叉树的最近公共祖先 递归，回溯 . | 对二叉树进行深度优先遍历并将每一个非叶子节点添加到缓存栈中 | 当找到第一个匹配后，立即停止再向缓存栈中添加节点，因为此时的答案已经在栈中了 | 递归回溯，将没有匹配的节点从缓存栈中移除 | 找到第二个匹配项后，返回栈顶节点 @@ 需要考虑跟节点就是匹配节点的情况，需要考虑叶子节点的情况，需要考虑匹配节点本身就是答案的情况； 找到第二个元素返回True，这时候整个递归都会返回，并且不再修改结果 if find: return True 找到第一个元素后在find数组中标记 并且将第一个找到的元素也考虑在可能的答案根结点上 考虑末尾节点，当节点为叶子节点时，直接对该节点返回False return False 如果当前匹配第一次的节点就是叶子节点，需要将该节点移除缓存栈 if stack[-1] == node: stack.pop(-1) 没有匹配的情况下，需要将每个非叶子节点加入缓存栈 if not find: stack.append(node) 对左右子树递归 if node.left: if depth_search(node.left, p, q): return True 如果没有一次匹配则回溯到本节点后从缓存栈移除 if not find or stack[-1] == node: stack.pop(-1) 如果当前节点就是缓存栈顶部节点，则移除，因为上面的左右子树递归没有找到第二个匹配项 | . | 除自身以外数组的乘积 1. dp i的结果等于dpinumsi dp0=1 2.相反的顺序做同样的操作dpi = dpi p * numsi-1 # a1, a2, a3, a4 # 1, 1*a1, 1*a1*a2, 1*a1*a2*a3 # a1, a2, a3, a4 # a4*1*a3*a1, a4*1*a3, a4*1, 1 . | 各位相加 数学问题，10x + y = z； x + y = z - 9x； a + b + c = z - (99a + 9b) = z - 9(11a + b) =》z - 9k z%9 if num == 0: return 0； eturn num % 9 if num % 9 &gt; 0 else 9 . | 缺失数字 [3,0,1] 输出：2 异或的第一个数字为数组长度是因为，如果是正常数组，最大值就是少一位的数组长度 位运算，位运算中相同数字经过^异或运算后得到0，所以对整个序列好正常序列经过异或后的到的就是： 缺失值^目标序列最大值 而目标序列最大值正好就是目标序列的长度 . | 最长上升子序列 解法1: 使用动态规划： . | . | 状态定义： dp[i] 表示到索引i为止的最长升序序列的长度值 | . | . | 状态转移：转移条件：序列索引上升，这时候需要考虑此索引前面每一个状态长度和当前值的关系得到最佳结果，如：比较当前值和该索引i前的每一个值的大小，如果出现大于前面索引值dp[j]的情况需要考虑在当前值和dp[j] + 1 中获取最大值，即表示最长升序 | . | 解法2 动态规划 + 二分查找 | . | 对解法1中的状态定义换一个角度，解法1中的状态定义的长度为dp[i]的值，这里的状态定义将换成保存到i为止的升序（严格来说不是i-1处的真正的升序序列）序列，而1中的dp值就是现在的dp序列的长度；这样就可以在此dp序列上进行目标元素的替换从而不影响上一个序列的长度； | . | 例如：2， 3， 4， 7， 10， 11， 6， 8， 9 ，10 | i = 5， dp = 2，3，4，7，10，11 | i = 6， dp = 2，3，4，6，10，11 | 这里状态的转移是将7替换成了6从而能够在目标序列中继续找升序序列，但是并没有影响当前找到的最大升序序列的长度，最终如果找到了新最小值（7被6替换表示，6替换了dp中第一个大于它自身的数字）从而得到了一个更长的序列例如找到最大数后append操作，最终新的长度也覆盖了上一次最长上升长度，而替换和append操作则可以使用二分查找的方式来实现； | 这里的难点在于： dp数组会对当前最长的长度进行保留并且也会在每个索引的位置上讲后续升序的潜在可能性提高到最高，比如大于6的正整数比大于7的正整数多； 重点： dp数组，1. 保存了到当前索引的最大升序长度 2. 保存了当前索引前替换发生前的dp状态和替换后的双重状态； | . | 水壶问题 数学问题， 类似3加仑和4加仑的桶到处5加仑水的问题： 数学问题 裴蜀定理，任意两个正整数a，b的公约数d，有xa+yb = d的倍数，也就是此题中结果想要得到的水的容量需要“满足他是两个水壶容量的最大公约数的倍数”； def _gcd(x, y): if y == 0: return x; z = x % y; return _gcd(y, z); x和y的公约数 . | 甲板上的战舰，和岛屿问题属于同一种类型，就是使用图的广度遍历找特殊条件的连通分量 if board[i][j] == “X”: if (i &gt; 0 and board[i - 1][j] == “X”) or (j &gt; 0 and board[i][j - 1] == “X”): continue count += 1 . | 两数相加 II 链表-(7 -&gt; 2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) 输出: 7 -&gt; 8 -&gt; 0 -&gt; 7 高位在左 解法1: 思想：暂存栈，存储之后pop相加，对L1 L2两个链表进行暂存存储在栈中，因为栈的push和pop操作又后进先出的特点，所以对两个栈进行相加并生成新的链表，就可以得到最终L1 L2之和的链表的结果；Om+n 解法2: 获取长度，对同位部分使用递归的方式相加，递归的return可以返回相加的进位，如此就可以处理进位的问题； 重点看下解法2: 1. 先同时遍历两个链表，获取两个链表的长度，n1 n2，确保n1 l1永远都是长的那个， 2. 开始递归操作， nums1为长串，在长串本身上进行修改，temp值为该点值加进位值，递归调用i.next — if num1 &gt; num2: temp = i.val + add(num1 - 1, num2, i.next, j) 递归调用直到两个长度相等，继续递归相同长度的两个链表，— else: temp = i.val + j.val + add(num1, num2, i.next, j.next) 当i next和j next到达末尾时，第一次返回，相加并修改i的值为tmp%10，返回进位值1或者0 — i.val = temp % 10 前一个相加会继续更新，直到返回到num1》num2的位置 — return temp // 10， 最后的答案如果有进位则在l1前加一个1 . | 用最少数量的箭引爆气球 - 排序后找最小相交点，所以能最小相交的则用一个箭 贪心算法 贪心算法的思想是每一步都选择最佳解决方案，最终获得全局最佳的解决方案。 . | 对于此题来说所有气球坐标最小和坐标最大的之间尽量使用最少的箭来引爆，对于每一个气球来说最好能找到与其坐标香蕉的气球，对每一个气球来说都是找到该气球下的最优解；sorted(points, key= lambda x:x[1]) 用右边排序是要将最小范围放在最左边，遍历每次更新l r的值，直到找到一个不符合的 | for v1, v2 in points: if v1 &gt; end: arr_n += 1 end = v2; | . | 找树左下角的值 - 广度优先，从右往左开始遍历，最后一个就是树左下角的值，最低一层 迭代，使用队列从右往左广度优先遍历整个树，输出最后一个元素就是最后一行最左边的元素 广度的迭代需要加 level + 1，每次遍历一次就更新一次值，遍历完成了也就是答案了 . | 字符串的排列 暴力法就是生成s1的所有排列，也就是s1的全排列，在使用KMP法再s2中进行子串搜索； 与kmp类似的方法是滑动窗口，通过子串在目标串的滑动过程中来记录窗口中的关键信息，从而实现算法时间复杂度的最优； 窗口前后元素更新比对法，在s1中找到所有字符的数量，不断更新map2直到map2于map1相等，如果遇到没有的元素直接跳过 count法，第一次去l1 l2的相同索引元素，并且把已经符合条件的做一个count，然后更新map2，map2的新入元素和出元素不同的情况下，如果构成了新的map1i=map2i count就加一，如果出现超出一个元素则count– . | 所以股票问题 买卖股票的最佳时机，动态规划 ``` 状态穷举： dp[i][k][0]: 表示第i天剩余k次交易的时候，没持有股票时手上的利润，两种可能延续了前一天没有股票，今天刚刚卖出股票，在这两种可能中找出最大值 dp[i][k][1]: 表示第i天剩余k次交易的时候，持有股票时手上的利润，两种可能延续了前一天持有的股票，今天刚买进股票，在这两种可能中找出最大值 . | . base case： dp[-1][k][0] = dp[i][0][0] = 0 dp[-1][k][1] = dp[i][0][1] = -infinity . 状态转移方程： dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]) dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]) . 52. 只有两个键的键盘 对于n个A，的最少操作次数 &gt; n = x*y*z 表示 1次复制，x-1次粘贴，刚好是x次操作，完成后是x个A，这里得到的结果就是 x +y+z要求是最小，那么xyz一定都是素数 &gt; 对n分解素数： pn_start = 2; while n &gt; 1: while n%pn_start == 0: result += pn_start n /= pn_start pn_start += 1 &gt; T = 根号n 53. 最大二叉树，无重复数组中，最大值左边是左子树，右边是右子树 &gt; 实现两个函数，第一个是生成 node node.left node.right 的递归函数，用来构造二叉树，第二个是一个输入为一个l和r的着l r之间最大值的函数；两个函数都需要传入l r 54. 灯泡开关I II &gt; I： 分析方法，画出自定义的n个灯泡的情况，不难发现，每个数字都有奇数个或者偶数个因数，比如9 1 9 3而12为1 12 3 4，从而可以看出只有奇数个因数的序号的灯泡会进行奇数次操作，最终结果为亮着的状态，而判断一个数字的因数是否为奇数个也很简单就是看该数字是否是平方数；答案为返回平方数的个数； &gt; II： &gt; Solution: 状态枚举，按位操作 &gt; 解法，首先列出前6个灯的所有可能性 &gt; Light 1 = 1 + a + c + d &gt; Light 2 = 1 + a + b &gt; Light 3 = 1 + a + c &gt; Light 4 = 1 + a + b + d &gt; Light 5 = 1 + a + c &gt; Light 6 = 1 + a + b &gt; 前三个灯已经包含了所有会出现的可能性，第五个和第六个灯的状态和第三个第二个完全一致，第四个灯地状态等于前三种开关状态之和，也就是前三种状态完全决定了第四个灯的状态； &gt; 此时由上述分析可知，前三个灯的状态决定了全部灯在序列里状态的可能性，所以只需要分析前三个灯在所有操作次数的可能性所有情况 &gt; 只需要考虑m分别为0，1，2的三种特殊情况下的前三灯的特殊状态，当m&gt;=3的时候前三个灯将包括他所有可能的亮灭过程，分别为2，4，8； &gt; 重点：1.分析前三个灯决定了所有灯的状态，2.分析操作次数大于等于3的情况下前三个灯将包含其所有可能的状态，因为前三个灯最多操作的是三种操作叠加，所以当操作次数为3的情况下，前三灯的所有的情况都可以包括； &gt; T: O(1) S: O(1) . ",
    "url": "/docs/archives/2020/2020-03-02-Algorithm-curve/#%E5%81%9A%E9%A2%98%E8%B7%AF%E5%BE%84-%E9%87%8D%E8%A6%81%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3",
    
    "relUrl": "/docs/archives/2020/2020-03-02-Algorithm-curve/#做题路径-重要算法思想"
  },"111": {
    "doc": "My Algorithm Curve",
    "title": "python",
    "content": "class Solution(object): def flipLights(self, n, m): n = min(n, 3) if m == 0: return 1 if m == 1: return [2, 3, 4][n-1] if m == 2: return [2, 4, 7][n-1] return [2, 4, 8][n-1 ] . 55. 删除注释 . in_block = False ans = [] for line in source: i = 0 if not in_block: newline = [] while i &lt; len(line): if line[i:i+2] == ‘/’ and not in_block: in_block = True i += 1 elif line[i:i+2] == ‘/’ and in_block: in_block = False i += 1 elif not in_block and line[i:i+2] == ‘//’: break elif not in_block: newline.append(line[i]) i += 1 if newline and not in_block: ans.append(““.join(newline)) . return ans ``` . ",
    "url": "/docs/archives/2020/2020-03-02-Algorithm-curve/#python",
    
    "relUrl": "/docs/archives/2020/2020-03-02-Algorithm-curve/#python"
  },"112": {
    "doc": "My Algorithm Curve",
    "title": "重要定理及延伸",
    "content": ". | 主定理： | . 情况1, 若𝑓(𝑛) &lt; 𝑛𝑙𝑜𝑔𝑏𝑎, 则复杂度为 T(n)=O(n ^ {log_b a}); 情况2, 若f(n) = n ^ {log_b a}, 则复杂度为T(n)= O(n ^ {log_b a} * lgn); 情况3, 若f(n) &gt; n ^ {log_b a}, 则复杂度为T(n)=O(f(n)); . 快排： T(n) = 2T(n/2) + n . | 斐波那契 fib if N &lt;= 1: return N return self.fib(N-1) + self.fib(N-2) . 斐波那契数列在数学中的重要意义 . | . 3.常见排序思想： . | 快速排序：利用二分法，每次的基准数和其他数比较大小，找到自己位置，在对两边做二分递归。时间复杂度使用主定理 | 桶排序，0～n之间的数，要n个桶，每个桶装和自己序号相等的数的数量，最后遍历桶，将数展开；m+n m是桶长度 | 冒泡排序，每次两两比较，将最大数放在最后一个位置，然后继续找第二大的数，用n**2的时间复杂度，将所有的数冒泡到自己的位置； | 堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。 a.将无需序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆; b.将堆顶元素与末尾元素交换，将最大元素”沉”到数组末端; c.重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序。 | . ###HARD的题目 待完成题目： 211. 添加与搜索单词 - 数据结构设计 212. 单词搜索 II 421. 数组中两个数的最大异或值 . ##HARD：HARD的题目至少每个要看一遍 . | 寻找两个有序数组的中位数，将一个集合划分为长度相等的子集的数字 https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xun-zhao-liang-ge-you-xu-shu-zu-de-zhong-wei-shu-b/ . | 合并K个排序链表 基于两个链表合并的算法，我们将k中每两个链表合并一次得出的新的集合再进行同样的操作，最终得到一个集合，T = kN 将 k 个链表配对并将同一对中的链表合并。第一轮合并以后， k 个链表被合并成了 k/2 个链表，平均长度为 2N/k 重复这一过程，直到我们得到了最终的有序链表。每次k的数目指数型下降，例如k k/2 k/4 k/8 S = Nlogk . | K 个一组翻转链表 类似两两交换，使用递归，先检查当前cur=cur.next指针是不是有k个点，有的话当前的cur为第k+1个点并进行递归返回反转完成后的head，没有则直接返回cur， 那么第一个进行反转的一定是最后一个k，反转的方法是 head.next = cur，cur = head，将head的next指向cur也就是尾部，更新尾部为head，这样head就被放在了尾部和尾部的前一个直接，记得保存head.next最后更新head，迭代操作直到k次，此时cur就是真正的head，将head返回给上一个递归重复此操作 . | 搜索旋转排序数组，nums = [4,5,6,7,0,1,2], target = 6 解法1: 两次二分查找，第一次找到分界点，数组中点i i-1 i+1 是否升序是否都比第一个数小，找到第一个比index0小的数字就向左边找； 找到分界点后再用二分搜索目标值 解法2: 一次二分查找，其实就是将两次二分查找相结合，重点在于利用index0的值，先比较目标值和index的大小，确定是在分界点左边还是右边，然后二分，二分点如果大于index0，证明二分点在左，小于证明二分点在右边，这样就可以定位下一次二分是在左还是在右，二分点和目标值也要对比； 时间复杂度logn，二分查找快速选择都是logn . | 地下城游戏 | 单词搜索 II | 天际线问题 | 整数转换英文表示 分治具体的方法实现； . | 每三位分出当前总数，题目要求是小于2**31 -1 = 1024 * 1024 * 1024 -1 所以可以确定需要转换的数在百万以内，确定数字的 bilion million thousand | 将每个3位的单位数前面的数字转换成因为，有三种转换方式第一10以内，第二100以内，第三999以内，并且不重复； | 将三种方法的函数实现并将进位的函数实现，题目就可以解出； | . | 二叉树的序列化与反序列化 string += str(node.val) + “,” string = recursive_serializer(node.left, string) string = recursive_serializer(node.right, string) node = TreeNode(data[0]) data.pop(0) node.left = recursive_serializer(data) node.right = recursive_serializer(data) . | . 其他 . 数组处理： 查找、排序、排列、搜索、合并、子串搜索、滑动窗口、贪心、局部最优，kmp-确定有限状态自动机 动态规划：最长升序数组、打家劫舍问题、股票问题 图处理：二维数组中找联通图数量，找特殊条件的连通图数量，深度广度 二叉树：前中后，深度广度、二叉搜索树、完全二叉树、满二叉树、迭代和递归 链表：指针操作，next指针的操作变化 . 其他特殊： 素数求解，筛就完事了，欧拉筛法 . | python的list的底层是一个C的结构体，类似于vector，有自身的capacity，存储结构就是一个数组，存储list的每个对象的指针，不是链表 . | 假设有数组 [a b c d e f g h ]，一个大小为 3 的 滑动窗口 在其上滑动，则有： [a b c] [b c d] [c d e] [d e f] [e f g] [f g h] 一般情况下就是使用这个窗口在数组的 合法区间 内进行滑动，同时 动态地 记录一些有用的数据，很多情况下，能够极大地提高算法地效率。 本题求解思路： . | . ",
    "url": "/docs/archives/2020/2020-03-02-Algorithm-curve/#%E9%87%8D%E8%A6%81%E5%AE%9A%E7%90%86%E5%8F%8A%E5%BB%B6%E4%BC%B8",
    
    "relUrl": "/docs/archives/2020/2020-03-02-Algorithm-curve/#重要定理及延伸"
  },"113": {
    "doc": "My Algorithm Curve",
    "title": "My Algorithm Curve",
    "content": "Algorithm . 2020-03-02 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-02-Algorithm-curve/",
    
    "relUrl": "/docs/archives/2020/2020-03-02-Algorithm-curve/"
  },"114": {
    "doc": "知识碎片",
    "title": "Python",
    "content": "1. python数组反转 . list(reversed(a)) #reversed(a)返回的是迭代器，所以前面加个list转换为list sorted(a,reverse=True) a[: :-1] #其中[::-1]代表从后向前取值，每次步进值为1 . 2. 类继承 class 关键字 . | 使用 class 关键字修改实例的类型引用 | . ",
    "url": "/docs/archives/2020/2020-03-07-capsule/#python",
    
    "relUrl": "/docs/archives/2020/2020-03-07-capsule/#python"
  },"115": {
    "doc": "知识碎片",
    "title": "Linux",
    "content": "1. proc目录下cpuinfo检查 . | 查看 CPU 物理个数 　　grep 'physical id' /proc/cpuinfo | sort -u | wc -l . | 查看 CPU 核心数量 　　grep 'core id' /proc/cpuinfo | sort -u | wc -l . | 查看 CPU 线程数 　　grep 'processor' /proc/cpuinfo | sort -u | wc -l . | 查看 CPU 型号 　　dmidecode -s processor-version . | 查看 CPU 的详细信息： 　　cat /proc/cpuinfo . | . 2. CentOS 7 修改时区 . # cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # timedatectl list-timezones # 列出所有时区 # timedatectl set-timezone Asia/Shanghai # 设置系统时区为上海 # timedatectl set-local-rtc 1 # 将硬件时钟调整为与本地时钟一致, 0 为设置为 UTC 时间 . 3. iptables基础 . iptables -t nat -L . 4. 在ls中列出文件的绝对路径 . ls | sed \"s:^:pwd/:\" . #在所有行之前/后加入某个字符串 sed 's/^/string/g' file sed 's/$/string/g' file find $PWD -maxdepth 1 | xargs ls -ld # 列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归 find $PWD | xargs ls -ld # 递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径 . ",
    "url": "/docs/archives/2020/2020-03-07-capsule/#linux",
    
    "relUrl": "/docs/archives/2020/2020-03-07-capsule/#linux"
  },"116": {
    "doc": "知识碎片",
    "title": "Windows",
    "content": "1. Windows下的TCP连接检查 . netstat -ant | findstr . | window下查看TCP端口连接情况：netstat -ano -p tcp | findstr 8080 | . ",
    "url": "/docs/archives/2020/2020-03-07-capsule/#windows",
    
    "relUrl": "/docs/archives/2020/2020-03-07-capsule/#windows"
  },"117": {
    "doc": "知识碎片",
    "title": "知识碎片",
    "content": "Capsule . 2020-03-02 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-07-capsule/",
    
    "relUrl": "/docs/archives/2020/2020-03-07-capsule/"
  },"118": {
    "doc": "C programming language recap",
    "title": "C recap",
    "content": "This file is a recap of programming language C, prepare for C++ learning . #include &lt;stdio.h&gt; // 引入包含头文件 int main() { // main 是程序执行的开始 printf(\"%s\\n\", \"shit happens\"); return 1; } . 通用高级语言，为Unix操作系统设计，以B语言为基础 . | 结构化 | 处理底层活动 | C11，ISO标准 | . /* GCC c源代码经过编译转为机器语言（CPU指令） 免费开源的编译器GNU的C/C++编译器 https://gcc.gnu.org/ https://github.com/gcc-mirror/gcc https://zh.wikipedia.org/wiki/GCC . The GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Ada, Go, and D, as well as libraries for these languages (libstdc++,…). GCC was originally written as the compiler for the GNU operating system. The GNU system was developed to be 100% free software, free in the sense that it respects the user’s freedom.”GNU’s Not Unix!” . gcc-core、gcc-g++、binutils gcc、g++、ar、ranlib、dlltool . 编译原理 LLVM GCC CLANG . GNU make https://hacker-yhj.github.io/resources/gun_make.pdf https://www.gnu.org/software/make/manual/make.html#toc-Overview-of-make https://www.gnu.org/software/make/ . c程序 . | 预处理函数指令 . | 函数 . | 变量 . | 语句&amp;表达式 . | 注释 . 简单了解编译 gcc xxx.c 生成 xxx.out 可执行文件 gcc x.c xx.c -o . | . tokens . | 分号 | 注释 | 识符 大写字母或小写字母或下划线开始，后面跟多个字母、下划线、数字 | 关键字，保留关键字 . | auto 变量自动声明 | break 跳出当前循环 | case switch分支 | char 声明字符型变量或函数返回类型 | const 定义常量 | continue 从continue直接开始下一轮循环 | default switch的默认分支 | do 循环语句执行体 | double 双精度浮点数声明 64比特 8个字节 | else 条件语句分支 | enum 声明枚举类型 | extern 声明变量或者函数再外部文件 | float 声明福鼎类型 32比特 4个字节 | for 循环 | goto 无条件跳转 | if 条件语句 | int 整形声明 | long 长整型声明 | register 声明寄存器变量 | return 返回 | short 短整形 | signed 声明有符号类型变量或者函数 | static 静态变量 | struct 声明结构体类型 | switch 开关条件语句 | typedef 给数据类型取别名 | unsigned 声明无符号类型变量或函数 | union 声明共用体类型 | void 声明 无返回或无参数 无类型指针 | volatile 变量在执行中被隐含的改变 | while 循环条件语句 | _Bool | _Complex | _Imaginary | inline | restrict | _Alignof | _Atomic | _Generic | _Noreturn | _Static_assert | _Thread_local | | . | . 数据类型，类型决定了占用的存储空间（详见体系结构） . | 基本类型：算数类型，包括整数类型和浮点类型 | 枚举类型：算术类型，用来定义程序中“只能赋予其一定的离散整数值的变量” | void类型：没有可用的值 | 派生类型； 包括，指针类型、数组类型、结构类型、共用体类型和函数类型 | . | 数组类型和结构类型统称为聚合类型； . | 函数类型指的是函数返回值的类型； . | 整数类型 . | 类型 存储大小 值范围 A为65 a为97 . | char 1 byte -128 到 127 或 0 到 255 . | unsigned char 1 byte 0 到 255 无负值的字符型 . | signed char 1 byte -128 到 127 . | int 2 或 4 byte -32,768 到 32,767 或 -2,147,483,648 到 2,147,483,647 32比特位整型和64比特位整型 . | unsigned int 2 或 4 byte 0 到 65,535 或 0 到 4,294,967,295 无负值的整型 . | short 2 byte -32,768 到 32,767 32比特位整型 . | unsigned short 2 byte 0 到 65,535 无负值的短整型 . | long 4 byte -2,147,483,648 到 2,147,483,647 64比特位整型 . | unsigned long 4 byte 0 到 4,294,967,295 无负值的长整型 . i686和x86_64中的存储大小不同，当前操作系统主要以x86_64为主 . | . | sizeof(type) . | 用来获取某个对象或类型的存储字节大小 . | printf() 函数 . | format – format 标签可被随后的附加参数中指定的值替换，并按需求进行格式化。 . | format 标签属性是 %[flags][width][.precision][length]specifier . | 格式化输出 . | %d 十进制有符号整数 . | %u 十进制无符号整数 . | %f 浮点数 . | %s 字符串 . | %c 单个字符 . | %p 指针的值 . | %e 指数形式的浮点数 . | %x, %X 无符号以十六进制表示的整数 . | %o 无符号以八进制表示的整数 . | %g 把输出的值按照 %e 或者 %f 类型中输出长度较小的方式输出 . | %p 输出地址符 . | %lu 32位无符号整数 . | %llu 64位无符号整数 . https://www.runoob.com/cprogramming/c-function-printf.html . | . | . | . | 浮点类型 . | float 4 byte 1.2E-38 到 3.4E+38 6 位小数 | double 8 byte 2.3E-308 到 1.7E+308 15 位小数 | long double 16 byte 3.4E-4932 到 1.1E+4932 19 位小数 | %E 为以指数形式输出单、双精度实数 | . | void类型 . | 指定没有可用值 . | . | 函数返回为空 function define以 void开头 . | 函数参数为空 不接受参数的函数； . | 指针指向void 类型为void 的指针代表对象的地址，指向void的地址，也就是xx存储了void在内存中的地址； . | . | . | . C 变量 . | 定义：变量是程序可操作的存储区的名称； . | C中每个变量都有特定类型，类型决定了变量存储的大小和布局，该范围内的值都可用存储在内存中； . | 变量的名称由字母+数字+下划线组成，以字母或者下划线开始，区分大小写； . | char 一个字节，8bit | int 整数时最自然的大小 | float 格式：1bit符号，8bit指数，23bit小数 | double 格式：1bit符号，11bit指数，52bit小数 | void 类型缺失 | . | C 变量定义 . | 变量定义就是告诉编译器在何处创建变量的存储，以及如何创建变量的存储； | 变量定义指定一个数据类型，并包含给类型的一个或者多个变量列表 | type variable_list | 指定类型 变量名称列表 | . | . int i, j, k; extern int a = 1, b = 2; //不带初始化的定义：带有静态存储时间的变量会被隐式初始化为NULL （所有字节的值都为0），其他变量初始值时未定义的； . C 变量声明 . | 变量声明向编译器保证变量以指定的类型和名称存在； | 变量声明在编译时才有意义，在程序连接时编译器需要实际的变量声明； | . | 建立存储空间的变量声明，例如 int a | 不需要建立存储空间的变量声明，使用extern关键字声明比变量名而不定义它； extern int a，a被声明但是可能在其他文件中被定义； . | 除了extern的情况外，变量都是被定义的； | 使用extern在一个文件中声明，在另一个文件中引用才会定义； | . | . extern int a; int b; . 左值和右值 Lvalues Rvalues . | 左值 lvalue ： 指向内存位置的表达式被称为左值表达式，可用出现在赋值号的左边或者右边 | 右值 rvalue ： 存储在内存中的某些地址的数值，只能出现在赋值号的右边；例如，存储在内存某个地址的一个8bit ASC字符 . | 左值： 指向内存位置的表达式 | . | . 常量 . | 常量，字面量； | 值在定义后不能修改； . | 整数常量 . | 十进制、八进制、十六进制的常量； | 前缀指定基数：0x或0X表示十六进制，0表示八进制，不带默认表示十进制； | 后缀U表示无符号整数（unsigned） | 后缀L表示长整数（long） | 后缀可用大写也可以小写； | . | 浮点常量 . | 整数部分、小数点、小数部分、指数部分组成； | 使用小数形式或者指数形式来表示 | 指数符合e\\E | 指数形式要包括小数点或者指数 | . | 字符常量 . | 使用 ‘单引号’ 存储在char类型的变量里；指向内存地址的可操作区域的名称，指向内存地址的表达式 | 转义符 . | \\ \\ 字符 | ' ‘ 字符 | \" “ 字符 | \\? ? 字符 | \\a 警报铃声 | \\b 退格键 | \\f 换页符 | \\n 换行符 | \\r 回车 | \\t 水平制表符 | \\v 垂直制表符 | \\ooo 一到三位的八进制数 | \\xhh . 一个或多个数字的十六进制数 | . | . | 字符串常量 . | 字符串在“双引号中” | . | 常量定义 . | #define | const | 代码规范：使用大写表示常量 | . | . #define identifier value; // 预处理定义 标识符 值 #define TIMEOUT 30; const type variable = value; // 常量定于 类型定义 变量名称（指向内存可操作区） 变量值（可操作区存储该值) . 存储类 . | 存储类定义C中变量和函数的范围（可见性）和生命周期； | 放在所修饰的类型之前； . | auto | register | static | extern | . | auto存储类 . | 是所有局部变量的默认存储类； | . { int m; auto int m; // 上面两个带有相同的存储类，auto只能用于函数内，只能修饰局部变量； } . | register 存储类 . | 定义存储在寄存器中而不是RAM中的局部变量； | 变量的最大size为寄存器的size； | 通常为1个词，不能对它应用一元“&amp;” 运算符，因为变量没有内存位置 | . { register int s; // 寄存器用于需要快速访问的变量，例如计数器 // 定义‘register’ 并不会绝对将变量存储在寄存器内，取决于硬件的实际限制； } . | static 存储类 . | 编译器在程序生命周期内保持局部变量的存在，而不需要在每次进入和离开作用域时都进行创建和销毁； static 修饰局部变量可用在函数调用之间保持局部变量的值； | static 修饰符也可以用于全局变量，修饰全局变量时，会使得变量的作用域限制在声明它的文件中； | 全局声明的一个static变量或者方法，可以被任何函数或者方法调用；前提时这些变量和方法与static全局变量在同一个文件中； | . static int c = 999; // 全局变量 - static 是默认的 void func1(void) { static int t = 1; // t 是函数func的局部变量，使用static后，该变量在函数第一次被调用时初始化，以后每次都不会在被重置； // 在程序的生命周期内会永远保留该局部变量的值； t ++; printf(\"%d %d\\n\", t, c); } . | extern 存储类 . | extern 存储类用于提供一个全局变量的引用，全局变量被extern修饰后，在程序的所有文件都可见； 使用extern，对于无法初始化的变量（相同变量名称已经在其他文件中定义过，extern声明会直接声明定义过的这个变量的地址），会把变量名指向之前定义过的一个存储位置； | 多个文件中定义了一个可以在其他文件中使用的全局变量或函数时，可以在其他文件中使用extern来得到已经定义的变量或函数的引用（引用就是存储了变量地址的表达式，而指针变量是存储了变量地址的变量的地址的表达式） | . // main.c #include &lt;stdio.h&gt; int count; extern void fun_from_another_file(void); //声明外部函数，函数定义在其他文件中 int main(int argc, char const *argv[]) { /* 可以直接使用本文件定义的静态全局变量 count */ return 0; } // 该文件中可以使用定义的外部全局函数 . | . 运算符 . | 算数运算符 | 关系运算符 | 逻辑运算符 | 位运算符 | 赋值运算符 | 杂项运算符 . | 算数运算符 . | / 分子除以分母 . | % 取模运算符，整除后的余数 . | ++ 自增运算符，整数值增加 A++ . | – 自减运算符，整数值减少 A– . | . | 关系运算符 . | == 检查两个操作数的值是否相等，如果相等则条件为真。 (A == B) 为假。 | != 检查两个操作数的值是否相等，如果不相等则条件为真。 (A != B) 为真。 | . | . 检查左操作数的值是否大于右操作数的值，如果是则条件为真。 (A &gt; B) 为假。 &lt; 检查左操作数的值是否小于右操作数的值，如果是则条件为真。 (A &lt; B) 为真。 = 检查左操作数的值是否大于或等于右操作数的值，如果是则条件为真。 (A &gt;= B) 为假。 &lt;= 检查左操作数的值是否小于或等于右操作数的值，如果是则条件为真。 (A &lt;= B) 为真。 . | 逻辑运算符 . | &amp;&amp; 称为逻辑与运算符。如果两个操作数都非零，则条件为真。 (A &amp;&amp; B) 为假。 | |   | 称为逻辑或运算符。如果两个操作数中有任意一个非零，则条件为真。 (A |   | B) 为真。 | . | ! 称为逻辑非运算符。用来逆转操作数的逻辑状态。如果条件为真则逻辑非运算符将使其为假。 !(A &amp;&amp; B) 为真。 | . | 位运算符 . | &amp; . | 按位与操作，按二进制位进行”与”运算。运算规则： | . | . | 按位或运算符，按二进制位进行”或”运算。运算规则： | . | . | 异或运算符，按二进制位进行”异或”运算。运算规则： 寄存器中的加法运算，就是用异或，“二进制的不进位相加” | . | ~ . | 取反运算符，按二进制位进行”取反”运算。运算规则：一个有符号二进制数的补码形式。 . 原码：原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值. 比如如果是8位二进制: 反码：正数的反码是其本身； 负数的反码是在其原码的基础上, 符号位不变，其余各个位取反. 补码：正数的补码就是其本身； 负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1) https://www.cnblogs.com/zhangziqiu/archive/2011/03/30/computercode.html 机器中码的处理，体系结构 . | . | « . | 二进制左移运算符。将一个运算对象的各二进制位全部左移若干位（左边的二进制位丢弃，右边补0）。 | . | &gt; &gt; . | 二进制右移运算符。将一个数的各二进制位全部右移若干位，正数左补0，负数左补1，右边丢弃。 | . | . | . 赋值运算符 . | = 简单的赋值运算符，把右边操作数的值赋给左边操作数 C = A + B 将把 A + B 的值赋给 C | += 加且赋值运算符，把右边操作数加上左边操作数的结果赋值给左边操作数 C += A 相当于 C = C + A | -= 减且赋值运算符，把左边操作数减去右边操作数的结果赋值给左边操作数 C -= A 相当于 C = C - A | *= 乘且赋值运算符，把右边操作数乘以左边操作数的结果赋值给左边操作数 C *= A 相当于 C = C * A | /= 除且赋值运算符，把左边操作数除以右边操作数的结果赋值给左边操作数 C /= A 相当于 C = C / A | %= 求模且赋值运算符，求两个操作数的模赋值给左边操作数 C %= A 相当于 C = C % A | «= 左移且赋值运算符 C «= 2 等同于 C = C « 2 | &gt;&gt;= 右移且赋值运算符 C »= 2 等同于 C = C » 2 | &amp;= 按位与且赋值运算符 C &amp;= 2 等同于 C = C &amp; 2 | ^= 按位异或且赋值运算符 C ^= 2 等同于 C = C ^2 | | = 按位或且赋值运算符 C | = 2 等同于 C = C | 2 | . | . 杂项运算符 . | sizeof() 返回变量的字节大小 sizeof(a) 将返回 4，其中 a 是整数。 &amp; 返回变量的地址 取地址符 &amp;a; 将给出变量的实际地址。 | * 指向一个变量 指针变量声明 *a; 将指向一个变量。 ? : 三元表单式 条件表达式 如果条件为真 ? 则值为 X : 否则值为 Y x == y ? return x : return y | . 运算符优先级 . | 上到下 -&gt; 高到低 . | 后缀 () [] -&gt; . ++ - - 从左到右 | 一元 + - ! ~ ++ - - (type)* &amp; sizeof 从右到左 | 乘除 * / % 从左到右 | 加减 + - 从左到右 | 移位 « » 从左到右 | 关系 &lt; &lt;= &gt; &gt;= 从左到右 | 相等 == != 从左到右 | 位与 AND &amp; 从左到右 | 位异或 XOR ^ 从左到右 | | 位或 OR | 从左到右 | . | 逻辑与 AND &amp;&amp; 从左到右 | | 逻辑或 OR |   | 从左到右 | . | 条件 ?: 从右到左 | | 赋值 = += -= *= /= %=»= «= &amp;= ^= | = 从右到左 | . | 逗号 , 从左到右 | . | . 判断语句 . | if | if else | 嵌套if | switch | 嵌套switch | condition ? block1 : block2; | . if () { }else { } switch () { case : case : default : } // case 关键字后面必须是一个整数，或者是结果为整数的表达式，但不能包含任何变量， . 循环 . | while | for | do while 循环,检查条件放在尾部while中 | break | continue | goto | . while (){ } do { /* code */ } while (/* condition */); // 无限循环 for ( ; ; ) { /* code */ } // Ctrl + C 发送终止信号 . 函数 . | 每个函数包含一组执行特殊任务的语句 | 声明：函数名称、返回类型、参数定义：函数主题 | 内置函数 | function method | . return_type function_name( parameter list) { body of functon } . A parameter is a variable in a method definition. When a method is called, the arguments are the data you pass into the method’s parameters. Parameter is variable in the declaration of function. Argument is the actual value of this variable that gets passed to function. | Argument：实参，函数调用时传入的实际参数，实际参数 | parameter：形参，函数定义时定义的参数名称，形式参数 | . 函数调用 . function_name(parameter1, parameter2) . | 传值调用 该方法把参数的实际值复制给函数的形式参数。在这种情况下，修改函数内的形式参数不会影响实际参数。 | 引用调用 通过指针传递方式，形参为指向实参地址的指针，当对形参的指向操作时，就相当于对实参本身进行的操作。 | C 使用传值调用来传递参数。一般来说，这意味着函数内的代码不能改变用于调用函数的实际参数。 | . 函数调用，直接传入参数的过程为传值调用 函数调用，传入指针变量的过程为引用调用，形参为指向实参的地址的指针； . C 作用域规则 . | 作用域是程序中定义的变量所存在的区域 | . | 函数或者块内部的局部变量 | 所有函数外部的全局变量 | 形式参数的函数参数定义中 | . | 局部 | 全局 | 形式 . | 局部 . | 某个函数或者块的内部声明的变量为“局部变量” | 只能被该函数或者该代码块使用 | auto存储类 | . | 全局变量 . | 定义在函数的外部，程序顶部 | 整个程序的生命周期内都有效 | 在任意函数内部访问，可以使用static、extern存储类 | 函数中，同名的局部变量和全局变量，函数会使用局部变量 | . | 形式参数 . | 函数声明和函数定义时，定义的入参，为形式参数 | 在函数内部也是局部变量 | . | 初始化 . | 系统不会初始化局部变量 . | 系统会自动对全局变量进行初始化 . | | int | 0 | . | char | ‘\\0’ | . | float | 0 | . | double | 0 | . | pointer | NULL | . | . | . | . C数组 . | 存储一个固定大小的相同类型元组的有序集合 . | 通过索引访问元素 . | 声明数组 . type arrayName [arraySize] //一维数组，arraySize必须大于0 double a1[10] char a2[10] int a3[10] char * a4[10] . | 数组初始化 . int a1[] = {1, 2, 3}; //初始化大小为{}之间的数目 int a2[5] = {1, 3}; // 初始化大小为5，index0为1，index1为3 a2[4] = 9; a2[0] = 999; . | 多维数组 . // 形式 type name[size1][size2]; //二维数组 type name[size1][size2][size3]; //三维数组 //二维数组初始化 int a[3][3] = { {1,2,3}, {4,5,6}, {7,8,9} } int a[3][3] = { 1,2,3,4,5,6,7,8,9 } . | 数组参数传递 . // 指针 void func(int *array){ } // 形参传递拷贝 void func(int array[10]) { } void func(int array[]){ } // 函数返回数组 int * func() { } . | 指针指向的数组 . | 数组名称： 指向数组中第一个元素的地址 | . double a[8]; // a 存储的是 a[0] 元素的地址，也就是a指向&amp;a[0] double * p; p = balance; // 数组名称作为指针是合法的 *(a + 4); // 使用间接访问运算符访问数组中的第5个元素，从a的地址向后4段地址 等同于 a[4] *(p) *(p+1) *(p+2)； . | . 枚举 enum . | 基本数据类型 | . 基本、枚举、void、派生 . enum 枚举名 {枚举元素1,枚举元素2,枚举元素3...}; enum WEEK { //定义了一个类型为 WEEK 的枚举类型 MON = 1, TUE, WED, THU, FRI, SAT, SUN }; enum WEEK w; // 定义了 WEEK 枚举类型的一个变量 enum WEEK { // 同时定义了类型为 WEEK 的枚举类型，和变量week MON = 1, TUE, WED, THU, FRI, SAT, SUN } week; enum { // 省略枚举名， 直接定义变量week MON = 1, TUE, WED, THU, FRI, SAT, SUN } week; int main() { for (week = MON; week &lt;= SUN; week ++) { printf(\"%d\\n\", week) } } // C中枚举为int 或者 unsigned int . | 第一个枚举成员的默认值为整型0，后面每一个成员在前一个成员+1； . | 可以在定义枚举的时候改变元素的值，其后的值还是会在前面的基础加1； . | 通过枚举类型定义枚举变量，枚举类中的元素可以直接赋值给枚举变量； . | 枚举列表中的 Mon、Tues、Wed 这些标识符的作用范围是全局的，不能再定义与它们名字相同的变量。 . | Mon、Tues、Wed 等都是常量，不能对它们赋值，只能将它们的值赋给其他的变量。 . | . 枚举和宏其实非常类似：宏在预处理阶段将名字替换成对应的值，枚举在编译阶段将名字替换成对应的值。我们可以将枚举理解为编译阶段的宏。 . 枚举的元素的访问方式，是将枚举变量 . | 它们不占用数据区（常量区、全局数据区、栈区和堆区）的内存，而是直接被编译到命令里面，放到代码区，所以不能用&amp;取得它们的地址。这就是枚举的本质。 | . 指针 . 函数指针 . | 指向函数的指针变量 | . typedef int (*func)(int,int); //函数指针的声明 int (* funcP)(int) = &amp;anotherFunc; //声明一个函数指针，保持另一个函数的地址 . | 回调函数 . | 函数指针作为某个函数的参数 | 回调函数：将”函数指针”作为参数传入新的函数，新的函数执行时某种条件触发后，调用传入的函数； | . | . 字符串 . | 使用NULL字符 ‘\\0’ 终止的一位字符数组 | 数组末尾存储了”空字符”，数组大小比存储的字符串大1 | . char string[] = 'hello'; char string[] = {'h', 'e', 'l', 'l', 'o','\\0'}; //C 编译器会在初始化数组时，自动把 '\\0' 放在字符串的末尾 . | 字符串操作的函数 . | 函数 &amp; 目的 | . | strcpy(s1, s2); 复制字符串 s2 到字符串 s1。 | . | strcat(s1, s2); 连接字符串 s2 到字符串 s1 的末尾。 | . | strlen(s1); 返回字符串 s1 的长度。 | . | strcmp(s1, s2); 如果 s1 和 s2 是相同的，则返回 0；如果 s1&lt;s2 则返回小于 0；如果 s1&gt;s2 则返回大于 0。 | . | strchr(s1, ch); 返回一个指针，指向字符串 s1 中字符 ch 的第一次出现的位置。 | . | strstr(s1, s2); 返回一个指针，指向字符串 s1 中字符串 s2 的第一次出现的位置。 | . | . 结构体 . | 允许存储不同类型的数据 . | 结构的定义，必须使用struct语句，struct语句定义了一个包含多个成员的新的数据类型； . stuct tag { member-list member-list ... } variable-list; // tag是结构体标签 // member-list 是标准的变量定义 // variable-list 结构变量，定义在结构的末尾，最后一个分后前，可以指定一个或多个结构变量； // tag、member-list、variable-list 这 3 部分至少要出现 2 个 // 结构体类型、结构体变量、结构体成员 // 没有类型标签 struct { int a; char b; double c; } s1; // 没有声明变量 struct SIMAPLE { int a; char b; double c; }; // 声明结构体变量 struct SIMPLE t1, t2[10], *t3; // 结构体SIMPLE变量，结构体SIMPLE变量赋值到t2数组索引10处，结构体SIMPLE指针类型变量 // 使用typedef 创建结构体类型 typedef struct { int a; char b; double c; } Simple2; . | 结构体成员可以包含其他结构体；可以包含指向自己结构体类型的指针（链表，二叉树）； | 如果两个结构体互相包含，则需要对其中一个结构体进行不完整声明； | . | 结构体变量的初始化 . | 结构体成员变量可以在定义时指定初始值； | . | 访问结构成员 . | (.), 成员访问运算符；来访问结构体的成员变量 | . | 结构体作为函数参数 . | 指针类型传参或者变量类型传参 | . | 指向结构体的指针 . struct NewStruct * s; s = &amp;new1; // 指针指向成员变量 s-&gt;title; printf(\"%s\\n\", s-&gt;title) . | 位域 . | 实现把一个字节的二进制bit划分为几个不同的区域，并且说明每个区域的位数； | 一个存储了指定比特数的成员变量的数据结构； | 每个域位有一个“域名”，允许按域名操作，实现把几个不同对象的二进制按照位域来表示； . | 例如，状态开关，一个比特来表示 0， 1 | 读取非标准文件格式 | . | . struct 位域结构名称 { 位域列表 }; struct B{ int a:8; int b:4; int c:4; }data; // 类型B的变量data，共占用16比特，两个字节，域a占8位，域b占4位，域c占4位； . | 一个位域存储在同一个字节中，如一个字节所剩空间不够存放另一位域时，则会从下一单元起存放该位域。也可以有意使某位域从下一单元开始。 | 由于单个位域不允许跨两个字节，因此位域的长度不能大于一个字节的长度，也就是说不能超过8位二进位。如果最大长度大于计算机的整数字长，一些编译器可能会允许域的内存重叠，另外一些编译器可能会把大于一个域的部分存储在下一个字中。 | 位域可以是无名位域，这时它只用来作填充或调整位置。无名的位域是不能使用的； | . | 本质上是一种结构类型，成员按照二进制分配； . | 使用 . | 位域变量名.位域名 位域变量名-&gt;位域名 . | . | . C 共用体 . | 共用体，允许成员共用相同的内存位置，且成员可以是不同类型；但是任何时间只能有一个成员有值 . | 共用体，提供了一种在同一段内存空间存储不同类型的值的方式； . | 定义 . union [union tag] { member definition; member definition; ... }[one or more union variables]; // union tag 是可选择，定义一个union类型 // 每个 member 都是标准的变量定义 // 定位的末尾可以指定多个共用体变量 // i f str union Data { int i; float f; char str[20]; } data; // Data类型的共用体可以存储一个整数，一个浮点数，或者一个字符串；可以在共用体中使用自定的数据结构 // 共用体占用的内存要足够存储共用体中最大的成员 . | 访问共用体成员 . | (.), 成员访问运算符；来访问共用体内部的成员 | 同一时间只有一个成员能够存储值，其他成员会指向数据类型默认值； | . | . C学习 . ",
    "url": "/docs/archives/2020/2020-03-16-c-programming-language-recap/#c-recap",
    
    "relUrl": "/docs/archives/2020/2020-03-16-c-programming-language-recap/#c-recap"
  },"119": {
    "doc": "C programming language recap",
    "title": "C programming language recap",
    "content": "C&amp;C++ . 2020-03-16 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-16-c-programming-language-recap/",
    
    "relUrl": "/docs/archives/2020/2020-03-16-c-programming-language-recap/"
  },"120": {
    "doc": "计算机网络",
    "title": "计算机网络基础",
    "content": "基础复习计算机网络自顶向下 . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#计算机网络基础"
  },"121": {
    "doc": "计算机网络",
    "title": "Top Down",
    "content": "OSI . Application Presentation Session Transport Network Data Link Physical . Simple . Application Transport Network Link Physical . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#top-down",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#top-down"
  },"122": {
    "doc": "计算机网络",
    "title": "1. 计算机网络",
    "content": "构成因特网的软件和硬件，根据分布式应用提供服务的联网基础设施来描述因特网 . 世界范围内的计算机网络 因特网就是将端系统彼此互联 . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#1-计算机网络"
  },"123": {
    "doc": "计算机网络",
    "title": "1.1 具体构成和描述",
    "content": "端系统，分组Packet . | 所有连接的设备，叫做主机或者端系统 HOST END SYSTEM | 端系统通过通信链路communication link和分组交换机连接在一起 | 通信链路又不同类型的物理媒介组成，链路的传输速率为 BIT/S bps 比特每秒来计算 | 分组Packet，发送端将数据分段并为每段加上首部字母，这样的信息包叫做分组 | . 分组交换机 . | 分组交换机，从交换机的一条入链路将分组转发并从出通信链路发出 | 分组交换机包括，路由器Router，链路层交换机Link-layer switch | 链路层交换机用于接入网，路由器用于核心网 | . 通信链路 . | 从发送端到接收端系统，一个分组所经历的一系列的通信链路和分组交换机称为通过该网络的路径，Path Route | 分组类似于运载货物的卡车，通信链路类似于公路，分组交换机类似于立交桥； | 链路的速率，主要取决于分组交换机的转发能力： RM bps表示路由器在1S内可以完成R兆bit的转发 | . ISP . | 端系统由 ISP internet service provider 接入因特网 | 每个ISP是一个由多个分组交换机和多段通信链路组成的网络，各ISP为端系统提供了各种不同类型的网络接入 | 底层ISP通过国际的高层ISP互联，独立管理，运行着IP协议 | 调制解调？ | . 协议 Protocol . | 协议控制着网络中或因特网中的信息接受和发送，TCP和IP协议是最重要的两个协议，主协议统称为TCP/IP | TCP Transmission Control Protocol 控制传输协议 | IP Internet Protocol 网际协议，IP协议定义了在路由器和端系统之间发送和接受的分组格式 | 背景，Internet Standard 由 InternetEngineering Task Force研发，其他组织也会制定标准，例如以太网标准，Wi-Fi标准 | . 服务描述 . | 应用程序提供服务的基础设施：分布式应用程序 distributed application，application运行在端系统上，分组交换机并不关心作为数据源或者宿的应用程序 | 端系统提供应用程序编程接口，API，API规定了运行在一个端系统上的软件向另一个端系统的特定目的地软件交付数据的方式 | . 协议 . | 因特网中涉及两个或者多个远程通信的实体活动都受到协议的制约，交换报文或者采取动作的实体是硬件或者软件 | 硬件实现的协议控制了在两块“接口卡”之间的“线上”比特流 | 端系统中，拥塞控制协议控制了发送方和接受方之间传输的分组Packet发送频率 | 一个协议定义了两个或者多个通信实体之间的交换的报文格式和次序，以及报文发送和接受所采取的动作； | 构成，原理，工作方式； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#11-%E5%85%B7%E4%BD%93%E6%9E%84%E6%88%90%E5%92%8C%E6%8F%8F%E8%BF%B0",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#11-具体构成和描述"
  },"124": {
    "doc": "计算机网络",
    "title": "1.2 网络边缘 - 边缘计算",
    "content": ". | 在因特网中处于边缘的系统，叫做端系统； | 主机 = 端系统 HOST = END SYSTEM ，Clinet，Server，web服务器属于大型的数据中心Data Center | . 接入网 . | 端系统和应用程序位于网络边缘，access network，接入网是将端系统接到其边缘路由器的物理链路（edge router）- 端系统接入边缘路由的链路 | 边缘路由器，是端系统到其他任何远程端系统路径上的第一台路由器 端系统 —(A)— 边缘路由（第一台路由） A:这样的一条链路称为接入网 . | 上下行速率由编码频率控制，频率越高，速度越高，家庭DSL，家庭接入同轴电缆 | 调制解调为外部设备 | 物理链路的搭建方式 1.2.1 | . 以太网 . | 局域网将端系统连接到边缘路由，以太网为接入技术 | . 广域无线接入 . | 5G | . 物理媒介 . | 通过跨越物理媒介 Physical Medium传播电磁波活着光脉冲来发送bit； | 物理媒介：引导型媒介，电磁波沿着物理媒介前进；非引导型媒介，电磁波沿着空气前进 | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#12-%E7%BD%91%E7%BB%9C%E8%BE%B9%E7%BC%98---%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#12-网络边缘---边缘计算"
  },"125": {
    "doc": "计算机网络",
    "title": "1.3 网络核心",
    "content": ". | 网络核心：由互联因特网端系统的分组交换机和链路构成的网状网络；分组交换机包括路由和链路层交换机； | . 分组交换 . | 端系统彼此交换报文（message），报文包含了协议设计者需要的所有的东西； | 源端系统向目的端系统发送一个报文，“源”将长报文划分为较小的数组快，为“分组”Packet； | 在源和目的之间，每个分组都通过通信链路的分组交换机（packet swith）传送；路由器和链路层交换机 | 每个分组以等于该链路最大传输速率的速度传输通过通信链路 | 一个Lbit的分组，链路速率为Rbit/s，则传输时间为L/R s | . 存储转发传输 . | 指交换机在开始向输出链路传输该分组的第一个bit前，必须已经接收到了整个分组；缓存分组比特，当路由器由输入链路接收完了整个分组后，才开始向出链路传输，总延时为2L/R s | N条速录为R的链路，转发一个分组，d源到端 = N L/R | . 排队时延和分组丢失 . | 每个分组交换机与多条线路相连，分组交换机有一个输出缓存，output buffer，output Queue；到达的分组的传输链路处于繁忙状态，传输其他分组，达分组会在“输出缓存”中等待； | 时延，1. 存储转发时延，2. 排队时延，时延处于变化的状态，变化程度取决于网络中的拥塞程度 | 丢包，一个分组发现“输出缓存”已经被其他的等到传输的分组完成充满了，这时就会出现“分组丢包”，Packet lost，到达分组或者已经排队的分组之一会被丢弃； | 分组达到率（每秒比特）超过了输出链路的速率，这些分组在通过链路传输前，在“链路输出缓存中排队”，在该路由器中将出现拥塞； | . 转发表和路由选择协议 . | 因特网中，每个端系统具有IP地址，源向目的端发送分组，分组的首部都包含了IP地址； | 路由器具有转发表，forwarding table，用于将目的地址（或者地址中的几段）映射为输出链路； | 分组到达路由器，路由器检查分组地址，并用目的地址搜索转发表，发现出链路，则将该分组导向出链路； | 转发表配置问题，路由选择协议 routing protocol，用于自动设置转发表； | . 电路交换 . | 网络链路和交换机转发数据的两种基本方式：1. 电路交换 2. 分组交换 | 电路交换需要提前预留报文要使用的资源，缓存链路传输速率等，传统的电话就是一种电路交换； | 实现方式：频分复用 Frequency-Division Multiplexing， 时分复用Time-Division Multiplexing | 带宽 bandwidth：频段的宽度 80——100Mhz | . 分组交换和电路交换的对比 . | 分组交换提供了和电路交换差不多的性能，并且允许用户数量是电路交换地3倍，分组交换的性能优于电路交换； 例子：假设10个用户，某个用户产生1000个1000bit的分组，其他用户保持静默。每帧具有10个间隙且每个间隙保护1000bit的TDM电路交换情况下，活跃用户只能使用每帧中的一个间隙来传输数据，传完1000，000的bit数据需要10S时间，而分组交换的情况下，活跃用户能连续的以1Mbps的速率使用链路，完成数据的发送只需要1S； . | 电路交换需要预先分配传输链路，使得已分配但是不需要的链路时间未被使用；分组交换按需分配链路使用，链路传世能力在所有用户之间逐分组共享； | . 网络的网络 . | 十多个第一层ISP和数十万个底层ISP组成，ISP覆盖大洲，大洋，有些覆盖小的地理区域；底层与高层互联，高层彼此互联； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#13-%E7%BD%91%E7%BB%9C%E6%A0%B8%E5%BF%83",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#13-网络核心"
  },"126": {
    "doc": "计算机网络",
    "title": "1.4 分组交换网中的时延、丢包、吞吐量",
    "content": ". | 时延：节点处理时延，排队时延，传输时延，传播时延，节点总时延； | 处理时延，检查分组首部需要的处理时延，用来决定将该分组导向何处 | 排队时延，分组在链路上等待传输是排队的时延（“输出缓存” output buffer） | 传输时延，先到先服务，仅当所有已到达分组被传输后，才能传输刚到达的分组，链路速率R bps，R个bit每秒，时延=分组比特/链路速率，毫秒微秒量级 | 传播时延，是分组从一个路由器传输到另一个路由器，所在的链路的传播需要的时间，它和链路的物理长度及物理媒介有关，和链路的速率以及分组长度无关； | 区别：传输时延是由路由器将整个分组推出所需要的时间，这里的速率完全取决于路由器的转发能力，R Mbps表示路由器在1S内可以完成R兆bit的转发，速率也和编码频率有关； 传播时延表示分组或者数据比特在物理或者媒介中传播所需要的时间； | . 排队时延和丢包 . | 排队时延取决于流量到达该队列的速率，链路传输的速率和流量到达的性质； | R表示链路的传输速率，就是从队列中推出bit的速率 bps | 假设a表示分组达到队列的速率，L表示分组的比特数量，则La bps表示比特到达队列的平均速率，La/R为 流量强度 traffic intensity； 流量强度不能大于 1 | . 丢包 . | 随着”流量强度” 接近1，分组交换机或路由器将会对已经满了的队列，丢弃新的分组，Drop，该分组将会丢失Lost； | 一个结点的性能是根据分组的丢失概率来度量的； | . 端到端时延 . | N-1台路由器 总时延 = N （主机和路由器上的处理时延 + 链路传播时延 + 传输时延L/R | traceroute软件做时延分析 | . 端系统、应用程序、其他时延 . | 对于某些协议，端系统application处理的延时； | . 吞吐量 . | 瞬时吞吐量：端系统接受到该文件的速率 bps，例如下载文件的的速率显示 | 平均吞吐量：F比特的文件，主机接收到所以的bit用了T秒时间，平均吞吐量为F/T | 有些Application中吞吐量比时延更重要； | Rs表示服务器与路由器之间的链路速率，Rc表示路由器和客户端之间的链路速率，对于Server来说他的吞入量为min{Rs, Rc}，这里的吞入量为瓶颈链路速率，bottleneck link，当然这里的吞吐量还需要考虑分组层次和传输协议的问题； | 吞吐量取决于数据流过链路的传输速率；在没有其他条件干扰时，吞吐量近似等于源和目的之间的最小传输速率； | . bandwidth 带宽 . | Bandwidth (signal processing) or analog bandwidth, frequency bandwidth or radio bandwidth, a measure of the width of a range of frequencies, measured in hertz | Bandwidth (computing), the rate of data transfer, bit rate or throughput, measured in bits per second (bit/s) | Spectral linewidth, the width of an atomic or molecular spectral line, measured in hertz | 对于信号处理中，bandwidth表示当前信号的频段宽度，例如模拟信号或者数字信号的”频率范围“ hz为单位 | 对于计算机网路链路，带宽为当前最大传输速率，没秒钟链路能够传输或处理的比特，bit/s为单位，注意在电路交换中带宽表示的是频率范围； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#14-%E5%88%86%E7%BB%84%E4%BA%A4%E6%8D%A2%E7%BD%91%E4%B8%AD%E7%9A%84%E6%97%B6%E5%BB%B6%E4%B8%A2%E5%8C%85%E5%90%9E%E5%90%90%E9%87%8F",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#14-分组交换网中的时延丢包吞吐量"
  },"127": {
    "doc": "计算机网络",
    "title": "1.5 协议层次及其服务模型",
    "content": "协议分层 . | 网络以分层的方式组织协议，某层会向上一层提供服务，就是服务模型； | 应用层协议在端系统中以软件方式实现，物理层和数据链路层则复杂处理跨越链路的通信，通常实现在给定的接口卡中；网络层则有软硬件的混合； | . 协议栈 . | 各层所有的协议被称为协议栈 protocol stack | 因特网的协议栈由5层组成 1. 物理层 2. 数据链路层 3. 网络层 4. 传输层 5. 应用层 | 应用层：网络应用程序之间定义的协议留存的分层，分布在多个端系统上，一个端系统的应用程序使用协议与另一个端系统中的应用程序交换信息的分组，位于应用层的信息分组称为报文（message） | 传输层、运输层：用于传输应用层报文，主要有TCP和UDP，TCP向他的应用程序提供了面向连接的服务。TCP也将长报文划分为短报文，提供拥塞机制；TCP源代码；UDP无连接，不提供服务的服务，运输分组可以称为报文段 segment | 网络层：负责将数据报 datagram 的网络层分组从一台主机移动到另一台主机；源主机中TCP或者UDP运输协议向网络层递交运输层报文段segment和目的地址，网络层IP协议定义了数据报中的各个字段和端系统及路由器如何作用这些字段，IP协议和路由选择协议，IP协议连接了硬件和软件层； | 链路层：网络层从源到目的之间经过路由器路由数据报，将分组从一个结点移动到另一个结点，必须“依靠数据链路层的服务”，网络层将数据报下传给链路层，链路层沿着链路将数据传递给下个结点，下个结点链路层又将数据报上报给了网络层；链路层提供的服务取决于链路层的协议。链路层的分组为”帧“Frame，以太网，Wi-Fi，DOCsis； | 物理层：物理层的任务是将链路层中的帧中的一个一个bit从一个结点移动到下一个结点，物理层协议于链路相关，也与物理介质相关，例如同轴电缆卡，光纤； | . OSI . | ISO国际标准化组织提出OSI，开发系统互联模型 | 应用层 表示层 会话层 传输层 网络层 链路层 物理层 | . 封装 . 应用层 报文 mesasge 传输层 报文段 segment = message + header 网络层 数据报 datagram = segment + header 链路层 帧 frame = datagram + header 物理层 . | application-layer message — transport-layer segment — network-layer datagram — link-layer frame . | 链路层交换机实现第一层和第二层，路由器实现第一层到第三层，路由器能够实现IP协议，链路交换机不能，链路层交换机能够实现第二层地址，以太网地址；网络边缘的端系统可以实现一到五层，将复杂性较高的结构放在边缘； | 封装 （encapsulation）：在发送端，一个应用层报文（application-layer message） — 应用层报文+传输层首部=运输层报文段（transport-layer segment） — 网络层增加了源和目的端地址等网络数据报的首部，产生了网络层数据报 — 链路层增加链路层首部信息并创建链路层帧 . | 每个分层：首部字段+有效载荷字段（header + payload field），有效载荷为上一层分组 | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#15-%E5%8D%8F%E8%AE%AE%E5%B1%82%E6%AC%A1%E5%8F%8A%E5%85%B6%E6%9C%8D%E5%8A%A1%E6%A8%A1%E5%9E%8B",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#15-协议层次及其服务模型"
  },"128": {
    "doc": "计算机网络",
    "title": "1.6 攻击的网络",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#16-%E6%94%BB%E5%87%BB%E7%9A%84%E7%BD%91%E7%BB%9C",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#16-攻击的网络"
  },"129": {
    "doc": "计算机网络",
    "title": "1.7 历史，分组交换的发展，专用网络和互联网络，因特网的发展",
    "content": ". ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#17-%E5%8E%86%E5%8F%B2%E5%88%86%E7%BB%84%E4%BA%A4%E6%8D%A2%E7%9A%84%E5%8F%91%E5%B1%95%E4%B8%93%E7%94%A8%E7%BD%91%E7%BB%9C%E5%92%8C%E4%BA%92%E8%81%94%E7%BD%91%E7%BB%9C%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E5%8F%91%E5%B1%95",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#17-历史分组交换的发展专用网络和互联网络因特网的发展"
  },"130": {
    "doc": "计算机网络",
    "title": "2. 应用层",
    "content": "2.1 网路应用程序体系结构 application architecture . | 客户 - 服务器体系结构 client-server architecture 如Web应用，客户之间并不直接通信 | P2P结构， per to per architecture，对于服务器有最小依赖，“对等方”在主机间直接通信，p2p特性，自扩展性； | . 进程通信 . | 运行在不同端系统上的进程，通过跨越计算机网络交换报文（message）而相互通信； | 进程通过“套接字” socket的软件接口向网络发送报文和从网络接受报文，Socket下面使用运输层TCP或UDP协议，套接字也称为“网络程序编程接口”，套接字对运输层仅仅能 1.选择运输层协议 2.设定运输层参数如最大缓存，最大报文长度等 | 开发者选择了运输层协议，应用程序就建立在由该协议提供的运输层服务至上； | 进程寻址，“IP地址”来标识主机地址，“端口号Port”来表示主机中的进程，从而定位到通信的进程； | . 可供应用程序使用的运输服务 . | 可靠数据传输：分组交换机的缓存溢出导致的分组丢失，可靠数据传输（reliable data transfer），运输层协议向应用程序提供进程到进程的可靠数据传输。 | 容忍丢失的应用，loss-tolerate application，多媒体应用可以容忍一定量的数据丢失 | 吞吐量：两个进程之间，可用吞吐量就是发送进程到接收进程交付比特的速率，会话会共享沿着网络路径的带宽，可用吞吐量会随着时间波动，运输层协议能够以某种特定的速率提供确保的可用吞吐量；具有吞吐量要求的应用程序为”宽铭感应用”，“弹性应用”是或多或少的利用可用吞吐量； | 定时：运输层协议保障提供数据传输的总时延小于一个特定值； | 安全性：运输层协议保障加密进程发送的数据 | . 运输服务 . | TCP/IP网络中两个运输层协议，TCP和UDP | . TCP服务 . | TCP服务模型包括面向连接服务和可靠数据传输服务，调用TCP服务作为运输协议，应用会获得TCP服务的“面向连接服务”和“可靠数据传输服务” | 面向连接服务：连接的三次握手，握手完成后，TCP连接就在两个进程的套接字之间建立了。四次分手 | 可靠的数据传输服务：TCP，会无差错、按照顺序交付所发送的数据，当App的一端将字节流传进套接字是，能够依靠TCP将相同的字节流交付给接收方的套接字，没有字节的丢失和冗余； | 拥塞控制机制，在网络发送拥塞时，TCP的拥塞控制机制会抑制发送进程；或使每个连接达到公平共享带宽的目的； | TCP UDP 不提供任何加密机制，安全套接字，SSL secure sockets layer；SSL是对TCP运输协议的加强，这样的安全强化是在应用层实现的；SSL有独立的一套SOCKET API | . UDP服务 . | 轻量级运输协议，提供最小服务，UDP是无连接的，提供一种不可靠的数据传输服务； | UDP不保证报文到达接收方进程，到达的数据有可能是乱序到达； | UDP没用拥塞机制，发送端可以使用UDP选定任何速率向下层注入数据； | . 运输协议不提供的服务 . | 不能提供定时和带宽保证； | 网络语音，以UDP作为主要运输协议，TCP作为当UDP流量被防火墙阻挡后的备选方案； | . 应用层协议 . | 应用层协议定义了 | . 交换的报文类型，如请求报文和响应报文 报文语法 字段含义 进程何时及如何发送报文，报文的响应规则 . HTTP 超文本传输协议，公共域的RFC SMTP 简单邮件传输协议 . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#2-%E5%BA%94%E7%94%A8%E5%B1%82",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#2-应用层"
  },"131": {
    "doc": "计算机网络",
    "title": "2.2 Web和HTTP",
    "content": "HTTP . | 一个客户程序和一个服务器程序，运行在不同的端系统中，通过交换HTTP报文进行会话；HTTP定义了报文格式，已经报文的交换方式； | 术语 | . Web页面 webpage 对象 object . | HTTP定义了web客户端向服务器请求页面的方式； | HTTP使用TCP运输层服务，客户向他的套接字发送http报文，并从套接字接收响应报文； | HTTP服务每次发送报文，都会将报文通过套接字交给TCP服务，HTTP协议不用担心数据的丢失和乱序问题； | HTTP服务器不保存每次客户访问的信息，是一个“无状态协议“ stateless protocol | . 非持续连接和持续连接 . | 非持续连接：每个请求是经过每次的单独的TCP连接发送，每次发送报文新建TCP连接 | 持续连接：所有的请求以同一个的TCP连接发送； | HTTP既能使用非持续，也能使用持续连接，默认方式是使用持续连接，可以配置成非持续 | . 非持续连接的HTTP . | 每个TCP连接只传输一个请求报文和一个响应报文； | 往返时间： Round-Trip Time RTT，一个短分组从客服到服务器，再返回客户端所花费的时间； | RTT：分组传播时延，分组传输时延、排队时延、处理时延 | 三次握手，客户向服务器发起一个TCP连接，客户向服务器发送一个小的TCP报文段，服务器用一个小TCP段作出确认和响应，最后客户向服务器返回确认； | . 持续连接的HTTP . | 非持续中，每个TCP都需要在服务器中分配TCP的缓冲区和保持TCP变量，给服务器带来较大负担，而且每个对象都需要经受两倍的RTT交付时延；一个RTT用来创建TCP连接，一个用来请求和接收对象； | HTTP的默认模式是使用带流水线的持续连接，服务器在发送响应后保持TCP连接打开，同一个客户和服务器的后续请求和响应报文通过相同的TCP连接进行；服务器可以以流水线的方式一个接一个的发出对象的请求，不必等待回答；超时后HTTP服务器就会关闭连接； | . HTTP报文格式 . 请求报文 . | 使用ASCII编写，最少一行，最后一行附加一个换行符； | . | 请求行，后续叫做首部行 【方法字段】【URL统一资源定位】【HTTP版本】 | . | 【方法字段】： GET POST HEAD PUT DELETE | 首部行：HOST指明了对象所在主机，Web代理高速缓存所要求的 | Connection：close 要求服务器在发送完被请求对象后关闭这条连接 | User-agent：用户代理，不同的agent表示不同的设备或者浏览器。Mozilla标准 | . 【方法】空格【URL】空格【版本】换行 【首部字段:】空格【值】换行 【首部字段:】空格【值】换行 【首部字段:】空格【值】换行 【首部字段:】… 空行 实体主体 . | POST报文仍然可以向服务器请求对象，表单的请求报文不是必须使用POST方法； | HEAD方法和GET方法类似，但是服务器不返回请求对象； | PUT方法多用于上传路径的服务 | DETELE方法允许用户删除服务器上的对象 | . 响应报文 . | 状态行status line，协议版本+状态码+状态信息 | 首部行 header line | 实体行 entity body | 实体部分是报文的主要部分，包含了对象本身； | Connection：close 表示告诉客户，发送完报文后服务器将关闭TCP连接 | Date：响应报文的时间 | Server：Server类型和版本 | Last—Modified：对象的最后修改时间 | Content-Length：被发送对象的字节数 | Content-Type：内容类型 | . 【版本】空格【状态码】空格【状态短语】换行 【首部字段:】空格【值】换行 【首部字段:】空格【值】换行 【首部字段:】空格【值】换行 【首部字段:】… 空行 实体主体 . | 常见短语和状态码 200 OK 301 Moved Permanently 400 Bad request 请求不能被服务器理解 404 Not Found 505 HTTP Version Not Supported | . cookie . | HTTP服务是无状态的，cookie允许站点对用户进行跟踪； | HTTP响应报文中包含一个cookie首部行 | HTTP请求报文中的一个cookie首部行 | 用户系统中保留一个cookie文件 | web站点后端数据库 | Set-cookie首部识别码可以确定一个用户，在站点上每次访问的路径，跟踪用户的活动； | 账号信息和识别码关联，从而不需要重复输入用户名密码； | . Web缓存 . | Web cache &amp; proxy server 也叫代理服务器 | 代表初始的web服务器来满足http请求的网络实体 | 有自己的磁盘空间用来存储最近保存过的对象的副本 | Web cache工作流程：浏览器在建立一个Web cache，并向web cache发送HTTP请求，Web缓存对对象做检查，有则直接返回给浏览器，无则与对象的初始服务器建立TCP连接。Web缓存器在这个TCP连接上发送HTTP请求，初始服务器Web cache进行响应，接收到对象的web cache会在本地存储一份副本，并向浏览器发送对象，web cache和浏览器也是TCP连接； | Web cache 缓存器可以看作一个代理服务器，即是初始服务器的客户端也是浏览器的服务器； | ISP提供 | 例子：page76，Web cache比升级网络速率成本低，效果好 | 内容分发网络 Content Distribution Network CDN，CDN在地理位置上安装了很多缓存器，使得大量流量本地化 | 共享CDN和专有CDN | . 条件GET方法 conditional get . | 请求使用 GET method | header line： “If-Modified-Since：” | 缓存器存储对象和对象的最后修改日期，对同一个对象，缓存器会通过发送GET检查对象是否更新，其中If-Modified-Since就是对象上一次的最后修改时间，没有修改就不会返回对象，而且有 Not Modified关键字； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#22-web%E5%92%8Chttp",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#22-web和http"
  },"132": {
    "doc": "计算机网络",
    "title": "2.3 FTP协议",
    "content": "文件传输协议FTP . | 本地主机FTP进程建立一个到远程主机FTP服务的TCP连接，该用户接着提供用户标示和口令，在TCP连接上传送，服务器授权后，即可复制文件 | FTP协议的C实现 | . FTP和HTTP的异同 . | 都运行在TCP服务上 | FTP使用两个并行的TCP连接来传输文件，一个做控制连接，一个做数据连接，控制连接用于控制两个主机之间的信息如标示、口令、改变远程目录的命令等get put命令，数据连接用来实际发送文件； | FTP的控制信息是”带外“传送到 out-of-band | HTTP是同一个TCP连接发送请求和响应的行首部，HTTP为”带内“ 发送控制信息 in-bond | FTP有“状态”， HTTP“无状态” | . FTP工作流 . | 用户主机和远程主机开启一个FTP会话，用户端在服务器的21号端口与服务器发起一个TCP连接用于控制，该连接用来发送命令，无论何种方向的文件传输，都是从服务器端发起一个新的TCP连接，完成一个文件的传输后TCP连接关闭； | FTP服务器需要在会话期间保留用户状态，服务器必须追踪用户在远程目录上的位置，对每个会话的状态信息追踪限制了FTP能够同时维护的总会话数量； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#23-ftp%E5%8D%8F%E8%AE%AE",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#23-ftp协议"
  },"133": {
    "doc": "计算机网络",
    "title": "2.4 SMTP邮件协议",
    "content": ". | 25号端口 | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#24-smtp%E9%82%AE%E4%BB%B6%E5%8D%8F%E8%AE%AE",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#24-smtp邮件协议"
  },"134": {
    "doc": "计算机网络",
    "title": "2.5 DNS，域名解析服务",
    "content": ". | IP地址由4个字节组成，每个字节8bit，大小为0-256 | 域名系统 Domain Name System — 1. 由分层的DNS服务器实现的分布式数据库 2. 使主机能够查询分布式数据库的应用层协议 | DNS运行在UDP服务上 使用53号端口 | DNS通常由其他的应用层协议使用 例如 HTTP，将提供的主机名解析成IP地址； | 主机本地的DNS缓存，主机上运行着DNS的客户端，客户端与服务器端交互，浏览器与客户端交互 | 主机别名，邮件服务器 别名，负载分配，load distribution | 工作机理：浏览器向用户DNS客户端发送主机名（gethostbyname），DNS客户端从缓存中查找，找不到向网络发送一个DNS查询报文，DNS请求和回答报文都是用UDP数据报经过53端口发送，DNS客户端将映射结果返回给调用的程序； | . 分布式、层次数据库 . | 根DNS服务器 | 顶级域名 TOP-Level Domain DNS服务器 | 权威DNS服务器 | 根服务器先返回顶级域名的ip地址，顶级域名的ip地址将返回权威域名的ip地址，权威域名服务器返回主机名的ip地址 | 根DNS服务器 – com DNS服务器 – amazon.com DNS服务器 | DNS查询为 迭代查询 或者 递归查询 | 详情见 PG92 | . DNS记录 DNS报文 . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#25-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E6%9C%8D%E5%8A%A1",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#25-dns域名解析服务"
  },"135": {
    "doc": "计算机网络",
    "title": "2.6 P2P",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#26-p2p",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#26-p2p"
  },"136": {
    "doc": "计算机网络",
    "title": "2.7 TCP 套接字编程",
    "content": ". | 服务器端应用和客户端应用使用统一的RFC标准，就能实现交互操作； | 选择TCP还是UDP，TCP面向连接并提供两个端系统之间数据流动的可靠字节流通道，UDP无连接，发送独立的分组，不对交付进行任何保证； | . UDP套接字 . | 发送进程为分组附上目的地址，为主机的ip地址和目的地套接字的端口号，发送方的原地址也是由套接字端口号和源主机的IP地址组成，该源地址也要附着在分组之上；将源地址附在分组上的操作并不是由UDP应用程序代码所为，而是由底层操作系统自动完成； | PG108 | . TCP套接字 . | . | UDP，TCP服务器在客户端开始发出接触前，必须已经准备好，服务器进程必须处于运行的状态； . | 客户进程创建一个TCP套接字，向服务器进程发起一个TCP连接，客户端套接字知道拿过来主机的IP和端口号，生成套接字后客户发起一个三次握手创建与服务器的TCP连接，发生在运输层的三次握手对客户和服务器是完全透明的； | 欢迎套接字：客户与服务器通信的起始接触点，欢迎套接字处进行三次握手 | 连接套接字：服务器侧为每个客户通信生成的套接字，连接套接字表示连接成功 | . | . | PG112 | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#27-tcp-%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#27-tcp-套接字编程"
  },"137": {
    "doc": "计算机网络",
    "title": "3. 运输层",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#3-%E8%BF%90%E8%BE%93%E5%B1%82",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#3-运输层"
  },"138": {
    "doc": "计算机网络",
    "title": "3.1 运输层服务",
    "content": ". | 运输层协议为运行在不同主机之间的应用程序提供了逻辑通信的功能 Logic communication | 运输层从应用程序接受报文并转化成”报文段“，实现方式是将报文划分成较小的块，并为每块加上一个运输层首部以生成运输层报文段； . | 报文分块 – 添加首部 – 生成报文段 – 运输层将这些报文传递给网络层，网络层将其封装成数据报分组并向目的地发送； | 路由器只会作用于网络层字段，不会检查封装在该数据报的运输层报文段和字段；运输层则处理接受到的报文段，使该报文的数据为接受应用程序使用； | . 运输层和网络层的关系 . | 网络层提供了主机之间的逻辑通信 | 运输层提供了进程之间的逻辑通信 | 运输层协议只在端系统中工作；对报文在网络核心中如何移动不做任何规定； | 不同的运输层协议为应用程序提供不同的服务模型 | 底层的网络层协议不可靠，分组交换机会发送分组丢失等，但是运输层协议仍然能够为应用程式提供可靠的数据传输； | . 概述 . | 运输层分组：报文段 segment TCP：报文段 UDP：数据报 网络层：数据报 | IP的服务模型：尽力为交付服务 best-effort delivery service，尽最大努力交付，但是不做任何确保，不确保报文段的交付、不确保报文段的按序交付、不确保报文段中的数据的完整性 | IP：不可靠服务 | TCP UDP的基本责任是：将两个端系统之间的IP的交付服务扩展为运行在端系统上的两个进程之间的交付服务； | 主机间的交付扩展到进程间的交付： 运输层的多路复用 与 多路分解 （transport-layer multiplexing, demultiplexing) | 进程和进程的数据交付和差错检查是两种最低限度的运输层服务 | . TCP概述 . | 可靠数据传输 reliable data transfer | 流量控制 | 序号 | 确认 | 定时器 | TCP能够正确的、按序的将数据从发送进程交付给接收进程 | 拥塞控制 congestion control | 提供给调用它的应用程序的一种服务，也是提供给因特网的一种服务，防止任何一条TCP连接用过多的流量来淹没主机之间的链路和设备交换 | TCP调节流量速率来让每个连接平均的共享链路带宽 | UDP的流量是不可调节的 | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#31-%E8%BF%90%E8%BE%93%E5%B1%82%E6%9C%8D%E5%8A%A1",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#31-运输层服务"
  },"139": {
    "doc": "计算机网络",
    "title": "3.2 多路复用与多路分解",
    "content": "多路分解 . | 接收主机的运输层将数据交付给套接字， | 每一个套接字都有一个唯一的标识符 | 主机将到达运输层的报文段定向到适当的套接字，运输层会检查报文字段，标识处接收套接字，进而将报文定向到套接字； | 多路分解：将运输层报文段的数据交付给正确的套接字 | 多路复用：源主机将不同套接字数据封装上首部信息从而生成报文段，将报文段传递到网络 | . 工作方式 . | 要求： 1. 套接字有唯一的标识符 2. 每个报文段有特殊的字段来指示该报文要交付给的套接字 | 源端口号字段+目的端口号字段 一个端口好是16bit （source port number field + destination port number field) | 每个套接字都能分配一个端口号 . | 当报文到达主机时，运输层检查报文中的目的端口号 ，并将报文段定向到相应的套接字 | . | . 端口 . | 0~1023的端口号为 well-known port number 保留给已知应用 | 0~65535 | 16bit | . 无连接的多路复用和多路分解 . | 对于UDP协议，运输层会创建运输层报文段，包括源端口，目的端口和数据 | 接收主机的UDP服务会设别目的端口，并将数据交给对应的套接字 | UDP的套接字：一个二元组来标识，保护一个目的IP和一个目的端口号 | UDP使用二元组中的两个值，来将报文定向到相应的套接字上 | 来自不同源地址的UDP报文，只要目的地址和目的IP相同，那么报文就会到达同一个套接字 | UDP套接字中包含源ip地址和源端口号，用于接收端进行回包的时候从报文中提取源地址和源端口作为目的地址和目的端口 | . 面向连接的多路复用和多路分解 . | TCP套接字是一个4元组 源地址 源端口 目的地址 目的端口 | 到达主机的报文，TCP服务会是使用全部4个值来将报文段定向到相应的套接字 | 4元组中任意一个不同，报文都会到达不同的套接字 | 服务器主机可以支持很多并行的TCP套接字，每个套接字与一个进程相联系，并由4元组来标识套接字；当一个TCP报文到达主机时，所有4个字段都将会用来定向报文到相应的套接字； | . Web服务器与TCP . | Web服务器具有多个新连接套接字的新线程，任意时间内会有不同标识的套接字连接到相同的进程中；线程管理的套接字可以接收或者发送HTTP请求和响应 | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#32-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B8%8E%E5%A4%9A%E8%B7%AF%E5%88%86%E8%A7%A3",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#32-多路复用与多路分解"
  },"140": {
    "doc": "计算机网络",
    "title": "3.3 无连接运输-TCP",
    "content": ". | 运输层必须最低限度的提供一种 复用/分解 的服务 | UDP协议的功能：多路复用，多路分解，差错检测 | UDP发送方和接收方之间没有握手，UDP是无连接的 | 选择UDP的原因依据： . | 时间和数据：不希望过分的延迟发送报文，且能容忍一定的数据丢失、 | 无需建立连接：UDP无连接时延 | 无连接状态：UDP无需维护连接状态，无需跟踪参数，无拥塞控制机制 | 分组首部开销小：源端口、目的端口、校验和、数据大小 | . | RIP路由表选择协议使用UDP，更新的丢失会被最新的更新替代，可以容忍数据丢失 | SNMP简单网络控制协议，对于处于重压下的网络，对于可靠的且有拥塞控制的协议无法完成对网络的实时管理； | UDP中缺乏拥塞控制，会导致UDP的接收方和发送方之间的高丢包率，并有可能会挤垮了TCP会话； | 使用UDP也可以实现可靠的数据传输，需要在应用程序自身建立可靠性机制，在应用程序中进行开发，可以不依赖TCP的服务和拥塞控制； | . UDP的报文段结构 . | 首部包含四个字段每个字段由2个字节组成，每个字节是8个bit . | 每个字段包含16个比特Bit . | . | 16bit | 16bit | . | 源端口 | 目的端口 | . | UDP报文首部和数据的总长度 | 校验和，对UDP报文段中的所有16比特字的和进行反码 | . | 报文数据 | 报文数据 | . UDP校验和 . | 校验和的值： 发送方的所有16比特字的和，进行反码运算，且相加溢出需要回卷 | 接收方将所有16比特字及校验和相加，无差错的情况下相加结果全为1 | 链路层路由协议及以太网协议也都提供了差错检测，传输层的差错检测存在的意义就是因为不能保证每一条链路都使用了差错检测的协议；这既是无法确保链路的可靠性； | 端到端原则： 必须基于端到端实现功能，因为相比在较高级别实现这些功能的代价，在较低级别上实现可以是冗余或者几乎无价值的； | UDP对检验出的受损报文段：1. 直接丢弃 2. 交给套接字并向应用程序发出警告 | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#33-%E6%97%A0%E8%BF%9E%E6%8E%A5%E8%BF%90%E8%BE%93-tcp",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#33-无连接运输-tcp"
  },"141": {
    "doc": "计算机网络",
    "title": "3.4 可靠数据传输原理",
    "content": ". | 可靠数据传输为上层实体提供的服务抽象： 数据可以通过一条可靠的信道传输 | 传输数据不会受损例如数据bit从0变为1或者从1变为0，且数据按照发送顺序交付 | TCP的下层不可靠，TCP在不可靠的IP协议端到端网络层上实验可靠数据传输，且可靠数据传输协议下层可能是一条或者多条物理链路 | . 可靠传输 . | 发送方：rdt_send()函数， 数据接收：rdt_rcv()，数据交付高层服务：deliver_data() 交换控制分组；udt_send() | 单向数据传输 unidirectional data transfer | 双向数据传输 bidirectional data transfer 全双工数据传 | . 3.4.1 构造可靠数据传输 . 1. rdt1.0 . 有限状态机 Finite-state Machine，FSM . 有限状态机是一种用来进行对象行为建模的工具，其作用主要是描述对象在它的生命周期内所经历的状态序列，以及如何响应来自外界的各种事件。 . 有限状态机-外部文档 . | rdt1.0 - 发送端 | {action} | . | 等待上次应用的调用 | rdt_send(data) | . |   | packet = make_pkt(data); udt_send(packet) | . | rdt1.0 - 接收端 | {action} | . | 等待来自下层的调用 | rdt_rev(packet) | . |   | extract(packet, data); deliver_data(data) | . | 发送方和接收方都有各自的FSM，上图FSM各自只有一个状态 | 发送端：rdt的发送端只通过rdt_send(data)事件接收来自较高层的数据，然后生成一个包含数据的分组，并将分组发送到信道中；事件由上层应用的过程调用产生； | . 过程调用和系统调用 . | 接收端：rdt通过rdt_rcv(packet)事件从底层信道接收一个分组，然后从分组中取出数据extract，并将数据上传给高层deliver；rdt_rcv事件由较为底层的协议过程调用产生 | . 2. rdt2.0 . | 肯定确认 (positive acknowledgement) 否定确认 (negative acknowledgment)，控制报文使得接收方可以让发送发知道哪些内容被正确接收，哪些内容接收有误需要自动请求重传； | 自动重传协议 Automatic Repeat reQuest ARQ | 自动重传协议 需要的支持 . | 差错检测，分组检验和字段 | 接收方反馈，“肯定确认” ACK，“否定确认” NAK | 重传，接收方收到有差错的分组时，发送方收到反馈后将进行重传 | . | . | 发送方 |   | . | STATE | ACTION | . | 等待来自上层的调用 | rdt_send(data) | . |   | sndpkt = make_pkt(date, checksum); udt_send(sndpkt) | . | 等待ACK或NAK | rdt_rcv(rcvpkt) &amp;&amp; isNAK(rcvpkt); udt_send(sndpkt) #接收到NAK分组并重发sndpkt分组 | . | ⬆ # 返回等待调用状态 | rdt_rcv(rcvpkt) &amp;&amp; isACK(rcvpkt) # 接收到ACK确认分组，不再做其他操作，状态返回“等待过程调用” | . | 接收方 |   | . | STATE | ACTION | . | 等待来自下层的调用（过程调用） | rdt_rcv(rcvpkt) &amp;&amp; corrupt(rcvpkt) | . |   | sndpkt = make_pkt(NAK); udt_send(sndpkt) #检验后发现分组数据受损，给发送方回发NAK分组 | . |   | rdt_rcv(rcvpkt) &amp;&amp; notcorrupt(rcvpkt) | . |   | extract(rcvpkt, data); deliver_data(data); sndpkt = make_pkt(ACK); udt_send(sndpkt) #检验后发现分组数据无损，将数据提交给高层应用后，给发送方回发ACK分组 | . | 发送方有两种状态，等待上层过程调用状态和等待ACK或者NAK状态，当发送方处于 . | 行rdt_send()调用，发送方只有收到确认ACK分组后，才会发送新的数据 . | 这样的等待协议为 停等 协议 stop-and-wait . | 接收方的FSM只有一个状态，当分组到达时，接收方检验分组是否受损，要么回答一个ACK要么回答一个NAK； . | 解决ACK或者NAK分组受损导致发送方无法明确分组是否被正确接收的方法是：引入新字段，分组编号，就是发送数据的分组序号 sequence number . | . rdt 2.1 2.2 . | 新增，接收方收到受损分组发送否定确认，发送方收到受损返回分组则重新发送分组 | 接收方包括一个由ACK报文所确认的分组序号，make_pkt()中包含ACK 0 ACK1 | 发送方必须检查接收到的确认分组中的序号 | . 3. rdt3.0 具有比特差错的丢包信道的可靠数据传输 . 检测丢包和丢包后的action . | 当前已经包含的： 检验和、序号、ACK分组、重传机制 | 发送方等待超时，如果等待足够长的时间没有收到接收方的响应，便对该分组进行重传 | 等待时间： 发送方与接收方之间的一个往返时延（传输时延，传播时延，排队时延） + 接收方处理一个分组的时间， 实践中，发送方明智的选择一个确定的时间值作为等待时间 | 如果一个分组经历了比较长的时延，但是并没有丢包，发送方也会重传该分组，这样的情况下接收方就会 “冗余数据分组，分组序号可以解决冗余数据分组的问题 | 过度延时或者分组丢失都会导致重传 | 倒计数定时器 countdown timer， 用于给定时间过期后，中断发送方； | . | 发送方 |   | . | 等待来自上层的调用 0 | rdt_send(data) | . |   | sndpkt = make_pkt(0, data, checksum); udt_send(sndpkt); start_timer; | . | 等待ACK 0 | rdt_rcv(rcvpkt) &amp;&amp; (corrupt(rcvpkt) || isACK(rcvpkt, 1)) # 等待响应分组，1. 下层过程调用rdt_rcv 2. 如果检验后数据受损 或 获得的确认包序号不是当前0序号 则保持当前状态 | . |   | timeout; udt_send(sndpkt); start_timer; #如果出现超时(数据丢失或者网络延时)，则重新发送序号为0的分组，并启动新的timer，发送后依然保持当前等待0响应的状态 | . | ⬇ 到下一状态 | rdt_rcv(rcvpkt) &amp;&amp; notcorrupt(rcvpkt) &amp;&amp; isACK(rcvpkt, 0)); stop_timer; #当在该状态下收到响应分组，调用rdt_rcv函数后，检验数据无损，且当前响应分组的序号与当前等待状态序号一致，此处为0，则进入下一状态 | . | 等待来自上层的调用1 | rdt_send(data) | . |   | sndpkt = make_pkt(1, data, checksum); udt_send(sndpkt); start_timer; | . | 等待ACK 1 | rdt_rcv(rcvpkt) &amp;&amp; (corrupt(rcvpkt) || isACK(rcvpkt, 0)) # 等待响应分组，1. 下层过程调用rdt_rcv 2. 如果检验后数据受损 或 获得的确认包序号不是当前1序号 则保持当前状态, 继续等待正确响应分组 | . |   | timeout; udt_send(sndpkt); start_timer; #如果出现超时(数据丢失或者网络延时)，则重新发送序号为1的分组，并启动新的timer，发送后依然保持当前等待0响应的状态 | . | ⬇ 到下一状态 | rdt_rcv(rcvpkt) &amp;&amp; notcorrupt(rcvpkt) &amp;&amp; isACK(rcvpkt, 1); stop_timer; #当在该状态下收到响应分组，调用rdt_rcv函数后，检验数据无损，且当前响应分组的序号与当前等待状态序号一致，此处为1，则进入下一状态 | . |   |   | . | 接收方 |   | . | STATE | ACTION | . | 等待来自下层的调用0（过程调用） | rdt_rcv(rcvpkt) &amp;&amp; (corrupt(rcvpkt) || has_seq1(rcvpkt)) ; sndpkt = make_pkt(NAK, 0, checksum); udt_send(sndpkt) #下层调用，检验数据是否受损, 检测分组序号，当数据受损或序号为1时，继续保持该状态等待下层调用0, 并发送0的NCK响应 | . | ⬇ 到下一状态 | rdt_rcv(rcvpkt) &amp;&amp; corrupt(rcvpkt) &amp;&amp; has_seq0(rcvpkt); extract(rcvpkt, data); deliver_data(data); sndpkt = make_pkt(ACK, 0, checksum); udt_send(sndpkt) # 接收分组，解出数据，校验数据无损且分组序号为0，则将数据提交给上层应用，并向发送方响应序号为0的ACK，当前状态转移到等待下层调用序号1 | . | 等待来自下层的调用1（过程调用） | rdt_rcv(rcvpkt) &amp;&amp; (corrupt(rcvpkt) || has_seq0(rcvpkt)) ; sndpkt = make_pkt(NCK, 1, checksum); udt_send(sndpkt) #下层调用，检验数据是否受损, 检测分组序号，当数据受损或序号为1时，继续保持该状态等待下层调用0, 并发送0的NCK响应 | . | 返回初始状态 | rdt_rcv(rcvpkt) &amp;&amp; corrupt(rcvpkt) &amp;&amp; has_seq1(rcvpkt); extract(rcvpkt, data); deliver_data(data); sndpkt = make_pkt(ACK, 1, checksum); udt_send(sndpkt) # 接收分组，解出数据，校验数据无损且分组序号为1，则将数据提交给上层应用，并向发送方响应序号为1的ACK，返回初始状态 | . 3.4.2 流水线可靠传输协议 . | rdt3.0的停等协议有着非常低的发送利用率 每个分组到达接收方后返回ACK的延时为一个RTT | 解决方法：不使用停等协议等方式运行，允许发送方发送多个分组而无需等待确认； | 流水线 pipelining 带来的影响 . | 必须增加序号范围，每个分组必须有一个唯一的序号 | 协议的发送方和接收方两端必须缓存多个分组 | 序号范围和缓冲 取决于数据传输协议如何处理丢失、损坏、延时过大的分组；流水线的差错恢复的方法： 回退N步 （Go-back-N GBN)，选择重传 (Seletive Repeat, SR) | . | . 3.4.3 回退N步 . |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   | . ​ base nextseqnum . ​ —–窗口长度—- . 窗口到nextseqnum前是已发送但未确认分组，nextseqnum后是未发送分组 . | 已经被发送但是还没有确认的分组的许可序号范围可以被看成一个在序号范围内的N的窗口； | N为窗口长度 window size， GBN协议也被称为滑动窗口协议 sliding window protocol | 运输层分组首部：分组序号，szie为k比特，则序号范围=[0, 2^k -1]，序号使用模2^k运算； | TCP的序号按照字节流中的字节计数 | GBN响应的三种类型 . | 上层调用 rdt_send()，当前窗口未满时（判断是否已经有N个已经发送但是未被确认的分组），产生一个分组并发送，并更新变量；如果窗口已满，发送方需要将数据返回给上层，上层会稍等再试； | 收到一个ACK，在GBN中，对序号为n的分组采用累计确认 cumulative acknowledgment 的方式，表明接收方已经正确接收n及n在内的所有的分组 | 超时事件，出现丢失和时延过长分组的情况下，发送方重传所有已经发送但是还未确认的分组，也就是重传当前窗口中的所有分组； | . | GBN中，接收方，序号为n的分组被按序正确接收则接收方发送一个ACK，其他情况下接收方丢弃分组，并为最近按序接收的分组重新发送ACK； | 如果序号为k的分组已经交付给上层，则证明k-1个分组都已经交付 | 因为数据必须按序交付，如果接收方等待分组n但是却收到了分组n+1，接收方会直接丢弃分组n+1，因为如果不丢弃会导致发送方重传，因此只需丢弃n+1，优点是接收缓存简单，接收方无需缓存失序分组； | 发送方需要维护窗口的上下边界及nextseqnum在该窗口的位置，接收需要维护下一个按序接收的分组序号；且保存在expectedseqnum; | . 基于事件编程 event-based programming . 3.4.4 选择重传 . | 选择重传 SR 协议通过让发送方仅重传那些它怀疑在接收方出错（丢失、受损）的分组 | . |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   | . ​ base nextseqnum . ​ —–窗口长度—- . nextseqnum前包含 已经确认的分组 和 已发送未确认分组 . nextseqnum之后是 未发送分组 . | 发送方和接收方的序号空间 | 发送发 . | 从上层接收数据，序号位于窗口内，将数据打包发送，如果不在窗口内，则将数据缓存或者将数据返回给上层； | 超时，每个分组有自己的逻辑定时器，超时发生后只能发送一个分组，使用一个硬件定时器模拟多个逻辑定时器； | 收到ACK，发送方收到ACK且判断在窗口内时，SR发送方将分组标记为“已接收”；当收到的序号等于send_base时，则base向前移动到“最小序号的未确认处”，如果序号为窗口内未发送分组，则发送这些分组 | . | 接收方，将确认每个正确接收的分组，失序的分组将被缓存直到所有丢失分组都被收到为止；所有分组被收到后，将分组按序交付给上层； . | 序号在[rcv_base, rcv_base + n -1]内的分组被正确接收，收到的分组落在接收方的窗口内，选择ACK被会送给发送方；分组以前没有收到过，则缓存；分组序号为base序号，则触发该分组前的连续分组交付给上层；窗口向前移动并按照编号交付分组； | 序号在[rcv_base, rcv_base + n -1]内的分组被正确接收，此时，必须产生一个AC | . | 接收方会重新确认（ACK）已经收到过的序号小于当前窗口base的分组； | SR中接收方和发送方的窗口不总是一致的； | . | 对于SR协议，窗口的长度必须小于或者等于序号空间大小的一半； | Page153，对于发送方窗口序号为0，1，2，3，0，1，2 窗口长度为3，接收方无法判断序号为0的分组是重传还是第五个分组的初次传输；此处序号空间是4，但是窗口size为3，导致协议无法工作； | . 可靠数据传输机制总结 . | 机制 | 说明 | . | 检验和 checksum | 检验分组数据bit是否受损 | . | 定时器timer | 用于分组丢失的情况下的超时重传，分组丢失或者ACK回复在链路中丢失，或者因为链路时延导致超时；重传可能会导致接收方的分组冗余 | . | 序号 sequence number | 对从发送方到接收方的数据按序编号，发送方可以按序交付数据给接收方，接收方通过序号检测数据是否受损或者丢失并向发送方回复；接收方还可以通过序号检测是否收到了冗余副本； | . | 确认 ACK | 接收方用于确认一个分组或者一组分组是否正确接收，携带被确认的分组的序号或者多个序号，确认可以逐个也可以是积累的； | . | 否定确认 NAK | 接收方用于回复发送方某一个序号的分组未正确接收，例如数据顺坏，携带被否定确认的分组的序号； | . | 窗口、流水线 sliding window | 发送方通过一次发送多个分组，不断更新窗口位置，接收方每次收到base序号的分组后，则将缓存中的分组交付给上层；窗口长度根据接收方 接收 和 缓存 报文的能力、网络拥塞程度来配置； | . | 通过假定一个分组在网络中“存活”时间不会超过一个最大的固定时间（最大分组寿命3分钟），来确保一个序号的分组都已经不再网络中，则可以重复使用该序号；对序号的重复使用会导致冗余分组和当前分组的混乱，所有重复使用序号的前提是必须保证网络中不再包含该序号的分组； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#34-%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#34-可靠数据传输原理"
  },"142": {
    "doc": "计算机网络",
    "title": "3.5 面向连接的运输：TCP",
    "content": "3.5.1 TCP连接 . | 发送预备报文段，进行握手，以建立确保数据传输的参数，进而建立“连接”； | TCP/IP Transmission Control Protocol/Internet Protocol，建立之初为单一的实体，后来将其分开为TCP和IP协议，存在于网络的不同层次 | 连接状态完全保留在两个端系统中，中间网络不会维持TCP连接，中间网络对TCP连接完全“视而不见” | 全双工服务（full-duplex service）；进程A和进程B可以同时发送数据； | 点对点（point-to-point），单个发送方和单个接收方； | . 连接的建立 . | 客服进程、服务器进程 | . clientSocket.connect((serverName, serverport)) . | 两个进程之间发送了3个报文段，前两个不承载“有效载荷”，建立的过程被称为三次握手（three-way handshake） | 客户进程通过套接字将数据传递给TCP服务，TCP将数据引导到发送缓存（send buffer）；TCP从缓存中取出数据放入报文段并发送，取出数据受限于最大报文段长度 MSS 1460byte，最大链路层帧长度最大传输单元 MTU | MSS指的是TCP报文段中的数据的最大长度； | TCP为每一块数据加上TCP首部，从而形成多个TCP报文段 TCP segment，报文段被传给网络层，IP协议的服务将其封装在IP数据报中；然后IP数据报被发送到网络中；TCP的接收端有自己的接收缓存； | 组成：一台主机上的缓存、变量、与进程连接的套接字，另一台主机上的缓存、变量、与进程连接的套接字 | . 3.5.2 报文段 结构 . | 32bit | . | 32bit | . | 源端口号 | 目的端口号 | . | 序号 | . | 确认号 | . | 首部长度|保留未用|URG|ACK|PSH|RST|SYN|FIN | 接收窗口 | . | 检验和 | 紧急数据指针 | . | 选项 | . | 数据 | . | MSS限制了报文段数据字段的最大长度，对于较大的文件，TCP会将文件划分成若干块进行处理 | 和UDP相同，首部包括了源和目的端口、检验和字段（checksum） | 32bit的序号字段，32bit的确认号字段 | 16bit的接收窗口字段，用于流量控制，用于指定接收方愿意接收的字节数量 | 4bit的首部长度字段，典型长度为20byte | 选项字段，可变长度用于协商MSS | 6bit的标志字段 flag field . | ACK 用于确认报文段是否被成功接收，1 bit | RST、SYN、FIN用于连接的建立和拆除，1bit | PSH表示，是否立即将数据交付给上层，1bit | URG表示，报文段中是否 ”存在“ 被发送端的上层实体置为”紧急“的数据 | 紧急数据指针字段用于指出紧急数据，存在时TCP会通知上层服务；16bit | . | . 序号和确认号 . | 一个报文段的序号（sequence number for a segment）是报文段的首字节的字节流编号； | . 例如MSS为1000，一个500 000字节的文件，TCP每个报文段的序号应该是：0，1000， 2000… . | 确认号： 接收方填充进报文段的确认号为接收方等待发送方发送的数据流中下一个的字节； . | TCP只确认该数据流中至第一个丢失字节位置的字节，TCP为 累计确认 （cumulative acknowledgement） | 报文失序到达的处理选择： . | 接收方将直接丢弃失序报文 | 接收方保留失序的字节，并等待缺少的自己以填补间隔。实践中采用此方法 | . | TCP连接双方可以随机的选择初始序号，目的是防止同端口的先前已经断开的连接但是有报文段存在与网络中，可能会导致这个报文段被认为是新连接的报文段； | . Telnet 远程登录的应用层协议，运行在TCP之上的交互式应用；Telnet和ssh的区别是没有加密 . 回显：echo back . telnet用例，Page160 . | 捎带：服务器对来自客户数据的确认被装载在一个承载了服务器到客户数据的报文段中； | TCP数据为空时，也会存在序号字段； | . 3.5.3 往返时间与超时 . | TCP使用超时重传机制 | TCP使用 SampleRTT来预估 一次的RTT时间，TCP会维持一个平均值EstimateRTT，当获取到新的SampleRTT，计算加权平均值的方式如下： | . EstimatedRTT = （1- α）· EstimatedRTT + α · SampleRTT . DevRTT = (1-β) · DevRTT + β · |SampleRTT - EstimatedRTT| . α参考值为0.125，β推荐值为0.25 . 指数加权移动平均 . 定义了DevRTT为SampleRTT到EstimatedRTT的偏离程度 . | 考虑到SampleRTT的波动，超时重传的时间间隔 | . TimeoutInterval = EstimatedRTT + 4 · DevRTT . | 初始推荐为1秒 | . 实践原则 . | TCP的快速重传，收到对一个报文段的3个冗余ACK就可作为对后面报文段的一个隐式的NAK，从而在超时触发前就对报文段重传； | TCP使用流水线，发送方在任意时刻都有多个已经发出但是还未被确认的报文段存在； | . 3.5.4 可靠数据传输 . | 回顾：IP协议的不可靠，数据报可能会溢出路由器输出缓存，数据报达到目的地址乱序，数据报在传输过程中比特可能损坏； | TCP是在IP的不可靠服务上创建的可靠数据传输服务（reliable data transfer service） | 确保：进程从接收缓存中读取的数据流是无损坏、无间隔、非冗余、按序 | . 单一重传定时器简化描述 . | 事件一，TCP从应用层接收数据，并将数据进行封装，报文段被发送给IP时，TCP启动定时器，这里定时器的timeout时间是前面提到的TimeoutInterval，由EstimatedRTT和DevRTT计算得出 | 事件二，发送方处理来自接收方的ACK（这里的ACK被包含数据的报文段捎带），TCP将ACK确认号与窗口变量SendBase进行比较，因为累计确认，ACK的值确认了该值前的所有序号的数据都已经正确接收，发送方更新SendBase后，TCP需要重启定时器； | . 情况描述，A为发送方，B为接收方 . | A发送序号为92的长度为8的报文段，等待B的确认号为100的报文段；B发送给A的报文丢失，A超时重发，B收到了已经收到的报文段，B中的TCP服务将丢弃报文段中的字节； | A发送序号为92的长度为8的报文段和序号100长度为20的报文段，两个报文段完好到达B，B为每个报文发送一个确认，第一个确认号为100，第二个确认号为120，两个确认报文段在超时前未到达B，A将重传序号为92的报文段，并重启定时器，120的ACK报文段到达，第二个报文段就不被重传； | 和2中情况一样，100的确认号的报文段在网络中丢失，120的确认号的报文段到达A，A确认199及之前的所有字节都已经正确接收，A不会重传任何一个报文段； | . 超时间隔加倍 . | 超时事件发生，TCP重传具有最小序号的还未被确认的报文段；每次重传将下一次的超时时间间隔设置为先前值的2倍，而不是使用计算值，定时器在收到上层数据或者收到ACK报文段时将恢复计算时间为超时时间间隔； | 这里的超时时间间隔的指数型增长，提供了一种简单形式的拥塞控制； | . 快速重传 . TCP不使用否定确认 NAK . | TCP接收方发送ACK的动作 . | 收到比期望序号要大的报文段，检测出现了间隔，则发送冗余ACK，也就是间隔低端的序号的确认号； | 按序到达的报文段，等待下一个按序到达的报文段500ms，下一个没有在此时间间隔内到达，则发送ACK | 单个积累ACK | 接收数据间隔的报文段到达，发送ACK | . | 接收方收到3个冗余ACK（快速重传的条件是3个冗余 ？为什么），TCP执行快速重传，即在该报文段定时器超时前重传丢失报文段； | 选择确认，有选择的确认失序报文段，而不是累积到最后一个正确接收的有序报文段，与选择重传相结合； | . 3.5.5 流量控制 . | TCP缓存溢出：TCP的两则都有接收缓存，TCP接收到正确的、按序的字节后，将数据放入缓存，应用程序从缓存中读取数据，如果应用当前其他事务繁忙，则有可能发送缓存溢出的情况； | 流量控制服务（Flow-control service），匹配发送方的发送速率和接收方应用程序的读取速率； | 流量控制 . | RcvBuffer：配置的接收缓存的大小 | LastByteRead：从缓存中读取的数据的最后一个字节的编号 | LastByteRcvd：达到的按序报文段放入缓存的数据流的最后一个字节的编号 | LastByteRcvd - LastByteRead &lt;= RcvBuffer 必须成立才可不发生溢出 | 当前的接收窗口：rwnd = RcvBuffer - [LastByteRcvd - LastByteRead] | rwnd空间为动态变化的空间，rwnd值会被接收主机放入发给发送方的报文段的”接收窗口“字段，开始时rwnd = RcvBuffer | 发送方跟踪的变量：LastByteSent, LastByteAcked | 发送方在整个连接的生命周期内必须保证： LastByteSent - LastByteAcked &lt;= rwnd | 发送方要保证，当前所有未被确认的数据长度一定小于等于接收方返回的窗口长度 | 特殊情况：接收方窗口为0时，发送发将继续发送只有一个字节数据的报文段，接收方确认，当缓存清空后，确认报文将包含一个非0的窗口值rwnd；这里再清空前还是会发生重传； | 注意：UDP不存在流量控制，所有对于UDP会出现缓存溢出 | . | . TCP的连接管理 . | TCP连接的建立与拆除 | 连接建立的过程会显著增加用户感受到的时延 | 网络攻击利用TCP连接管理的弱点、 | . 连接建立的步骤 . isn = identity sequence number . | 第一步，客户的TCP服务向服务端的TCP发送一个特殊的TCP报文段，该报文段不包含应用层数据，但是报文段的首部的标志位“SYN”的比特被置为1；客户随机选择一个起始序号（client_isn），并将该编号放在TCP SYN报文段的序号字段中；表示发起建立新的连接 | 第二步，包含TCP SYN报文段的IP数据报到达服务端，服务器从数据报中提取TCP SYN报文段，为TCP连接分配缓存和变量（这里分配的缓存和变量容易受到洪泛攻击），并发送允许连接的报文段，允许连接的报文段：不包含任何应用层数据，SYN标志位被置为1，确认号为client_isn+1，序号为随机选择的服务器初始序号 server_isn；表示收到了发起连接的SYN的client_isn，同意建立连接，称作SYNACK报文段(SYNACK segment) | 第三步，客户收到SYNACK报文段后，客户给该连接分配缓存和变量，**客户向服务端发送一个对服务端SYNACK的确认，确认序号为server_isn+1，且SYN被置为0，这个数据报中可以携带客户应用层数据； | . | 这个步骤被称为“3次握手”，从第三个步骤开始次周的报文段传输的过程中SYN标志位都为0，建立的过程中交换了3个分组； | . 连接拆除的步骤 . 两个进程都可以终止当前的连接，连接接收后，TCP服务分配的缓存和变量都会被释放和回收； . | 客户应用程序发起关闭连接的命令，客户TCP向服务器发送报文段：首部标志位FIN被置为1； | 服务器收到FIN 为1的报文段后，向发送发会送一个确认报文段； | 服务器发送自己的终止报文段，其FIN比特被置为1； | 客户向服务端发送的终止报文段，发送一个确认，此时两台主机上用于该连接的所有资源都被释放； | . 状态变迁 . | TCP状态 TCP state | 客户连接状态变化： . | CLOSED -&gt; 客户向服务端发起一个连接，并发送SYN 1的无数据报文段 | SYN_SENT -&gt; 接收到服务端会送的SYN 1的无数据报文段并且携带了对client_isn的确认，并发送对server_isn的确认 ，该确认只进行确认，SYN为0，且可以携带应用层数据 | ESTABLISHED -&gt; 客户端连接建立成功； 拆除： 应用层调用了关闭连接，TCP发送FIN标志位 1的报文段，客户进入等待FIN确认的状态 | FIN_WAIT_1 -&gt; 接受到服务端回送的对FIN1的确认报文段，进入等待服务端发送FIN 1的报文段的状态； | FIN_WAIT_2 -&gt; 接收服务端回送的FIN 1的报文段，发送对该报文段的确认； | TIME_WAIT -&gt; 等待状态，等待30S后关闭连接，ACK丢失，TIME_WAIT状态使TCP客户重传最后的确认报文，TIME_WAIT消耗的时间与集体实现有关系，典型值30s，1min，2min | CLOSED -&gt; 连接关闭资源释放 | . | 服务端连接的状态变化： . | CLOSED -&gt; 服务器创建一个监听套接字，进入LISTEN状态 | LISTEN -&gt; 处于LISTEN状态的TCP服务，接收来自客户的SYN，并回送SYN和确认号+序号 | SYN_RCVD -&gt; 进入已经接收SYN并等待ACK的状态 | ESTABLISHED -&gt; 接收来自客户对SYN回报的确认正确接收ACK，ACK中包含服务端等待的的报文序号和服务端发送SYN的确认号，且可能包含数据，此时TCP服务将分配缓存及变量开始处理数据； | CLOSE_WAIT -&gt; 拆除：处于已经建立了连接的服务端，收到一个FIN标志位为1数据报，并对客户发送收到确认，确认号及序号 | LAST_ACK -&gt; 服务端主动向客户发送一个FIN标志位为1的的数据报 | CLOSED -&gt; 接收来自客户对服务端发送的FIN数据报的ACK确认，不在发送数据，TCP和套接字 、进入关闭状态； | . | 客户的TIME_WAIT作用， . | . | 当主动关闭方处于TIME_WAIT状态时，一般会等待两个MSL（一般为60S），目的是确保，最后对被动方发送的FIN 1的报文的ACK确认报文段如果在网络中穿线丢失或者网络拥塞未到达处于LAST_ACK的被动关闭方，则被动关闭方可能会多次重传最后一个FIN 1的报文段，这样主动方可以发送ACK回复； | 如果做超时等待和重传，当该该端口和套接字再次建立新的TCP连接时，可能会导致新的连接收到被动关闭方最后的多次重传FIN 1的报文段的影响；所以TIME_WAIT时保障被动关闭方完全进入CLOSED状态，超时后主动发起方才会进入关闭状态并释放相应缓存和变量； | . | . | 三次握手的最后一次，服务端等待客户发送最后的携带数据的ACK报文段，如果超时时间内没有收到（超时时间一般 为60s），则服务端将终止当前的半开连接，并回收资源； | DoS攻击(Denial-of-service attack)，SYN洪泛攻击（SYN flood attack），攻击者发送大量的TCP SYN报文段，不完成与server的三次握手，服务端不断对这样的半开连接分配资源（但资源未得到使用），导致服务器的连接资源被消耗殆尽； | 防止攻击的手段时，使用SYN cookie，使用散列函数生成对SYN的特殊TCP序号，对返回的ACK报文段中的确认号和再次以相同方式计算散列函数的值相比较，也就是ACK=服务器返回的序号+1，这种情况下就可以判断是否要建立连接，否则对服务器无危害，因为服务器并没有分配任何资源，仅仅只使用了散列函数； | 当TCP向一个不处于监听状态或者说不接收任何连接的端口，发送SYN建立连接的报文段时，接收主机的TCP将向源地址回送一个重置报文段，该报文段首部的RST标志位置为1；这个标志位表示的是”我没有那个报文段的套接字，请不要再发送该报文段了“；同样的问题出现再UDP套接字不匹配的情况时，接收主机将会发送一个特殊的ICMP数据报； | . nmap端口扫描工具 . 扫描一个TCP端口，发送一个TCP SYN 1的报文段，有可能的三种情况 . | 目的主机回送SYN ACK报文段，该端口的TCP连接处于打开状态（LISTEN） | 目的主机回送一个RST报文段，SYN报文段到达了目标主机，但是目标主机该端口未运行TCP应用 | 源主机没有收到任何返回，标识SYN报文段被防火墙阻挡，无法到达目标主机 | . nmap工具可以检查TCP打开的端口，打开的UDP端口，哈可以检查防火墙配置 . 3.6 TCP拥塞控制原理 . | 异步传递方式 ATM | 可用比特率 ABR | . 3.6.1 拥塞原因和代价 . | 两个发送方和一台具有无穷大缓存的路由器 . | 两个主机各自有一条连接，且共享源和目的之间的单跳路由，PAGE 175 | 代价1：当分组到达的速率接近链路容量时，分组经历了巨大的排队时延； | 共享输出链路的容量 R | 代价2：发送方必须执行重传以补偿因为缓存益处导致的分组丢失 | 代价3：发送方再遇到网络时延较大的情况下，会重传分组，导致路由器会利用链路带宽来转发一个不需要的分组副本； | 代价4：一个分组沿着一条路径被丢弃时，每个上游的路由器对该分组的转发都是在浪费传输容量； | . | . 3.6.2 拥塞控制方法 . | 端到端拥塞控制：TCP通过端到端的方法解决拥塞问题，IP层不会向端系统提供有关网络拥塞的反馈；TCP接收方通过三次冗余确认告知接收方报文段的丢失，报文段的丢失就是一种网络拥塞的迹象，TCP会相应的减小窗口长度，往返的时延值作为网络拥塞程度的指示； | 网络辅助的拥塞控制，网络层的路由器会向发送方提供关于链路中的拥塞情况；反馈方式为，阻塞分组（choke packet），路由器标记或更新从发送方流向接收方的分组中的某个字段来指示拥塞的产生；收到标记的分组后，接收方就会向发送方通知网络的拥塞； | . 3.6.3 网络辅助的拥塞控制的例子：ATM ABR 拥塞控制 . | ATM ABR拥塞控制算法，采用网络辅助的方法解决拥塞控制的协议； | . ATM . | ATM采用面向虚电路（VC）的方法来处理分组交换；交换机将维护有关源到目的的VC状态；逐个VC的状态允许交换机跟踪各个发送方的行为，并采取相应的拥塞控制动作；例如跟踪分组的平均速率，显示的通知发送方减少发送分组的速率； | ABR是一种弹性数据传输服务，ABR服务会在网络轻载时充分利用空闲的可用带宽；网络拥塞时，ABR服务会将其传输速率抑制为某些预先确定的最小传输速率； | . 详细：PAGE 180 . 3.7 TCP 拥塞控制 . | TCP使用端到端的拥塞控制机制，IP层不向端系统显示的提供任何网络拥塞程度的反馈； | 采用的方法：让每个发送方根据所感知的到的网络的拥塞程度来限制向连接发送流量的速率，动态调整流量发送速率，无拥塞时增加速率，有拥塞时降低速率； | 拥塞控制的实现： . | 流量速率限制：TCP连接维护一个发送缓存，和一个接收缓存，和多个变量（接收方LastByteRead，LastByteRcvd，RcvBuffer，rwnd 发送方：LastByteSent，LastByteAcked）；发送方会跟踪变量”拥塞窗口“（congestion window），表示为cwnd； . | LastByteSent - LastByteAcked &lt;= min { cwnd, rwnd} | 发送方中未被确认的数据量不会超过 接收窗口和拥塞窗口中的最小值； | 通过调节cwnd的值，发送方能够调整它向连接发送数据的速率； | . | 感知拥塞：分组丢失后接收方发送3个冗余ACK，或者接收方出现超时，这时发送方就认为路径上出现了拥塞； . | TCP使用确认（或者计时）来触发增大拥塞窗口的长度，self-clocking; | 一个丢失的报文段意味着拥塞，因此当丢失报文段时应该降低TCP的发送方的速率； | 一个确认报文段指示网络在向接收方交付发送方的报文，因此，当先前未确认的报文段的确认达到时，能够增加发送方的速率； | 带宽探测；增加传输速率以响应到达的ACK确认报文段，除非出现丢包事件，此时才减小传输速率；TCP发送方增加发送速率，到出现拥塞，从该速率后退，进而再次进行探测，检查拥塞是否发生了变化；ACK和丢包事件充当了隐式的信号； | TCP发送方根据异步于其他TCP发送方的”本地信息“行动； | . | . | TCP拥塞控制算法（TCP congestion control algorithm） . | 慢启动 | 拥塞避免 | 快速恢复 | . | . 慢启动 . | slow-start，发送方的起始cwnd值为一个MSS，起始发送速率为MSS/RTT，每当传输的报文段首次被确认接收ACK，cwnd就增加一个MSS，在这个过程中每一个RTT，cwnd的值就会翻番，起始阶段很慢，但是在整个慢启动阶段以指数增加； | 慢启动对超时和丢包事件的处理，即发送拥塞时的处理，有两种方式，1是将cwnd设置为1重新开始慢启动过程，将ssthresh（慢启动阀门）设置为cwnd/2，当出现拥塞将ssthresh设置为拥塞窗口的一半；当cwnd的值等于ssthresh时，结束慢启动并且将TCP转移到”拥塞避免模式“； | 当检测到3个冗余ACK，这时TCP执行一种快速重传并进入快速恢复状态； | . TCP分叉 PAGE 193 . 拥塞避免 . | 进入拥塞避免的TCP，cwnd的值大约是遇到拥塞时的一半，这时每个RTT的确认ACK只将cwnd的值增加1个MSS；例如当前窗口每次发送10个报文段，假设每个报文段都有自己的确认ACK，则每次收到一个ACK，拥塞窗口的长度就增加1/10MSS，当10个ACK都收到时，就增加了一个MSS； | 出现超时：cwnd的值被设置为1个MSS，ssthresh被设置为cwnd/2，并进入慢启动状态； | 出现冗余ACK事件：TCP将cwnd减半，加上三个ACK的3个MSS，进入快速恢复状态 | . 快速恢复 . | 进入快速恢复后，对每个收到的冗余报文段的ACK，cwnd的值增加一个MSS，当丢失报文的一个ACK到达时，TCP再降低cwnd后进入拥塞避免状态； | 出现超时，执行与拥塞避免相同的操作，进入慢启动状态； | 出现丢包，cwnd的值设置为1个MSS，将ssthresh的值设置为cwnd的一半； | . 全局回顾 . 当TCP通过3个冗余ACK感知到了丢包，TCP进行的拥塞控制是：每个RTT内cwnd线性增加1MSS，出现3个冗余ACK事件时cwnd减半； . | TCP拥塞控制：加性增，乘性减 additive-increase， multiplicative-Decrease AIMD | TCP线性的增加他的拥塞窗口的长度（线性增加发送速率），直到出现3个冗余ACK事件，然后以两个因子来减少拥塞窗口的长度，然后又开始线性增长，探测是否还有另外可用的带宽； | Reno算法 | . 吞吐量的宏观描述 . | PAGE187 | 一天连接的平均吞吐量0.75 x w /RTT ，这里的w表示当前拥塞窗口的长度； | . 经高带宽路径的TCP . | PAGE187 | . 公平性 . | UDP没有内置的拥塞控制，UDP上的应用需要好以恒定的速率将数据注入网络中，UDP连接在TCP的观点看来时不公平的，因为它不与其他的连接合作，也不会适时的调整传输速率，TCP的拥塞控制在面临拥塞增加时，会降低其传输速率，原则上UDP并不会这样做；UDP源可能会压制TCP流量； | TCP应用建立的并行连接会导致网络中应用程序带宽分配的不公平； | . 3.8 本章总结 . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#35-%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E8%BF%90%E8%BE%93tcp",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#35-面向连接的运输tcp"
  },"143": {
    "doc": "计算机网络",
    "title": "4. 网络层",
    "content": ". | 交付方式 . | 数据报模式 | 虚电路模式 | . | 网络层功能 . | 转发 forwarding | 路由选择 routing | 网际协议IP IPv4, IPv6 | 网络地址转换NAT | 数据报分段 | 因特网控制报文协议ICMP | 路由选择算法：链路状态和距离矢量算法，等级制路由选择方法；RIP，OSPF，IS-IS，BGP | . | . 概述 . | 路由器的主要作用是将数据报（data grama）从入链路转发到出链路，路由器具有截断的协议栈，即没有网络层以上的部分；路由器除了控制目的外，不运行网络层以上的协议；、 | . 4.1.1 转发和路由选择 . | 转发：将分组从输入链路移动到适当的输出链路的过程 | 路由选择：网络层需要决定分组从发送方到接收方所要采用的路径或者路由，计算这些路径的算法为路由选择算法 routing algorithm； | . 类比驾驶：驾驶车辆通过路段可以看作转发，查看地图选择到达目的地的路径可以看作路由选择； . | 每台路由器有一张转发表（forwarding table）； . | 转发表存储：分组首部的值和路由表的输出链路接口 | 路由器通过检查到达的分组首部的字段，用该字段值再转发表中查询，从而找出输出链路的接口 | 路由选择算法，决定了插入路由器的转发表中的值，路由选择算法可能是集中式的也可能是分布式的； | 路由器接收路由选择协议报文，将报文信息用以配置路由转发表； | . | 重要术语 . | 分组交换机：一台通用分组交换设备，根据分组首部字段，从输入链路到输出链路来转移分组； | 包括链路层交换机 link-layer switches，基于链路层字段做转发决定； | 路由器 router，基于网络层字段做转发决定； | 连接建立 connection setup | . | . 4.2.1 网络服务模型 . | 网络服务模型 network service model 定义了分组再发送与接收端系统之间端到端的端运输特性 | 网络层提供的服务 . | 确保交付：确保分组最终到达目的地 | 具有时延上界的确保交付：确保分组交付，且再特定主机到主机时延上界内交付 | 有序分组交付：分组按照发送顺序达到目的地 | 确保最小带宽：主机以低于特定比特率的速率传输比特，则不会发送分组丢失，且分组再预定的时延内到达； | 确保最大时延抖动：确保发送方两个相继分组间的时间量 = 目的地接收两个分组之间的时间量 | 安全性服务，使用源和目的主机知道的会话密钥，再源主机的网络层加密向目的主机发送的所有数据报负载； | . | 因特网尽力而为服务（best-effort service），分组间的定时不能被保证，分组接受顺序也不能保证，发送分组最终是否能交付也不能保证； | 恒定比特率（Constant bit rate，CBR） ATM网络服务；像发送方和接收方之间的一条专用的、固定带宽的传输链路；信元的端到端时延、时延抖动、丢失、推迟交付的比率都确保再特定值一下； | 可用比特率（Available Bit Rate，ABR）ATM网络服务；最小信元传输速率（MCR）可以得到保证；网络有足够的空闲资源的情况下，发送方也会使用比MCR高的速率发送数据； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#4-%E7%BD%91%E7%BB%9C%E5%B1%82",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#4-网络层"
  },"144": {
    "doc": "计算机网络",
    "title": "4.2 虚电路和数据报网络",
    "content": ". | 网络层的面向连接服务和无连接服务 . | 网络层的面向连接服务和无连接服务向运输层提供主机到主机的服务，运输层则是向应用层提供进程到进程之间的服务； | 只在网络层提供连接服务的网络：虚电路网络 Virtual-Circuit VC | 只在网络层提供无连接服务的网络：数据报网络 datagram network | 运输层的连接服务只在网络边缘的端系统中实现，网络层的连接服务再端系统中和网络核心的路由器中实现； | 计算机网路的两种基本类型：虚电路网络， 数据报网络 | . | . 虚电路网络 . 因特网时一个数据报网络 . | ATM、帧中继的体系结构都是虚电路网络，在网络层使用连接，成为虚电路； | 虚电路的组成： . | 源和目的之间的路径，链路和路由器 | VC号，沿着该路径的每段链路的一个号码； | 沿着路径的每台路由器中的转发表表项； . | 每台路路由器会为分组替换一个新的VC号，分组在每条链路上有不同的VC号，且再分组的首部携带； | 路由器的转发表会管理入VC号字段和对应的出VC号字段； | 创建虚电路对路由器新增转发项，终止一条虚电路，删除相应的转发表项； | 路由器需要对进行中的连接 维持连接状态信息，分组跨越一个路由器就创建新连接，增加路由器的表项，每释放一个连接从表中删除表项； | . | . | 虚电路的3个阶段 . | 虚电路建立，运输层向网络层指定接收方地址，网络层决定一条分组通过的路径，网络层沿着路径向链路中的每一个路由器节点决定VC，在转发表中增加表项； | 数据传输，分组沿着创建号的虚电路流动； | 虚电路拆除，发送方或者接收方通知网络层希望终止该电路时，网络层会通知另一侧的端系统结束呼叫并更新路径上的每台路由器的转发表； | . | 沿着两个端系统之间的路径上的路由器都要参与虚电路的建立，且每台路由器都完全知道通过它的所有虚电路； | 端系统向网络发送的指示网络层终止虚电路的报文，和路由器之间用来传递修改路由表的虚电路建立报文，位信令报文 （signaling message），用来交换这些报文的协议位信令协议 （signaling protocol）； | . 数据报网络 . | 端系统为想要发送的分组加上目的端系统的地址，然后将分组推进网络中；路由器不维护任何虚电路； | 分组在链路中经过每一台路由器，路由器都是用分组目的地址来对分组进行转发； | 每台路由器维护一个链路接口转发表用来给目的地址做映射，对于到达分组，路由器会使用其首部的目的地址在链路转发表中查找适当的输出链路接口；然后路由器将分组向该接口转发； | IPv4地址长度 32 位bit，4段（4 group） | IPv6地址长度128位bit，8段（16进制，8group） | 转发表：路由器用分组的目的地址的前缀（prefix）与该表中的表项进行匹配；当初先多匹配时，例如一个分组的目的地址与转发表中的21位表项匹配且又与24位表项匹配，则路由器使用最长前缀匹配规则，将该分组转发到24位表项相匹配的输出链路接口上，路由器总是在链路接口转发表中匹配最长的prefix，最长匹配项；最长匹配与编址规则有关； | 路由器维护的转发表，维持了转发转台信息，转发表由路由选择算法进行更新和修改，路由器建立新连接和拆除一条连接都会更新转发表； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#42-%E8%99%9A%E7%94%B5%E8%B7%AF%E5%92%8C%E6%95%B0%E6%8D%AE%E6%8A%A5%E7%BD%91%E7%BB%9C",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#42-虚电路和数据报网络"
  },"145": {
    "doc": "计算机网络",
    "title": "4.3 路由器的工作原理",
    "content": "回顾：链路层交换机实现第一层和第二层，路由器实现第一层到第三层，路由器能够实现IP协议，链路交换机不能，链路层交换机能够实现第二层地址，以太网地址 . | 转发功能 （forwarding function） | 路由器的体系结构 | . | 输入端口： . | 物理层功能：将一条输入链路与路由器相连接 . | 数据链路层功能：与位于入链路远端的数据链路层交互 . | 通过查询转发表决定输出端口，到达分组通过路由器的交换结构转发到输出端口； . | 将“控制分组”从输入端口转发到路由器的“选择处理器”，（携带路由选择控制协议的分组） . 端口，这个词语在网络硬件中表示，路由器物理的输入和输出接口； . | . | 交换结构： . | 与输入端口和输出端口相连，交换结构完全包换在路由器中，网络路由器中的网络； | . | 输出端口： . | 存储从交换结构接收的分组 | 执行相应的物理层和链路层功能，在输出链路上传输分组 | 双向链路，输出端口和输入端口在同一线路卡上成对出现； | . | 路由选择处理器： . | 执行路由选择协议 | 维护路由表及连接的链路状态信息 | 计算转发表 | 执行网络管理功能 | . | 路由转发平面 router forwarding plane ：路由转发是路由器用输入输出端口、交换结构共同实现的转发功能，总是用“硬件”实现； . | 路由器对n个端口数据的处理，数据处理流水线需要n倍的处理速率，通过厂商定制的硬件来实现这样的功能； | . | 路由器控制平面 router control plane ：通过软件实现，路由器的控制功能，包括执行路由选择协议，对上线和下线的连接链路进行响应，及路由的管理功能； . | 路由器和交换机的设计面对一系列的拥堵问题； . | . 4.3.1 输入端口 . | 输入端口的线路端接功能 与 链路层处理 实现了用于各个输入链路的物理层和链路层，执行输出链路处理，包括链路协议，和分组的拆封； . | 输入端口中：路由器使用转发表来查找输出端口，使得到达的分组能够经过交换结构转发到该输出端口； . | 转发表由路由器的选择处理器计算和更新，转发表的一份影子副本通常会被存放在每个输入端口； . | 转发表从路由选择处理器经过独立总线，复制到线路卡； . | 影子副本的作用：在每个端口本地作出转发决策，无需调用中央路由选择处理器，避免了集中式处理的瓶颈； . | 对于Gbps的链路，要求对转发表的查询必须在纳秒级别完成； . | 硬件执行查找 | 快速查找算法，快速搜索算法使用二分的思想，平均时间复杂度为logn，对于n为百万的情况，只需要执行20次 | DRAM和更快的SRAM的嵌入式芯片设计 | 三态内容可寻址寄存器（Tenary Content Address Memory, TCRM），该寄存器可以在常数时间内对地址的转发表项内容做返回 | . | 因为交换结构可能会被其他的分组使用，当前已经匹配了转发表项的输入分组需要在输入端口排队，并等待 被调度通过交换结构； . | 物理层和链路层处理 | 检查分组版本号、检验和、寿命字段，重写字段 | 更新用于网络管理的计数器（例如IP数据报的数目） | . &gt; 对于路由器的输入端口，查找转发表然后进入交换结构进行转发，的过程可以抽象为“匹配加动作”，这个抽象在链路层交换机和防火墙中都存在； . | . 4.3.2 交换结构 . 三种交换技术 . 内存，总线，纵横 . | 经内存交换 . | 传统计算机的设计方式，CPU对分组进行在内存的I/O操作； | 现代内存交换：输入线路卡查找转发表，并将分组放入适当的内存存储位置，也就是输出端口的内存 | . | 经总线交换 . | 通过共享总线将分组发送到输出端口 . | 输入端口为分组预先计划一个内部标签（首部），该标签用来标识输出端口 | 分组在总线上传送到输出端口 | 所有输出端口都会收到分组，只有与标签匹配的端口才将分组保存，然后标签在输出端口被去除 | . | 一次只有一个分组可以跨越总线，路由器的交换带宽受到其总线速率的限制； | . | 经互谅网络交换 . | 纵横式交换机是一种由2N条总线组成的互联网络； | 连接N个输入端口和N个输出端口 | 垂直总线在交叉点和水平总线交叉，交叉点通过交换结构控制器能在任何时候开启和闭合； | 对于来自不同输入需要达到不同输出端口的分组，纵横网络能够转发多个这样的分组； | 对于进入相同总线的分组，还是需要排队等待； | . | . 4.3.3 输出端口 . | 输出端口：取出存放在输出端口内存中的分组，并将其发送到输出链路上； | 选择和取出排队分组进行传输，执行链路层和物理层传输功能； | . 4.3.4 排队 . | 输入和输出端口处都会形成分组排队 | 排队位置和程度：取决于流量负载、交换结构的相对速率、线路速率； | 随着队列增长，路由器的缓存空间最终耗尽，新到达的分组将会出现丢包 packet loss； | PAGE 218 描述了从理论到实践路由器转发分组的排队情况和路由器缓存配置情况 | . 分组调度程序 packet scheduler . | 服务原则 . | 先来先服务 FCFS | 加权公平排队 WFQ，端到端之间公平的共享输出链路 | 服务质量保证 quality-of-service guarantee | . | . 丢弃到达分组的策略 . | 弃尾策略 | 主动队列管理 Active Queue Management AQM 算法，在缓存满前就丢弃分组的策略 | 随机早期检测算法 广泛应用的AQM算法 . | 算法思想：为输出队列长度维护一个加权平均值，平均队列长度小于阈值MINth，接纳分组，如果平均长度大于MAXth，则丢弃新到达的分组，如果平均长度处于[MINth MAXth]，则使用函数概率标记或丢弃函数； | . | 线路前部阻塞，一个输入队列中的排队分组，必须等待通过交换结构发送，即使当前目标的输出端口是空闲的，因为它被位于线路前部的另一个分组所阻塞； | . 4.3.5 路由选择控制平面 . 路由选择控制平面驻留并运行在路由器选择的处理器上，网络范围的路由选择控制平面是分布式的，不同功能部分执行在不同的路由器上，并且通过彼此发送控制报文进行交互； . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#43-%E8%B7%AF%E7%94%B1%E5%99%A8%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#43-路由器的工作原理"
  },"146": {
    "doc": "计算机网络",
    "title": "4.4 网际协议： 转发和编址",
    "content": ". | 编址和转发 | IPv4 IPv6 . | 网络层的三个组件 . | IP协议 | 路由选择，决定数据报从源地址到目的地址流经的路径 | ICMP协议：报告数据报中的差错，对网络层信息请求进行响应的设施 | . | 视图 | . | 运输层 TCP、UDP | . | 路由选择协议 * 路径选择 *RIP OSPF BGP —&gt; 转发表 | . | IP协议 * 编址规则 * 数据报格式 * 分组处理规则 | . | ICMP协议 * 差错报告 * 路由器 ”信令“ | . | 链路层 | . | 物理层 | . 4.4.1 数据报格式 . | 网络层的分组： 数据报 datagram | IPv4 数据报格式 | . | IPv4数据报格式 32bit | . | 版本 | 首部长度 | 服务类型 | 数据报长度（字节） | . | 16比特标识 | 标志 | 13比特片偏移 | . | 寿命 | 上层协议 | 首部检验和 | . | 32比特源IP地址 | . | 32比特目的IP地址 | . | 选项（如果有的话） | . | 数据 | . | 版本：4个比特，IP协议版本 . | 首部长度：4个比特，用来确定数据部分从哪里开始，不包含选项的情况，数据报首部为20字节 . | 服务类型：TOS，实时数据报，非实时数据报，用来确定数据报的优先级 . | 数据报长度：包括首部的IP数据报的总长度，16比特，最大理论长度2^ 16,65535 . | 标识、标志、片偏移：IP分片 . | 寿命：Time-To-Live TTL，每经过一个路由器，该值减1，TTl为0时丢弃，取保数据报不会永远在路由选择环路中循环转发； . | 协议：上层协议，6为TCP，17为UDP . &gt; 协议号：网络层与运输层绑定到一起的粘合剂 &gt; &gt; 端口号：运输层与应用层绑定到一起的粘合剂 &gt; &gt; 链路层帧 . | 首部检验和：checksum，检验收到的ip数据报中的比特错误； . | 只对首部做检验 | 计算方式：将首部中的每2个字节，也就是16个比特相加在进行反码运算； | 每个路由器都要对每个收到的IP数据报进行首部检验和的计算，检测出差错就丢弃，因为TTL每次都会减1，所有路由器会每次重新计算检验和并放置到数据报的检验和位置 | IP协议和TCP/UDP协议都需要进行检验和 . | IP数据报只是对数据报的首部进行检验 | TCP/UDP是对整个报文段进行检验，而且报文段就是IP数据报的数据部分 | TCP原则上可以运行在其他协议上 如ATM | . | . | 源和目的IP地址 . | 选项：允许IP首部被扩展，很少使用，已经在IPv6中去除 . | 数据：有效载荷，运输层报文段，或者ICMP报文 . | . 对于无 “选项” 的IP数据报首部总长度为20个字节； . 如果IP数据报承载了TCP报文段，则数据报承载了20字节的IP数据报首部，20字节的运输层TCP报文段的首部，及应用层报文； . IP数据报分片 . | 对于不同的链路层协议，其能承载的网路层数据报的长度不同，以太网协议能承载1500字节的数据，某些广域网链路帧可承受不超过576字节的数据； | “最大传送单元”：Maximum Transmission Unit, MTU, 一个链路层数据帧能够承载的最大数据量； | 发送方和接收方的路径上的每段链路可能使用不同的链路层协议，每种协议都可能由不同的MTU； | 对于过大的IP数据报，超过链路MTU的情况下，需要对IP数据报做分片；单独的链路帧将封装这些较小的IP数据报；然后将链路帧发送到链路上，每个较小的数据报为“片” fragment | 分片方法： . | 发送端该数据报设置源目的地址的同时，会贴上“标识”，为每个发送的数据报标识加1； | 路由器需要对数据报分片时，每个数据报都会由源目的地址和自己的标识号； | 目的主机通过标识号确定那些数据报（片）是同一个大的数据报； | 最后一片的标志比特为0，其他片的标志比特为1，目的是让目的端确定已经收到了所有的片； | 偏移字段用来指定该片在数据报中的位置，目的端按照顺序组装，同时也可以确定数据报是否有片丢失； | . | 目的端，只有当IP层已经完成了重构初始IP数据报时，有效载荷才会被传递给运输层；如果一片或者多片没有到达目的地，则不完整的数据报会被丢弃，不会交给运输层；TCP超时重传、选择重传、快速重传 | Jolt2 DoS攻击 | . 4.4.2 IPv4 编址 . | 主机与路由器连入网络 . | 一台主机通常只有一条链路连接到网络； | 主机和物理链路之间的边界叫做接口 interface； | 一个ip地址与一个接口相关联，不与主机及路由器相关联； | IP地址，32bit，点分十进制法书写； | 因特网处NAT之外的每台主机的接口都有一个唯一的IP地址； | IP地址的一部分由连接的子网来决定； | 例子： . | 3台主机与1台路由器相连，4个接口的ip地址的前24bit相同； | 3个主机的接口与一个路由器的接口形成一个子网（subnet）； | IP编址为这个子网分配一个地址，”/24“，为子网掩码（network mask），这表示32bit中最左侧的24比特定义了子网地址； | 任何需要连入该子网的主机，ip地址都需要具有与前24bit子网地址相同的形式； | 确定网络中子网的方法： . | 分开主机和路由器的每个接口，产生几个隔离的网络岛，使用接口“端接”隔离的网络端点，隔离的网络中的每一个都是一个子网（subnet） | . | 一个具有“多个以太网段”和点对点链路的组织将具有多个子网； | . | . | 地址分配策略： . | 无类别域间路由选择（Classless Interdomain Routing，CIDR） | CIDR将子网地址划分为两部分，表示为a.b.c.d/x，其中x表示地址的第一部分的比特数； | a.b.c.d/x 的地址的x 最高比特构成了ip地址的网络部分，地址的前缀（prefix）（网络前缀）； | 路由选择协议，转发只考虑该网络前面的前缀比特x，这就减少了路由器中转发表的长度； | 实践原则： . | 地址聚合 address aggregation：使用单个网络前缀通告多个网络或多个子网的能力 | 也称作 路由聚合 route aggregation，路由摘要 route summarization | . | 一个地址剩余的32-x比特用来区分内部设备；只有内部设备连接的内部路由器在转发分组时，才会考虑这些剩余的bit；低级的bit可能有另外的子网结构； . | 例如：a.b.c.d/21中的前21个比特表示当前组织的网络前缀，a.b.c.d/24表示组织内部的子网； | . | 分类编址，旧方式 | ip广播地址 255.255.255.255，当一台主机向广播目的地址发送数据报时，该报文会交付给同一子网内所有的主机； | . | 获取地址 . | 从ISP获取，因特网名字和编号分配机构获取；（Internet Corporation for Assigned Names and Numbers，ICANN） | . | DHCP 动态主机配置协议 . | DHCP允许主机自动获取（被分配）IP地址，可以配置，在每次连接外部网络时都能获得相同的IP地址，或者被分配一个临时的IP地址（temporary IP address）； | DHCP还允许主机得知，子网掩码，第一跳路由器地址（默认网关），与本地DNS服务器地址 | DHCP为 即插即用协议 plug-and-play protocol | DHCP在主机加入或者 离开网络时，DHCP服务器会更新可用IP地址表；一台机器加入，则从当前可用地址池中分配任意一个地址；主机离开时，地址会回收到该地址池中； | 客户-服务器协议，客户为新到达的主机，客户需要获取一个自身使用的IP地址和网络配置信息；如果该网络中没有DHCP服务器，则需要一个DHCP中继代理； | 对于新到达的主机DHCP的四个步骤： . | DHCP服务器发现，DHCP发现报文（DHCP discover message)，客户使用UDP的DHCP发现报文，以广播地址255.255.255.255作为目的地址，本机源地址0.0.0.0作为源地址，67作为目标端口，DHCP客户将IP数据报传递给链路层，链路层将帧广播到所有与该子网连接的子网； | DHCP服务器提供，DHCP服务器收到报文后，用DHCP提供报文（DHCP offer message）向客户做出响应；仍然使用广播地址 . | 提供报文包括：发现报文的事务ID，向客户推荐的IP地址、网络掩码及IP地址租用期（address lease time） | . | DHCP请求，客户从多个DHCP服务器中选择一个，并向服务器发送DHCP请求响应（DHCP request message）进行响应，回显配置参数； | DHCP ACK，服务器用DHCP ACK报文对DHCP请求报文进行确认响应； | . | 客户收到DHCP ACK之后，交互完成，客户可用在租用期之内使用分配的IP地址，如果超时后还希望继续使用，DHCP提供一种机制允许用户更新对地址的租用； | . | 网络地址转换 NAT Network Address Translation . | NAT“使能”路由器对于外部网络来说，就是一台具有单一ip的设备，所有离开这个NAT子网的数据报，都有同一个源地址IP，所有进入该网络的数据报都有同一个相同的目的IP； . | 本质：NAT使能路由器对外界隐藏了内部网络的细节； . | 在此网络内部，有独立的NAT-DHCP服务为内部的设备分配IP，路由器从ISP的DHCP服务获取外部IP； . | NAT转发表 NAT traslation table . | 表中包含了WAN端的IP地址和端口 及 映射的 LAN端 IP地址和端口 | 对于本地子网要发送的数据报，NAT会将内部子网主机的IP地址及端口号，记录在转发表的LAN端，NAT路由器收到数据报后会生成一个新的源端口（选择当前任意一个不在转换表中的端口，支持超过60 000个并行的广域网IP地址连接），并将**数据报中的端口改为新的源端口，IP地址改为NAT的接口的广域网IP地址，并将数据报发送到目的地址；目的主机无法感知数据报中的源IP和端口都经过NAT协议的改装； | 目的端响应报文到达NAT路由器时，路由器会使用数据报中的源IP地址和源端口检索出内部子网主机的ip和端口，并改写数据报的目的IP和目的端口，并向主机转发该数据报； | . 主机通过DHCP服务器，获取了第一跳路由器的地址（网关），和自己的IP地址、子网掩码、DNS域名解析服务器的IP地址，主机会将包含目的IP和端口号的数据报直接发送到第一跳路由器（中间可能会经过NAT服务，例如家庭路由器上运行的NAT服务），路由器会对分组进行转发； . | NAT对P2P应用的影响：连接反转，NAT穿越 . | . | UPnP，即插即用协议，plug-and-play-protocol . | UPnP允许外部之际使用TCP或UDP向NAT化的主机发展期通信会话；UPnP提供了有效的NAT穿越解决方案； | UPnP协议的主要作用是：允许主机发现并配置NAT协议 | 使用UPnP，在主机上运行的应用程序能够为某些请求的公共端口号，请求一个NAT映射；UPnP让应用程序知道公共IP和公共端口，应用程序就可以将该公共IP和公共端口通知到目的主机，目的主机通过公共IP和公共端口与源主机通信； | . | . 4.4.3 因特网控制报文协议 ICMP . | ICMP协议 Internet Control Message Protocol，用于主机和路由器之间彼此沟通网络层信息，如差错报告； . | 例如在通常的应用层协议中收到的“目的网络不可达”的错误报文，就是由ICMP产生的； | 当路由器无法找到一条路径通向目的地址时，该路由器就会向源主机发出类型3的ICMP报文； | . | ICMP为IP的一部分，但是在体系机构上位于IP协议之上；ICMP报文段承载在IP数据报中；ICMP报文也时IP有效载荷； . | 主机收了指明了上层协议为ICMP的IP数据报时，解析出来的数据报内容会发送到ICMP服务； . | ICMP报文字段包括： . | 类型字段 . | 编码字段 . | 引起ICMP报文生成的IP数据报的首部和前8个字节的内容；用于发送方确定出错的数据报 . | ICMP类型 编码 描述 | 4 0 源抑制 拥塞控制 这里的拥塞控制的方式：路由器向主机发送一个ICMP源抑制报文，强制主机减小其发送速率，TCP有自己的拥塞控制机制； | . | . | ping程序基于ICMP的工作原理 . | ping程序发送一个 ICMP 类型8编码0的报文到指定主机 | 目的主机收到回显echo请求，目的主机返回一个类型0，编号0 的ICMP回显回答； | linux操作系统支持ping服务器，该服务不是一个进程（源代码） | . | IP协议规则：路由器丢弃一个数据报并发送一个ICMP告警报文给源主机，告警报文包含路哟求名称和IP地址； . | Traceroute使用特定TTL值的UDP报文来探测源和目的之间的路由器的数量和标识，以及两台主机之间的时延，对于到达目的主机的UDP报文段，由于端口不可达，所有目的主机会返回一个ICMP报文； . | . 防火墙和入侵检测系统（IDS），关注安全性PAGE238 . 防火墙可用阻挡ICMP回显请求分组，从而防止ping检测 . 防火墙也可以基于IP地址和端口号配置特殊的过滤策略 . IDS位于网络边界，执行“深度分组检查”，检查数据报的首部，检查有效载荷；并分享分组特征数据库 . 4.4.4 IPv6 . | IPv6数据报格式 | . | 32bit | . | 版本 | 流量类型 | 流标签 | . | 有效载荷长度 | 下一个首部 | 跳限制 | . | 源地址 （128bit） | . | 目的地址 （128bit） | . | 数据 | . | IPv6数据报格式变化 . | 扩大的地址容量 . | 地址容量从32bit扩大到128比特，用16进制表示； | IPv6引入了任播地址 （anycast address），用来将数据报交付给一组主机中的任意一个； | . | 简化的高效的40字节首部 . | 40字节定长首部，去除IPv4中的选项字段，允许更快的处理IP数据报 | . | 流标签与优先级 . | Flow：给属于特殊流的分组加上标签，这些特殊流是发送方要求进行特殊处理的流，如一种非默认服务质量或需要实时服务的流； | 音频和视频的传输就是一种“流” | 流量类型字段，类似与IPv4中的TOS字段，用于给出一个流中某些数据报的优先级，用来指示某些应用程序的数据报比其他应用有更高的优先权； | . | . | IPv6数据报的结构更简单，更高效： . | 版本：4bit，用于标识IP版本号； 6 | 流量类型：8bit，与IPv4中的TOS字段含义相似 | 流标签：20bit，用于标识一条数据报的流 | 有效载荷长度：16bit，给出IPv6数据报中定长40字节的首部后面的数据部分的比特数； | 下一个首部：标识数据报中的内容需要交付给，哪个协议（TCP/UDP）与IPv4中的上层协议字段相同 | 跳限制：转发数据报的每台路由器对该值减1，当计数为0时，数据报被丢弃；用来限制数据报转发的路由器数量，防止数据报在环路中一直存在； | 源地址和目的地址：128bit的源地址和目的地址字段 | 数据：有效载荷部分，包括运输层报文段的首部及应用层数据部分 | . | IPv4数据报中的字段在IPv6中已不存在 . | 分片/重新组装：IPv6不允许路由器对数据报进行分片和组装；分片和重新组装只在源和目的端执行；当路由器遇到较大分组无法转发到链路时（如超过1500个字节），直接将数据报丢弃，并向发送方回复“分组太大的” ICMP差错报文，ICMP报文也封装在IP数据报中；这样发送端收到ICMP报文后，将数据报在端系统出进行分片，从而加快了转发速率； | 首部检验和：为了快速处理IP分组，将检验和去除，数据报中只有运输层报文端有首部检验和做检验；（IPv4的耗时主要体现在每个数据报都有自己的TTL，所有每个路由器进行检验后，还需要更新数据报中的检验和） . | 选项：选项字段去除，但是任然有选项的存在，如“下一个首部”字段指向的位置有可能时“选项” | . | IPv4到IPv6的迁移 . | 双栈， 有发送和接收IPv4，IPv6两种数据报的能力； | IPv6/IPv4节点必须有IPv6和IPv4两种地址； | IPv6数据报可以转换成IPv4数据报，但是会丢失IPv6数据报首部 一些在IPv4中无对应项的字段信息； | 建隧道（tunneling），两个端系统进行IPv6数据报的交换，但是中间有一个IPv4的路由器，两个IPv6路由器之间的IPv4路由器的集合为 隧道 Tunnel，借助隧道，在隧道发送端的IPv6结点，将IPv6数据报方到一个IPv4数据报的数据部分（有效载荷），该IPv4数据报通过中间路由被转发到隧道接收端，隧道接收到取出IPv6的数据，然后再为IPv6的数据报提供转发； | . | . 4.4.5 IP安全性 . | IPsec 和 密码学基础 | IPsec兼容IPv4，IPv6 | IPsec只在端系统中可用，运输模式 . | 两个端系统先创建一个IPsec会话，IPsec是面向连接的 | 发送端运输层向IPsec传递一个报文段，IPsec加密该报文段，并在报文段上附加安全性字段，再封装到IP数据报中； | 目的主机，IPsec将解密报文段并将脱密的报文段发送给运输层； | . | IPsec会话提供的服务包括： . | 密码技术约定；两台主机之间的加密算法和密钥保持一致 | IP数据报有效载荷加密； | 数据完整性，IPsec允许主机验证数据报的首部，保证被加密的有效载荷在传输过程中没有被修改过 | 初始鉴别，受信任的源收到IPsec数据报，确信数据报中的源IP是该数据报的实际源 | . | 两台主机之间创建了IPsec会话，两主机之间的所有TCP和UDP的报文段都将会被加密和鉴别； | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#44-%E7%BD%91%E9%99%85%E5%8D%8F%E8%AE%AE-%E8%BD%AC%E5%8F%91%E5%92%8C%E7%BC%96%E5%9D%80",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#44-网际协议-转发和编址"
  },"147": {
    "doc": "计算机网络",
    "title": "4.5 路由选择算法",
    "content": ". | 主机通常直接和一台路由器相连 . | 该路由器为该主机的 默认路由器 default router . | 第一跳路由器 first-hop router . | 源主机的默认路由器为：源路由器(source router) . | 目的主机的默认路由器为目的路由器 destination router . | 路由选择： 源路由器到目的路由器的路由选择 . | 源主机 —&gt; (默认路由器 | 第一跳路由器 | 默认网关 | 源路由器) —&gt; {中间链路及路由器} —&gt; 目的路由器 —&gt; 目的主机 | . | . | 路由选择算法的目的： . | 给定一组路由器及连接路由器的链路，路由选择算法就是要找到一条从源路由器到目的路由器的“好”路径； | 简单的网络结构抽象可以用“图”graph（无向图）的数据结构来表示，G=（N，E），N表示图中的每个顶点的集合，E表示每条弧也就是每个路由器之间的链路的集合；每条弧上的权值代表这条链路的费用（费用反应出了一条边的物理链路的长度、速度、金融费用）； . | 属于E的一条弧的顶点 (x, y) ，y也被称为x的邻居（neighbor）； | 路由选择算法的目标是找到最低费用路径 | 源路由器和目的路由器之间最少链路数量为最短路径； | 当一个位置或结点有该网络的完整信息，再该节点的路由选择算法就是“集中式的” | . | . | 分类 . | 全局式的路由选择算法（global routing algorithm） . | 该算法为“集中式的全局路由选择算法” | 输入为所有节点的连通性及链路的费用，算法执行前需要获取全局的完整信息； | 全局状态信息：链路状态算法 | . | 分散式路由选择算法（decentralized routing algorithm） . | 以迭代、分布式的方式计算出最低费用路径，迭代的每个节点逐渐的计算到达某目的节点的最低费用； | 距离向量算法（Distance-Vector， DV） | . | . | 第二种广义分类 . | 静态路由选择算法（static routing algorithm），路由变化缓慢，通常人工调整 | 动态路由选择算法（dynamic routing algorithm），网络流量负载或者拓扑发生变化时改变路由选择路径；动态算法周期性的运行或者对拓扑变化直接响应 | . | 第三种分类 . | 负载敏感算法（load-sensitive algorithm） | 负载迟钝算法（load-insensitive algorithm），链路费用无法直接反应链路拥塞水平 | . | . 4.5.1 链路状态路由选择算法 Link-State . | 链路状态算法中，网络拓扑和所以的链路状态都是已知的，并且作为LS算法的输入 | 实践中 . | 让每个结点向网络中所有其他结点广播链路状态分组 | 每个链路状态分组包含它所连接的链路的特征和费用 例如OSPF路由选择协议 | 链路状态广播算法 （link state broadcast）来完成 | 广播的结果是该网络中的所有结点都具有了与该网络等同的、完整的视图 | 每个结点都能运行LS算法计算出最低费用的集合 | . | Dijkstra算法 - Prim算法 O(n^2) . | Dijkstra算法计算源结点到网络中其他所有结点最低费用路径 | 迭代算法，经过k次迭代后，可以直到k个目的结点的最低费用路径 | 算法思想： . | 保存每个结点的最低费用，和集合N’ | 每次迭代找出不属于N’且最小费用的节点，将它加入N’，并遍历它的所有邻居节点，并更新最小费用； | 迭代次数为节点总数 | . | 算法步骤： . | 将源节点加入集合N’中，获取和源节点相邻节点，最小费用为链路费用，如果不相邻最为正无穷 | 找到上一次所有链路费用最小的点x，将x加入N‘，遍历x的所有邻居节点，并为这些节点更新其最小链路费用 | . | 通过对每个目的节点存放从源结点到目的结点的最低费用路径上的”下一跳结点“，结点中的转发表就能够根据此信息构建； | 此算法的最差时间复杂都为 O(n^2)，使用堆的数据结构，可以将时间复杂度降低到logn级别 | 当链路的费用依赖于当前链路所承载的流量时，链路状态选择算法会出现”振荡“，解决方式是确保路由器不同时运行LS算法； | . | . 4.5.2 距离向量路由选择算法 . | 距离向量 （Distance-Vector）算法 . | 迭代：获取信息和执行计算的过程需要持续到邻居之间无更多的信息交换为止 | 异步：不要求所有结点步骤一致的进行操作 | 分布式：每个结点要从一个或者多个直接相邻的结点获取信息，执行计算，将结果分发给邻居 | . &gt; Bellman-Ford方程： &gt; &gt; dx (y) = min v { c(x, v) + d v (y) } &gt; &gt; 获取x到所有邻结点的费用，取从这些邻结点v到目标结点y的最小费用，则x到y的最小费用是所以邻居v的 c(x, v) + d v (y) 的最小值 &gt; &gt; 详见：Page 258 . | DV算法的基本思想 . | 每个结点x，对N中的所有结点，估计从自己到结点y的最低费用； | 每个结点x，维护的信息如下： . | 对于每个邻居v，从x到直接邻居v的费用 c(x, v) | 结点x的距离向量，包含了x到N中所有目的地y的费用估计值 | 每个邻居的距离向量，x的每个邻居v | . | 算法思想的理解： . | 该算法以分布式的方式，在网络中，每个结点接收相邻结点的距离向量副本，每次更新都会触发结点向响铃结点广播自己最新的距离向量； | 每个结点根据B-F方程的思想不断更新自己缓存的到其他每个结点的最小距离；（最低费用） | 当所有结点触发的更新完成后，也就是不再有异步更新时，该网络中的路由选择表趋于稳定； | . | 路由器需要周期性与相邻的路由器交换更新通告（routing updates），动态建立路由表，以决定最短路径。 | . | 伪代码： . | . // 对每个路由结点x的算法 Initialization: for all destination y in N: Dx(y) = c(x,y) // 获取结点到网络中其他结点的距离向量（如果y和x不相邻，则初始化为正无穷） for each neighbor w: Dw(y) = ? for all for all destination y in N //初始化每个邻居结点w到每个结点y的距离向量 for each neighbor w: send distance vector Dx = [Dx(y): y in N] to w // 将当前结点x到其他结点y的距离向量发送给每个邻居结点 Loop wait //一直处于等待状态。等待结束的条件：1. 发现与当前结点相连的链路费用发生变化 2. 接收到邻居结点发送来的距离向量集合 for each y in N: Dx(y) = minv {c(x, v), Dv(y)} // 结点对收到的邻居结点的距离向量集合，x到y的最小费用是，x到邻居结点v+邻居结点v到y的距离向量的最小值，从所有邻居中找到这个最小值 if Dx(y) changed for any destination y send distance vector Dx = [Dx(y): y in N] to all neighbors // 如果当前链路有费用改变，则直接向邻居结点发送距离向量集合 . | 再该分布式、异步的算法中，每个结点不时的向它的每个邻居发送它的距离向量副本，当结点x从它的任意一个邻居v接收到新的距离向量，保持v的距离向量，然后使用Bellman-Ford方程更新他自己的距离向量，对每个节点；结点x的距离向量更新后，向每个邻居发送更新后的向量；最终结果会收敛到最低费用路径； | TODO ： PAGE258 | . Dijkstra算法，LS算法是全局的，在运行之前需要先获取整改网络的完整信息 . DV算法是分布式和异步的，每个结点具有的信息是他到直接相邻结点的链路费用，和它收到的这些邻居发给它的信息； . DV算法的实践： RIP、BGP、ISO IDRP、Novell IPX . | 从邻居接收更新的距离向量、重新计算路由选择表 和通知邻居到目的地的最低费用路径的费用已经发送变化，这个过程会持续下去，直到无更新报文发送为止；这时算法进入等待状态，直到再次有线路费用变化触发算法； | . 1. 距离向量算法：链路费用改变与链路故障 . | 在链路费用变化的过程中，如果某个结点接受了邻居结点的信息后，路由选择表并没有更新，则该结点不再向其邻居结点发送信息； . | 路由选择环路 routing loop . | 分组将在两个结点之间不停的转发，例子见Page262 | 无穷级数问题 count-to-infinity | . | . 2. 距离向量算法：增加毒性逆转 . | 毒性逆转 （poisoned reverse），可以避免路由环路 | 思想：例子PAGE 262 | 无法解决3个或者更多系欸但的环路问题 | . 3. LS与DB路由选择算法的比较 . | DV和LS算法采用互补的方法来解决路由选择计算问题； | 比较 N为结点集合（路由器） E是边（链路）集合 . | 报文复杂性 . | LS算法要求每个结点都知道网络中每条链路的费用，要求发送O( | N |   | E | )个报文；一条链路如果发生了改变，则需要向所有结点发送新报文； | . | DV算法要求每次迭代时，在两个直接相邻的结点之间交换报文；当链路费用发生变化时，DV算法仅在新的链路费用，导致与该链路相连的结点的最低费用改变时，才会向其他相邻结点传播费用信息，如果不在发生改变则不会在向相邻结点发送； | . | 收敛速度 . | LS算法实现的时一个O( | N |   | E | )个报文的O(n^2)的时间复杂度 | . | DV算法收敛较慢，而且遇到路由选择环路时，会遇到无穷计数的问题； | . | 健壮性 . | LS：一个结点可以会损坏或者丢弃它收到的LS广播分组，但是LS结点只计算自己的转发表，每个结点各自接收广播分组，各自进行计算，提供了一定程度的健壮性； | DV算法：一个结点如果产生了错误的链路费用，会通知它所有的相邻结点，这个错误会一直扩散到整个网络的所有路由器上； | . | . | . 4. 其他路由选择算法 . | 因特网实践中仅有的两种类型的算法：LS算法和DV算法 | . 4.5.4 层次路由选择 . | 实践和路由选择算法模型 . | 规模，当前的因特网上路由器需要巨大容量的内存存储路由选择信息；路由器的LS广播的开销会导致没有剩余的带宽用来发送数据分组，大量路由器中算法将永远无法收敛； | 管理自治，网络需要按照意愿进行管理，还需要和外部其他网络连接； | . | 自治系统 Autonomous System AS . | 每个AS由一组通常处于相同管理控制下的路由器组成 | 相同的AS中的路由器全都运行的同样的路由选择算法（如一种LS或一种DV）,且拥有彼此信息； | 在一个自治系统内运的路由选择算法：自治系统内部路由选择协议 intra-autonomous system routing protocol | 在AS内部有一台或者多台路由器 ”网关路由器 gateway router“，负责向本AS之外的目的地转发分组； | 源AS只有一台网关路由器，且只有一条通向外部AS的链路时，分组会直接通过该链路传输； | 自治系统之间的路由选择协议（inter-autonomous system routing protocol），AS间路由选择协议BGP4 . | 从AS间协议知道经过多个网关可达子网x | 使用来自AS内部协议的路由选择信息，以决定到每个网关的 最低费用路径 的费用 | 热土豆路由选择（hot potato routing），选择具有最低费用的网关 | 从转发表确定通向最低费用网关的接口I，将（x，I）项田间道转发表中 | . | . | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#45-%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#45-路由选择算法"
  },"148": {
    "doc": "计算机网络",
    "title": "4.6 因特网中的路由选择",
    "content": "一个AS是一个处于相同的管理与技术控制下的路由器集合，在AS之间都运行相同的路由选择协议；每个AS通常又都包含多个子网； . 4.6.1 自治系统内部的路由选择：RIP . | AS内部的路由选择方式，用于确定在AS内执行路由选择的方式 | AS内路由选择协议，又称为：内部网关协议 interior gateway protocol，包括： . | 路由选择信息协议 Routing information Protocol RIP | 开放最短路优先 Open Shortest Path First，OSPF | . | . RIP Routing information Protocol RIP . 最早使用的AS内部的路由选择协议，广泛应用 . | 距离向量协议，运行方式类似DV . | RIP中费用从源路由器到目的子网； . | RIP使用 ”跳“，跳是沿着源路由器到目的子网的最短路径经过的子网数量； . | 一条路径的最大费用被限制为15，RIP的使用限制在网络直径不超过15跳的自治系统内； . | DV协议：任何一台路由器的距离向量是从这台路由器到该AS中子网的最短路径距离的当前估计值； . | 路由器和相邻路由器的信息交换使用：RIP 响应报文 RIP response message 来交换，大约没30秒交换一i此； . | 由一台路由器发送的响应报文，包含该AS内多达25个目的子网列表，及发送方到每个子网的距离； . | RIP响应报文：RIP通告 RIP advertisement . | 每台路由器维护一张“路由选择表 routing table“； . | 路由选择表包括 . | 距离向量 | 转发表 . | 第一列：目的子网 | 第二列：沿最短路径到目的子网的路由器标识 | 第三列：到达目的地的跳数 | . | . | 目的子网 | 下一台路由器 | 到达目的地的跳数 | . |   |   |   | . | RIP每30秒相互交互一次，如果一台路由器180秒都没有从邻居收到报文，则认为邻居不再可达，RIP修改本地路由选择表，然后向其他邻居发送通告来传播该信息； . | 路由器也可以通过使用RIP报文，请求邻居到指定的目的地的费用； . | 路由器在UDP上使用端口520互相发送RIP请求与响应报文； . | RIP使用一个位于网络层IP协议之上的运输层UDP协议来实现网络层的路由选择功能 . | 工作原理 . | RIP在路由器操作系统中，以routed名称的进程运行，来维护路由选择信息和相邻的路由器上的routed进程交换报文； | 因为RIP的实现是一个应用层进程，所有它能在标准的套接字上发送和接收报文，并使用标准的运输层协议； | RIP是一个运行在UDP上的应用层协议，但他实现的功能是网络层的功能； | . | . | . 4.6.2 自治系统内部的路由选择： OSPF Open Shortest Path First，OSPF . | OSPF通常设置在上层的ISP中，RIP被设置在下层ISP和企业网中； | OSPF的路由协议规范是公众可用的； | OSPF核心： . | 一个使用洪泛链路状态信息的链路状态协议 | 一个Dijkstra最低费用路径算法 | 使用OSPF，一台路由器构建了一副关于整个自治系统的完整拓扑图，路由器运行Dijkstra最短路径算法，以确定一个以自身 为根节点的到所有子网的最短路径数； | OSPF提供机制，为“给定链路权值集合”确定最低费用路劲路由选择 | . | 原理 . | OSPF，路由器向自治系统内所有其他路由器广播路由选择信息； | 当一条链路发生变化，路由器就会广播链路状态信息，当链路状态未发生变化，路由器会周期性的广播链路状态信息（至少每30min） | OSPF报文，由IP协议承载，上层协议值为89，OSPF协议自己实现可靠报文传输、链路状态广播等功能 | OSPF要检查链路正在运行，并允许OSPF路由器获得相邻路由器的网络范围链路状态的数据库 | . | OSPF的优点 . | 安全；能够鉴别OSPF路由器之间的交换；使用鉴别，只有受到信任的路由器能参与AS内的OSPF协议；MD5散列值计算； | 多条相同费用的路径；出现多条相同费用路径时，OSPF允许使用多条路径； | 对单播和多播路由选择的综合支持；多播：使用现有的OSPF链路数据，为现有的OSPF链路状态广播机制增加了新型的链路状态通告； | 支持在单个路由选择域内的层次结构；具有按层次结构构建一个自治系统的能力 | . | 一个OSPF自治系统可用配置成多个区域，每个区域都运行自己的OSPF链路状态路由选择算法； . | 一个区域内每台路由器都向该区域其他所有路由器广播其链路状态 | 一个区域内，有一台或者多台区域边界路由器 area border router，负责为流向该区域以外的分组提供路由选择； | AS内只有一个OSPF区域配置成主干（backbone）区域； . | 主干区域的主要作用是，为AS内其他区域之间的流量提供路由选择； | 主干包含：AS内的所有区域边界路由器，和一些非边界路由器 | 在AS内的区域间的路由选择要求，分组首先到达一个区域边界路由器，再通过主干路由器到位于目的区域的区域边界路由器，然后再到最终目的地； | . | . | 实践原则：设置OSPF链路权值，PAGE270 | . 4.6.3 自治系统间的路由选择：BGP . | RIP 和 OSPF 来决定位于相同AS内部的源和目的之间的路由选择路径； . | 跨越多个AS的源和目的之间的路由选择，边界网络协议 Border Gateway Protocol, BGP . | 当今因特网中域间选择协议事实上的标准；BGP4或BGP . | 工作手段 . | 从相邻AS处获得子网可达信息 | 向本AS内部的所有路由器传播这些可达信息 | 基于可达性信息和AS策略，决定到达子网的 “好” 路由 | . &gt; BGP 使得每个子网向因特网的其余部分通告自己的存在； &gt; &gt; BGP保证在因特网中的所有AS直到该子网以及如何到达； . | . 1. BGP基础 . | 路由器通过使用”179“端口的半永久TCP连接，来交换”路由选择“信息； | 半永久TCP连接：该连接位于两个不同AS的路由器的链路； | 一个AS内部的路由器之间的BGP TCP连接：在AS内部形成网状TCP连接； | 对于每条TCP连接，位于连接端点的两台路由器为“BGP对等放 BGP-peers”，沿着连接发送的BGP报文的TCP连接为BGP会话 BGP session，跨越两个AS的BGP会话为外部BGP会话 eBGP external BGP session，同一个AS中的会话为”内部BGP会话 iBGP internal BGP session” | . 实践原则：PAGE 272 . | BGP使得每个AS直到经过其相邻AS可以到达那些目的地，BGP中，目的地不是主机而是Classless Inter-Domain Routing、CIDR化的前缀prefix，每个前缀代表一个子网或者一个子网的集合 | 任何AS中的网关路由器，接受到eBGP学习到的前缀后，该网关路由器使用它的iBGP会话来向该AS中的其他路由器发布这些前缀； | 当路由器得知一个新前缀时，它为该前缀在其转发表中创建一个项； | . 2. 路径属性和BGP路由 . | BGP中，一个自治系统由其全局唯一的自治系统号 Autonomous system Number ASN所标识；例如桩 stubAS通常没有ASN，桩AS仅仅承载源地址或者目的地址为本AS的流量； . | 类似与IP地址，AS号由ICANN地区注册机构分配 . | 路由器通过BGP会话通告一个前缀，前缀中包含BGP属性（BGP attribute），带有属性的前缀叫做 一条BGP路由 route，BGP对等方彼此通告路由； . | 属性 AS-PATH . | 包含来前缀通告已经通过的AS | 当一个前缀传送到一个AS时，该AS将它的ASN怎加到AS-PATH属性中； | . | 属性 NEXT-HOP . | 是一个开始某AS-PATH的路由器接口 | 路由器利用NEXT-HOP属性正确的配置他们的转发表 | . | 对于两条路由具有到前缀x的相同AS-PATH，但有不同的NEXT-HOP值对应于不同的对等链路；使用NEXT-HOP值的AS内部路由选择算法，路由器能够确定到每条对等链路的费用，使用热土豆路由选择来决定适当的接口； . WIKI: 热马铃薯路由选择（Hot-potato routing）是在当前AS接收到一个数据包后，使其停留在该AS中的时间尽可能短。在“热马铃薯路由”这个名字中，数据包被类比成了你手中的一个滚烫的马铃薯，因为它很烫，所以你想要尽可能快地把它传递给另一个人（另一个AS） . | . | 其他属性 . | 允许路由器对路由分配偏好测度的属性 | 指示前缀如何插入位于起始AS的BGP属性 | 当一台网关路由器接收到一台路由器的通告时，它使用其输入策略（import policy）来决定是否接收或者过滤该路由，是否设置某种属性； . | 输入策略可能会过滤一条路由，因为AS可能不希望通过该路由AS-PATH中的某个AS来发送流量； | 网关路由器也可能过滤一条路由，因为已经知道了一条相同前缀的偏好路由 | . | . | . 3. BGP路由选择 . BGP使用eBGP和外部建立会话，向外部路由器发布路由 . BGP使用iBGP和内部路由器建立会话，向内部路由器发布路由 . 路由：带有BGP属性的ip前缀 . | 对于BGP发布的路由，路由器可能到达任何一条前缀的多条路由，路由器进入路由选择进程，输入为路由器接收的所有的路由集合； | BGP顺序调用下列消除规则： . | 路由被指定一个本地偏好值作为路由的属性； . | 本地偏好，会被同一AS中其他路由器学习到； | 具有最高本地偏好的路由将被选择 | . | 在所有具有相同本地偏好值的路由中，具有最短AS-PATH的路由将被选择； . | BGP使用距离向量算法，距离测度使用AS跳数目； | . | 在所有具有相同本地偏好值和相同AS-PATH长度，选择最靠近NEXT-HOP路由器的路由； . | 最靠近，指到达NEXT-HOP接口最低费用路由路径，使用AS内部算法来决定，热土豆路由选择； | . | 仍然留下多条路由，该路由器使用BGP标识符来选择路由； | . | 时间原则：PAGE275 | . 4. 路由选择策略 . 桩网络(stub network): 不会进行流量转发，所有离开AS进入桩网络的流量，必然是去往桩网络，所有离开桩网络的流量，必然是进入其他AS； . | 通过控制BGP路由的方式可以实现，两个连入桩网络的网络流量不会被该桩网络转发，原因就是这两个连入的网络不会将转发链路通告给桩网路； | ISP之间的路由选择：任何穿越莫ISP主干网的流量必须是其源地址或者目的，位于该ISP的某个客户网络中；不然这些流量将会免费搭车通过该ISP的网络； | AS和AS之间的路由选择目标之间的差别： . | 策略 | 规模 | 性能 | PAGE277 | . | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#46-%E5%9B%A0%E7%89%B9%E7%BD%91%E4%B8%AD%E7%9A%84%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#46-因特网中的路由选择"
  },"149": {
    "doc": "计算机网络",
    "title": "4.7 广播和多播路由选择",
    "content": ". | 广播路由选择 broadcast routing . | 网络层提供了从一个源结点到网络中其他所有结点交付分组的服务 | . | 多播路由选择 multicast routing . | 使单个源结点能向其他网络结点的一个子集发送分组的副本 | . | . 4.7.1 广播路由选择算法 . | N次单播 . | 源结点产生分组的N份副本，对不同目的地的每个副本进行编址，并用单播路由器选择向N个目的地传输N份副本； | 无需网络层路由选择协议以及分组复制或转发功能； | 缺陷 . | 生成了太多冗余副本，让接收结点再去生成冗余副本更加有效 | 需要另外的协议，如广播成员或目的地注册协议，会怎加更多开销，且协议变得复杂； | 单播路由情况下，选择基础设施来取得广播并不明智； | . | . | . 1. 无控制洪泛 . | 洪泛 flooding . | 源结点向所有的邻居结点发送分组副本，当某个结点接收到一个广播分组时，复制该分组并向所有的邻居转发；（不会再次给发送方邻居转发） | 缺陷 . | 此连通图具有圈，一个或者多个广播分组将会无休止的循环下去，例如R2，R3，R4互相连通为圈，则R2向3和4广播，3和4复制后又像4和3广播，4和3复制后又像2广播； | 广播风暴 broadcast storm，导致无休止的广播分组的复制； | . | . | . 2. 受控洪泛 controlled flooding . | 序号控制洪泛 sequence-number-controlled flooding . | 源结点，将其地址和广播序号 broadcast sequence number放入广播分组；再向邻居发送副本； | 每个结点维护一个收到分组标示的列表 | 收到广播分组后，首先检查是否存在列表中，如果再，直接丢弃，如果不再，则更新列表，并复制发送给邻居结点； | . | 反向路经转发 reverse path forwarding，RPF 反向路经广播 . | 当一台路由器接收到一个“源”的广播分组时，只有分组到达的路经 = 路由器到“源”的最短单播路经时，路由器才会接收该广播分组并向其他邻居转发； | . | . 3. 生成树广播 . 序号控制洪泛和RPF避免了广播风暴，但是无法完全避免冗余分组的传输； . | 生成树 spanning tree | 所有生成树中费用最小的生成树：最小生成树 | 广播方法 . | 最网络结点构造一颗生成树 | 源结点向所有属于生成树的特定链路发送分组 | 接收广播分组的结点则向生成树中所有邻居转发该分组（接收该分组的邻居除外） | . | 生成树生成算法 . | 基于中心的方法 center-based approach . | 定义一个中心点为汇合点 rendezvous point 或者 核 core | 结点向中心结点单播加入树 tree-join 报文，加入树报文使用单播路由选择朝中心结点转发，直到到达一个已经属于生成树的结点或者中心结点； | 加入树报文经过的路经定义了发起加入树报文的边缘结点和中心结点之间的分支，新的分支已经被认为能够嫁接到现有的生成树上了； | 生成过程：PAGE281 | . | . | . 4. 实践中的广播算法 . | 实践中，广播协议被应用于：网络层和应用层 | 在Gnutella网络中，使用应用级的广播； | 在OSPF路由选择算法和 中间系统到中间系统 IS-IS路由选择算法中，使用一种序号来靠内阁制洪泛； . | OSPF使用一个32bit的序号和一个16bit的age字段来标识LSA 广播链路状态通知； | . | 详情: PAGE 281 282 | . 4.7.2 多播 . | 多播（multicast）服务，多播服务将分组交付给网络中一个结点的子集； . | 应用程序要求将分组从一个或多个发送方交付给一组接收方； . | 批量数据传输 | 流媒体服务 | 数据共享应用 | Web缓存更新 | 交互式游戏 | . | . | 多播数据报，使用间接地址 address indirection来编址，用一个标识来表示一组接收方，寻址到该组的分组副本被交付给所有与该分组相关联的多播接收方，且使用单一标识符； | D类多播地址 | 与D类多播地址，相关联的接收方小组为多播组 multicast group | 每台主机由一个唯一的单播IP地址，且完全独立于主机所参与的多播地址 | IGMP （因特网组管理协议，与ICMP因特网连接管理协议完全不同） | . 1. 因特网组管理协议 IGMP . | IGMP为主机提供手段，通知与其相连的路由器 | 主机上的应用程序想要加入一个特定的多播组，IGMP与多播路由选择协议 互补组成； | . IGMP . | IGMP三种报文类型 . | membership_query . | 确定主机已经加入所有的多播集合 | . | membership_report . | 响应membership_query报文 | 主机首次加入多播组，主机产生membership_report报文，无需等到路由器的membership_query报文 | . | leave_group . | 可选 | . | 路由器检测主机离开多播组，使用membership_query，当无主机响应具体组地址membership_query报文时，路由器推断出没有任何主机在当前多播组了 | 软状态 . | IGMP中，多播组未被 “来自主机的membership_report” 报文显示的更新，通过超时事件将主机从多播组中删除； | 软状态来源：PAGE284 | . | . | IGMP报文和ICMP报文类似，封装在一个IP数据报中，使用IP上层协议号为2； | . 2. 多播路由选择算法 . | 选择方法 . | 多播路由器选择的目标就是发现一颗链路树，这些链路连接了所有属于该多播组的相连主机的路由器； | 多播分组 将 沿着这颗树从发送方路由到所有属于该多播树的主机； | . | 确定多播路由选择树的方法： . | 使用一棵组共享树的多播路由选择； . | 使用基于中心的方法来构建多播路由选择树； | 属于多播组的主机，与主机相连的边缘路由将用“单播的方式”向中的结点发送加入报文； | 关键：中心选择算法 | . | 使用一颗基于源的树的多播路由选择； . | 为多播组中的源构建一个多播路由选择树； | 使用RPF算法，来构造一个多播转发树； . | 缺陷与接近方法： . | 数千台下游路由器都将收到一个不想要的多播分组； | 剪枝 . | 一台接收到多播分组的多播路由器，如果它没有要加入多播组的相连主机，则向上游返回一个剪枝报文； | 对一个路由器来说，如果它收到了来自下游每台路由器的剪枝报文，那么它会向自己上游的路由器发送剪枝报告； 反向路经广播算法 RPF . | . | . | . | . | . | . 3. 因特网中的多播路由选择 . | 距离向量多播路由选择协议 Distance Vector Multicast Routing Protocol, DVMRP . | 实现了反向路经转发 | 实现了剪枝算法的基于源的树 | 使用RFP算法 | . | 协议无关的多播路由选择协议 Protocol Independent Multicast, PIM . | 稠密模式 Dense mode | 稀疏模式 sparse mode | . | 不同域间的多播，使用域间BGP； | 详情：PAGE 286 | . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#47-%E5%B9%BF%E6%92%AD%E5%92%8C%E5%A4%9A%E6%92%AD%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#47-广播和多播路由选择"
  },"150": {
    "doc": "计算机网络",
    "title": "第五章 链路层：链路、接入网和局域网",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/#%E7%AC%AC%E4%BA%94%E7%AB%A0-%E9%93%BE%E8%B7%AF%E5%B1%82%E9%93%BE%E8%B7%AF%E6%8E%A5%E5%85%A5%E7%BD%91%E5%92%8C%E5%B1%80%E5%9F%9F%E7%BD%91",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/#第五章-链路层链路接入网和局域网"
  },"151": {
    "doc": "计算机网络",
    "title": "计算机网络",
    "content": "Network . 2020-03-16 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-16-network-curve/",
    
    "relUrl": "/docs/archives/2020/2020-03-16-network-curve/"
  },"152": {
    "doc": "Linux网络基础",
    "title": "Linux Network",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-18-linux-networking/#linux-network",
    
    "relUrl": "/docs/archives/2020/2020-03-18-linux-networking/#linux-network"
  },"153": {
    "doc": "Linux网络基础",
    "title": "1. TCP连接状态中大量客户处于TIME_WAIT",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-18-linux-networking/#1-tcp%E8%BF%9E%E6%8E%A5%E7%8A%B6%E6%80%81%E4%B8%AD%E5%A4%A7%E9%87%8F%E5%AE%A2%E6%88%B7%E5%A4%84%E4%BA%8Etime_wait",
    
    "relUrl": "/docs/archives/2020/2020-03-18-linux-networking/#1-tcp连接状态中大量客户处于time_wait"
  },"154": {
    "doc": "Linux网络基础",
    "title": "2. Linux的套接字线程",
    "content": "为了实现客户端请求的快速相应和快速处理，据是高并发，则必须使用多线程机制。主题思想是：serversocket通过accept建立一个socket，然后起一个线程，把这个socket扔给新建的线程进行处理，而serversocket所在的主线程，则继续去监听端口，以此实现多线程通信 . Linux中的ipv6 实际上是可以处理 ipv4 的请求的当 V6ONLY 没有开启的时候，反之不然； . If we have the unspecified IPv4 address (0.0.0.0) and the unspecified IPv6 address (::) is next, we need to swap the order of these in the list. We always try to bind to IPv6 first, then IPv4, since an IPv6 socket might be able to receive IPv4 packets if V6ONLY is not enabled, but never the other way around. ",
    "url": "/docs/archives/2020/2020-03-18-linux-networking/#2-linux%E7%9A%84%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BA%BF%E7%A8%8B",
    
    "relUrl": "/docs/archives/2020/2020-03-18-linux-networking/#2-linux的套接字线程"
  },"155": {
    "doc": "Linux网络基础",
    "title": "Linux网络基础",
    "content": "TODO . Linux . Network . 2020-03-16 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-18-linux-networking/",
    
    "relUrl": "/docs/archives/2020/2020-03-18-linux-networking/"
  },"156": {
    "doc": "Python实现动态生成类的http接口-monitor动态监控项",
    "title": "项目背景",
    "content": ". | 采集厂商网络硬件设备基础指标，封装OpenFalcon数据结构 | 参与开发人数：1人 | . ",
    "url": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF",
    
    "relUrl": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#项目背景"
  },"157": {
    "doc": "Python实现动态生成类的http接口-monitor动态监控项",
    "title": "监控系统动态监控",
    "content": ". | 需要实现的目标： . | 数据库监控表项动态管理监控项数据处理、封装接口 | 新增监控项由对于处理规则处理，项目的新监控项开发只需要编写规则函数和录入监控项字段即可 | . | . ",
    "url": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E7%9B%91%E6%8E%A7",
    
    "relUrl": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#监控系统动态监控"
  },"158": {
    "doc": "Python实现动态生成类的http接口-monitor动态监控项",
    "title": "1. API 处理和报文解析",
    "content": ". | 项目启动，导入文件后，解释器会执行 RouteRegister.registerAPI() | 文件路经 monitor/monitor-server/monitor/api/metric_api/dynamic_router_api.py | . | 从数据库获取动态监控表项的字段 | 根据获取回来的字段生成对于HTTP接口和类 | . | 此文件的执行入口是RouteRegister.registerAPI()，需要关注 . | 使用了项目统一实现的 @get_mapping 装饰器，实现了RESTfulAPI的路经(路由)注册 | 因为python的type底层为c结构体，此处使用type函数，实现type的new，call，init方法，返回一个类的引用，且该引用会在装饰器中存储在全局的变量中，内存地址在可分配地址段，“堆”； | 从数据库获取回来的数据保存在每个类的静态变量中 | tornado API 接收socket调用后，会执行process函数 | process函数实现原始数据处理的对象，并将从数据库表项获取的字段做初始化 | 调用DynamicMetricDataHandler的对象报文处理函数（此处http接收报文的载荷部分为json format） | . | cpython source _typeobject https://github.com/python/cpython/blob/master/Objects/typeobject.c typedef struct _typeobject { int ob_refcnt; //引用计数 struct _typeobject *ob_type; // 类型对象 int ob_size; //变长对象的长度，如len（list）， len(str), len(dict)，int类型没有该属性 const char *tp_name; /* For printing, in format \"&lt;module&gt;.&lt;name&gt;\" */ // 变量的类型名字 如&lt;class 'int'&gt; &lt;class 'type'&gt; Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */ // ....... } . | . #!/usr/bin/env python # -*- coding: utf-8 -*- # @Time : 2019-10-30 15:32 # @Author : NAYAN # @Site : # @File : snmp_metric_api_v2.py # @Software : PyCharm \"\"\" DES: 监控项目数据处理入口 @API 1. 从数据库t_snmp_task中全量拉取监控项 2. 根据拉取得数据生成对应的数据上报API 3. API关联到相应的数据处理函数 \"\"\" MONITOR_ITEM_TB = \"t_monitor_item\" from tornado import escape from monitor.core.handlers import get_mapping, BaseHandler from monitor.pkg.utils.logger import LOG from monitor.core.metric.dynamic.dynamic import DynamicMetricDataHandler from monitor.core.handlers.agent_error_handler import MetricErrorHandler from monitor.db import api class RouteRegister(object): metric_taks = { } @staticmethod def bindRouteToMetircDataHandler(__route, __des, monitor_item): \"\"\" :param __route: :param __des: :param monitor_item: :return: \"\"\" @get_mapping(__route, __des) class MonitorMetricAPI(BaseHandler): _metric = \"\" def process(self): \"\"\" :return: \"\"\" try: body = self.request.body content_type = self.request.headers.get(\"Content-Type\", \"\") if content_type.startswith('application/json'): data = escape.json_decode(body) try: dynamic= DynamicMetricDataHandler(monitor_item=MonitorMetricAPI._metric) did_send_metric = dynamic.handler_distributor(metric_raw=data) if did_send_metric: return 1, 'success', {} else: return 0, 'failed', {} except Exception as e: LOG.error(\"Dynamic metric data handler bind filed! error=%s\" % (e)) return 0, 'failed', {} except Exception as e: return 0, 'failed', {\"Message\": str(e)} if not monitor_item: return None MonitorMetricAPI._metric = monitor_item new_class_name = \"\".join([v[0].upper() + v[1:] for v in __route.split(\"/\")[-1].split(\"_\")]) return type(new_class_name, (MonitorMetricAPI,), {}) @staticmethod def registerAPI(): raw_tasks = RouteRegister.loadAllAPIFromInventory() LOG.info(\"[Register Monitor Item API From DB...]\") for raw in raw_tasks: if raw and raw.get('OpenFalcon_upload'): # __route = str(raw[\"upload_api\"]) __des = str(raw[\"desc\"]) LOG.info(\"[Upload API]: %s\" % __route) RouteRegister.bindRouteToMetircDataHandler(__route, __des, raw) @staticmethod def loadAllAPIFromInventory(): data = api.pg_query(MONITOR_ITEM_TB) LOG.info(\"[ITEM DATA] %s\" % data) return data @get_mapping('/monitor_upload/metric_error_handler.do', '') class ErrorHandler(BaseHandler): def process(self): try: body = self.request.body content_type = self.request.headers.get(\"Content-Type\", \"\") if content_type.startswith('application/json'): data = escape.json_decode(body) MetricErrorHandler.process_metric_error(data) return 1, 'success', {} except Exception as e: return 0, 'failed', {\"Message\": str(e)} RouteRegister.registerAPI() . ",
    "url": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#1-api-%E5%A4%84%E7%90%86%E5%92%8C%E6%8A%A5%E6%96%87%E8%A7%A3%E6%9E%90",
    
    "relUrl": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#1-api-处理和报文解析"
  },"159": {
    "doc": "Python实现动态生成类的http接口-monitor动态监控项",
    "title": "2. 规则映射数据处理",
    "content": ". | 实现了对不同类型规则的处理逻辑； . | 单OID处理：一个OID为采集对象，采集结果为单一类型数据，例如整型、浮点类型、字符、字符串、数组 | 多OID处理：一个OID为采集对象，采集结果为多行数据，数据类型一致，例如带索引的分组交换机接口或硬件端口 | 多OID多处理：多个OID为采集对象，采集结果可能为每个OID一个单一结果，或者每个OID多个结果，具体规则函数会对这样的报文做处理； | . | . 动态监控项表的字段结构 . +-------------+---------------------+------+-----+---------+---------------------------------+ | Field | Type | Null | Key | description | +-------------+---------------------+------+-----+---------+---------------------------------+ | id | varchar | NO | PRI | 主键，唯一监控项名称，包含小写字母和下划线 | vendor | varchar | NO | 厂商 | type | varchar | NO | 设备类型 （链路交换机，路由器，防火墙） | model | jsonb | YES | 设备型号 厂商定义 | series | jsonb | YES | 设备系列 厂商定义 | metric | varchar | NO | 采集数据名称，元数据描述 | metric_type | int4 | NO | 采集数据类型（处理） 0表示普通数据，1表示增量数据 | upload_api | varchar | NO | 原始数据上报RESTful接口 | task | jsonb | NO | agent端执行的采集任务定义 | desc | varchar | YES | 描述 | OpenFalcon_upload| bool | NO | 是否将数据发送到 OpenFalcon 平台 | update_time | timestamp | NO | 记录更新时间 | interval | int4 | YES | agent执行采集的时间间隔 | +-------------+---------------------+------+-----+---------+---------------------------------+ . #!/usr/bin/env python # -*- coding: utf-8 -*- # @Time : 2019-10-31 14:57 # @Author : NAYAN # @Site : # @File : dynamic.py # @Software : PyCharm \"\"\" 动态监控项处理 1. 从数据库t_monitor_item表拉取监控项 2. 由监控项生成API和监控处理对象(class) 3. 监控处理对象将调用相应的动态处理函数 4. 动态处理函数会根据 task_operation 判断数据处理函数的类型，包括单数据处理，批量数据处理，表达式处理三种 5. 监控数据部分会有两个处理函数，第一个是tags的配置，第二个是value的处理 \"\"\" from monitor.core.handlers.device_info_handler import DeviceInfo from monitor.pkg.utils.import_util import LOG from monitor.core.model.monitor_data_model import MonitorItemDataModel from monitor.core.model import monitor_data_model as DModle from monitor.core.metric.dynamic.dynamic_rules import ValueRules from monitor.core.metric.dynamic.dynamic_rules import TagRules from monitor.core.metric.dynamic.dynamic_rules import OperationRules from monitor.core.metric.publisher import Falcon LogPrefix = \"[Dynamic Monitor]\" DefaultValue = -1 Metric_Value_Type = { 1: \"int\", 0: \"float\", -1: \"counter\" } Metric_Type = { 1: \"GAUGE\", 0: \"GAUGE\", -1: \"COUNTER\" } class DynamicMetricDataHandler(object): \"\"\" @metric_item 监控项数据结构，用来生成监控项上报API和处理函数 @metric_raw Agent上报的原始监控数据 \"\"\" def __init__(self, monitor_item=None): \"\"\" :param monitor_item: \"\"\" mon_object = MonitorItemDataModel(**monitor_item) self._mon_object = mon_object # @监控对象 self._vendor = mon_object.vendor # @设备厂商 self._type = mon_object.type # @设备类型 self._model = mon_object.model # @设备型号 self._series = mon_object.series # @设备型号所属系列 self._metric = mon_object.metric # @监控项名称m self._metric_type = mon_object.metric_type # @是否计数器 self._upload_api = mon_object.upload_api # @上报接口 self._OpenFalcon_upload = mon_object.OpenFalcon_upload # @是否上报OpenFalcon self._des = mon_object.description # @监控项描述 self._task = mon_object.task # @监控项对应监控任务 self.manage_ip = DModle.DEFAULT_STRING self.raw_data = DModle.DEFAULT_JSON_DIC self.timestamp = DModle.DEFAULT_INTEGER self.sysname = DModle.DEFAULT_STRING self.step = DModle.DEFAULT_INTEGER self.oid_data = {} def _parse_metric_raw(self, metric_raw): \"\"\" @@@ Handle Agent upload original DATA :param metric_raw: @example: { \"content\": null, \"host\": null, \"protocol\": null, \"scheduler\": null, \"timestamp\": 1572574430, \"company\": null, \"interval\": null, \"id\": null, \"response\": { \"get\": { \"1.3.6.1.4.1.2636.3.1.13.1.8.9.1.0.0\": { \"oid_index\": \"\", \"oid\": \"enterprises.2636.3.1.13.1.8.9.1.0.0\", \"snmp_type\": \"GAUGE\", \"value\": \"1\" } } } } @@ Agent采集数据结构 \"content\": @采集job内容 \"host\": @采集对象管理ip \"protocol\": @采集使用的网络协议 \"scheduler\": @采集是否为周期interval || once \"timestamp\": @采集数据的时间戳 \"company\": @采集设备的厂商 \"interval\": @采集的时间间隔 \"id\": @采集任务的唯一ID :return: \"\"\" try: if not self._metric: ##TODO Value Check and LOG IT!!!!!!!!!!!!!!!!!!!!!!!! LOG.error(\"%s metric item data parse failed, error=\" % LogPrefix) return if not metric_raw: LOG.error(\"%s metric raw parse failed, error=\" % LogPrefix) return self.manage_ip = metric_raw.get(\"host\") self.raw_data = metric_raw.get(\"response\") self.timestamp = metric_raw.get(\"timestamp\") self.step = int(metric_raw.get(\"interval\")) self.sysname = DeviceInfo.devs[self.manage_ip].get('sysname') # self.sysname = \"abcd\" if not self.sysname: raise Exception(\"get sysname failed!\") return True except Exception as e: LOG.exception(self._error_handler(err_des=\"parse raw metric error\", exp=e)) return False def _error_handler(self, err_des=\"\", exp=None): \"\"\" @@@ Error handler :param e: :return: Error msg # LOG.error(self._error_handler(err_des=\"\", exp=e)) \"\"\" e_msg = '%s monitor item data process error, device=[ip=%s, sysname=%s, vendor=%s, type=%s, model=%s, series=%s, metric=%s], err_msg=%s, exp=%s' \\ % (LogPrefix, self.manage_ip, self.sysname, self._vendor, self._type, self._model, self._series, self._metric, err_des, exp) return e_msg def _is_value_valid(self, value): \"\"\" @@@ SNMP error handler @TIMEOUT @UNKNOWN @NO_SUCH_INSTANCE @UNDETERMINED_TYPE_ERROR @Connection_Error @Undetermined_Type_Error :param value: :return: \"\"\" if value or isinstance(value, (int, float)): return True elif isinstance(value, (str, unicode)): return True # TODO check snmp error value TIMEOUT UNKNOWN OBJECTID NO_SUCH_INSTANCE NO_SUCH_OBJECTID # except EasySNMPTimeoutError: # LOG.error(\"%s request snmp error TIMEOUT.oid=%s\" % (self.hostname, oids)) # except EasySNMPUnknownObjectIDError: # LOG.error(\"%s request snmp error UNKNOWN OBJECTID.oid=%s\" % (self.hostname, oids)) # # except (EasySNMPNoSuchObjectError, EasySNMPNoSuchInstanceError): # LOG.error(\"%s request snmp error NO_SUCH_INSTANCE OR NO_SUCH_OBJECTID.oid=%s\" % (self.hostname, oids)) # # except EasySNMPUndeterminedTypeError: # LOG.error(\"%s request snmp error UNDETERMINED_TYPE_ERROR.oid=%s\" % (self.hostname, oids)) # except EasySNMPConnectionError: # LOG.error(\"%s request snmp error Connection_Error.oid=%s\" % (self.hostname, oids)) # except EasySNMPUndeterminedTypeError: # LOG.error(\"%s request snmp error Undetermined_Type_Error.oid=%s\" % (self.hostname, oids)) else: return False def _process_value_rule(self, rule_name, **kwargs): \"\"\" @@@ Matching the value process rule :param rule_name: :param kwargs: :return: \"\"\" ## ToDO NO SUCN rule r = ValueRules() func = getattr(r, rule_name) return func(manage_ip=self.manage_ip, **kwargs) def _process_tag_rule(self, rule_name, **kwargs): \"\"\" @@@ Tags handler @ Tags get attr from raw content :param tags: :return: \"\"\" r = TagRules() func = getattr(r, rule_name) return func(manage_ip=self.manage_ip, **kwargs) def _process_opera_rule(self, rule_name, **kwargs): \"\"\" @@@ Matching the operation process rule :param rule_name: :param kwargs: :return: \"\"\" r = OperationRules() func = getattr(r, rule_name) return func(manage_ip=self.manage_ip, **kwargs) def _raw_data_wrapper(self): \"\"\" :wrapper: wrap raw data to a dic, oid as key :return: { \"1.3.6.1.4.1.2636.3.1.13.1.8.9.1.0.0\": [ { \"oid_index\": \"\", \"oid\": \"enterprises.2636.3.1.13.1.8.9.1.0.0\", \"snmp_type\": \"GAUGE\", \"value\": \"1\" }... ], \"\"1.3.6.1.4.1.2636.3.1.13.1.8.9.1.0.1\": [ { \"oid_index\": \"\", \"oid\": \"enterprises.2636.3.1.13.1.8.9.1.0.1\", \"snmp_type\": \"GAUGE\", \"value\": \"1\" }... ]... } \"\"\" oid_data = {} for method, oid_dic in self.raw_data.items(): for oid, oid_value in oid_dic.items(): if not isinstance(oid_value, (list)): oid_value = [oid_value] oid_data.update({oid: oid_value}) self.oid_data = oid_data def handler_distributor(self, metric_raw=None): \"\"\" @self._task { \"snmp_task\":{ \"oid\": { 'get': [], 'bulk': [], 'walk': [], 'getnext': [] }, \"value_rule\": \"\", \"tag_rule\": \"\", \"opera_rule\": \"\" } } @@@ Rules :rule:三种采集数据处理规则，规则都在task_content中 1. value_rule 值处理规则，对上报数值进行处理，比如从字符串中截取监控指标 2. tag_rule 标签处理规则，如对根据接口索引获取接口速率和名称并添加到上报tags中 3. opera_rule 运算操作规则，对多个oid取回值进行运算处理获取监控指标，比如对metric_raw中的值进行加减乘除 @@@ Handlers :handler: 三种OID处理规则 1. snmp_single 单值处理，task中只有一个操作方法和一个oid，采集结果也只有单一值(例如：get操作单一oid) 2. snmp_batch 批量处理，task中只有一个操作方法和一个oid，采集结果会有索引(例如：walk操作单一oid) 3. snmp_multi 多值处理，task中有多个操作方法或多个oid，采集结果会有多种值或多种索引(例如：风别walk操作三个oid) :param metric_raw: :return: @@True 数据处理成功发送OpenFalcon @@False 数据处理失败写入日志 \"\"\" try: did_parse_data = self._parse_metric_raw(metric_raw) if not did_parse_data: return False if not self._task: LOG.error(self._error_handler(err_des=\"monitor item task empty\")) return False # @ task handler caller for task_type, task_content in self._task.iteritems(): # @SNMP task if task_type == \"snmp_task\": self._raw_data_wrapper() if len(self.oid_data.values()): # 多oid多值 if len(self.oid_data) &gt; 1: return self.snmp_multi_monitor_item_handler(task_content) # 单oid多值 if len(self.oid_data.values()[0]) &gt; 1: return self.snmp_batch_monitor_item_handler(task_content) else: return self.snmp_single_monitor_item_handler(task_content) # @Netconf task elif task_type == \"netconf_task\": pass else: LOG.error(\"%s monitor task type not supported!\" % LogPrefix) except Exception as e: LOG.exception(self._error_handler(exp=e)) def snmp_single_monitor_item_handler(self, task_content): \"\"\" :param metric_raw: @metric_raw[\"response\"] \"response\": { \"get\": { \"1.3.6.1.4.1.2636.3.1.13.1.8.9.1.0.0\": { \"oid_index\": \"\", \"oid\": \"enterprises.2636.3.1.13.1.8.9.1.0.0\", \"snmp_type\": \"GAUGE\", \"value\": \"1\" } } } :return: Bool \"\"\" task_value_rule = task_content.get(\"value_rule\") task_tag_rule = task_content.get(\"tag_rule\") try: if len(self.raw_data) &gt; 1 or len(self.raw_data.values()) &gt; 1: raise Exception(\"upload data is not single value\") else: oid_dic = self.raw_data.values()[0] oid_content_dic = oid_dic.values()[0] if isinstance(oid_content_dic, dict): value = oid_content_dic.get(\"value\") elif isinstance(oid_content_dic, list) and len(oid_content_dic) &gt; 0: value = oid_content_dic[0].get(\"value\") oid_content_dic = oid_content_dic[0] else: value = None tags = None if value and self._is_value_valid(value): # process rules # 1. value rule if task_value_rule: value = self._process_value_rule(task_value_rule, value=value, sysname=self.sysname) # 2. tag rule if task_tag_rule: tags = self._process_tag_rule(task_tag_rule, oid_content=oid_content_dic) return self.metrics_sender(value, tags) else: return False except Exception as e: LOG.exception(self._error_handler(err_des=\"single value process failed\", exp=e)) def snmp_batch_monitor_item_handler(self, task_content): \"\"\" :rule:三个处理规则，规则都在task_content中 1. value_rule 值处理规则，对上报数值进行处理，比如从字符串中截取监控指标 2. tag_rule 标签处理规则，如对根据接口索引获取接口速率和名称并添加到上报tags中 3. operation_rule 运算操作规则，对多个oid取回值进行运算处理获取监控指标，比如对metric_raw中的值进行加减乘除 @@ 基于metric索引批量处理监控数据 :param metric_raw: @example @metric_raw[\"response\"] \"response\": { \"walk\": { \"1.3.6.1.2.1.2.2.1.14\": [ { \"oid_index\": \"1\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" }, { \"oid_index\": \"4\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" }, { \"oid_index\": \"5\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" } ] } } :param task_content: :return: \"\"\" task_value_rule = task_content.get(\"value_rule\") task_tag_rule = task_content.get(\"tag_rule\") try: if len(self.raw_data) &gt; 1: raise Exception(\"upload data format error\") else: oid_dic = self.raw_data.values()[0] oid_content_list = oid_dic.values()[0] ret_res = [] for oid_content_dic in oid_content_list: if isinstance(oid_content_dic, dict): value = oid_content_dic.get(\"value\") if value == \"2147483647\": value = \"0\" tags = \"index={}\".format(oid_content_dic.get(\"oid_index\")) if value and self._is_value_valid(value): # process rules # 1. value rule if task_value_rule: value = self._process_value_rule(task_value_rule, value=value, sysname=self.sysname) # 2. tag rule if task_tag_rule: tags = self._process_tag_rule(task_tag_rule, oid_content=oid_content_dic) if not tags: continue res = self.metrics_sender(value, tags) ret_res.append(res) if False in ret_res or len(ret_res) == 0: return False else: return True except Exception as e: LOG.exception(self._error_handler(err_des=\"batch value process failed\", exp=e)) def snmp_multi_monitor_item_handler(self, task_content): \"\"\" :param metric_raw: @example @metric_raw[\"response\"] \"response\": { \"walk\": { \"1.3.6.1.2.1.2.2.1.14\": [ { \"oid_index\": \"1\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" }... ], \"\"1.3.6.1.2.1.2.2.1.15\": [ { \"oid_index\": \"1\", \"oid\": \"\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" }... ], ... } } :param task_content: :return: [{\"value\": \"\", \"tags\": \"\"}, {\"value\": \"\", \"tags\": \"\"}, ...] \"\"\" task_opera_rule = task_content.get(\"opera_rule\") try: if task_opera_rule: result = self._process_opera_rule(task_opera_rule, raw_data=self.raw_data.values()[0]) #LOG.debug(\"multi task name=\" + task_opera_rule + \",result metric length=\" + str(len(result))) did_send = False for v in result: did_send = self.metrics_sender(v[\"value\"], v[\"tags\"]) return did_send return False except Exception as e: LOG.exception(self._error_handler(err_des=\"get multi value process failed\", exp=e)) def metrics_sender(self, value, tags): \"\"\" @@Tags 1. 检查tag字段，如果有值则调用 _match_tags_handler 2. 如果为空，侧检查index_tag是否有值 3. 如果有值，侧使用tags=\"%s/%s\" %(index_tag, index) 4. 如果为空，侧无tags :param metric: :param title: :return: \"\"\" __OpenFalcon_metric_type = Metric_Type[self._metric_type] __v_type = Metric_Value_Type[self._metric_type] if __v_type == \"float\": value = float(value) else: value = int(value) try: m = { \"endpoint\": self.sysname, \"metric\": self._metric, \"timestamp\": self.timestamp, \"step\": self.step, \"value\": value, \"counterType\": __OpenFalcon_metric_type, \"tags\": tags } # LOG.info(\"[DEBUG Send] %s\" % m) Falcon.send([m]) except Exception as e: LOG.exception(\"parser OpenFalcon metric failed, e=%s\" % e) return True @staticmethod def common_data_handler(func): \"\"\" :param func: :return: \"\"\" def monitor_wrapper(*args, **kwargs): \"\"\" :param args: :param kwargs: :return: \"\"\" try: value = func(*args, **kwargs) data_dic = dict() data_dic[\"type\"] = args[1] value = value if value else -1 data_dic[\"val\"] = value if isinstance(value, (float, int)) else int(value) return data_dic except Exception as e: LOG.exception('get error, e=%s' % e) raise e return monitor_wrapper . ",
    "url": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#2-%E8%A7%84%E5%88%99%E6%98%A0%E5%B0%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#2-规则映射数据处理"
  },"160": {
    "doc": "Python实现动态生成类的http接口-monitor动态监控项",
    "title": "3. 执行任务和处理规则",
    "content": ". | agent所要执行的任务定义和处理规则定义 | . MonitorTaskJsonDic = { \"snmp_task\": { #@SNMP采集任务 \"oid\": { #@采集OID和执行方式-同步到job.content中并关联设备 'get': [], 'bulk': [], 'walk': [], 'getnext': [] }, \"tag_rule\": \"\", #@数标签处理规则 \"opera_rule\": \"\", #@多数据处理规则 \"value_rule\": \"\" #@采集值处理规则-如：从字符串中匹配整形并转为百分比 } } . | 此处定义一个snmp_task，agent根据此task来执行采集和上报数据 | 规则处理函数会接收 agent采集返回报文的json对象的 response 部分 \"response\": { \"walk\": { \"1.3.6.1.2.1.2.2.1.14\": [ { \"oid_index\": \"1\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" }, { \"oid_index\": \"4\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" }, { \"oid_index\": \"5\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" } ] } } . | 规则定义 . | 在task中定义tag_rule, value_rule, opera_rule，处理函数会自动将数据和处理规则进行动态匹配，当有新报文段交付后，会触发对应的规则函数； | 规则匹配顺序为：ValueRules， TagRules， OperationRules | 规则选用建议 | . | 如果采集结果为单一结果，例如”value”: “35”，使用ValueRules，将该字符串进行处理，比如”35%”,或0.35； | 如果采集结果携带索引，对其值的处理结果可以参考1，对索引值可以使用TagRules，将索引处理为特定的标签，标识一条唯一的数据，并且该标签还可以携带其他和数据相关的属性； | 对于多种采集OID对象和多种结果的类型，只使用自定义的OperationRules 部分ValueRules，TagRules可以对数据做通用处理 . class ValueRules(object): class TagRules(object): class OperationRules(object): . | . | . ",
    "url": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#3-%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%A4%84%E7%90%86%E8%A7%84%E5%88%99",
    
    "relUrl": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#3-执行任务和处理规则"
  },"161": {
    "doc": "Python实现动态生成类的http接口-monitor动态监控项",
    "title": "4. 新监控项开发",
    "content": ". | 如何添加一个新的监控项 （测试环境） . | 添加数据记录到动态监控表，根据每个字段名称定义相应的字段； | . | vendor，type，model，series 设备相关，用来定义那些厂商哪些类型哪些型号的设备要”被agent执行新增的监控项任务“ | id，metric，metric_type，upload_api，用来定义一个唯一的监控项，和监控项在dashboard和rrd数据库中的名称，且包含唯一一个为此监控项创建的上传RESTful接口 | task 定义采集任务，agent执行什么样的任务；定义处理规则，采集回来的数据要被映射到哪些自定义的规则函数上 | interval agent对设备多久进行一次采集，”UDP“报文段交互 | . | . | 数据都定义完成后，编写你的规则函数 . | 函数名称要和task中定义的函数名称一致 | 函数所属要的类，要和task中给定的一致 | 函数入参固定 . | ValueRules manage_ip=None, value=None, sysname=None | TagRules manage_ip=None, oid_content=None | OperationRules manage_ip=None, raw_data=None | . | 处理逻辑，manage_ip为设备在各自AS的子网中的管理IP地址，采集回来的数据为其他参数 . | value 采集唯一值 | sysname 设备名称 | oidcontent python列表类型，列表中包含多个采集结果字典，例如 [ { \"oid_index\": \"1\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" }, { \"oid_index\": \"4\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" }, { \"oid_index\": \"5\", \"oid\": \"ifInErrors\", \"value\": \"0\", \"snmp_type\": \"COUNTER\" } ] . | raw_data 报文中json对象的response部分的全部数据 | . | 处理规则的返回值 . | ValueRules 返回处理后的value | TagsRules 返回固定格式的Tags字符串，字符串中的标签字符用”=”和”,”分隔 | OperationRules 返回处理完成后的所有数据的列表，列表中为相同结构的字典 包含”value”和”tags”，例如 [{\"value\": , \"tags\"},{\"value\": , \"tags\"},{\"value\": , \"tags\"}] . 其中tags格式依然固定，value可以是整型或者浮点类型 . | . | . | 完成规则函数编写后，数据上报部分有独立线程来自动完成，无需关注； | . ",
    "url": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#4-%E6%96%B0%E7%9B%91%E6%8E%A7%E9%A1%B9%E5%BC%80%E5%8F%91",
    
    "relUrl": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#4-新监控项开发"
  },"162": {
    "doc": "Python实现动态生成类的http接口-monitor动态监控项",
    "title": "5. 调试",
    "content": ". | agent和server的调试，请移步单元测试文档 | . ",
    "url": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#5-%E8%B0%83%E8%AF%95",
    
    "relUrl": "/docs/archives/2020/2020-03-24-Python-dynamic-map/#5-调试"
  },"163": {
    "doc": "Python实现动态生成类的http接口-monitor动态监控项",
    "title": "Python实现动态生成类的http接口-monitor动态监控项",
    "content": "Python . 2020-03-24 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-24-Python-dynamic-map/",
    
    "relUrl": "/docs/archives/2020/2020-03-24-Python-dynamic-map/"
  },"164": {
    "doc": "理解C/C++中的指针和引用",
    "title": "C的指针",
    "content": "Pointer_C指针_C++指针_Golang指针 . | 内存的硬件在软件层面的抽象 . | 一维线性，M个连续的1个字节大小的单元组成的数组，每个字节有连续且唯一的物理地址 Physical Address | CPU访问内存最自然的方式就是物理寻址（physical addressing） | 大于一个字节的数据类型会被连续的存储在多个内存地址中，任然只用一个地址来寻址 | 每个位置有独一无二的地址用来寻址 | 每个地址都存放了一个值 体系结构，深入理解计算机操作系统，第九章，虚拟内存 . | . | 指针 编译原理 . | 指针：存储了另一个“内存地址”的变量 . | 首先，指针是一个变量，同样可以使用变量类型修饰符，（变量在编程语言的层面表示：程序可以操作的内存地址空间的“名称”，名称只在编程语言中有实际意义，在编译器中会进行相应的分析和链接处理，最终转为机器码；） | 指针存放了，另一个段内存地址的“地址编号” | 指向：表示指针存储的“内存地址”，经过寻址后找到的存储在该“内存地址中的” 值 | . | &amp; 取地址运算符 *间接访问运算符/解引用运算符 . | &amp; 用来取得任何变量当前的地址 | 对一个指针变量取地址后，得到的是该指针变量自己的地址 | * 的第一个作用是，声明，表示声明的变量类型为“某种指针类型”，如int指针类型，char指针类型，等（指针基类type） | * 的第二个作用是，间接访问，可以通过在变量前面加* 表示，获取该指针指向的“值” | 指针变量自己的值同样为一个 无符号整数（内存地址的16进程表示） | . | 声明、定义、赋值 . | 使用 类型 + * + 变量名称 进行声明 | 变量名称 = 来进行定义，指针的类型会被绑定到指向的值的类型 | 只有同样的类型的地址才能赋值 | 创建指针对象的过程中，并不会在内存上开辟空间来进行初始化，指针变量初始地址为一个随机地址； | 声明指针对象的同时不能直接赋值，对于未分配内存空间的指针变量，值无处存放； | 声明指针对象的同时定义，必须赋值一个内存地址； warning: initialization makes pointer from integer without a cast . | . | 解引用，脱去解引用 &amp; 在C/C++中具体 3种语义， 按位与，取地址 和 声明一个引用。 . | int a = 999; int * b = &amp;a; * b = 0; 解引用，解释引用，表示将指针变量保存的内存地址中存储的999修改为了0 | &amp;*b 获取a的地址，脱去了解引用 | . | 指针运算 算数运算和关系运算 . | NULL指针 . | 直接给指针赋值0或者NULL int * p = 0; int * p = NULL; | NULL指针不指向任何地方，所以无法解引用 | . | 指针的指针 . | 指向指针变量的指针变量（指向指针对象的指针对象） | . | . | . #include &lt;stdio.h&gt; int main() { int a = 100; int * b = &amp;a; //声明了一个变量类型为type的类型（因为指针的基类型就是type) //b = &amp;a; // 这里对已经声明的指针类型b，进行了定义，将其定义为了 整型指针类型 printf(\"%p\\n\", &amp;a); // 取地址，取地存放a内存地址，也就是存放整数100的地址段 printf(\"%p\\n\", b); // 取地址，由于指针变量本身就存储了它指向的地址段，所以使用取地址符打印指针变量的值，就会打印出它存放的指针地址 printf(\"%p\\n\", &amp;b); // 取该指针变量自己的地址 printf(\"%d\\n\", a); printf(\"%d\\n\", *b); // * 为间接访问运算符，通过在指针便变量前面加*，可以间接的访问该指针指向的值 // char * c = (char *)&amp;a; // printf(\"%d\\n\", *b); // printf(\"%d\\n\", *c); char s = 'f'; char * p1 = &amp;s; char ** p2 = &amp;p1; printf(\"%c\\n\", s); printf(\"%c\\n\", * p1); printf(\"%p\\n\", * p2); printf(\"%c\\n\", ** p2); printf(\"%p\\n\", &amp;s); printf(\"%p\\n\", p1); printf(\"%p\\n\", &amp;p1); printf(\"%p\\n\", p2); printf(\"%p\\n\", &amp;p2); return 0; } . ",
    "url": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/#c%E7%9A%84%E6%8C%87%E9%92%88",
    
    "relUrl": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/#c的指针"
  },"165": {
    "doc": "理解C/C++中的指针和引用",
    "title": "C++ 指针、引用&amp;",
    "content": ". | 指针 . | 空指针 nullptr int * p = nullptr 解引用没有初始化的指针发送错误 定义了对象之后再定义指向这个对象的指针,对于不清楚的指向哪里的指针,一律初始化为nullptr(C++11)或者NULL(0).之后再判断是否指向对象再进行相应的操作. | . | . ",
    "url": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/#c-%E6%8C%87%E9%92%88%E5%BC%95%E7%94%A8",
    
    "relUrl": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/#c-指针引用"
  },"166": {
    "doc": "理解C/C++中的指针和引用",
    "title": "C 中的 &amp;",
    "content": ". | C的标准中对于运算符 &amp; 出现在变量前，表示的是取地址符 | 取地址符，可以取得任何变量当前在虚拟内存中的地址 | . ",
    "url": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/#c-%E4%B8%AD%E7%9A%84-",
    
    "relUrl": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/#c-中的-"
  },"167": {
    "doc": "理解C/C++中的指针和引用",
    "title": "C++ 引入的新特性“引用”",
    "content": ". | 引用，对于目标一个变量的一个别名，使用引用对变量的操作和对变量的直接操作是完全一样的； | 引用使用 &amp; 进行声明 . | 类型标示符 &amp;引用名 = 目标变量名 | 在这个声明中，使用&amp;符号对目标变量声明了一个新的名字，而这个名字代表的就是目标变量的值； | 【&amp;】在这个变量声明中不是一个取地址符，而是起到标示作用，用来声明当前是一个引用声明，类似于指针类型的声明，需要加， 也是在当前声明中来声明这是个指针相关的类型声明； | 【类型标示符】是目标变量的类型； | 声明引用的同时，必须完成其初始化； | 完成了引用声明之后，相当于该变量有两个名称，用这两名称都可以直接访问变量，即该变量的原名和引用名，这时候该引用名属于该变量，不能再将该引用名作为其他变量名的别名（不能再做其他变量的引用）； | . https://blog.csdn.net/weixin_44023607/article/details/104235331 . TODO . | . ",
    "url": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/#c-%E5%BC%95%E5%85%A5%E7%9A%84%E6%96%B0%E7%89%B9%E6%80%A7%E5%BC%95%E7%94%A8",
    
    "relUrl": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/#c-引入的新特性引用"
  },"168": {
    "doc": "理解C/C++中的指针和引用",
    "title": "理解C/C++中的指针和引用",
    "content": "C&amp;C++ . Pointer . 2020-03-25 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/",
    
    "relUrl": "/docs/archives/2020/2020-03-25-pointer-reference-understanding/"
  },"169": {
    "doc": "Python内存管理的底层实现&程序内存分析",
    "title": "Python内存管理的底层实现&程序内存分析",
    "content": "CPython . Python-gcc . 2020-03-25 10:00:00 +0800 . | 问题1：python内存管理，cpython内存管理部分的代码 | 问题2：tornado线程管理，htop问题 | 问题3：python内存debug | 问题4：gcc debug | . ",
    "url": "/docs/archives/2020/2020-03-25-python-memory-management-implementation/",
    
    "relUrl": "/docs/archives/2020/2020-03-25-python-memory-management-implementation/"
  },"170": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "Computer Systems A Programmer’s Perspective",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#computer-systems-a-programmers-perspective",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#computer-systems-a-programmers-perspective"
  },"171": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "CSAPP",
    "content": "从程序员的角度学习计算机系统如何工作 . 学习的方法： do it，在真正的系统上解决具体的问题 . 文中代码GCC编译的C程序并在Linux系统上测试 . 概述 . 第一章，研究简单的程序的声明周期；介绍计算机系统的主要概念和主题； . 第二章，计算机算数运算、补码、数学属性； . 第三章， . 第四章， . 第五章， . 第六章， . 第七章 . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#csapp",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#csapp"
  },"172": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "第一章，计算机系统漫游",
    "content": "如何优化C代码，以充分利用现代处理器和存储器系统的设计 . 编译器如何实现过程调用 . 如何避免缓冲区溢出 . 如何识别和避免链接时的错误 . 编写自己的Unix shell、自己的动态存储分配包 . 自己的web服务器 . 并非的希望和陷阱 . #include &lt;stdio.h&gt; int main() { printf(\"hello world\\n\"); return 0; } . | hello程序的声明周期，从被创建，在系统上运行，输出简单信息，终止； | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#第一章计算机系统漫游"
  },"173": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "1.1 信息就是位 + 上下文",
    "content": ". | 源文件：编辑器创建并保存的文本文件 | 源程序：实际上就是一个比特序列，8bit位1byte | ASCII, 每个字符有唯一的整数值，97a，65A | 程序以字节序列的方式存储在文件中，每个字节有一个整数值，对应ASCII中的字符，代码中换行符\\n，hello.c由ASCII字符构成的文件为文本文件，其他文件为二进制文件； | . 系统中的所有信息，磁盘文件，内存文件，用户数据，网络报文数据，都是一串比特表示； . 区分数据对象的方式就是 “上下文”， 根据上下文确定当前的“字节序列”表示的时整数还是浮点还是机器指令 . | 数字的机器表示方式，是对真值的有限近似值； | . C 起源：C和C标准库，为Unix而设计，小而简单，为实践设计； . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#11-%E4%BF%A1%E6%81%AF%E5%B0%B1%E6%98%AF%E4%BD%8D--%E4%B8%8A%E4%B8%8B%E6%96%87",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#11-信息就是位--上下文"
  },"174": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "1.2 程序被其他程序翻译成不用格式 - 编译",
    "content": ". | 每条C语句都需要被“其他程序”转化为一系列“机器语言”指令 . | 指令按照一种称为“可执行目标程序”的格式打包，以二进制的形式存放，可执行目标文件 . | Unix上的C “编译器驱动程序” gcc . | 编译系统的编译过程简介 . | hello.c | 预处理器 | hello.i | 编译器 | hello.s | 汇编器 | hello.o | 链接器 | hello | . | 源程序文本 | cpp | 修改了的源程序文本 | ccl | 汇编程序文本 | as | 可重定位目标程序二进制 | ld | 可执行目标程序二进制 | . | 编译系统（compilation system） . | 预处理器 | 编译器 | 汇编器 | 链接器 | . | 预处理阶段 . | 预处理器（cpp，c Preprocessor） | 从#include开始修改C程序，例如include导入系统头文件，预处理器会将头文件内容插到当前文本中； | 输出 .i 文件扩展名的文本文件 | . | 编译阶段 . | 编译器（ccl, c compiler) . | 将 .i 文本文件翻译为 .s 文本文件，包含汇编语言程序； . | hello.s 包含mian函数的汇编语言，main以外的每条都以一种文本格式描述了一条低级机器语言指令 . 汇编语言为不同的高级语言的不同的编译器提供了通用的输出语言； . | . | 汇编阶段 . | 汇编器 Assembler （as） | 将hello.s 翻译成机器语言指令 | 打包为“可重定位目标程序 （relocatable object program）的格式，将结果保存在hello.o中 | hello.o 为二进制文件，包含main的指令编码 | . | 连接阶段 . | 链接器 ld | C编译器提供了标准C库的预编译的文件，例如 printf函数，预编译目标文件为 printf.o | 链接器负责处理目标预编译文件 和 源程序 的合并； | 最终的得到的结果就是一个可执行文件，被加载到内存中，由系统执行 | . | . GNU项目， GUN’s Not Unix . GNU包含：EMACS编辑器，GCC编译器，GDB调试器，汇编器，链接器，处理二进制文件的工具和其他部件； . 支持C/C++/Java/Objective-C . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#12-%E7%A8%8B%E5%BA%8F%E8%A2%AB%E5%85%B6%E4%BB%96%E7%A8%8B%E5%BA%8F%E7%BF%BB%E8%AF%91%E6%88%90%E4%B8%8D%E7%94%A8%E6%A0%BC%E5%BC%8F---%E7%BC%96%E8%AF%91",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#12-程序被其他程序翻译成不用格式---编译"
  },"175": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "1.3 编译系统何如工作",
    "content": "编译系统如何工作，带来的帮助 . | 优化程序性能 . | 第三章，第五章，第六章 | switch语句和一系列的if-else语句那个高效 | 函数调用的开销多大 | while循环和for循环哪个更有效 | 指针引用和数据索引哪个更有效 | 循环求和结果放在本地变量中比放在引用传参高效 | 用括号优化算数表达式 | . | 理解链接时出现的错误 . | 第七章 | 链接器导致的错误 | 链接器无法解析一个引用 | 静态变量和全局变量的区别 | 不同C文件中定义同名的全局变量会发生什么 | 静态库和动态库的区别 | 命令行上排列库的顺序 | . | 避免安全漏洞 . | 缓冲区溢出 | 第三章，堆栈原理，缓冲区溢出错误 | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#13-%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E4%BD%95%E5%A6%82%E5%B7%A5%E4%BD%9C",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#13-编译系统何如工作"
  },"176": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "1.4 处理器读取和解释存储在内存中的指令",
    "content": ". | 在Unix系统中执行目标程序，在shell中输入名称执行 | shell会对不是内置命令的命令，当作可执行文件，并加载运行这个文件；等待程序终止将结果回显输出； | . 1.4.1 系统的硬件组成 . 典型系统的硬件组成 . 1. 总线 . | 贯穿整个系统的一组电子管道，称为总线； . | 携带”信息字节“ 并负责在各个部件之间传递； . | 被设计为”定长的字节快“，字 word； . | 字中的字节数（字长）是一个基本的系统参数 . 32位机器，字长4个字节 . 64位机器，字长8个字节 . | . 2. I/O device . | 每个I/O设备都通过一个”硬件芯片组 控制器” 或者 “主板插槽卡 适配器” 与I/O总线相连； | 功能都是用于I/O总线和I/O设备之间的信息传递； | . 3. 主存 . | DRAM，动态随机存取存储器芯片组成的临时存储设备；用来存放程序和程序处理的数据 | 逻辑上是“一维线性的字节数组” | 每个字节都有唯一的“地址” （逻辑上是数组索引） | 每个字节有连续且唯一的物理地址 Physical Address，CPU访问内存最自然的方式就是物理寻址（physical addressing） | . 4. 处理器 . | 中央处理单元 CPU | 解释或执行存储在主存中的执行的引擎 | 核心是“一个字”的寄存器，程序计数器PC，永远都指向主存中的机器语言指令（保存执行的内存地址) . | 处理器不断执行着指令，在更新程序计数器； | . | 处理器的指令执行模型，由指令集架构决定，INTEL和ARM . | 指令集架构的执行模型，按照严格的顺序执行 | 执行一条指令的步骤： . | 处理器从程序计数器指向的内存处读取指令 | 处理器解释指令中的位 | 处理器执行指令指示的操作 | 更新PC，让程序计数器指向下一条指令（寻址） | . | 寄存器文件 register file . | 小的存储设备，由多个单个字长的寄存器组成，每个寄存器有唯一的名字 | . | 算数/逻辑单元 ALU . | ALU计算新的数据和地址值 | 例子 . | 加载，从主存复制一个字节过着一个字到寄存器，覆盖寄存器原来的内容 | 存储，从寄存器复制一个字节或者一个字到主存的某个地址，覆盖原来的值 | 操作，把两个寄存器的内容复制到ALU，ALU对两个字进行算数运算，并将结果存放到一个寄存器中，以覆盖寄存器中原来的内容 | 跳转，从指令本身抽取一个字，并将这个字复制到程序计数器（PC），以覆盖PC中原来的值 | . | . | 处理的的指令集架构 . | 描述每条指令（机器代码）的效果，指令集架构提供的抽象（第四章） | . | 处理器的微体系机构 . | 处理器的实践实现 | . | . | . 1.4.2 运行hello . | 初始时，shell执行自己的指令，等待输入，键盘输入./hello之后，shell程序将字符注意读入“寄存器”，在把字符放入内存； . | 输入回车后，shell获取了程序输入结束的命令，并执行”一系列的指令来加载可执行文件hellio“ . | 指令将 hello 目标文件中的代码和数据从磁盘复制到主存 . | 利用“直接存取器存器（DMA）”，数据可以不通过处理器直接从磁盘到达主存 | . | 加载到主存后，处理器开始执行hello程序中的main程序中的机器语言指令 . | 这些指令将 输出字符串 从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上 | . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#14-%E5%A4%84%E7%90%86%E5%99%A8%E8%AF%BB%E5%8F%96%E5%92%8C%E8%A7%A3%E9%87%8A%E5%AD%98%E5%82%A8%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84%E6%8C%87%E4%BB%A4",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#14-处理器读取和解释存储在内存中的指令"
  },"177": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "1.5 高速缓存",
    "content": "系统花费大量的开销（时间）把信息从一个地方复制到令一个地方，从磁盘复制到主存，从主存到寄存器，从寄存器到处理单元； . 高速缓存存储器（cache memory）/ cache/ 高速缓存 . | 作为在那时的集结区域，存放处理器近期会需要的信息 | L1 高速缓存，容量达到 ”数万字节“，访问速度和寄存器文件一样快 | L2 高速缓存，容量位”数十万到数百万“，通过一条特殊的总线连接到处理器；访问速度比L1 cache慢5倍（进程对其访问时间比L1长5倍），依然比访问主存快 5到10倍； | . L1 和 L2 高速缓存使用 静态随机访问存储器（SRAM）的硬件技术实现 . | 1级，2级，3级别高速缓存： L1， L2 ，L3 | 系统利用高速缓存和局部性原理，获取一个很大的存储器，访问速度也很快； . | 局部性：程序具有访问局部区域里的数据和代码的趋势； | . | 通过让高速缓存存放可能经常访问的数据，大部分的内存操作都在快速的高速缓存中完成； | 使用高速缓存将程序性能提高一个数量级 | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#15-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#15-高速缓存"
  },"178": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "1.6 存储设备形成的层次结构",
    "content": "|   | 存储结构，自上而下，访问速度变慢，容量变大 |   | . | L0 | 寄存器 | CPU寄存器保存来自高速缓存存储器的字 | . | L1 | L1高级缓存（一级缓存）（SRAM) | L1高速缓存保存取自L2高速缓存的高速缓存行 | . | L2 | L2高速缓存（二级缓存）(SRAM) | L2高速缓存保存取自L3高速缓存的高速缓存行 | . | L3 | L3高速缓存（三级缓存）（SRAM） | L3高速缓存保存取自主存的高速缓存行 | . | L4 | 主存（DRAM） | 主存保存取自本地硬盘的磁盘块 | . | L5 | 本地二级存储（本地永久存储，硬盘，磁盘） | 本地磁盘保存远程网络服务器的文件 | . | L6 | 原创二级存储（分布式文件系统，Web服务器） |   | . | 主要思想 . | 上一层的存储器作为第一层的存储器的高速缓存 | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#16-%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87%E5%BD%A2%E6%88%90%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#16-存储设备形成的层次结构"
  },"179": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "1.7 操作系统管理硬件",
    "content": "操作系统 . | 防止硬件被控制应用程序滥用 | 向应用程序提供简单一致的机制来控制复杂而又通常不同的低级硬件设备； | 抽象 . | 文件 是对I/O设备的抽象 | 虚拟内存 是对主存和磁盘I/O设备的抽象 | 进程 是对处理器，主存，I/O设备的抽象表示 | . | . | 进程 | 进程 | 进程 | . |   | 虚拟内存 | 虚拟内存 | . |   |   | 文件 | . | 处理器 | 主存 | I/O设备 | . Unix 标准化 Posix，C语言接口，shell程序和工具，线程及网络编程 . 标准Unix规范 . 1.7.1 进程 . | 进程时操作系统对一个正在运行的程序的一种抽象 | 并发运行 . | 一个进程的指令和另一个进程的指令交错执行 | 多核心处理器，可以同时执行多个程序 | 上下文切换： 单个CPU并发执行多个进程，时通过处理器在进程间切换来实现的 | 操作系统保持跟踪进程运行所需要的所有状态信息，这种状态就是 上下文，如PC和寄存器文件的当前值，主存内容 | 操作系统决定要把控制权从当前进程转移到新进程时，进行上下文切换，新进程从上次停止的地方开始 . | 保存当前进程的上下文，恢复新进程的上下文 | . | 系统调用 . | shell通过系统调用（用户态进程和内核态进程唯一的入口），来执行命令请求，系统调用会将控制权传递给操作系统，操作系统保存shell进程的上下文，创建新进程的上下文，然后再将控制权传给新的进程，新进程终止后，操作系统恢复shell进程的上下文，并将控制权传回给它； | . | 内核 . | 常驻内存的操作系统代码 | 管理进程间的切换（进程控制块） | 系统调用 system call . | 应用程序需要操作系统的某些操作，会执行一条特殊的系统调用指令，将控制权传递给内核，然后内核执行被请求的操作并返回应用程序； | . | 内核是系统管理全部进程所用代码和数据结构的集合 | . | . | . 1.7.2 线程 . | 一个进程由多个线程执行单元组成 | 每个线程都运行在进程的上下文中 | 共享同样的代码和全局数据，并发和线程，第12章 | . 1.7.3 虚拟内存 . | 虚拟内存 - 抽象概念 | 为每个进程提供了独立占用主存的抽象，每个进程看到的内存都是一直的，虚拟地址空间 | 虚拟地址空间 . | 最上面的区域保留给操作系统中的代码和数据 | 底部区域存放用户进程定义的代码和数据 | 高地址段到低地址段是从上往下增大的 | . | 简单模型 | . | 虚拟内存模型 |   | . | 内核虚拟内存 | 用户代码不可见的内存 | . | 用户栈 （运行时创建的） |   | . |   |   | . | 共享库的内存映射区域 | printf函数 | . |   |   | . | 运行时堆 （在运行时由malloc创建） |   | . | 读/写数据 | 从hello可执行文件加载进来 | . | 只读的代码和数据 | 从hello可执行文件加载进来 | . | {程序开始} |   | . | 每个进程开到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能 | 简单介绍内存区域的功能 . | 程序代码和数据 . | 对所有进程来说，代码从同一固定地址开始，紧接着C全局变量和相对应的数据位置； | 代码和数据区是直接按照可执行文件的内存初始化的 | . | 堆 . | 代码和数据区在进程一开始运行时就被指定了大小 | 堆，调用malloc和free这样的C标准库函数时，堆可以在运行时动态的扩展和收缩； | . | 共享库 . | 在地址空间的中间部分是一块用来存放C标准库和数学库的共享代码和数据的区； | . | 栈 . | 位于用户虚拟地址空间的顶部，用户栈 | 编译器用栈来实现函数调用，用户栈可以在执行期间动态的扩展和收缩 | 每次调用一个函数是，栈就会增长；从一个函数返回时，栈就会收缩； | . | 内核虚拟内存 . | 地址空间顶部的区域是为内核保留的 | 不允许应用程序读写这个区域，不允许直接调用内核代码定义的函数 | 通过系统调用，调用内核来执行函数和操作 | . | . | . 1.7.4 文件 . | 文件 就是字节序列 | Unix思想中，一切皆文件 . | 每个I/O设备，磁盘、键盘、输出设备、网络 | . | 所有的输入输出都通过使用一小组为 Unix I/O 的系统函数调用读写文件来实现的； | 一切皆文件的思想，为应用程序提供了统一的试图，来处理系统中的各种I/O | . Linux：完整的符合Posix标准的Unix操作系统版本 . 1.8 系统之间的网络通信 . | 从单独的系统来看，网络可以看作一个I/O设备； | 系统从主存复制一串字节到网络适配器中，数据流经过网络到达另一台机器，系统读取从其他机器发送来的数据，并把数据复制到主存； | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#17-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E7%A1%AC%E4%BB%B6",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#17-操作系统管理硬件"
  },"180": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "1.9 主题",
    "content": ". | 系统是由硬件和软件互相交织的集合体；共同协作达到运行应用程序的目的； | . 1.9.1 Amdahl 定律 . | 思想 . | 当对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度； | 想要显著加速整个系统，必须提升全系统中相当大的部分的速度； | . S = 1/ (1-a) + a/k . 详细公式：Page16 . | . 1.9.2 并发和并行 . | concurrency 并发 ：指一个同时具有多个活动的系统 | parallelism 并行： 用并发来使一个系统运行的更快；并行可以在计算机系统的多个抽象层次上运行； | . 1. 线程级并发 . | 构建在进程这个抽象之上 . | 使用线程，在一个进程中执行多个控制流 . | 单个处理器的并发：通过计算机在执行的进程间快速的上下文切换来实现； . | 典型多核处理器的机构 . | 每个核心由自己的L1 cache和L2 cache，L1 高速缓存分为两部分，1保存最近拉取的指令，2存放数据 | 所有核心共享更高层次的高速缓存，到主存的接口 | . 结构图： . | 超线程，同时多线程（simultaneous multi-threading） . | 允许CPU执行多个控制流 | CPU某些硬件有多个备份 . | 程序计数器 | 寄存器文件 | . | 其他硬件只有一份 . | 浮点算术运算单元 | . | 常规的处理器需要大约20 000个时钟周期做不同线程间的转换，超线程的处理器可以在单个时钟周期内决定要执行哪个线程； | 超线程使CPU能更好的利用它处理资源 | 例 . | 在线程等待数据被装载到 高速缓存时，CPU切换执行线程去执行另一个线程； | . | 8核，可以并行的执行16个线程； | . | . 2. 指令级别并行 . | 底层抽象，现代处理器可以同时执行多条指令 指令级并行 | 流水线 . | 将执行一条指令需要的活动分成不同的步骤 | 将处理器的硬件组成一系列的阶段，每个阶段执行一个步骤，这些阶段可以并行的操作，用来处理不同指令的不同部分； | 达到近一个时钟周期一条指令的执行速率； | . | 超标量处理器，比一个时钟周期更快的执行一条指令的速率； . | 超标量处理器高级模型； | . | . 3. 单指令、多数据并行 . | 允许一条指令产生多个可以并行执行的操作 . | 单指令、多数据， SIMD并行 | 例：对8对单精度浮点数做加法的指令，一个指令包含8对单精度浮点数的相加 | 使用编译器支持的特殊向量数据类型来写程序 GCC 支持向量数据类型 | . | . 1.9.3 计算机系统的抽象 . | 抽象 . | 例如一组函数规定一个简单的API，无需了解内部的实现就可以使用 . | 抽象 . | 虚拟机 | 虚拟机 | 虚拟机 | 虚拟机 | . |   | 进程 | 进程 | 进程 | . |   | 指令集架构 | 虚拟内存 | 虚拟内存 | . |   |   |   | 文件 | . | 操作系统 | 处理器 | 主存 | I/O设备 | . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#19-%E4%B8%BB%E9%A2%98",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#19-主题"
  },"181": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "第二章，信息的表示和处理",
    "content": "###### 数字表示 . 把比特位组合在一起，加上某种解释 （interpretation） . | 无符号，unsigned 编码基于传统的二进制表示法 | 补码，two’s-complement 编码表示有符号整数，可以为正或者为负的实数 | 浮点数，floating-point 编码是表示实数的科学记数法的以2为基数的版本 . | 计算机用有限数量的位对一个数字编码，当结果太大时不能表示，会导致某些运算溢出（ovaerflow） | 浮点数的一组整数的乘积总是正的，由于表示的精度有限，浮点运算不可结合 | 整数运算和浮点数运算会有不同的数学属性 . | 处理数字表示有限性的方式不同 | 整数表示一个相对较小的数值范围，是精确的 | 浮点数编码一个较大的数值范围，表示是近似的 | . | 可表示的值的范围和不同算术运算的属性 | . C/C++/Java 数字表示 . | C/C++一致 | Java创造了一套新的语言和运算标准 . C/C++ 数字类型 . | char 1 byte -128 到 127 或 0 到 255 | unsigned char 1 byte 0 到 255 无负值的字符型 | signed char 1 byte -128 到 127 | int 2 或 4 byte -32,768 到 32,767 或 -2,147,483,648 到 2,147,483,647 32比特位整型和64比特位整型 | unsigned int 2 或 4 byte 0 到 65,535 或 0 到 4,294,967,295 无负值的整型 | short 2 byte -32,768 到 32,767 32比特位整型 | unsigned short 2 byte 0 到 65,535 无负值的短整型 | long 4 byte -2,147,483,648 到 2,147,483,647 64比特位整型 | unsigned long 4 byte 0 到 4,294,967,295 无负值的长整型 | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E7%AC%AC%E4%BA%8C%E7%AB%A0%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#第二章信息的表示和处理"
  },"182": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "2.1 信息存储",
    "content": ". | 1 byte = 8 bit | 一个字节作为最小寻址的内存单位 | 程序将内存视为一个非常大的字节数组，虚拟内存 virtual memory | 内存中每个字节有唯一标识，地址 address | 所有可能的地址的集合：虚拟地址空间 virtual address space | 编译器和运行时系统将存储器空间划分位更可管理的单元，来存放不同的程序对象 program object、 | 将**程序数据、指令、控制信息、可以用各种机制来分配和管理程序不同部分的存储； . | C中的指针的值，无论指向整型还是结构，都是某个存储块的第一个字节的虚拟地址； | C编译器将每个指针和类型信息联系起来，根据指针类型生成不同的机器代码来访问存储在执行所指向地址的值； | C编译器维护类型信息，但是生成的实际机器级程序并不会包含有关类型的信息； | 每个程序对象可以简单的视为一个字节块，程序本身就是一个字节序列； | . | . 2.1.1 十六进制 . | 一个字节 . | 二进制 00000000 ~ 11111111 | 十进制 0 ~ 255 | 16进制 hexadecimal （hex） 0~9 A~F： 0 ~ FF | . | 二进制 十六进制 相互转换 . | 每四位一组进行转换，位数不是4的倍数情况，最左边一组少于4位，前面补0 | x = 2 ^n ，x位2的n次幂，将n转化位 i + 4j 的形式，0&lt;= i &lt;= 3，x就可以写为开头16进制数字为2^i，后面跟随j个0； . | 2048 = 2^11 则 11= 3 + 2*4， i =3， j=2，则 2048的16进制表示为 0x800； | . | . | 十进制 十六进制 相互转换 . | 将十进制的数字，反复的除以16，得到的商和余数，余数为当前的最低位，商继续除以16； | 十六进制转换十进制就直接用乘法 | . | . 2.1.2 字数据大小 . | 每台计算机都有 字长 word size： 用来指明数据的标称大小（nomianl size） | 虚拟地址以一个字来编码，字长决定了虚拟地址空间大小 | 对一个字长为 ω位的机器，虚拟地址的范围是0~2^ ω -1，程序最多访问2 ^ ω个字节 | 32位字长限制虚拟地址空间位4GB | 64位字长，虚拟地址空间位16EB | . 应为字长 用来指定数据标称的大小，所以32位字长内容纳的最大值就是2的32次方 . 64位的机器可以运行32位编译的程序，向后兼容； . 所谓的32位程序和64程序，区别在于该程序的编译，而不是运行的机器类型； . | 数据类型的确切字节数依赖于程序如何被编译 | char 用来存储文本串中的一个字符，也可以用来存储整数值； | 新数据类型，数据大小固定不变，不随着编译器和机器的设置发生变化 . | int32_t 4byte | int64_t 8byte | 使用确定大小的整数类型是控制数据表示的最佳途径 | . | 大部分数据类型都编码为有符号数值 | 无符号声明：unsigned | C标准中char不能保证一定是有符号的 | 关键词的顺序包括和省略，C中存在多种形式 . | 表示一个意思 . | unsigned long | unsigned long int | long unsigned | long unsigned int | . | . | char * 使用程序的全字长 | 单精度：4 | 双精度：8 | . 2.1.3 寻址和字节顺序 . | 多字节的对象 . | 被存储位连续的字节序列 | 对象的地址为所使用字节中最小的地址 | 如 . | int变量的x地址0x100，&amp;x为0x100，它的4个字节存储在 0x100，0x101，0x102，0x103 位置 | . | . ω位整数，最高有效字节包括[x ω -1, x ω -2, … , x ω -8]，最低有效字节包括[x7, x6, x5 … x0] . | 小端法 little endian： . | 最低有效字节在最前面的方式 | 选择在内存中按照从低有效字节到最高有效自己顺序的存储对象 | . | 大端法 big endian： . | 最高有效字节在最前面的方式 | . | 位于地址0x100处的整数，十六进制的值为0x01234567，占用32个bit . | 小端法 . | | … | 0x100 | 0x101 | 0x102 | 0x103 | … | . | … | 67 | 45 | 23 | 01 | … | . | . | 大端法 . | | … | 0x100 | 0x101 | 0x102 | 0x103 | … | . | … | 01 | 23 | 45 | 67 | … | . | . | . | Intel兼容机使用“小端模式” . | 微处理器还会支持双端法，操作系统配置 . | . | 网络应用需要遵守关于字节顺序的规则，以确保发送方机器将内部表示转换成网络标准； . | 反汇编器 . | 确定可执行程序文件所表示的指令的工具 | 4004d3: 01 05 43 0b 20 00 add %eax,0x200b43(%rip) | 十六进制 01 05 43 0b 20 00 是一条指令的字节级别表示，该指令是：把一个字长的数据加到一个值上 | 该存储地址：0x200b43 + 程序计数器的值，程序计数器的值就是下一条要执行的指令的地址 | 按照小端法读取当前值： 0x200b340501 . | 阅读小端的方法，按照相反的顺序 | . | . | C中通过使用强制类型转换 cast 或者 联合 union，来允许一种数据类型引用一个对象，这种类型与创建对象时定义的类型不同； . | | 通过 (byte_pointer) &amp;x , (指针类型) 变量地址，强制将变量转化为了当前的指针类型 | sizeof 通过返回不同机器类型的上的对象类型的长度，来适配 | 这种强制类型转换告诉编译器：程序应该将这个指针当作一个指向字节序列的指针，而不是指向任何一个原始定义的数据类型的对象，指针保存了对象使用的最低字节地址 | . | 不同的操作系统或机器使用不同的存储分配规则； . | . C中typeof声明提供了一种给数据类型命名的方式 . | 浮点和整型使用不同的编码方法； | . 查看 ascii ：man ascii . 2.1.4 表示字符串 . | C中的字符串是一个以null(值为0)字符结尾的字符数组； | 每个字符都用ASCII标准来编码表示 . | 十进制的ascii表示就是0x3x，终止字节的十六进制表示为0x00 | . | 使用ASCII码的任何系统上得到的字符都是相同的结果，与字节顺序和字大小无关； | 文本数据并二进制数据有更强的平台独立性 | . Unicode 统一字符集，用32位来表示字符；用来表示多种语言和文字的标准 . UTF-8 表示将每个字符编码位一个字节序列，UTF-8中的ASCII码表示的和ASCII一样 . 2.1.5 代表代码 . | 对于C代码，不同的机器类型使用不同且不兼容的指令和编码方式 | 完全一样的进程在不同的操作系统上也有会不同的编码规则 | 二进制代码是不兼容的，很少人在不同类型的机器和操作系统中移植 | 从机器的角度，程序仅仅只是字节序列； | . 2.1.6 布尔代数简介 . | 二进制值是计算机编码、存储和操作信息的核心； | 布尔运算 . | ~ 表示逻辑运算的NOT | &amp; 表示逻辑运算的AND | | 表示逻辑运算的OR | . | ^表示逻辑运算的异或 XOR Exclusive-OR | . | 布尔代数在数字逻辑电路有重要的角色 | 位向量运算 . | 位向量； 固定长度位 ω，由0和1组成的串 | 位向量的运算可以定义为参数的每个对应元素之间的运算 . | 例如a位向量和b位向量长度都为 ω， 则a&amp;b也是一个 ω的位向量，其中每个元素位 a&amp;b | | 类似可以使用 | ^ ~ | . | . | . | . | 布尔运算&amp;对 | 和 | 对&amp;有分配律 | . 布尔环 PAGE36 . | 位向量的编码集合 . | 以位向量的形式做两个集合的并和交、补 | &amp;对应交集 | | 对应并集 | . | ~对应补集 | 位向量对集合编码 . | 如：信号中断程序执行，通过指定一个位向量掩码，有选择的使能或者屏蔽一些信号 . | 1表示信号i的使能 | 0表示信号i的屏蔽 | . | 掩码表示的就是设置位有效信号的集合 | . | . | . 2.1.7 C语言中的位级运算 . | C支持按位的布尔运算 . | ~ 表示逻辑运算的NOT | &amp; 表示逻辑运算的AND | | 表示逻辑运算的OR | . | ^表示逻辑运算的异或 XOR Exclusive-OR | . | 能用到任何”整型“的数据类型上 | 手动确定结果的方式：将16进制转化为2进制，然后做相应的位运算，再将结果转化为16进制 | 掩码运算 . | 掩码表示从一个字中选出的位的集合 | 例如 . | 0xFF，表示一个字的最低位字节，x&amp;0xFF的结果为：x的最低为有效字节 | ~0 将生成一个全1的掩码 | . | . | . 2.1.8 C中的逻辑运算 . |   | 代表代码逻辑中的OR | . | &amp;&amp; 代表代码逻辑中的AND | ! 代表代码逻辑中的NOT | 按位运算只有参数被限制在1个位时，才会和逻辑运算有相同的行为； | . 2.1.9 C中的移位运算 . | 移位运算，向左向右移动位模式 . | 左移 . | x«k, x向左移动k位，丢弃最高的k位，并在右端补k个0 | . | 右移 . | 逻辑右移 . | 在左端补k个0，k个低位丢弃 | . | 算数右移 . | 在左端补k个最高有效位的值 | 最高有效位为1时，则全部补1 | 最高有效位为0时，则全部补0 | . | 编译器/机器 都对有符号树使用算数右移，无符号数，右移必须为逻辑右移 . Java . x»k 算数右移 . x»&gt;k 逻辑右移 . 移动的k位大于字长 ω，则真正要做的移动位 k mod ω . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#21-%E4%BF%A1%E6%81%AF%E5%AD%98%E5%82%A8",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#21-信息存储"
  },"183": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "2.2 整数表示",
    "content": ". | 用位编码整数的两种不同方式 | 只能表示非负数 | 表示正数、负数、0 | . 计算机对整数的编码和操作，算数操作语句 . 2.2.1 整数数据类型 . | C支持多种整数类型，表示有限范围的整数； . | 64位程序的C整型数据类型的典型取值范围 . | C整型数据类型 | 最小值 | 最大值 | . | [signed] char | - 2^7 | 2^7 - 1 | . | unsigned char | 0 | 2^8 -1 | . | short | - 2 ^ 15 | 2^15 -1 | . | unsigned short | 0 | 2^16 -1 | . | int | - 2^31 | 2^31 -1 | . | unsigned | 0 | 2^32 -1 | . | long | - 2^ 63 | 2^63 - 1 | . | unsigned long | 0 | 2 ^ 64 -1 | . | int32_t | - 2^31 | 2^31 -1 | . | uint32_t | 0 | 2^31 - 1 | . | int64_t | - 2^63 | 2^63 - 1 | . | uint64_t | 0 | 2^64 -1 | . | 上图的取值范围不是对称的 – 负数的范围比整数的范围大1；因为负数的表示 | . | . C/C++都支持有符号（默认）和无符号数；Java只支持有符号数； . 2.2.2 无符号数的编码 . | 位向量带入 B2U 函数 Binary to Unsigned | 最小值为0 | 最大值为2^ω - 1 | . | 介于0 ~ 2^ω - 1 之间的数都有一个唯一的ω位的编码值 | 函数B2U是一个双射函数，每个长度位 ω 的位向量都映射为0 ~ 2^ω - 1 之间的一个唯一值，反过来，在于0 ~ 2^ω - 1 之间的数都有一个唯一的 ω位 的编码值 | . 2.2.3 补码编码 . | 有符号数的计算机表示方式 ”补码 two’s-complement” | 定义：将字的最高有效位解释为负权（negative weight） . | 函数 B2T Binary to Two’s-complement | | 最高有效位x ω -1 为符号位，权重 - 2^ ω -1 ； | 符号位为0表示非负 | 符号位为1表示负数 | . | 表示的最小值为[100….0]，值为 - 2^ (ω -1) | 表示的最大值为[011….1]，2^(ω -1) - 1 | 例如当长度为4的位向量，补码能表示的最小值为- 8，最大值为7 | 补码编码的唯一性 . | 取值范围内的每个数字都有唯一的 ω 位的补码编码 | B2T是一个双射函数 . | 对于每个 ω 位的位向量，其中每个向量都有唯一的x，且TMin ω &lt;= x &lt;= TMax ω | . | . | 注意： . | . | 补码范围时不对称的，TMin没有与之对应的正数，导致了补码运算的特殊属性； . | 一半的位模式符号位为1，表示负数，另一半表示非负数，但是正数不包含0，所以导致不对称； | . | 最大的无符号数值，比补码的最大值的两倍大一：UMax ω = 2TMax ω + 1； | . | . | 所有的机器都用补码来表示有符号整数 | C的标准库中定义了 | 一组常数，来限定编译器运行的机器不同类型数据的取值范围；INT_MAX INT_MIN UINT_MAX | . Java: 采用补码表示整数数据类型的取值范围，取值与64情况一致，单字节位byte类型；保证Java程序在任何机器都能表现一致； . 求补码 . 正数：最高有效位位0，将正数转为2进制数，输出16位或者32位或者64位 . 0：补码为 所有位都为0 . 负数：将负数的值部分转为16位/32位/64位二进制，每位取反，并+1； . 反码 （Ones‘ complement）：对数字0有两种表示方式，[00..0]为+0，[11…1]为-0，反码已经被淘汰 . 原码：浮点数中使用 . 2.2.4 有符号数和无符号数之间的转换 . | C允许不同数字数据之间做“强制”类型转换； . | int x; unsigned u; (unsigned)x; (int)u; unsigned u = 4294967295u; int tu = (int)u; // tu的最终值为-1，因为无符号编码的4294967295u和补码编码的-1的二进制表示完全一样； . | 强制类型转换保持结果的位值不变，但是解释位值的编码方式不同，如将无符号编码的整型转化为补码编码的有符号的整型，虽然数值在位的表示上一样，但是系统对位的解释方式就不同了； . | C中的有符号和无符号之间的相互转换，规则 . | 数值可能会改变，但是位模式不变； | . | T2U . | 补码和无符号数之间的关系： . | . | T2U 16(-12345) = -12345 + 2^16 = 53191 . | 补码表示的负数转化成无符号数，最高位的权重从-2^ω变成了2^ω，对于整个数来说大小增加了2*2^ω； . | 例如对于一个4位位向量[1,0,1,1]来说，它的补码表示-5，它的无符号表示位2^4 + (-5) == 11; | . | 对于T2U来说，将一个有符号数映射成它相应的无符号数时，负数就被转化为了大的正数，而非负数会保持不变； . 补码的符号位，1表示负数，0表示非负； . | . | U2T . | 无符号数和补码之间的关系； | | 对于小数（&lt;= TMaxω），从无符号数到有符号的转换将保留数字的原值； | 对于大数（&gt; TMaxω)，从无符号到有符号的转换将转换为一个负数值； | . | 总结 . | 对于无符号和补码之间的转换 | 对于范围在 0 &lt;= x &lt;= TMaxω之内的值而言，无符号和补码之间的数字相同；T2Uω(x) = x, U2Tω(x) = x; | 对与这个范围之外的数，需要加上或者减去2^ω | . | . | . 2.2.5 C中的有符号数和无符号数 . | C支持所有的整型数据类型的有符号和无符号运算 | 几乎所有的机器都是用补码 | 大多数数字都认为是有符号的，对于要创建的无符号型常量，需要明确在字符后缀加上字符‘U’或者‘u’； | C中的有符号和无符号数之间的转换原则是保持位表示保持不变 . | 无符号转有符号：U2Tω | 有符号转无符号：T2Uω . | ω表示数据类型的位数 | . | 显示的方式是用(type)进行强制转换 | 隐式的方式是将一种类型的表达式被赋值给另一种变量 | %d 有符号十进制 | %u 无符号十进制 | %x 十六进制 | printf输出也会隐式的对 有符号和无符号做类型转换 | C语言会在一个有符号和一个无符号数运算时，会隐式的将有符号参数强制类型转换为无符号数，并假设两个数都是非负的，再执行运算； . | -1 &lt; 0U 这个表达式的第一个数为有符号，但是第二数为无符号，所以C会将第一个数转换成无符号的32位整型，所以最终的结果为0（否）； | C中对INT_MIN的表示为 -INT_MAX - 1， 所以再表示32位有符号最小值的时候，用-2147483647 - 1；这个细节的原因是因为，补码表示的不对称性和C语言的转换规则之间的交互，详细需要研究C语言标准的一些比较隐晦的角落 | . | . | . 2.2.6 扩展一个数字的位表示 . | 无符号数的零扩展 . | | B2Uω(x) = B2Uω’(x’) | 将一个无符号的数转换成一个更大的数据类型，只需要简单的再表示的开头加0 | 零扩展 zero extension | . | 补码数的符号扩展 . | | B2Tω(x) = B2Tω’(x’) | 将一个补码数字转换位一个更大的数据类型，再表示中添加最高位的有效值 | 符号扩展 sign extension | . 大端法：最高位有效字节在内存地址的最前面，按内存地址的增长可以直接读取 . 小端法：最高位有效字节在内存地址的最前面，按内存地址的增长反向读取 . 2进制存储，16进制表示 . | 推到见PAGE55 . | . 2.2.7 截断数字 . | 将一个ω位的数截断位一个k位的数字，将会丢弃高位ω-k位，截断一个数可能会改变它的值，溢出； . | 截断无符号数 . | | 所有被截去的位其权重都是2^i，其中i &gt;= k，每一个权在取模操作下的结果都为0：2^i mod 2^k = 0； | 如： . | 对8位2进制数： 10010001 将其截断位4位二进制数：结果位 10010001 mod 2^4 . | 因为2^7 mod 2^4 为0，就是被截取的每一位的权和2^k取模都为0，所有只需要将原值与2^k取模就可以得到截断后的结果； | . | . | . | 截断补码数值 . | | x mod 2^k 的结果是一个0~2^k -1之间的一个数，然后对这个数应用函数 U2T 产生的效果是将最高位有效位x k-1 的权重从2^(k -1)转变为-2^(k -1)； | 如： . | x=53191 从int转化为short，x mod 2^16 = 53191，U2T(x)= 53191 - 65536 = - 12345 | 1001 0001为-119的补码表示，将它截断为4位补码的结果因为 1001，-119 mod 2^4 = -7， -7的补码表示位1001； | . | . | 证明见 PAGE 58 | . 2.2.8 有符号数和无符号数的建议 . | 有符号和无符号数的隐式强制转换导致了非常直观的行为；这些行为会导致程序错误； . | 隐式强制类型转换的差别错误，较难被发现； . | 有符号和无符号导致的运算错误，见PAGE58； . | 有符号数到无符号数的隐式转换，会将一个负值转换成一个非常大的正数，如果是对内存空间的访问，会导致访问到某些程序并无权限能去访问的数据，导致错误和漏洞； . | 避免的方式 . | 绝不是用无符号数 . | 例如Java本身只支持有符号整数，并且要求全部使用补码运算；»位算数右移 »&gt;逻辑右移 . | 在左端补k个最高有效位的值 | 最高有效位为1时，则全部补1 | 最高有效位为0时，则全部补0 | . | . | 需要把字当作位的集合不考虑任何数字意义的时候，无符号数值非常有用；例如：bit-flag，bitmap . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#22-%E6%95%B4%E6%95%B0%E8%A1%A8%E7%A4%BA",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#22-整数表示"
  },"184": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "2.3 整数运算",
    "content": "计算机的运算有限性 . 2.3.1 无符号加法 . | 字长膨胀，如果要对算术运算进行完整的标识，就不能对运算字长做任何限制； . 例如，编程语言Lisp，支持无限精度的运算，允许任意的整数运算（需要在机器的内存限制之内） . | 编程语言支持固定精度的运算； . | . | x+y映射到右边的无符号ω位的x + y； . | 正常情况下x+y的值保持不变 | 益处情况则：x+y - 2^ω | . | 例如： . | x=9 y=12 用4位标识位1001，1100； | x + y = 21 表示为 10101 | 丢弃最高位的1后，得到0101，结果为5 | 21 mod 16 结果为5 | . | . | 算术运算溢出 . | 指完整的整数结果不能放到数据类型的字长限制中 | . | C程序中，不会将溢出座位错误而发送信号 . | 判断是否会发生溢出 . | | 相加的结果小于任何一个相加的数，则表示相加溢出； | . | . | 加法逆操作 . | 阿贝尔群 Abelian group，每个元素都有一个加法逆元 | 对于每个值x，必然由一个 -x满足，-x + x = 0 | 无符号数求反 . | | x为0时，加法逆元为0 | x &gt; 0 时，（x + 2^ω - x ）mod 2^ω = 0 | . | . | . 2.3.2 补码加法 . | 补码加法 . | . | 正溢出： . | 当x+y超过TMaxω | 截断的结果为从数中减去2^ω | 正溢出的截断等于是对 2^ω 取模mod | . | 负溢出： . | 当x+y小于TMinω | 截断的结果为从数中加上2^ω | 负溢出的截断，将符号位截断了，此时表示的结果为 x +y + 2^ω，因为补码表示的负数的大小为 - 2^ω + sum(i*2^i) | 如两个4位数，1000，1000，补码表示都为-8，x+y = - 16 + 2^4 = 0，位相加为 10000，截断前面的1，结果就是0000 | . | . | 两个数的ω位补码和 与 无符号和 有完全相同的位级表示 | 大多数计算机使用同样的机器指令来执行无符号加法或者有符号加法 | . | 检测补码加法中的溢出 . | | 发生正溢出条件： . | x &gt; 0, y &gt; 0, 但是结果 &lt;= 0 | . | 发生负溢出的条件： . | x &lt; 0, y &lt; 0, 但是结果 &gt;= 0 | . | . | . 2.3.3 补码的非 . | 对于在范围 TMinω &lt;= x &lt;= TMaxω 中的每个数字x都有加法逆元； | 补码的非 . | | 对于ω位的补码来说，TMinω是其加法的逆； | 对于任何其他数值，其逆为-x； . | 对于一个x &gt; TMinω，数值-x表示为ω位的补码，那么x就是其正数的补码表示，则-x+x = 0， | -x | + | x | = 2^ω | . | 例如：1001为-7，0111为7，1001 &amp; 0111 = 10000 | . | . | 补码的位级表示 PAGE66 | . | . 2.3.4 无符号的乘法 . | C中无符号乘法被定义为产生ω位的值 | . | 将一个无符号的数截断为ω位等价于 计算该值模2^ω，对2^ω取模后，模的值正好就是ω位前的每一位的值； | . | . 2.3.5 补码乘法 . | C中对有符号乘法通过将2ω位的乘积截断为ω位来实现的； | 将一个补码数截断为ω位 . | 先计算该值模2^ω | 再将无符号数转换为补码 | . | | 无符号和补码的乘法，运算的位级表示都是一样的； . | | 例如： . | 对两个不同的3位二进制数的乘法，得到6位乘积； | 无符号的截断 x * y mod 2^3 | 补码将无符号的截断结果再转换成补码表示 | 虽然无符号和补码两种乘法的6位表示不同，但是截断后的乘积位级表示都相同 . | 无符号：101，011，表示5和3，乘积为 001111，截断后111，表示7 | 补码：101，011，表示-3和3，乘积为-9，110111，截断后111，补码为-1 | . | . | . | XDR库中的安全漏洞PAGE69 | . 2.3.6 乘以常数 . 理论上，乘法需要比 加法 减法 位级运算 移位 等需要更多的时钟周期来完成运算指令； . 编译器使用一项重要的优化： . ​ 用位移和加法运算的组合来代替乘以常数因子的乘法； . | 乘以2的幂 . | 如： . | ω为4时，11的表示为 1011 | 当k=2时，利用以上的位移原理：4*2^2可以用4+2位来表示，且再右边补充0 | 结果为6位的向量 101100， 11*4 = 44； | . | . | 与2的幂相乘 . | | | 固定大小的补码 算术运算和位级操作 与其无符号运算等价； | 所有可以使用左移运算进行对**补码运算的2的幂的乘法 | . | 对于无符号运算或是补码运算，乘以2的幂都有可能导致溢出 . | 溢出的结果，再位移运算后的结果上进行截断 | . | 常数乘法 . | C编译器使用移位、加法、减法的组合来消除整数乘以常数的情况； | 如： . | x * 14 | x * (x^3 + 2^2 + 2^1) | 编译器对于这个乘法操作：(x«3) + (x«2) + (x&lt;1) 将这个乘法替换为三个移位操作和两个加法操作 | 或者利用 14 = 2^4 - 2^1 这样的属性，来用两个移位和一个减法 | . | . | 对于使用移位、加法、减法的组合指令，还是一条乘法指令，取决于指令的相对速度； . | 大多数编译器再需要少量移位、加法、减法的情况下才会使用这种优化； | . | . 2.3.7 除以2的幂 . 大多数机器上，整数除法要比整数乘法更慢，需要30个或者更多的时钟周期 . | 除以2的幂用右移来实现 . | 无符号使用逻辑移位 | 补码使用算术移位 | . | 无符号的除法 除以2的幂 . | | 逻辑右移，从左端移入0； | . | 补码除法 除以2的幂 . | | 为了保证负数仍然是负数，移位需要执行算术右移； | 对于非负数，右移效果和无符号的除以2的幂的右移效果一致 | 当需要进行舍入时，移位导致结果向下舍入； . | -12340/4 表示为16位 1100111111001100 | 算术位移的结果为1111110011111100 | 计算结果为 -771.25 但是位移结果为 -772，所以舍入的方式是向下舍入 | . | . | 通过移位之前偏置 biasing这个值，来修正这种不合适的舍入 . | | 在执行算术右移之前加上一个适当的偏置导致正确的舍入结果； . | -12340/4 表示为16位 1100111111001100 | 增加偏置 **后，偏量为将1右移k位再-1，也就是1右移4位再-1**，结果为1100111111011011 | 算术位移的结果为1111110011111101 | 计算结果为 -771.25 但是位移结果为 -771，所以舍入的方式是向零舍入 | . | . | 对于使用算术右移的补码机器 . | C表达式： (x&lt;0 ? x+(1&lt;&lt;k) -1 : x) &gt;&gt; k | . | 除以2的幂，可以通过逻辑运算和算术运算来实现；大多数机器上同时提供这两种类型的右移； | 这种方法不能推广到除以任意常数；除以2的幂的除法无法用来表示除以任意常数K的除法 | . 2.3.8 总结思考 . | 计算机执行的 整数 运算实际上是一种模运算的形式； | 表述数字的有限字长限制类可能的值的取值范围，运算结果可能溢出； | 补码： . | 提供了，正数和负数的表示方法 | . | 无符号和补码都使用来位级来实现算术运算，包括加法、减法、乘法、除法 | C中需要特别注意对unsigned类型的数据的隐式的强制类型转换 | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#23-%E6%95%B4%E6%95%B0%E8%BF%90%E7%AE%97",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#23-整数运算"
  },"185": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "2.4 浮点数",
    "content": "所有计算机所支持的浮点数标准：IEEE . | 浮点数的表示 | 舍入问题（rounding） | . 2.4.1 二进制小数 . | bmbm-1bm-2...b1b0.b-1b-2b-3...b-m-1b-m | 点好左边的位的权是2的正幂，殿后右边的位的权是2的负幂； . | 二进制小数点向左移动一位，相当于该数除2 . | 例如：101.11位5又3/4 | 10.111表示2又7/8 | 1011.1表示11又1/2 | . | 二进制小数点向右移动一位，相当于该数乘2 | . | 对于有限长度的编码，类似十进制无法精确的表达1/3这样的数 . | 2进制只能精确表示能被写成 x * 2^y 的数 | 其他值只能被近似的表示 | 增加二进制表示的长度，可以提高表示的精度； | . | 练习：2.46 | . 2.4.2 IEEE浮点表示 . | V = (-1)^s X M X 2^E . | **s ** 用来决定是负数还是、正数 . | M 是一个二进制小数，范围是1~2-ε或者是0~1-ε . | E 作用是对浮点数加权，权重位2的E次幂（可能是负数） . | 单独符号位s用来直接编码符号s . | k位的阶码字段E，exp . | n位的小数字段M，frac . | 单精度浮点格式 . | | 31 | 30-23 | 22-0 | . | s | exp | frac | . | s为1位，exp位k=8位，frac为n=23位，得到一个32位的表示 | . | 双精度浮点数 . | | 63 | 62-52 | 51-0 | . | s | exp | frac | . | s位1位，exp为段k=11位，frac段k=52位；得到一个64位的表示； | . | 根据exp的值，被编码值的情况： . | 规格化的值，最普遍的情况 . | 当exp的模式不全为0，不全为1(float155，double2047)，属于这种情况； | 阶码字段被解释为以偏置（biased）形式表示的有符号整数； | 阶码的值位 E = e - Bias . | e是无符号数，位向量 ek-1ek-2…e3e2e1 | Bias 为2^(k-1) -1 . | 单精度位127 | 双精度为1023 | . | 由此产生的指数的取值范围 . | 单精度 -126 ~ +127 | 双精度 -1022 ~ +1023 | . | . | 小数字段frac，用来描述小数值f，其中0&lt;= f &lt; 1，二进制表示位0.fn-1…f1f0; . | 二进制小数点就在最高有效位的左边 | 尾数 M 定义为1+f | . | . | 非规划化的值 . | 阶码的域全为0时 . | 阶码值E = 1 - Bias 尾数值位M=f； | . | 提供来表示数值0的方法 | 逐渐溢出 gradual underflow，表示数值分布均匀接近0.0的数 | . | 特殊值 . | 阶码全为1 . | 小数域全为0，得到的表示无穷大 . | s=0，表示+♾️ | s=1，表示-♾️ | 无穷能够表示算术运算的溢出结果，如使用一个数除以0 | . | 小数域位非0时，结果位NaN . | 表示 Not a Number | 对于一个无法实现的运算，将会返回NaN值 | 如对-1开根号 | . | . | . | . | . 2.4.3 数字示例 . | 上图6位格式表示的浮点，k=3的阶码E，n=2的尾数M； . | 偏置为 2^(3 - 1) -1= 3 | 两个正负无穷大再左右两端 | 最大的规格化数值位-14和+14 . | e最大值为110，为6，则E=3，2^E = 8 | 小数最大值为11，最大值为1/2 + 1/4，f=3/4，M= 1+ 3/4 = 7/4 | 最大数的表示为 2^E X M = 14 | M = 1 + f，f=fn-1 + fn-2 + … f2 + f1 | E = ek1ek-2k-3…e2e1 - 2^(k-1) -1(Bias) | 表示的结果位2^E X M | . | 非规格化的数聚集在0附近 . | 并不是均匀分布，越靠近原点越稠密 | . | . | 对于使用IEEE表示的浮点数 . | 八位浮点格式 . | 详细 PAGE 81 | 位表达式按照升序排列，是为了让浮点数能够使用整数的排序算法来排序； | . | 属性 . | . | . | . 2.4.4 舍入 . | 表示方法限制了浮点数的范围和精度，所以浮点运算只能近似的表示实数的运算； . | 舍入运算（rounding） . | 对于一个值x，找到最接近值的x‘，并使用浮点形式表示 . | IEEE提供四种舍入方式 . | 默认的方法是找到最接近的匹配 . | 其他三种方法用来计算上界和下界 . | 向偶数舍入 round-to-even，最接近值的舍入 round-to-nearest，为默认方式 . | . 偶数舍入，大多数现实情况下避免统计偏差； . | . | . | . 2.4.5 浮点运算 . | 浮点值x和y看作实数，运算 . 定义在实数上，对浮点的运算将产生Round(x . y); | IEEE对浮点运算的参数中出现的 -0， -♾️，TeddyynadyyteddyynaN是，给出了合理的规则； . | 1/-0 产生 -♾️ | 1/ +0 产生 +♾️ | . | 浮点数的运算是可交换的 | 浮点数的运算是不可结合的 | 浮点加法的不可结合，再编译器层面可能会导致计算值与原始值的差异，编译器偏向保守，避免任何对功能产生的影响； | 浮点数的加法满足单调性 . | a&gt;=b 除了NaN外 x +a &gt;= x + b | 无符号和补码不具有这个实数加法属性 | . | 浮点数乘法 . | 定义 x * y 为Round(x X y) | 运算再乘法中封闭，可交换，可能发生溢出，可能产生无穷大或者NaN | 乘法不可结合 | 乘法单调性 . | a &gt;= b , c&gt;=0 =&gt; a * c &gt;= b * c | a &gt;= b , c&lt;=0 =&gt; a * c &lt;= b * c | a!=NaN, a * a &gt;= 0 | . | 无符号或者补码的乘法没有这些单调属性 | . | . 2.4.6 C中的浮点数 . | float . | double . | 再支持IEEE浮点格式的机器上，float对应单精度，double对应双精度 . | 这类支持IEEE的机器使用向偶数舍入的方式 . | C不要求机器使用IEEE浮点格式 . | 大多数系统提供，头文件或者过程库，来提供-0，-♾️，+♾️，NaN这些特殊值 . | #define _GNU_SOURCE 1 #include &lt;math.h&gt; // 表示GNU编译器GCC 会定义程序常数 INFINITY和NAN . | . | 浮点数的强制类型转换 . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#24-%E6%B5%AE%E7%82%B9%E6%95%B0",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#24-浮点数"
  },"186": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "2.5 本章小结",
    "content": "###### . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#25-%E6%9C%AC%E7%AB%A0%E5%B0%8F%E7%BB%93",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#25-本章小结"
  },"187": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "第三章，程序的机器级表示",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E7%AC%AC%E4%B8%89%E7%AB%A0%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BA%A7%E8%A1%A8%E7%A4%BA",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#第三章程序的机器级表示"
  },"188": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "「第一部分」",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#第一部分"
  },"189": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "第六章，存储器层次结构",
    "content": "简单的计算系统模型： . CPU执行指令，存储系统为CPU存放指令和数据，这个简单模型中，存储系统为线性字节数组，CPU能够在一个常数时间内访问每个存储器的位置； . | 存储器系统 memory system 具有不同容量、成本和访问时间的存储设备层次结构； . | CPU寄存器保存着最常用的数据 | 靠近CPU的小的、快速的高速缓存存储器（cache memory）作为一部分存储在相对较慢的住存储器（main memory）中数据和指令的缓冲区域； | 主存缓存磁盘上的数据； | . | 存储访问数据的时钟周期的数量级 . | CPU的寄存器中，指令执行期间，0个周期就能访问到 | 存储在高速缓存中，4 ~ 75个周期 | 访问主存中存储的数据需要上百个周期 | 访问磁盘中的数据，需要大约几千万个周期 | . | 思想 . | 局部性（locality） . | 具有良好局部性的程序，倾向于一次又一次的访问相同能够的数据项集合，或者倾向于访问领近的数据向集合； | 良好的局部性的程序比较差局部性的程序更多倾向于从存储器结构层次较高的层次访问数据项； | . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E7%AC%AC%E5%85%AD%E7%AB%A0%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#第六章存储器层次结构"
  },"190": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "6.1 存储技术",
    "content": "6.1.1 随机访问存储器 . | Random-Access Memory . | 静态 SRAM . | 作为高速缓存存储器 | 不超过几兆字节 | . | 动态 DRAM . | 作为主存或者图形芯片的帧缓冲存储器 | DRAM上百上千兆字节 | . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#61-%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#61-存储技术"
  },"191": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "TODO",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#todo",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#todo"
  },"192": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "6.2 局部性",
    "content": ". | 局部性原理 . | 程序倾向于引用邻近于其他最近引用过的数据项的数据向，或者最近引用过的数据本身； | . | 时间局部性（temporal locality） . | 被引用过一次的内存位置很可能在不久的时间内再次被多次引用； | . | 空间局部性（spatial locality） . | 一个内存位置被引用过一次，程序可能会在不久的时间内引用其附近的一个内存位置； | . | . 6.2.1 对程序数据引用的局部性 . | . 6.3 存储器层次结构 . | 存储器层次结构 （memory hierarchy） . | | L0 | 寄存器 | CPU寄存器保存着从高速缓存存储器取出的字 | . | L1 | L1高速缓存(SRAM) | L1高速缓存保存着从L2高速缓存取出的缓存行 | . | L2 | L2高速缓存(SRAM) | L2高速缓存保存着从L3高速缓存取出的缓存行 | . | L3 | L3高速缓存(SRAM) | L3高速缓存保存着从主存取出的缓存行 | . | L4 | 主存(DRAM) | 保存着从本地磁盘取出的磁盘块 | . | L5 | 本地二级存储（本地磁盘） | 保存从远程网络服务器磁盘上取出的文件 | . | L6 | 远程二级存储 （分布式文件系统、Web服务器） |   | . | 一个时钟周期内访问寄存器中的字 . | 几个时钟周期内访问SRAM中的缓存 . | 几十到几百个时钟周期内访问DRAM中的字 | . | . 6.3.1 存储器层次结构中的缓存 . | 高速缓存 cache | 使用高速缓存的过程为缓存 caching | 中心思想 . | k层的更快更小的存储设备作为位于k+1层更大更慢的存储设备的缓存； | 存储结构中的每一层缓存都来自较低的一层的数据对象 | . | 块（block） . | k+1层的存储器被划分成为了连续的**数据对象组块（chunk），块； | 每个块都有一个唯一的地址或名字，使其区别于其他的块； | 块可以是固定大小（通过的存储器），也可以是可变大小（web服务器上的HTML）； | . | 基本缓存原理 . | | k层和k+1层都被划分为大小相等的块 | k层的块数量更少，更快 | 任何时刻，k层的缓存包含第k+1层块的一个子集的副本 | . | 传送单元（transfer unit） . | 数据总是以块大小在k和k+1层之间来回复制 | 以块为传送单元（transfer unit) | L1 和 L0之间通常1个字节大小的块来做传送单元 | L2和L1之间、L3和L2之间、L2和L1之间通常几十个字节 | L5和L4之间传送用几百或几千字节的块 | 层次结构中较低的也是离CPU较远的设备访问时间较长，为了补偿这些时间，倾向于使用较大的块； | . | . 1. 缓存命中 cache hit . | 程序在第k层中找到了，其需要的处于k+1层的数据对象d | 因为d刚好就在缓存在k层中，这个过程为缓存命中 | . 2. 缓存不命中 cache miss . | 第k层没有缓存数据d，就是缓存不命中 | 缓存不命中时，k层会从k+1层取出包含d的块，如果k层缓存已满，可能会发生覆盖； . | 替换 replacing / 驱逐 evicting . | 被驱逐的块称为 牺牲块 victim block | 决定该替换哪个块，由缓存的替换策略 replacement policy来控制 . | 随机替换策略 | LRU 最近最少被使用策略 | . | . | 不命中后，从k+1层取出d，复制到k层之后，等待访问； | . | . 3. 缓存不命中的种类 . 虚拟内存 . | Linux为每个进程维护了一个单独的虚拟空间地址 | 地址段包括 . | 代码段 | 数据段 | 堆 | 共享库 | 栈 | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#62-%E5%B1%80%E9%83%A8%E6%80%A7",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#62-局部性"
  },"193": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "Greek alphabet",
    "content": "| Letter | Name | . |   |   | . | Α α | alpha, άλφα | . |   |   | . | Β β | beta, βήτα | . | Γ γ | gamma, γάμμα | . |   |   | . | Δ δ | delta, δέλτα | . | Ε ε | epsilon, έψιλον | . | Ζ ζ | zeta, ζήτα | . |   |   | . | Η η | eta, ήτα | . | Θ θ | theta, θήτα | . | Ι ι | iota, ιώτα | . |   |   | . | Κ κ | kappa, κάππα | . | Λ λ | la(m)bda, λά(μ)βδα[note 3] | . | Μ μ | mu, μυ | . | Ν ν | nu, νυ | . | Ξ ξ | xi, ξι | . | Ο ο | omicron, όμικρον | . | Π π | pi, πι | . | Ρ ρ | rho, ρώ | . | [Σ σ/ς, Ϲ ϲnote 4] | sigma, σίγμα | . |   |   | . | Τ τ | tau, ταυ | . | Υ υ | upsilon, ύψιλον | . |   |   | . | Φ φ | phi, φι | . | Χ χ | chi, χι | . | Ψ ψ | psi, ψι | . | Ω ω | omega, ωμέγα | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#greek-alphabet",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#greek-alphabet"
  },"194": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "CSAPP &lt;2020第三阶段&gt;",
    "content": "SUB： 2020年4月-2020年5月，当前规划第三阶段 . 问题描述 . \\1. 程序生命周期的全部过程 （内存、编译、链接、指令、运行时、并发） . \\2. 程序内存管理和存储结构访问的全部过程 . \\3. 程序网络交互的全部过程、并发的全部过程 . 当前解决问题的方法： . 对重点内容做笔记 . 暂时不再做太过于详细的笔记内容 . 当前阶段性问题（2020第三阶段）完全解决后，再次完全详细的复习和回溯本笔记中涉及的章节和内容，本笔记的目的是，在对CSAPP的阅读过程中，将黑盒部分进行打开，并且进行对上述问题的结构性知识总结，以补充现阶急需的底层知识； . 存储器结构-重点笔记： . 存储器结构模型 . 时间局部性 . 空间局部性 . 存储器结构中每一层缓存访问的成本：时间延迟、管理者、缓存内容 . 缓存命中、缓存不命中 . 高速缓存结构模型 . S= 2^s ,表示S个高速缓存组（cache set） . E，每个组包含E个高速缓存行 . B = 2^b 为没一行的B个数据块 . 有效位：valid bit . 标记位：tag bit t = m - （b+s） . s为组索引 索引有2^s个索引 . 使用一个（S,E,B,m）的元组来描述 . 高速缓存是一个高速缓存的数组 . 每行：1个有效位、1个标记位、2个字节的缓存数据块 . 高速缓存的结构将m个地址位，划分为了t个标记位、s个组索引位，b个块偏移位 . 高速缓存器的大小C，是所有块大小的和，标记位和有效位不包括在内，C = S x E x B . 指令读取： . 当一条CPU执行指令是从地址A中读取一个字，CPU将地址A发送给高速缓存，如果高速缓存保存着A的副本，则直接将副本返回给CPU； . 高速缓存通过检查地址位，找到所请求的字，类似使用了于哈希函数的哈希表； . 工作方式： . 参数S和B将m个地址位分为了三段 . 地址A，s个组索引位是一个到s个组的数组的索引，从0到2^s -1，通过索引位s找到目标字所在组 . A中t个标记位，用来定位字所在的行 . 当且仅当设置了有效位且改行的标记位与A中的标记位相匹配时，组中存在该字，通过b块偏移，定位B个字节的数据块的字偏移； . 字偏移？ . 每个高速缓存组只有一个高速缓存行： . 直接映射高速缓存； direct-mapped cache . 高速缓存的工作示例： . 第七章： . 链接（快速阅读，记录核心知识点） . 链接 linking . 将各种代码和数据片段收集并组合成一个单一文件的过程，然后文件被加载（load）到内存并执行； . 链接的执行发生 . \\1. 编译时（compile time）（源代码到机器码的过程） . \\2. 加载时（load time）（程序被加载器 loader 加载到内存并执行时） . \\3. 运行时（run time）（由应用程序来执行） . 链接由连接器 linker程序自动执行 . • 链接器导致了分离编译（separate compilation） . ○ 将一个大型的应用程序分解为更小的更好管理的模块 . ○ 可以独立的修改和编译这些模块 . ○ 改变一个模块，只需要重新编译，并重新链接 . 编译驱动程序 . Complier driver . 用户在需要时调用 语言预处理器、编译器、汇编器、链接器； . gcc驱动程序调用后执行的步骤，gcc驱动程序运行其他处理程序，运行gcc驱动程序时在shell命令中添加-v，可以看到verbose详情 . \\1. 运行C预处理器 cpp，将C的源程序的ASCII码翻译成中间文件main.i . \\2. 运行C编译器 ccl，将main.i翻译成一个ASCII汇编语言文件main.s . \\3. 运行汇编器as，将main.s 翻译成一个可重定位的目标文件 （ relocatable object file） main.o . \\4. 对于多个C文件，驱动程序经过相同的过程生成xxx.o 可重定位目标文件 . \\5. 驱动程序最终运行链接器 ld，将main.o和xxx.o文件以及一些必要的系统目标文件组合起来；创建可执行目标程序 . \\6. Executable object file . \\7. 运行该文件，在shell中输入文件名称，shell调用操作系统中的 “加载器” 函数，加载器将可执行文件中的代码和数据复制到内存，然后将控制转移到该程序的开始（main）； . 可重定向目标文件中，包括各种不同的代码和数据节（section），每一个section中都是连续的字节序列 . \\1. 指令 . \\2. 初始化的全局变量 . \\3. 未初始化得变量 . Linux LD 程序 静态链接器 static linker . 链接器LD的任务: . • 符号解析 symbol resolution . ○ 目标文件定义和引用符号，每个符号对应一个函数、一个全局变量、一个静态变量（C中任何static属性声明的变量） . ○ 符号解析的目的是：将每个符号引用和一个符号定义关联起来 . • 重定位 relocation . ○ 编译器和汇编器生成从地址0开始的代码和数据节 . ○ 链接器通过把每个符号定义与一个内存位置关联起来，来重定位这些节； . ○ 修改对所有符号的引用，使得他们指向定义的内存位置； . ○ 链接器使用汇编器产生的重定位条目 relocation entry 的详细指令，来执行重定位； . • 目标文件是纯粹的字节块的集合 . ○ 程序代码 . ○ 程序数据 . ○ 引导链接器和加载器的数据结构； . • 链接器将字节块链接起来，确定被链接的块的运行位置，并修改代码和数据块中的各种位置； . 目标文件 . | 可重定位目标文件 . | 由编译器和汇编器生成 | . | 可执行目标文件 . | 链接器生成 | . | 共享目标文件 . | 特数的可重定位目标文件，可以在加载或运行时被动态加载入内存； | . | 目标模块 object module . | 一个字节序列 | . | 目标文件 object file . | 以文件形式存放在磁盘中的目标模块 . 目标文件都是按照目标文件格式组织的 . 不同操作系统目标文件格式都不相同 . 格式 . Unix a.out . Windows Portable Executable PE . MacOS Mach-O . x86-46 Linux和Unix 可执行链接格式 Executable and Linkable Format ELF . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#csapp-2020%E7%AC%AC%E4%B8%89%E9%98%B6%E6%AE%B5",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#csapp-2020第三阶段"
  },"195": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "7.4 可重定位目标文件",
    "content": ". | ELF . | ELF header . | 以16字节的序列开始，描述系统字的大小和字节顺序 | 其余部分为帮助语法分析和解释目标文件的信息 | . | ELF头和节头部表之间的内容 . | .text | 以编译程序的机器代码 | .rodata . | 只读数据，例如printf语句中的格式串，开关语句跳转表 | . | .data . | 已经初始化的全局和静态C变量（局部C变量在运行时，保存在栈中，不出现在.data和.bss节中） | . | .bss . | 为初始化的全局变量和静态C变量 | 被初始化为0的全局变量和C变量 | 在目标文件中这个节不占据实际的空间，仅为一个占位符 | 运行时，在内存中分配这些变量，初始值为0 | . | .symtab . | 符号表 | 存放程序中定义和引用的函数和全局变量的信息； | 可重定向目标文件中都存在 .symtab 符号表 | 和编译器的符号表不用，.symtab符号表不包含局部变量的条目 | . | .rel.text . | 一个.text节中位置的列表，用来修改调用外外部函数或引用全局变量的指令的位置； | 可执行文件中不需要重定位信息； | . | .rel.data . | 被模块引用或定义的所有全局变量的重定位信息； . | 已经初始化的全局变量，初始值为一个全局变量地址活着外部定义函数的地址 | . | . | .debug . | 调试符号表，条目是程序中定义的局部变量和类型定义，定义和引用的全局变量； . | C中，编译器驱动程序 -g才会得到 | . | . | .line . | C中行号和.text机器指令之间的映射 . | C中，编译器驱动程序 -g才会得到 | . | . | .strtab . | 字符串表，包括.symtab和.debug节中的符号表，节头的名字； | 字符串表就是以null结尾的字符串序列 | . | . 未初始化的数据 .bss . Block Storage Start 沿用 . Better Save Space 理解记忆 . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#74-%E5%8F%AF%E9%87%8D%E5%AE%9A%E4%BD%8D%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#74-可重定位目标文件"
  },"196": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "7.5 符号和符号表",
    "content": ". | 每个可重定位的符号m都有一个符号表，它包含m定义和引用的符号的信息： . | 由模块m定义，并能被其他模块引用的全局符号 . | 全局链接器符号对应于非静态的C函数和全局变量 | . | 由其他模块定义，并被m引用的全局符号 . | 外部符号 | 对应于其他模块中定义的非静态C函数和全局变量 | . | 只被m定义和引用的局部符号 . | static属性的C函数的全局变量，static 存储类修饰的全局变量或者函数，只能在当前文件中被调用和使用； | . | . | 链接器不管理 .symtab不包含 “本地非静态程序变量的任何符号，这些符号在运行时在栈中被管理； | static属性的本地过程变量（局部变量）不在栈中管理，编译器在.data和.bss中为每个定义分配空间； . | 并在符号表中，创建一个有唯一名字的本地链接器符号； | 在同一个文件中或者说模块中，出现了同名的静态局部变量 . | 编译器会向汇编器输出两个不同名字的局部链接器符号 | . | . | . C中使用static用来**隐藏模块中的内部全局变量和函数声明； . 提供了和C++、Java中public private 属性声明一样的功能； . static 的全局变量和函数 = 表示私有 . 符号表 . | 由汇编器构造 | 使用编译器输出到汇编语言.s文件中的符号，汇编器构造ELF符号表； | . 7.6.2 与静态库链接 . | 编译系统提供机制 | 将所有目标模块打包成为一个单独的文件，静态库static library | 作为链接器的输入，链接器复制被应用程序引用的目标模块，构造一个可执行文件 | 静态库 . | 相关的函数被编译为独立的目标模块，然后封装为一个单独的静态库文件 | 通过命令，应用可以指定单独的文件名来使用库中定义的函数 | 链接时，链接器只复制被程序引用的目标模块 | . | Linux中的静态库 . | Linux中的静态库以存档 archive的特殊文件格式存放在磁盘中 | 存档文件 archive files，是一组连接起来的可重定向目标文件的集合 | 有一个头部用来描述每个成员目标文件的大小和位置 | 存档以.a标识 | . | . 链接的引用解析：PAGE 476-477 . 7.6.3 使用静态库来解析引用 . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#75-%E7%AC%A6%E5%8F%B7%E5%92%8C%E7%AC%A6%E5%8F%B7%E8%A1%A8",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#75-符号和符号表"
  },"197": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "7.7 重定位",
    "content": ". | 将代码中的每个符号引用和符号定义（输入目标模块的一个符号表条目）关联起来； | 链接器知道输入目标模块中的代码节和数据节的确切大小； | 重定向 . | 合并输入模块，并为每个符号分配运行时地址 . | 重定位节和符号定义 . | 合并所有模块中同一类型的节到聚合节 | 链接器将运行时地址赋给新的聚合节； | 赋值给输入模块定义的每个节； | 赋值给输入模块定义的每个符号； | 完成后，程序中每条指令和全局变量都有唯一的运行时内存地址-物理地址； | . | 重定位节中的符号引用 . | 链接器修改代码节和数据节中对每个符号的引用，使其指向正确的运行时地址； | 依赖 ：重定位条目relocation entry | . | . | . | . 重定位节和符号定义 . 重定位节中的符号引用 . 7.7.1 重定位条目 . | 汇编器对最终位置未知的目标引用，就会生成一个重定位条目 | 重定位条目用来告诉链接器，就目标文件合成并生成可执行文件时如何修改这个引用 | 代码的重定位条目放在.rel.text | 已经初始化数据的重定位条目.rel.data中 | . | 重定位PC相对引用（程序计数器）：PC当前运行地址的偏移量 | 重定位绝对引用：绝对地址引用，通过绝对寻址，CPU直接使用再指令中编码的32位值作为有效地址，无需进一步修改； | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#77-%E9%87%8D%E5%AE%9A%E4%BD%8D",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#77-重定位"
  },"198": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "7.8 可执行目标文件",
    "content": ". | 链接器将多个目标文件合并为一个可执行目标文件 | 最终的可执行文件由最初的 一组ASCII 文本文件，转化为了一个二进制文件 | 该二进制文件包含加载程序到内存并运行它所需要的所有信息； | . 可执行目标文件的格式 . |   | ELF头 | 1只读内存段 | . | 将连续的文件节映射到运行时内存段 | 段头部分 | 1只读内存段 | . |   | .init | 1只读内存段 | . |   | .text | 1只读内存段 （代码段） | . |   | .rodata | 1只读内存段（代码段） | . |   | .data | 2读写内存段（数据段） | . |   | .bss | 2读写内存段（数据段） | . |   | .symtab | 3不加载到内存的符号表和调试信息 | . |   | .debug | 3不加载到内存的符号表和调试信息 | . |   | .line | 3不加载到内存的符号表和调试信息 | . |   | .strtab | 3不加载到内存的符号表和调试信息 | . | 描述目标文件的节 | 节头部表 | 3不加载到内存的符号表和调试信息 | . 可执行目标文件的格式 类似于 可重定位目标文件的格式 . | 可执行文件格式的各节内容 | . | ELF | 作为ELF头部，描述文件的总体格式，包括程序的入口点 entry point（程序执行的第一条指令的地址） | . | .init | .init节定义了一个函数，_init函数，程序的初始化代码会调用_init函数 | . |   |   | . |   |   | . |   |   | . |   |   | . | .text | 已编译程序的机器代码 | . | .rodata | 只读数据，例如printf语句中的格式串，开关语句跳转表 | . | .data | 已经初始化的全局和静态C变量（局部C变量在运行时，保存在栈中，不出现在.data和.bss节中） | . | .bss | 为初始化的全局变量和静态C变量 被初始化为0的全局变量和C变量 在目标文件中这个节不占据实际的空间，仅为一个占位符 运行时，在内存中分配这些变量，初始值为0 | . |   |   | . |   |   | . | 可执行文件已经**完全链接，且已经完成了重定位，所有.rel节中的重定位条目已经不再需要 | ELF可执行文件被设计的很容易加载到内存 . | 可执行文件的连续的片 （chunk） 被映射到连续的内存段 | **程序头部表 program header table ** 描述了连续的chunk映射到内存段的映射关系； . | 分为两部分 . | 第一段，代码段，有 读/执行 访问权限 . | 指定内存开始地址，和总占用内存的大小n个字节，可执行文件的头的n个字节，包含：ELF头，程序头部表，.init, .text, .rodata节 | . | 第二段，数据段，有 读/写 访问权限 . | 指定内存开始地址，总大小，从目标文件的偏移m处开始的.data节中的mx个字节初始化，该段剩下的字节对应需要被初始化位0的.bss数据节 | . | . | 对于任何段s，链接器必须选择一个起始地址 . | off位目标文件中的段的第一个字节偏移量 | align为程序头部中指定的对齐 . | 对齐是一种优化，因为虚拟内存的组织方式，为大小位2的幂次的字节片； | . | . | . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#78-%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#78-可执行目标文件"
  },"199": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "7.9 加载可执行目标文件",
    "content": ". | shell调用驻留在内存中的加载器 loader 的操作系统代码来运行可执行文件 . 涉及到shell和操作系统的交互以及交互方式 「system call」 . | 任何Linux程序都可以通过调用execve函数来调用加载器loader . | 加载 (加载器把程序复制到内存并运行的过程) . | 加载器 loader将可执行目标文件中的代码和数据从磁盘复制到内存中，再通过跳转到程序的第一条指令或者entry point来运行该程序； | . | 运行时内存映像 . | 代码段总是从 0x400000 处开始 | 接着是数据段 | 运行时堆再数据段之后，通过调用malloc库往上增长 | 堆后面的区域为共享模块保留 | 用户栈总是以最大的合法用户地址 2^48 -1 开始，向较小的内存地址增长 | 栈上的区域，从地址 2^48 - 1 开始，是内核（kernel）中的代码和数据保留； | . | 下面内存模型的问题： . | 栈顶放在64位字长的机器的最大合法用户地址处 | 堆、数据、代码在下面模型中相邻，实际上.data段有对齐的要求，所有代码段和数据段之间有间隙； | 分配栈、共享库、堆段运行时地址的时候，链接器会使用地址空间布局随机化 ASLR . | ASLR . | 地址空间布局随机化 （Address-Space Layout Randomization） | ASLR技术能够增加攻击一个系统的难度，保证了一定程度的安全； | 程序开始时，在栈上分配一段0~n字节之间随机大小的空间； . | 使用alloca在栈上肥胖指定字节数量的空间 | 这个空间会导致程序执行时，后续的栈位置发生变化； | linux系统的栈随机化 . | 32位系统的随机地址范围为2^23 | 64位系统的随机地址范围为位2^32 | . | . | . | . | 每次程序运行时区域地址都会改变，但是相对位置不变； | . | . | 高地址 | 2^48 -1 处开始 | 内核内存 | 对用户代码不可见的内存 | . |   |   | 用户栈，运行时创建 | %rsp 栈指针 | . |   |   |   |   | . |   |   | 共享库的内存映射区域 |   | . |   |   |   |   | . |   |   |   |   | . |   |   | 运行时堆 （由程序调用的某个版本的 malloc函数创建） | brk | . |   |   | 读/写段 「.data, .bss」 (已初始化全局变量、静态变量，未初始化全局变量和静态变量)此处的静态变量：包含1. 全局静态变量，此类变量使用static存储类修饰符修饰后之内在当前所在的模块中使用，或者说只能再所在的c文件中使用，C中的static修饰全局变量相当于声明private属性 2. 本地过程变量的static，也就是函数或者块中声明的静态局部变量，为了舍得所有的函数调用不再分配新的堆空间，并且保持一个值的变量，此变量和auto的局部变量不同，此变量依然在堆中，编译器再.data和.bss中为每个定义分配空间 static属性的本地过程变量（局部变量）不在栈中管理，编译器在.data和.bss中为每个定义分配空间；并在符号表中，创建一个有唯一名字的本地链接器符号； 在同一个文件中或者说模块中，出现了同名的静态局部变量 编译器会向汇编器输出两个不同名字的局部链接器符号 |   | . |   | 0x400000 | 只读代码段 「.init, .text, .rodata」初始化函数，代码段机器指令代码，格式串和开关语句跳转表 |   | . | 低地址 | 0 |   |   | . | 详细学习 - 第九章 虚拟内存 | . Linux系统中的每个程序都运行在一个进程上下文中，有自己的虚拟地址空间； . 当shell运行一个程序时，父shell进程生成一个子进程，他是父进程的一个复制； . 子进程通过 execve 系统调用启动加载器； . 加载器删除子进程现有的虚拟内存段，并创建一组新的代码、数据、堆和栈段； . 新的栈和堆段被初始化为0； . 通过将虚拟地址空间中的页映射到可执行文件的页大小的片（chunk）； . 新的代码和数据段被书痴华为可执行文件的内容； . 加载器跳转到_start地址，最终会调用相应的程序的main函数； . 加载过程中，只会将“头部信息“从磁盘复制到内存； . CPU引用一个被映射的虚拟内存页时才会进行复制，此时，操作系统利用页面调度机制自动将页面从磁盘传送到内存； . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#79-%E5%8A%A0%E8%BD%BD%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#79-加载可执行目标文件"
  },"200": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "7.10 动态链接共享库",
    "content": ". | 共享库 shared library . | 一个目标模块，运行和加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来；这个过程位动态链接 dynamic linking | 动态链接器 dynamic linker | 共享目标 shared object | 在linux系统中通常用.so后缀来表示 | . | ”共享“方式 . | 给定的文件系统中，一个库只有一个.so文件，所有引用该库的可执行目标文件共享.so文件中的代码和数据； | 不会像静态库一样被复制和嵌入到引用的可执行文件中； | 在内存中，一个共享库的.text节的一个副本可以被不同的正在运行的进程共享； | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#710-%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%85%B1%E4%BA%AB%E5%BA%93",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#710-动态链接共享库"
  },"201": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "第八章，异常流控制",
    "content": ". | 控制流 . | 程序计数器中指令地址的过度称为控制转移 control transfer | 程序计数器指令地址的过度的序列为处理器的控制流（control flow） . | 平滑的控制流序列，其中每个指令的地址都是相邻的； | 平滑流的突变，通常由跳转， 调用、返回等指令造成 | . | 控制流突变 . | 异常控制流 Exceptional Control Flow ECF | 发生在计算机系统的各个层次 . | 硬件事件触发控制突然转移到异常处理程序 | 内核通过上下文切换将控制从一个用户进程转移到另一个用户进程 | 应用层，进程之间使用信号通信，接受者会将控制转移到信号处理程序； | 程序通过回避通常的栈规则，执行到其他函数任意位置的非本地跳转来对错误作出反应； | . | . | ECF . | ECF是OS用来实现I/O，进程、虚拟内存的基本机制； | 应用程序使用系统调用 （system call）的ECF形式，向系统请求服务； . | 磁盘写入数据 | 网络读取数据 | 创建新进程 | 终止当前进程 | 通过系统调用实现 | . | ECF是计算机系统实现并发的基本机制； . | 中断应用程序执行的异常处理程序 | 时间上重叠执行的进程和线程 | 中断应用程序执行的信号处理程序； | . | ECF软件异常 . | C++ try catch throw | 软件异常允许程序进行非本地跳转，来响应错误； . | 非本地跳转是一种应用层ECF，C中通过setjmp和longjmp函数提供 | . | . | 各种形式的ECF | . | . | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%BC%82%E5%B8%B8%E6%B5%81%E6%8E%A7%E5%88%B6",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#第八章异常流控制"
  },"202": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "8.1 异常",
    "content": ". | 异常 exception 就是控制流中的突变，用来响应处理器状态中的某些变化； . | 状态被编码为不同的位和信号 | 状态变化称为事件event | 与当前指令直接相关 . | 虚拟内存缺页 | 算术溢出 | . | 与当前指令无关 . | 系统定时器信号 | 一个I/O请求完成 | . | . | 事件发生 – 处理器通过异常表 exception table 跳转表，进行一个间接的过程调用 – 异常处理程序 exception handler – 处理完成后 . | 处理程序将控制返回给当前指令，事件发生时正在执行的指令 | 处理程序将控制返回给当前指令的下一条指令，没有发生异常就会执行下一条指令 | 处理程序终止被中断的程序 | . | . 8.1.1 异常处理 . | 系统中每一个异常都有一个唯一的非负整数的异常好 exception number | 处理器相关 . | 被零除 | 缺页 | 内存访问违例 | 断点 | 算术运算溢出 | . | 操作系统内核相关 . | I/O设备的信号 | . | 异常处理表 . | 间接过程调用 | . | 陷阱 . | 有意的异常，执行一条指令的结果，像中断处理程序一样； | 用途 . | 用户程序和内核之间提供一个像过程一样的接口，系统调用 | 用户程序向系统内核请求服务： . | read | fork （创建新进程） | execve | exit | . | 为了允许对内核服务的受控的访问，处理器提供一条特殊的“syscall n”指令； | 用户程序想要请求服务n时，执行指令 syscall n，就会导致一个异常处理程序的陷阱； . | 这个处理程序解析参数，并调用适当的内核程序； | . | . | . | . 完全详细的描述 . | gcc hello.c -o hello.out | ./hello.out | 过程 | . 设计知识： 编译 -&gt; 汇编 -&gt; 连接 -&gt; 加载 -&gt; 系统调用 . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#81-%E5%BC%82%E5%B8%B8",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#81-异常"
  },"203": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "过程",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E8%BF%87%E7%A8%8B",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#过程"
  },"204": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "运行时栈",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E8%BF%90%E8%A1%8C%E6%97%B6%E6%A0%88",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#运行时栈"
  },"205": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "栈帧",
    "content": ". | | 用户栈 | - | . | 参数 |   | . | 返回地址 |   | . | 被保存的寄存器 |   | . | 局部变量 |   | . | 参数构造区 | &lt;-%rsp | . | 过程是一种软件中的抽象 | 提供一种封装代码的方式，用一组指定的参数和一个可选的返回值来实现某种功能 | 不同的语言中过程有多重形式 . | 函数 function | 方法 method | 子例程 subroutine | 处理函数 handler | 块/闭包 block | . | 过程的共同属性包括 . | 传递控制 . | 程序开始阶段，运行时栈的rip（程序计数器指针）指针指向入口函数，然后开始执行，例如执行主函数Q的指令，该指令指向主函数内的过程调用的函数P，这是新的函数P在栈中分配了新的栈帧，该栈帧中的过程返回后，rip指针又指向Q中调用P的那条指令，此时这条指令指向P函数的返回值； | . | 传递数据 | 分配和释放内存 | . | C过程调用的关键特性 -&gt; 使用栈数据结构的提供的先进后出的内存管理原则 | 过程在被调用时候，才会在栈中为局部变量分配空间，而过程结束后分配的局部存储空间都会被释放掉； | 栈和程序寄存器存放着传递控制和数据、分配内存所需要的信息； . | X86_64 栈向底地址增长 | 栈指针%rsp指向栈顶元素 | pushq指令入栈 | popq指令出栈 | 将指针减小一个适当的量可以为没有指定初始值的数据在栈上分配空间 （指针偏移量，变长数组） | 增加栈指针来释放空间 . | 栈帧 （stack frame）：X86_64 过程所需要的存储空间超出寄存器能够存放的大小，就会在栈上分配空间 | 栈通过增加和减小%rsp的大小来释放空间和分配栈帧； | 当前正在执行的过程的栈总是在栈顶 | 定长栈帧 | 变长栈帧 | 栈帧的实质就是过程因为所需要的寄存器空间不足而在栈顶分配的新的内存空间；内存中一个过程所包含的过程调用和数据及返回； . | 6个或者更少的参数可以直接通过寄存器传递 （6个参数：可以通过寄存器最多传递6个参数，例如整数和指针参数，寄存器只用有特殊的顺序，名字取决于传递的参数的大小） | 叶子过程：所有局部变量都保存在寄存器中，而且不会调用其他函数的过程 | X86_64 只分配自己所需要的栈帧部分 | . 去 . csapp.cs.cmu.edu . C中的指针的机器级表示 . | 3.10.1 | . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/#%E6%A0%88%E5%B8%A7",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/#栈帧"
  },"206": {
    "doc": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "title": "深入理解计算机系统 [Computer-Systems-A-Programmer's-Perspective]",
    "content": "CSAPP . Computer-Systems . 2020-03-27 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-27-csapp/",
    
    "relUrl": "/docs/archives/2020/2020-03-27-csapp/"
  },"207": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "Python进程内存分析&amp;大量内存占用的优化方案",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#python%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E5%A4%A7%E9%87%8F%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%A1%88",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#python进程内存分析大量内存占用的优化方案"
  },"208": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "CPython预编译运行库",
    "content": ". | python-debuginfo-2.7.5-86.el7.x86_64 | glibc-debuginfo-common-2.17-292.el7.x86_64 | python-debuginfo-2.7.5-86.el7.x86_64 | . ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#cpython%E9%A2%84%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E5%BA%93",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#cpython预编译运行库"
  },"209": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "monitor-server 内存分析，大量内存占用的优化方案",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#monitor-server-%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E5%A4%A7%E9%87%8F%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%A1%88",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#monitor-server-内存分析大量内存占用的优化方案"
  },"210": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "1. 当前程序状态",
    "content": ". | 物理机 417593 root 20 0 4325700 1.946g 6724 S 8.9 0.8 891:53.36 python 641599 root 20 0 4322988 1.922g 6748 S 3.0 0.8 1219:54 python 641904 root 20 0 4328792 1.968g 6748 S 3.0 0.8 1359:53 python 641963 root 20 0 4327696 1.930g 6748 S 2.0 0.8 1263:28 python . | 虚拟机 609083 root 20 0 4123852 1.5g 1660 S 2.3 9.5 109:47.85 python 643875 root 20 0 4262180 1.7g 1284 S 1.3 11.0 89:58.01 python 643877 root 20 0 4192588 1.6g 1440 S 1.3 10.6 86:33.74 python 671562 root 20 0 4253364 1.7g 1704 S 1.0 10.8 69:23.61 python . | 运行时间在1000小时左右的进程 | 在裸金属中占用物理内存比例为0.8%，主机内存总大小为256GB，每个python进程占用大小为2GB左右 | 在虚拟机中占用的物理内存大小9%~ 11%，主机内存总大小16GB，每个python进程占用内存大小为2GB左右 | 同一LISTEN端口，TCP服务保持的TCP长链接对应Socket数量 . | 虚拟机：80左右 | 物理机：120 - 140左右 | . | 因为在LVS转发配置 . | 虚拟机 权重 20 单个进程的权重 20/10 | 物理机 权重 100 单个进程的权重 100/30 | . | . ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#1-%E5%BD%93%E5%89%8D%E7%A8%8B%E5%BA%8F%E7%8A%B6%E6%80%81",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#1-当前程序状态"
  },"211": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "2. server对交付报文的处理",
    "content": ". | server处理HTTP报文的有效载荷数据大小为数bk到数百kb，服务器使用I/O多路复用，借助select(此处使用了linux的epoll)函数检查事件输入，进程通过监听描述符创建了80到140个连接描述符，并将数据交付给multiprocessing线程池中25个线程中空闲的线程，在文件的读写过程中，server的动态监控及接口监控等数据处理有一定复杂度的函数，会产生大量的数据拷贝和引用，并会创建很多对象（datamodel等）； . | python的垃圾回收发生的条件 https://docs.python.org/2/library/gc.html 官方文档：The GC classifies objects into three generations depending on how many collection sweeps they have survived. New objects are placed in the youngest generation (generation 0). If an object survives a collection it is moved into the next older generation. Since generation 2 is the oldest generation, objects in that generation remain there after a collection. In order to decide when to run, the collector keeps track of the number object allocations and deallocations since the last collection. When the number of allocations minus the number of deallocations exceeds threshold0, collection starts. Initially only generation 0 is examined. If generation 0 has been examined more than threshold1 times since generation 1 has been examined, then generation 1 is examined as well. Similarly, threshold2 controls the number of collections of generation 1 before collecting generation 2. | python内存管理的三层结构 . | generation 0：新建的对象 | generation 1：垃圾回收后，任然存在引用，则归入1 | generation 2：最老的无法被collection函数回收的对象 | . | 回收机制会在内存分配数量和取消分配数量的差值超过 一个特定的阈值 才会触发 | 通过gc模块，可以查看默认的阈值，且可以通过调用set_threshold函数，配置定制的阈值 import gc gc.get_threshold()　　#gc模块中查看阈值的方法 (700, 10, 10) . | 这里的解释是：阈值超过700时才会对g0的对象进行回收，每10次回收g0会发生1次回收g1，每10次回收g1会发生1次回收g2； | gc模块提供主动触发垃圾回收的函数 def collect(generation=None) collect([generation]) -&gt; n . | . With no arguments, run a full collection. The optional argument may be an integer specifying which generation to collect. A ValueError is raised if the generation number is invalid. | 对于不传入参数的调用来说，会发起g0 g1 g2三代的全部的回收； | CPython对C运行库提供的free函数的调用，也存在一定的条件 . | 第3层：最上层，用户对Python对象的直接操作 | 第1层和第2层：内存池，有Python的接口函数PyMem_Malloc实现-----若请求分配的内存在1~256字节之间就使用内存池管理系统进行分配，调用malloc函数分配内存，但是每次只会分配一块大小为256K的大块内存，不会调用free函数释放内存，将该内存块留在内存池中以便下次使用。 | 第0层：大内存-----若请求分配的内存大于256K，malloc函数分配内存，free函数释放内存； | . | . ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#2-server%E5%AF%B9%E4%BA%A4%E4%BB%98%E6%8A%A5%E6%96%87%E7%9A%84%E5%A4%84%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#2-server对交付报文的处理"
  },"212": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "3. 动手操作，问题定位",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#3-%E5%8A%A8%E6%89%8B%E6%93%8D%E4%BD%9C%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#3-动手操作问题定位"
  },"213": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "中断运行的程序，输出无法回收的对象",
    "content": "A list of objects which the collector found to be unreachable but could not be freed (uncollectable objects). By default, this list contains only objects with del() methods. 1 Objects that have del() methods and are part of a reference cycle cause the entire reference cycle to be uncollectable, including objects not necessarily in the cycle but reachable only from it. Python doesn’t collect such cycles automatically because, in general, it isn’t possible for Python to guess a safe order in which to run the del() methods. If you know a safe order, you can force the issue by examining the garbage list, and explicitly breaking cycles due to your objects within the list. Note that these objects are kept alive even so by virtue of being in the garbage list, so they should be removed from garbage too. For example, after breaking cycles, do del gc.garbage[:] to empty the list. It’s generally better to avoid the issue by not creating cycles containing objects with del() methods, and garbage can be examined in that case to verify that no such cycles are being created. | pip install pyrasite | pip show pyrasite | . Name: pyrasite Version: 2.0 Summary: Inject code into a running Python process Home-page: http://pyrasite.com Author: Luke Macken . | 安装pyrasite工具，该工具可以中断正在运行的进程，并对进程进行注入和检查 | pyrasite-shell ， 接下来就可以在的进程里调用任意的python代码, 来查看进程的状态. | guppy 取得内存使用的各种对象占用情况，guppy 可以用来打印出各种对象各占用多少空间, 如果python进程中有没有释放的对象, 造成内存占用升高, 通过guppy可以查看出来: | pip install guppy pyrasite-shell &lt;pid&gt; from guppy import hpy h = hpy() h.heap() . | 运行此命令报错，暂时未定位原因，h.heap可以查看当前进程堆的内存分配情况，例如各种类型的对象占用的内存长度； # Partition of a set of 48477 objects. Total size = 3265516 bytes. # Index Count % Size % Cumulative % Kind (class / dict of class) # 0 25773 53 1612820 49 1612820 49 str # 1 11699 24 483960 15 2096780 64 tuple # 2 174 0 241584 7 2338364 72 dict of module # 3 3478 7 222592 7 2560956 78 types.CodeType # 4 3296 7 184576 6 2745532 84 function # 5 401 1 175112 5 2920644 89 dict of class # 6 108 0 81888 3 3002532 92 dict (no owner) # 7 114 0 79632 2 3082164 94 dict of type # 8 117 0 51336 2 3133500 96 type # 9 667 1 24012 1 3157512 97 __builtin__.wrapper_descriptor # &lt;76 more rows. Type e.g. '_.more' to view.&gt; h.iso(1,[],{}) # Partition of a set of 3 objects. Total size = 176 bytes. # Index Count % Size % Cumulative % Kind (class / dict of class) # 0 1 33 136 77 136 77 dict (no owner) # 1 1 33 28 16 164 93 list # 2 1 33 12 7 176 100 int . | 无法回收的对象 | python垃圾回收, 对象无法被垃圾回收(uncollectable object), 满足2个条件: . | 循环引用 | 循环引用的链上某个对象定义了__del__方法, 循环引用的一组对象被gc模块识别为可回收的, 但需要先调用每个对象上的__del__方法, 才能回收. 但用户自定义了__del__的对象, gc系统不知道应该先调用环上的哪个__del__. 因此无法回收这类对象. | . | 不能回收的python对象会持续占据内存 | 查找uncollectable的对象: pyrasite-shell {PID} &gt;&gt;&gt; import gc &gt;&gt;&gt; gc.collect() # first run gc, find out uncollectable object and put them in gc.garbage # output number of object collected &gt;&gt;&gt; gc.garbage # print all uncollectable objects &gt;&gt;&gt; [] # empty . 如果在上面最后一步打印出了任何不能回收的对象, 则需要进一步查找循环引用链上在哪个对象上包含__del__方法. | gdb查看python线程执行上下文及调用栈 . | 安装python的debuginfo及gcc的debuginfo | gdb python {PID} (gdb) info threads Id Target Id Frame 36 Thread 0x7f4b2bbad740 (LWP 404510) 0x00007f4b2a9e1e63 in epoll_wait () at ../sysdeps/unix/syscall-template.S:81 35 Thread 0x7f4a7bb7a700 (LWP 412337) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a58000910) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 34 Thread 0x7f4a7c37b700 (LWP 412248) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a54000b30) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 33 Thread 0x7f4a7cb7c700 (LWP 410227) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a5c000b30) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 32 Thread 0x7f4a7d37d700 (LWP 409187) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a6826fa50) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 31 Thread 0x7f4a7dc3e700 (LWP 408137) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a70003470) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 30 Thread 0x7f4a7e43f700 (LWP 406936) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a6c33ccc0) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 29 Thread 0x7f4a8effd700 (LWP 405827) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a74811da0) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 28 Thread 0x7f4a8f7fe700 (LWP 404586) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a80001b90) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 27 Thread 0x7f4a8ffff700 (LWP 404585) 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a88002620) ... (gdb) thread 24 [Switching to thread 24 (Thread 0x7f4aadffb700 (LWP 404582))] #0 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a9c002050) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 43 err = lll_futex_wait (futex, expected, private); (gdb) py-list 334 waiter.acquire() 335 self.__waiters.append(waiter) 336 saved_state = self._release_save() 337 try: # restore state no matter what (e.g., KeyboardInterrupt) 338 if timeout is None: &gt;339 waiter.acquire() 340 if __debug__: 341 self._note(\"%s.wait(): got it\", self) 342 else: 343 # Balancing act: We can't afford a pure busy loop, so we 344 # have to sleep; but if we sleep the whole timeout time, (gdb) . | 看到大量的线程处于 futex_abstimed_wait 状态，使用py-list查看代码后，发现当前该线程的ioloop处于等待状态，结合htop或者top命令，可以看到当前进程的25个线程大多数线程处于等待调度状态（饥饿状态），分析为server扩容后，单个进程的负载很大程度下降，导致对80~140个范围内的已连接FD不需要频繁的线程上下文切换即可完成处理； . | 使用gcc debug 可以查看当前CPython的调用栈 0x00007f4b2b3c7afb in futex_abstimed_wait (cancel=true, private=&lt;optimized out&gt;, abstime=0x0, expected=0, futex=0x7f4a9c002050) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:43 #1 do_futex_wait (sem=sem@entry=0x7f4a9c002050, abstime=0x0) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:223 #2 0x00007f4b2b3c7b8f in __new_sem_wait_slow (sem=0x7f4a9c002050, abstime=0x0) at ../nptl/sysdeps/unix/sysv/linux/sem_waitcommon.c:292 #3 0x00007f4b2b3c7c2b in __new_sem_wait (sem=&lt;optimized out&gt;) at ../nptl/sysdeps/unix/sysv/linux/sem_wait.c:28 #4 0x00007f4b2b6e7795 in PyThread_acquire_lock (lock=0x7f4a9c002050, waitflag=1) at /usr/src/debug/Python-2.7.5/Python/thread_pthread.h:323 #5 0x00007f4b2b6eb482 in lock_PyThread_acquire_lock (self=0x7f4b1862a930, args=&lt;optimized out&gt;) at /usr/src/debug/Python-2.7.5/Modules/threadmodule.c:52 #6 0x00007f4b2b6bad40 in call_function (oparg=&lt;optimized out&gt;, pp_stack=0x7f4aadffa060) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4408 #7 PyEval_EvalFrameEx ( f=f@entry=Frame 0x7f4af4026420, for file /usr/lib64/python2.7/threading.py, line 339, in wait (self=&lt;_Condition(_Verbose__verbose=False, _Condition__lock=&lt;thread.lock at remote 0x7f4b18756f30&gt;, acquire=&lt;built-in method acquire of thread.lock object at remote 0x7f4b18756f30&gt;, _Condition__waiters=[&lt;thread.lock at remote 0x7f4b1862a3f0&gt;, &lt;thread.lock at remote 0x7f4b10aab750&gt;, &lt;thread.lock at remote 0x7f4b1862adb0&gt;, &lt;thread.lock at remote 0x7f4b1862ab10&gt;, &lt;thread.lock at remote 0x7f4b1862ae50&gt;, &lt;thread.lock at remote 0x7f4b1862abd0&gt;, &lt;thread.lock at remote 0x7f4b1862a4d0&gt;, &lt;thread.lock at remote 0x7f4b1862a930&gt;, &lt;thread.lock at remote 0x7f4b1862a8b0&gt;, &lt;thread.lock at remote 0x7f4b1862ae70&gt;, &lt;thread.lock at remote 0x7f4b1862a530&gt;, &lt;thread.lock at remote 0x7f4b1862ab90&gt;, &lt;thread.lock at remote 0x7f4b1862a8d0&gt;, &lt;thread.lock at remote 0x7f4b1862a9d0&gt;, &lt;thread.lock at remote 0x7f4b1862a150&gt;, &lt;thread.lock at remote 0x7f4b1862a290&gt;, &lt;thread.lock at remote 0x7f4b1862aad0&gt;, &lt;thread.lock at remote 0x7f4b1862ad30&gt;, &lt;thread.lock at r...(truncated), throwflag=throwflag@entry=0) at /usr/src/debug/Python-2.7.5/Python/ceval.c:3040 #8 0x00007f4b2b6bd08d in PyEval_EvalCodeEx (co=&lt;optimized out&gt;, globals=&lt;optimized out&gt;, locals=locals@entry=0x0, args=&lt;optimized out&gt;, argcount=1, kws=0x7f4aa800cd30, kwcount=0, defs=0x7f4b1fe30188, defcount=2, closure=closure@entry=0x0) at /usr/src/debug/Python-2.7.5/Python/ceval.c:3640 #9 0x00007f4b2b6ba58c in fast_function (nk=&lt;optimized out&gt;, na=&lt;optimized out&gt;, n=&lt;optimized out&gt;, pp_stack=0x7f4aadffa270, func=&lt;optimized out&gt;) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4504 #10 call_function (oparg=&lt;optimized out&gt;, pp_stack=0x7f4aadffa270) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4429 #11 PyEval_EvalFrameEx ( f=f@entry=Frame 0x7f4aa800cb80, for file /usr/lib64/python2.7/Queue.py, line 168, in get (self=&lt;Queue(unfinished_tasks=47882, queue=&lt;collections.deque at remote 0x7f4b0fed62f0&gt;, maxsize=0, all_tasks_done=&lt;_Condition(_Verbose__verbose=False, _Condition__lock=&lt;thread.lock at remote 0x7f4b18756f30&gt;, acquire=&lt;built-in method acquire of thread.lock object at remote 0x7f4b18756f30&gt;, _Condition__waiters=[], release=&lt;built-in method release of thread.lock object at remote 0x7f4b18756f30&gt;) at remote 0x7f4b177ab710&gt;, mutex=&lt;thread.lock at remote 0x7f4b18756f30&gt;, not_full=&lt;_Condition(_Verbose__verbose=False, _Condition__lock=&lt;thread.lock at remote 0x7f4b18756f30&gt;, acquire=&lt;built-in method acquire of thread.lock object at remote 0x7f4b18756f30&gt;, _Condition__waiters=[], release=&lt;built-in method release of thread.lock object at remote 0x7f4b18756f30&gt;) at remote 0x7f4b177ab790&gt;, not_empty=&lt;_Condition(_Verbose__verbose=False, _Condition__lock=&lt;thread.lock at remote 0x7f4b18756f30&gt;, acquire=&lt;built-in method acquire of thread.lock objec...(truncated), throwflag=throwflag@entry=0) at /usr/src/debug/Python-2.7.5/Python/ceval.c:3040 #12 0x00007f4b2b6bd08d in PyEval_EvalCodeEx (co=&lt;optimized out&gt;, globals=&lt;optimized out&gt;, locals=locals@entry=0x0, args=&lt;optimized out&gt;, argcount=1, kws=0x7f4a9c000d58, kwcount=0, defs=0x7f4b1f725800, defcount=2, closure=closure@entry=0x0) at /usr/src/debug/Python-2.7.5/Python/ceval.c:3640 #13 0x00007f4b2b6ba58c in fast_function (nk=&lt;optimized out&gt;, na=&lt;optimized out&gt;, n=&lt;optimized out&gt;, pp_stack=0x7f4aadffa480, func=&lt;optimized out&gt;) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4504 #14 call_function (oparg=&lt;optimized out&gt;, pp_stack=0x7f4aadffa480) at /usr/src/debug/Python-2.7.5/Python/ceval.c:4429 . | 通过调用栈可以看到，频繁出现的线程等待的信号量/linux/sem_waitcommon.c | 如果发现某个线程有问题, 切换到那个线程上, 查看调用栈确定具体的执行步骤, 使用bt 命令: | py-bt显示出python源码的调用栈, 调用参数, 以及所在行的代码. #4 Waiting for a lock (e.g. GIL) #5 Waiting for a lock (e.g. GIL) #7 Frame 0x7f4af4026420, for file /usr/lib64/python2.7/threading.py, line 339, in wait (self=&lt;_Condition(_Verbose__verbose=False, _Condition__lock=&lt;thread.lock at remote 0x7f4b18756f30&gt;, acquire=&lt;built-in method acquire of thread.lock object at remote 0x7f4b18756f30&gt;, _Condition__waiters=[&lt;thread.lock at remote 0x7f4b1862a3f0&gt;, &lt;thread.lock at remote 0x7f4b10aab750&gt;, &lt;thread.lock at remote 0x7f4b1862adb0&gt;, &lt;thread.lock at remote 0x7f4b1862ab10&gt;, &lt;thread.lock at remote 0x7f4b1862ae50&gt;, &lt;thread.lock at remote 0x7f4b1862abd0&gt;, &lt;thread.lock at remote 0x7f4b1862a4d0&gt;, &lt;thread.lock at remote 0x7f4b1862a930&gt;, &lt;thread.lock at remote 0x7f4b1862a8b0&gt;, &lt;thread.lock at remote 0x7f4b1862ae70&gt;, &lt;thread.lock at remote 0x7f4b1862a530&gt;, &lt;thread.lock at remote 0x7f4b1862ab90&gt;, &lt;thread.lock at remote 0x7f4b1862a8d0&gt;, &lt;thread.lock at remote 0x7f4b1862a9d0&gt;, &lt;thread.lock at remote 0x7f4b1862a150&gt;, &lt;thread.lock at remote 0x7f4b1862a290&gt;, &lt;thread.lock at remote 0x7f4b1862aad0&gt;, &lt;thread.lock at remote 0x7f4b1862ad30&gt;, &lt;thread.lock at r...(truncated) . | . coredump 如果要进行比较长时间的跟踪, 最好将python程序的进程信息全部coredump出来, 之后对core文件进行分析, 避免影响正在运行的程序. (gdb) generate-core-file 这条命令将当前gdb attach的程序dump到它的运行目录, 名字为core., 然后再用gdb 加载这个core文件, 进行打印堆栈, 查看变量等分析, 无需attach到正在运行的程序: . gdb python core. 其他命令 其他命令可以在gdb输入py 看到, 和gdb的命令对应, 例如: (gdb) py py-bt py-list py-print python py-down py-locals py-up python-interactive py-up, py-down 可以用来移动到python调用站的上一个或下一个frame. py-locals 用来打印局部变量 等等等等. gdb里也可以用help命令查看帮助: . (gdb) help py-print Look up the given python variable name, and print it 在这次追踪过程中, 用gdb-python排除了程序逻辑问题. 然后继续追踪内存泄漏问题: . | 可以结合mmap，及x\\命令查看内存地址和程序计数器寄存器的情况 | . 参考文档 https://github.com/lmacken/pyrasite https://docs.python.org/2/library/gc.html https://www.cnblogs.com/geaozhang/p/7111961.html http://man7.org/linux/man-pages/man7/epoll.7.html https://linux.die.net/man/4/epoll https://blog.csdn.net/ljx0305/article/details/4065058 https://drmingdrmer.github.io/tech/programming/2017/05/06/python-mem.html#不可回收对象的例子- https://blog.csdn.net/evsqiezi/article/details/8061176 https://github.com/torvalds/linux/blob/master/net/ipv4/tcp.c https://juejin.im/post/5cfdd44a6fb9a07eb67d83e9 https://blog.csdn.net/haoel/article/details/1602108 https://mg.pov.lt/objgraph/ http://guppy-pe.sourceforge.net/ http://guppy-pe.sourceforge.net/heapy_tutorial.html https://www.cnblogs.com/chengliangsheng/p/3597010.html https://blog.csdn.net/gogoytgo/article/details/64130179 . https://github.com/google/tcmalloc https://github.com/jemalloc/jemalloc https://blog.csdn.net/junlon2006/article/details/77854898 . ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#%E4%B8%AD%E6%96%AD%E8%BF%90%E8%A1%8C%E7%9A%84%E7%A8%8B%E5%BA%8F%E8%BE%93%E5%87%BA%E6%97%A0%E6%B3%95%E5%9B%9E%E6%94%B6%E7%9A%84%E5%AF%B9%E8%B1%A1",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#中断运行的程序输出无法回收的对象"
  },"214": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "4. 内存占用分析",
    "content": ". | 针对monitor-server的情况 . | 进程启动后，创建到权重占比的已连接描述符后（例如2的权重占总连接的80个左右，3.3占130左右），物理内存占用值会稳定到一个确定值，不会一直上涨，所有初步判断并没有循环引用或者内存泄漏； | 在测试环境中，给动态监控的逻辑部分在请求处理完成返回前，做一次全generation的主动垃圾回收，程序启动后，物理内存的占用会有一定的下降，表现为在几个小时呢从700MB到1.5GB之间； | . | 初步结论，内存无泄漏且无对象的循环引用，主动的gc回收或者降低阈值并增加垃圾回收的频率，会一定程度的降低进程的物理内存的占用，大概可以下降测试前的20%~30%; . | 考虑C底层预编译的运行库的内存管理算法 | 生产环境的CentOS7.x 64默认提供的C运行库glibc的版本为2.17，其中malloc库的为ptmalloc2 | Google提供的替代品： | TCMalloc is Google’s customized implementation of C’s malloc() and C++’s operator new used for memory allocation within our C and C++ code. TCMalloc is a fast, multi-threaded malloc implementation. | https://github.com/google/tcmalloc | FaceBook提供的替代品： | jemalloc is a general purpose malloc(3) implementation that emphasizes fragmentation avoidance and scalable concurrency support. | https://github.com/jemalloc/jemalloc | https://www.facebook.com/jemalloc . | 生产环境网络进过yum search后，找到了jemalloc X86_64的版本，而且可以直接yum安装，无需再次下载和编译； | . ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#4-%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E5%88%86%E6%9E%90",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#4-内存占用分析"
  },"215": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "5. 最终方案测试",
    "content": ". | 在测试环境中，给动态监控的逻辑部分在请求处理完成返回前，做一次全generation的主动垃圾回收； . | 使用LD_PRELOAD，可以直接用jemalloc代替ptmalloc2，对python代码进行链接执行 | 测试方式 | LD_PRELOAD=”/usr/lib64/libjemalloc.so” /home/monitor_server/bin/python /opt/netmon/service/monitor-server/monitor/run_server.py –config-file /opt/netmon/service/monitor-server/monitor/conf/conf.ini –port 51035 » /var/log/monitor-server/server_debug.log 2&gt;&amp;1 &amp; root 76913 76489 20 15:36 pts/1 01:17:10 /home/monitor_server/bin/python /opt/netmon/debug/monitor-server/monitor/run_server.py --config-file /opt/netmon/debug/monitor-server/monitor/conf/conf.ini --port 51035 VmRSS: 522232 kB 76913 root 20 0 1991M 518M 6736 R 113. 0.2 1h17:15 │ └─ python /opt/netmon/debug/monitor-server/monitor/run_server.py --config-file /opt/netmon/debug/monitor-serve . | 最终表现 . | 稳定运行15小时的server进行内存占用率维持在0.2%，物理内存的占用为500MB（上下不超过50MB），且添加了主动GC回收后，对单个逻辑核心的5分钟平均占用在50%（估计值） | . ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#5-%E6%9C%80%E7%BB%88%E6%96%B9%E6%A1%88%E6%B5%8B%E8%AF%95",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#5-最终方案测试"
  },"216": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "6. 文档",
    "content": "第三方模拟真实应用的算法测试-ptmalloc2-tcmalloc-hoard-jemalloc I/O多路复用技术的简单介绍 . ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#6-%E6%96%87%E6%A1%A3",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/#6-文档"
  },"217": {
    "doc": "Python进程内存分析&大量内存占用的优化方案",
    "title": "Python进程内存分析&大量内存占用的优化方案",
    "content": "GDB-gcc-debug . jemalloc . ptmalloc2 . TCMalloc . 2020-03-29 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/",
    
    "relUrl": "/docs/archives/2020/2020-03-30-CPython-malloc-python-gc/"
  },"218": {
    "doc": "Redis学习及源码分析",
    "title": "Redis学习及源码分析",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#redis%E5%AD%A6%E4%B9%A0%E5%8F%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#redis学习及源码分析"
  },"219": {
    "doc": "Redis学习及源码分析",
    "title": "编译安装",
    "content": "CentOS Linux release 7.4.1708 (Core) . | redis官网下载最新稳定版 | 安装链接所需静态库 . | libhiredis | libjemalloc | liblua / lua-static | . | 使用make 调用gcc驱动程序进行编译、链接并生成可执行二进制文件 . | make_file 在src目录下； | 在没有安装支持版本的情况下，编译后无法连接，需要删除重定向文件进行重新编译和汇编； | . | . ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#编译安装"
  },"220": {
    "doc": "Redis学习及源码分析",
    "title": "启动运行",
    "content": ". | 进入 utils 目录，运行 ./install_server.sh 交互式脚本文件 | 根据提示进行配置 | 使用systemctl调用init.d下的启动脚本 | . ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#%E5%90%AF%E5%8A%A8%E8%BF%90%E8%A1%8C",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#启动运行"
  },"221": {
    "doc": "Redis学习及源码分析",
    "title": "redis的C源代码分析",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#redis%E7%9A%84c%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#redis的c源代码分析"
  },"222": {
    "doc": "Redis学习及源码分析",
    "title": "redis存储模型原理",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#redis%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#redis存储模型原理"
  },"223": {
    "doc": "Redis学习及源码分析",
    "title": "redis cli",
    "content": ". ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#redis-cli",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#redis-cli"
  },"224": {
    "doc": "Redis学习及源码分析",
    "title": "redis支持的数据结构于实现方式",
    "content": ". | 有序集合 . | 有序集合的实现方式 . | 结合散列表和跳表实现 . | 跳表：层级索引的单向链表，查询时间复杂度降低到n/2^k | 散列表：散列函数+散列冲突法+装载因子 | . | . | . | . ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#redis%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BA%8E%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#redis支持的数据结构于实现方式"
  },"225": {
    "doc": "Redis学习及源码分析",
    "title": "redis集群部署，分布式写入算法",
    "content": ". | 一致性哈希 . | 哈希槽 . | . ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#redis%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%88%86%E5%B8%83%E5%BC%8F%E5%86%99%E5%85%A5%E7%AE%97%E6%B3%95",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#redis集群部署分布式写入算法"
  },"226": {
    "doc": "Redis学习及源码分析",
    "title": "redis数据写入方式",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#redis%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E6%96%B9%E5%BC%8F",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#redis数据写入方式"
  },"227": {
    "doc": "Redis学习及源码分析",
    "title": "redis基础命令",
    "content": ". | ACL 相关命令 Access Control List | . Redis ACL . redis cli . Usage: redis-cli [OPTIONS] [cmd [arg [arg ...]]] -h &lt;hostname&gt; Server hostname (default: 127.0.0.1). -p &lt;port&gt; Server port (default: 6379). -s &lt;socket&gt; Server socket (overrides hostname and port). -a &lt;password&gt; Password to use when connecting to the server. You can also use the REDISCLI_AUTH environment variable to pass this password more safely (if both are used, this argument takes predecence). -u &lt;uri&gt; Server URI. -r &lt;repeat&gt; Execute specified command N times. -i &lt;interval&gt; When -r is used, waits &lt;interval&gt; seconds per command. It is possible to specify sub-second times like -i 0.1. -n &lt;db&gt; Database number. -x Read last argument from STDIN. -d &lt;delimiter&gt; Multi-bulk delimiter in for raw formatting (default: \\n). -c Enable cluster mode (follow -ASK and -MOVED redirections). --raw Use raw formatting for replies (default when STDOUT is not a tty). --no-raw Force formatted output even when STDOUT is not a tty. --csv Output in CSV format. --stat Print rolling stats about server: mem, clients, ... --latency Enter a special mode continuously sampling latency. If you use this mode in an interactive session it runs forever displaying real-time stats. Otherwise if --raw or --csv is specified, or if you redirect the output to a non TTY, it samples the latency for 1 second (you can use -i to change the interval), then produces a single output and exits. --latency-history Like --latency but tracking latency changes over time. Default time interval is 15 sec. Change it using -i. --latency-dist Shows latency as a spectrum, requires xterm 256 colors. Default time interval is 1 sec. Change it using -i. --lru-test &lt;keys&gt; Simulate a cache workload with an 80-20 distribution. --replica Simulate a replica showing commands received from the master. --rdb &lt;filename&gt; Transfer an RDB dump from remote server to local file. --pipe Transfer raw Redis protocol from stdin to server. --pipe-timeout &lt;n&gt; In --pipe mode, abort with error if after sending all data. no reply is received within &lt;n&gt; seconds. Default timeout: 30. Use 0 to wait forever. --bigkeys Sample Redis keys looking for keys with many elements (complexity). --memkeys Sample Redis keys looking for keys consuming a lot of memory. --memkeys-samples &lt;n&gt; Sample Redis keys looking for keys consuming a lot of memory. And define number of key elements to sample --hotkeys Sample Redis keys looking for hot keys. only works when maxmemory-policy is *lfu. --scan List all keys using the SCAN command. --pattern &lt;pat&gt; Useful with --scan to specify a SCAN pattern. --intrinsic-latency &lt;sec&gt; Run a test to measure intrinsic system latency. The test will run for the specified amount of seconds. --eval &lt;file&gt; Send an EVAL command using the Lua script at &lt;file&gt;. --ldb Used with --eval enable the Redis Lua debugger. --ldb-sync-mode Like --ldb but uses the synchronous Lua debugger, in this mode the server is blocked and script changes are not rolled back from the server memory. --cluster &lt;command&gt; [args...] [opts...] Cluster Manager command and arguments (see below). --verbose Verbose mode. --no-auth-warning Don't show warning message when using password on command line interface. --help Output this help and exit. --version Output version and exit. Cluster Manager Commands: Use --cluster help to list all available cluster manager commands. Examples: cat /etc/passwd | redis-cli -x set mypasswd redis-cli get mypasswd redis-cli -r 100 lpush mylist x redis-cli -r 100 -i 1 info | grep used_memory_human: redis-cli --eval myscript.lua key1 key2 , arg1 arg2 arg3 redis-cli --scan --pattern '*:12345*' (Note: when using --eval the comma separates KEYS[] from ARGV[] items) When no command is given, redis-cli starts in interactive mode. Type \"help\" in interactive mode for information on available commands and settings. ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#redis%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#redis基础命令"
  },"228": {
    "doc": "Redis学习及源码分析",
    "title": "支持的高级语言库",
    "content": ". | Go . | go-redis | . | . ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#%E6%94%AF%E6%8C%81%E7%9A%84%E9%AB%98%E7%BA%A7%E8%AF%AD%E8%A8%80%E5%BA%93",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#支持的高级语言库"
  },"229": {
    "doc": "Redis学习及源码分析",
    "title": "更多feature",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#%E6%9B%B4%E5%A4%9Afeature",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#更多feature"
  },"230": {
    "doc": "Redis学习及源码分析",
    "title": "Source-Code",
    "content": "redis . ",
    "url": "/docs/archives/2020/2020-03-31-Redis/#source-code",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/#source-code"
  },"231": {
    "doc": "Redis学习及源码分析",
    "title": "Redis学习及源码分析",
    "content": "TODO . Redis . 2020-04-06 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-31-Redis/",
    
    "relUrl": "/docs/archives/2020/2020-03-31-Redis/"
  },"232": {
    "doc": "Algorithm-heap 堆排序的实现",
    "title": "algorithm-heap 堆排序的实现",
    "content": " ",
    "url": "/docs/archives/2020/2020-03-31-algorithm-heap/#algorithm-heap-%E5%A0%86%E6%8E%92%E5%BA%8F%E7%9A%84%E5%AE%9E%E7%8E%B0",
    
    "relUrl": "/docs/archives/2020/2020-03-31-algorithm-heap/#algorithm-heap-堆排序的实现"
  },"233": {
    "doc": "Algorithm-heap 堆排序的实现",
    "title": "合并2个有序序列，合并n个有序序列",
    "content": "相关算法回顾 . 合并2个有序链表为一个有序链表 . | 比对l1和l2的大小，将最小的放在新链表的next上，更新l1或者l2，直到其中一个链表为空 while l1 and l2；最终返回新链表的next。T = M + N | . 合并n个有序链表为一个有序链表 . | 基于两个链表合并的算法，我们将k中每两个链表合并一次得出的新的集合再进行同样的操作，最终得到一个集合，T = kN 将 k 个链表配对并将同一对中的链表合并。第一轮合并以后， k 个链表被合并成了 k/2 个链表，平均长度为 2N/k 重复这一过程，直到我们得到了最终的有序链表。每次k的数目指数型下降，例如k k/2 k/4 k/8 S = Nlogk | . ",
    "url": "/docs/archives/2020/2020-03-31-algorithm-heap/#%E5%90%88%E5%B9%B62%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%BA%8F%E5%88%97%E5%90%88%E5%B9%B6n%E4%B8%AA%E6%9C%89%E5%BA%8F%E5%BA%8F%E5%88%97",
    
    "relUrl": "/docs/archives/2020/2020-03-31-algorithm-heap/#合并2个有序序列合并n个有序序列"
  },"234": {
    "doc": "Algorithm-heap 堆排序的实现",
    "title": "简单暴力",
    "content": "n个长度都为m的有序数组，合并为一个有序数组 . | 拼接所有数组，组成长度为m x n的新数组，对数组做时间复杂度为mnlogmn的排序算法 . | 快速排序 （基准数选择很大程度决定最终的时间复杂度，三数取中法，平均时间复杂度的计算方式需要带入“主定理”求解，详细可以回顾 “我的算法训练学习曲线” | 归并 （先分后治） | 堆排序，涉及堆的生成（大顶堆，小顶堆） | . | . 归并的思想 divide-and-conquer . | 先分后治，分而治之，将一个目标问题分解为多个子问题，对各个子问题求解，最终合并子问题的结果就是分治的思想； | 归并排序 . | 分：先将长度位n的序列，经过logn次“分”，分为n个单独的元素 | 治：每两个相邻元素进行排序，一次结果的时间复杂度位O(n)，递归进行新的子问题或者说子序列的合并，i j双指针比较，每次将较小的更新到结果中，所有新的子问题的合并时间复杂度还是O(n) | 最终经过logn次平均时间复杂度为O(n)的运算，返回结果； | 归并的时间复杂度为O(nlogn)，而且不会出现和快速排序相似的基准数选取影响排序效率的问题； | . | 在已经完成排序的k个长度为n的子序列的合并中，就是半个归并排序，只需要对已经完成排序的子问题做递归的治理就可以； . | k个n长度的子问题，每次两两合并的总的时间复杂度为O(nk) | k个最终两两合并为1个，那么子问题到结果的治理过程经历了logk次 | 那么此问题的最优解就是O(nklogk) | . | . 堆排序的思想 . | 堆排序是利用堆这种数据结构而设计的一种排序算法，属于一种选择排序，最坏，最好，平均时间复杂度均为O(nlogn)，属于不稳定排序； . | 堆 . | 一个完全二叉树 . | 大顶堆：每个结点的值都大于或者等于左右孩子结点的值 . | 小顶堆：每个结点的值都小于或者等于左右孩子节点的值 . | 0 | 1 | 2 | 3 | 4 | 5 | 6 | . | 50 | 40 | 30 | 30 | 35 | 20 | 25 | . | 大顶堆 arr[i] &gt;= arr[2i+1] &amp;&amp; arr[i] &gt;= arr[2i+2] | 小顶堆 arr[i] &lt;= arr[2i+1] &amp;&amp; arr[i] &lt;= arr[2i+2] | . | 堆排序的基本思想 . | 将待排序序列构造成一个大顶堆，整个序列的最大值就在堆顶的根节点 | 将根节点元素和序列末尾元素交换，末尾就是待排序序列的最大值 | 将剩余的n-1个元素构造成新的堆 | 重复以上步骤，知道无元素在进行堆的构造 | . | 构造堆的过程 . | 从最后一个非叶子结点开始，与其左右孩子进行调整，先左右，再上下，此处三个节点中权值最大的结点被升到第一个非叶子结点的位置； | 按顺序找到第二个非叶子结点，重复第一步 | 按顺序找完所有的非叶子结点，则第一次构造完成； | . | 构造完成后，将根节点和最后一个叶子结点交换，再对剩下的元素进行构造； | 时间复杂度分析： . | 初始化建堆的过程需要消耗的时间 . | O(n)l . | 对于这个堆来说，每一个非叶子结点都需要，和它自己的左右孩子比较，如果发现小于孩子，将发生交换，如何没有就直接不再继续执行这个结点的调整； | 发生一次交换后，还会继续往剩下的子树进行交换； | 假设树的高度为k | 那么第i层的时间复杂度为：2^( i -1 ) * (k -i)，表示层有2^i-1个结点，每个结点向下比较最差的情况下需要执行k-1次； | 那么总时间就是 **2^( k -2 ) * 1 + 2^( k -3 ) * 2 + 2^( k - 4 ) * 3 + … + 2 - (k -1) ** 叶子节点不进行交换； | 根据等差数列，最终结果为 2^k - k - 1， 又因为k为完全二叉树的深度，所以 (2^k) &lt;= n &lt; (2^k -1 ) ，所以 log(n+1) &lt; k &lt;= logn | 最终的时间复杂度为 n-logn -1，所以建立堆的时间复杂度为O(n) | . | . | 每次交换首位元素后，对堆的重新整理的时间复杂度为 logn，共整理了n-1次，所以整理和交换的时间复杂度为 . | O(nlogn) | . | 所以最终该算法的最差和平均时间复杂度都为O(nlogn) | . | . #include &lt;stdio.h&gt; // make heap // 原地算法 void _heapAdjust(int *array, int i, int len) { // 从最后一个非子叶子结点向前 // 2*i+1 2*i+2 为元素i的左右孩子 int tmp = array[i]; for (int k=2*i+1 ; k &lt; len; k=2*k+1) // 从第一个元素i的左孩子开始，每次更新 { if (array[k] &lt; array[k+1] &amp;&amp; k+1&lt;len) { // 右边子节点更大,则将k更新的右边 k ++; } if (tmp &lt; array[k]) { array[i] = array[k]; // 将最大值更新到i i = k; // 将下次更新的坐标更新为k }else{ break; } } array[i] = tmp; //将最终值放在最新的i处 } int main() { int len = 9; int array[] = {5, 6, 3, 7, 8, 9, 1, 2, 4}; for (int i = len/2 - 1; i &gt;= 0; i--) { _heapAdjust(array, i, len); } for (int i = 0; i &lt; 9; ++i) { printf(\"%d, \", *(array+i)); } printf(\"\\n\"); for (int j = len -1; j &gt; 0; j--) { // printf(\"%d\\n\", j); int t = array[0]; array[0] = array[j]; array[j] = t; // for (int i = 0; i &lt; 9; ++i) // { // printf(\"%d, \", *(array+i)); // } // printf(\"\\n\"); _heapAdjust(array, 0, j); } for (int i = 0; i &lt; 9; ++i) { printf(\"%d, \", *(array+i)); } return 0; } . ",
    "url": "/docs/archives/2020/2020-03-31-algorithm-heap/#%E7%AE%80%E5%8D%95%E6%9A%B4%E5%8A%9B",
    
    "relUrl": "/docs/archives/2020/2020-03-31-algorithm-heap/#简单暴力"
  },"235": {
    "doc": "Algorithm-heap 堆排序的实现",
    "title": "Algorithm-heap 堆排序的实现",
    "content": "Algorithm . Heap . 2020-03-29 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-03-31-algorithm-heap/",
    
    "relUrl": "/docs/archives/2020/2020-03-31-algorithm-heap/"
  },"236": {
    "doc": "海量数据程序设计思路",
    "title": "海量数据程序设计思路",
    "content": "massive-data-programming . bitmap . | 位图 . | 存储方式属于hash . | bitmap是将原本需要占用1个字节或者多个字节的整数，转化成对一个字节单位中的一个确定位置的比特的占用 . | 如有： | . | . int array[] = {1, 2, 3, 4, 5} //使用int型数组存储的数据在内存中，以32位整型为例，需要占用20个字节的空间 //使用bitmap #include &lt;stdio.h&gt; #define LEN 1 #define MASK 0xff //表示8个比特位1 #define SHIFT 3 char bitmap[LEN]; void set(char i) { bitmap[i &gt;&gt; SHIFT] |= 1 &lt;&lt; (i + 1); } int main(int argc, char const *argv[]) { int array[] = {1, 2, 3, 4, 5}; //使用int型数组存储的数据在内存中，以32位整型为例，需要占用20个字节的空间 for (int i = 0; i &lt; 5; ++i) { set(array[i]); } int x = bitmap[0]; while (x &gt; 0) { printf(\"%d\", x % 2); x = x / 2; if (x == 0) { printf(\"0 -- revert\"); } } printf(\"\\n\"); printf(\"%d\\n\", bitmap[0]); printf(\"%x\\n\", bitmap[0]); printf(\"%d\\n\", sizeof(bitmap[0])); return 0; } . | | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | . | 0 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | . | bitmap[0] . | 存储方法：使用字节中的位来存储一个整数 . | 用 整数/size 表示整数在bitmap中的索引位置 | 用 整数 模 size 表示整数在这个索引位置处应该将那个位置上的bit置为1 | 这样想要获取存储在bitmap中的整数值，只需要计算出该bit在整个bitmap中的位置 | . | 取模的方式是最简单的hash函数 . | 应用 . | Bit-Map做数据的查找、去重、排序等 | 如对于4,000,000,000个ip地址的存储，需要内存空间为16,000,000,000个字节，如果使用bitmap只需要500,000,000个字节，也就是500MB，大小从16GB缩小到了500MB，缩小了32倍； | 例如，2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数 . | 将bit-map扩展一下，用2bit表示一个数即可：0表示未出现；1表示出现一次；2表示出现2次及以上，即重复，在遍历这些数的时候，如果对应位置的值是0，则将其置为1；如果是1，将其置为2；如果是2，则保持不变。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map，都是一样的道理。 | . | . | . 分治法 . | 对于海量数据处理的问题，现实情况基本不可能遇到，而且此类问题也经常会限制C程序所能使用的内存空间大小，而文件中经常包含上10亿行的字符数据； | 此类问题涉及到 . | 对数据在有限的内存中存储的极端条件，例如bitmap | 对数据的操作要尽可能涉及少量的文件I/O操作 . | 传统的机械硬盘使用磁盘存储数据，每4kb作为一个页，因为磁头的机械移动，每次读写数据的平均花费8 ~ 11 ms | 当今的固态硬盘根据不同的封装方式，平均的一次I/O花费的时间在0.1ms左右 | . | . | 分治 . | 类似于归并的分治思想 – divide-and-conquer | 先将大数据量的文件分割成小的数据块或文件 | 在分别对小文件进行处理，处理小文件的时候每次也只进行一次读写 | 最终处理结果所花费的总读写文件次数位：分割的小文件的倍数 | . | 例题 . | 要求：当前有一个100亿行的日志文件，每行中有一个v4的IP地址，且总共有10亿个ip地址，且每个IP随机出现多次，现在要求只使用100MB的内存空间，设计一个C程序，用最高效的方式输出每个ip地址及地址在日志中出现的次数； . | 100MB = 100 X 1000 X 1000 Byte 表示 1亿个字节， IP地址为4个字节，总共40亿个地址空间才能完全容纳 | 分析： . | 不重复ip地址数量位1, 000, 000, 000个ip地址，顺序存储的话也需要4, 000, 000, 000个字节，4GB空间； | 地址在日志文件中随机分布； | 当前给定能够存储该结构的空间位100MB = 100, 000, 000字节； | 顺序存储的条件下需要将4GB空间分成40份； | 假设一个ip地址在整个文件中出现的最多次数为32位无符号整型的最大值；也就是一个32位的无符号整型就可以存储一个ip地址出现的次数；并且假设日志每行都有一个ip地址；那么总共要处理的地址数量位100亿个； | . | Solution： . | 假设总共每行出现1个ip地址，那么总ip地址数量10,000,000,000，不重复的是1,000,000,000个； | 将10,000,000,000分成400份，那么每一份都可以完全能读入主存； | 遍历日志文件，匹配ip地址，将地址按照二进制大小分为400份，对ipv4的所有地址转化为2进制，然后对100,000,000取模的方式将其分到400份的数组中，在100MB内存空间内初始化400个长度位25MB的数组，将ip地址更新到每个数组内，当数组满后，将数组写入文件一次并清空，再次满后，在追加到文件，那么平均的情况下要进行40 X400 次I/O操作，总耗时160000ms，也就是160s； | 这样对于400个文件来说，每个文件中都会包含所有的重复的无序的ip地址，这时候将文件逐个读入内存并，对数组排序(选择快速排序或者归并将时间复杂度降低到logn，假设每个文件为)，排序完成后，在输出每个ip地址出现的此处到一个文件，或者使用类似bitmap的方式，将每4个字节看成一个bit，并将该位置出现的ip地址的数量更新到4个字节的int中；本次共400X2次文件读写，总耗时为80,000ms为8s； | 所有结合分而治之即bitmap的思想，最大化的利用有限的内存，可以将整个问题的处理时间下降到数分钟的级别； | . | . | . 数据结构 B+TREE . 海量数据处理方法，也可以参考MySQL底层的B+树的索引方式，将根节点存放在内存中，顺序查找孩子指针，指针指向磁盘或者硬盘中存储的对象，一次搜索将I/O操作降低到1次，又根据磁盘的局部性预读特性，可以用一次I/O查询一定范围内的数据； . 海量数据处理面试题集锦 . ",
    "url": "/docs/archives/2020/2020-04-01-iter-massive-data-programming/#%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF",
    
    "relUrl": "/docs/archives/2020/2020-04-01-iter-massive-data-programming/#海量数据程序设计思路"
  },"237": {
    "doc": "海量数据程序设计思路",
    "title": "海量数据程序设计思路",
    "content": "Iterview . 2020-03-29 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-01-iter-massive-data-programming/",
    
    "relUrl": "/docs/archives/2020/2020-04-01-iter-massive-data-programming/"
  },"238": {
    "doc": "红黑树&B树应用及索引原理",
    "title": "红黑树&amp;B树应用及索引原理",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-02-b-tree-and-indexing-principle/#%E7%BA%A2%E9%BB%91%E6%A0%91b%E6%A0%91%E5%BA%94%E7%94%A8%E5%8F%8A%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-04-02-b-tree-and-indexing-principle/#红黑树b树应用及索引原理"
  },"239": {
    "doc": "红黑树&B树应用及索引原理",
    "title": "算法导论（第三版）学习笔记 红黑树 + B树部分",
    "content": "第13章 红 黑 树 . | 二叉搜索树的基本动态集合操作，该二叉搜索树的高度为h . | SEARCH | PREDECESSOR | SUCCESSOR | MINIMUN | MAXIMUM | INSERT | DELETE | . | 以上操作的时间复杂度为O(h)，对于高度较低的二叉搜索树，操作执行较快，但是当树高度较高时，这些集合操作可能并不比链表上执行的要快 | 红黑树 red-black tree . | 可以保证最坏情况下的基本动态集合操作的时间复杂度为O(lgn) | . | . 13.1 红黑树的性质 . | 红黑树是一颗二叉搜索树 . | 每个结点上增加一个存储位来表示结点的颜色 RED BLACK . | 通过对任何一条从根结点到叶子结点的简单路径上各个结点的颜色进行约束，红黑树确定没有一条路径会比其他路径长出2倍，因而近似平衡 . | 红黑树的每个结点的属性 . | color | key | left | right | p | . | 如果一点结点没有孩子或者父结点，则相应指针属性的值为NIL . | NIL视为指向二叉搜索树叶子结点的指针 | 把带关键字的结点视为树的内部结点 | . | 红黑树性质 . | 每个结点或是红色，或者黑色 | 根节点是黑色的 | 每个叶子结点（NIL）是黑色 | 如果一个结点是红色，则它的两个孩子都是黑色 | 对每个结点，从该结点到其所有后代叶结点的简单路径上，均包含相同数目的黑色结点 | . | 一颗红黑树是满足以上5个性质的二叉搜索树 | . | 从某个结点出发到达一个叶节点的任意一条简单路径上的黑色结点的数量称为该节点的黑高 black-height . | 根据性质5，从该节点出发的所有下降到其叶子的简单路径的黑色结点个数都相同； . | 红黑树的黑高为其根节点的黑高 . | . 基础概念回顾，详细学习包括算法导论红黑树的基本动态集合操作学习，和C++红黑树map实现学习； . MARK - PAGE188 . 第18章 B 树 . | B树是为磁盘或者其他直接存取的辅助设备而设计的一种平衡搜索树； | 类似于红黑树，但是能更好的降低磁盘I/O操作数； | 关系型数据库使用B树或者B树的变种来存储信息（MySQL，PGSQL） . | B树的结点可以有很多，从数个到数千个，一个B树的“分支因子”可以相当大，依赖于使用的磁盘单元特性 | 类似于红黑树，每棵树含有n个结点，B树的高度为O(lgn) | . 一颗B树的严格高度可能比一颗红黑树高度要小的多，因为它的分支因子，也就是表示高度的对数的底数可以非常大；因此，我们可以使用B树在时间O(logn)之内完成动态集合的操作 . | B树是一种平衡多叉查找树 | B树的子节点最多的节点数为m，则B树为m阶树 | B树的搜索方式 . | 从根节点开始沿着起始位置查询 | 找到第一个搜索范围后，进入指针指向的孩子结点 | 沿着孩子结点依次比较，确定下一个范围后，即进入新的指针 | 重复以上步骤，找到结果后，返回，如果找到叶子结点，则返回NIL，因为页结点的指针指向了指针为NIL的哨兵结点 | . | B树的特点 . | m阶的B树每个节点，至多可以拥有m棵子树； | 关键字集合分布再整棵树中 | 任何一个关键字出现且只出现再一个节点中 | 搜索在非叶子节点结束后，直接返回 | 搜索性能等价于在有序关键字集合内做一次二分查找 | B树的插入删除新的数据记录的操作，会破坏BTree的性质 . | 插入删除，需要对B树进行一次分裂 合并 转移 等操作以保持B树性质 | . | B树的基本动态集合操作，见算法导论第18章； | . | . 基础概念回顾，详细学习包括算法导论B树的基本动态集合操作学习；以及MySQL B+ B-树底层的实现源码 . MARK - PAGE278 . ",
    "url": "/docs/archives/2020/2020-04-02-b-tree-and-indexing-principle/#%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E7%AC%AC%E4%B8%89%E7%89%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%A2%E9%BB%91%E6%A0%91--b%E6%A0%91%E9%83%A8%E5%88%86",
    
    "relUrl": "/docs/archives/2020/2020-04-02-b-tree-and-indexing-principle/#算法导论第三版学习笔记-红黑树--b树部分"
  },"240": {
    "doc": "红黑树&B树应用及索引原理",
    "title": "B+Tree实现及索引原理",
    "content": "B+ 树 . | 相较于B树，B+树 . | n棵树的节点含有n个关键字，所有的关键字全都存储在页节点上，且叶子节点本身根据关键字大小顺序连接（链表） | B+树的非叶子节点为索引部分，且节点中只包含其子树的根中的最大或最小关键字； | . | 查询方式 . | 查询方式和B树基本一致 | 不同点 . | 查询时如果非叶子节点上的值与查询关键词一致，并不终止，而继续沿指针向下，知道叶子节点的位置； | . | B+树的查询，无论成功与否，每次查询都会走一条从根节点到叶子节点的路径； | . | B+树的特性 . | 所有关键字都在叶子节点上，叶子节点组成的链表有序 | 不可能非叶子节点命中后返回 | 非叶子节点相当于叶子节点的索引，叶子节点相当于存储数据的数据层 | B+树更适合与文件搜索系统，或者说与磁盘I/O交互的索引系统 | . | . B+Tree + 顺序访问指针 . | 关系型数据库系统中，对经典的B+Tree进行了优化，增加了顺序访问指针 | 在相邻的叶子节点之间增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree | 顺序访问指针很大程度上提高了区间搜索的性能 . | 需要查询A到F之间的内容，当通过根节到到叶子的路径搜索到A后，使用顺序访问指针，很快就能找到F，并返回该区间的数据内容； | 通过一个H高度的查询，一次可以访问到区间呢所有的数据 | . | . B+树的应用 - MySQL . | 实现索引的方式包括 . | 红黑树 | B树 | B+树/B-树 | . | 索引本身的存储 . | 索引本身可能会很大，不可能完全存储在内存中，索引通常以索引文件的形式存储在磁盘上； | 索引的根节点在主存中，其他子树在磁盘存储，索引的数据结构需要尽可能的减少磁盘I/O操作的存取次数； | . | . 计算机存储原理 . 详细回顾CSAPP . | 主存 . | 计算机将主存虚拟化为了一个一维线性的固定长度数组 | 物理层面主存为DRAM，动态随机读写存储器； | 工作原理： . | 读取 . | 系统需要读取主存时，将物理地址放在地址总线上传给主存，主存（控制器）读取信号后，解析信号，并定位到指定存储单元； | 主存将存储单元的数据放到数据总线上，其他共部件读取； | . | 写入 . | 系统将要写入的物理地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，并作出相应的操作； | . | . | 主存的存取时间和存取次数成线性关系； | . | 磁盘存取原理 . | 磁盘由数个磁盘和磁头组成；每个磁头负责读取磁盘上的内容； | 盘片上由多个同心磁道，所有盘片上半径相同的磁道组成了一个柱面；磁道沿着半径被划分为扇区，每个扇区为磁盘的最小存储单元； | 读取数据 . | 系统将逻辑地址转给磁盘控制器，磁盘控制电路按照寻址逻辑将逻辑地址翻译为物理地址； | 磁头经过机械运动（寻道，耗费的时间为寻道时间，8ms~10ms），将磁头放在物理地址指定的扇区上，磁盘需要旋转到目标扇区（旋转时间） | . | 局部性原理 . | 磁盘为了提高效率，会对数据进行预读，如只需要一个字节的数据，磁盘会将从该位置开始的一定长度的数据都放入内存； | 计算机科学-局部性原理：当一个数据被用到时，其附近的数据也通常会被使用； | . | 页 page . | 计算机管理存储器的逻辑块 | 操作系统将磁盘存储的扇区分割为大小相等的块； | 每一块就是一页（通常为4kb）； | 主存和磁盘以页为单位进行数据交换； | 当程序需要读取的数据不在主存，出发缺页异常，操作系统向磁盘控制器发送读盘信号，磁盘会找到数据的起始地址开始，连续读入内存几页，然后异常返回，程序继续运行； | . | . | . B-/+ Tree索引性能分析 . | B树就是B-树 . | 对于B-树，检索一次需要从根节点开始到叶子节点，假设树的高度为h，则每次检索需要访问h个节点；利用操作系统的磁盘预读原理，将一个节点的大小设置为一个页 4kb; 每个节点只需要一次I/O操作就可以完全载入； . | 新建节点，申请一个页的空间，保证节点在物理存储上也被存储在一个“页”中，计算机存储分配都会按页对其； | . | 由于根节点常驻在内存中，B- Tree中的一次检索最多需要h-1次I/O操作； . | 渐进复杂度为O(h)=O(logdN)O(h)=O(logdN) . h表示树的高度，d表示树的度，一颗树的度为树种每个节点度的最大值； . 实际应用中一棵树的度一般都非常大，大于100；树的高小于3； . 由于B-Tree的结构特点，所以他的搜索效率非常高，对磁盘的I/O操作不超过3次 . | . | . | 红黑树 Red-Black-Tree . | 由于红黑树为特殊的二叉搜索树的，深度h较深； | 由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。 | . | B+Tree . | B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小： . dmax=floor(pagesize/(keysize+datasize+pointsize)); // floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。 . | 出度越大，一次I/O操作能够读取到主存的数据量越大，检索效率越高，而出度d的最大值，却决于当前一个页（存储一个节点），能够存储多少个指针结构（key+point)； . | . | MySQL索引的实现 . | MySQL包含两个主流的存储引擎，不同的引擎中索引的实现方式不同； . | MyISAM，InnoDB . | MyISAM索引的实现 . | MyISAM Engine使用B+Tree作为索引结构，树的叶子节点的Data域存放的是数据记录的地址； | 包含两种索引类型： . | 主索引 Primary Key . | 作为数据记录的主键，要求key必须唯一 | 可以不存在主键 | . | 辅助索引 Secondary key . | 作为数据库中手动创建的查询索引，key可以重复 | . | 在结构上两者都使用B+树，且根节点常驻内存； | . | 检索方式 . | 同样使用B+树的检索方式，对索引进行检索 | 到达叶节点后，如果指定key或者数据范围存在，则从叶子节点的值域部分取出数据的地址； | 读取相应地址的数据到主存并返回； | . | “非聚集”，因为数据和索引是分开的，用指针关联； | . | InnoDB Engine . | 同样使用B+Tree的索引结构 . | 与MyISAM的不同 . | 表数据本身 - 按照B+Tree的结构组织为索引，叶子节点的值域部分保存了该数据记录的完整数据，且索引的Key为数据记录的主键，InnoDB表数据本身就是主键索引 . | 这样的索引方式为聚集索引 . | 因为表数据按照主键生成索引结构（按照主键聚集），所以InnoDB Engine要求必须有主键，且唯一 . 如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整型。 . | . | InnoDB 辅助索引的叶子节点的值域部分存储相应数据记录的主键的值，而不是地址； . | 这就表示InnoDB的辅助索引，引用了主键作为叶子节点的data； . key在索引中以ASCII的形式存储 . | 所以，对于InnoDB Engine来说，对于手动创建的辅助索引来说，检索数据的过程，要找到对两个B+Tree进行检索，就是先检索辅助索引，到达对应的叶子节点的值域后获取记录主键，再根据主键在主索引中进行检索； . | 这样的效率比直接使用主键检索要低一半； | . | . | . | . 了解数据库Engine的原理，对使用有很大帮助，例如： . | 为什么不建议使用过长的字段作为主键 . | 因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。 | . | 用非单调的字段作为主键在InnoDB中不是个好主意 (单调: 微积分概念，表示一个函数的单调递增或者单调递减) . | 因为InnoDB数据文件本身是一棵B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 | . | . 学习地址 . | . | . | . ",
    "url": "/docs/archives/2020/2020-04-02-b-tree-and-indexing-principle/#btree%E5%AE%9E%E7%8E%B0%E5%8F%8A%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-04-02-b-tree-and-indexing-principle/#btree实现及索引原理"
  },"241": {
    "doc": "红黑树&B树应用及索引原理",
    "title": "红黑树&B树应用及索引原理",
    "content": "B+Tree . B-Tree . Red-Black-Tree . MySQL, Algorithm . 2020-04-02 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-02-b-tree-and-indexing-principle/",
    
    "relUrl": "/docs/archives/2020/2020-04-02-b-tree-and-indexing-principle/"
  },"242": {
    "doc": "Kubernetes & Docker",
    "title": "Kubernetes &amp; Docker",
    "content": "https://kubernetes.io/ . | Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications; | kubernetes components architecture | . | 控制面 . | 控制平面，用来对整个集群作出决策，并监测和响应集群产生的事件； | 控制平面的组件可以运行再一台或者多台机器上，默认的部署脚本，提供所有控制平面的组件部署并运行在同一台机器上，并且不会将用户创建的容器或者pod服务创建在已经部署了控制组件的机器上； | . | 各个组件的简单介绍及功能 . | kube-apiserver . | kube API服务器是整个控制平面前端，将kubernetes的API接口提供给外部进行访问； | 该服务提供横向的伸缩和扩容，通过在更多机器实例上部署kube-apiserver，来提供接口对外访问的负载均衡，当然这里的负载均衡需要其他组件参与，例如双结点的LVS+Nginx做负载均衡转发，并将外部访问的报文段转发到不同权重的API服务节点上； | . | etcd . | etcd.io | 分布式且高可用的 key-value 存储系统，用来对分布式系统的关键及重要数据做持久化； | 在kubernetes架构中，用于对kubernetes产生的集群数据做持久化； | etcd提供高可用，kubernetes后端的集群数据的持久化存储对应生产环境来说，还需要更多的数据备份方式； | . | kube-scheduler . | kubernetes管理的微服务的最小单位是一个Pod | 类似于Openstack的Nova的scheduler对新建虚拟机的调度，kube-scheduler对新创建的Pod进行调度，用来选择一个适合的节点来运行该Pod； | 这里的适合的节点取决于多个因素 . | 单一的组合的资源需求 | 硬件/软件/策略的约束 | 亲和力/反亲和力 的规格 ？ | 数据的局部性 | 内部任务之间的影响和干扰 | 截止日期 | . | . | Kube-controller-manager . | 控制平面的控制器，单独的进程运行控制器/管理者 . | 该控制器进程的源程序中包含多个“功能独立”的控制器，kubernetes为了进一步简化复杂性，将这些功能独立的控制器编译到同一个可运行指令的二进制文件； . | 该进程中包括的”功能独立“的控制器： . | Node Controller：负责对节点的异常（节点服务崩溃）进行事件回调和响应； . | Replication Controller：负载管理和维护Pod的个数，这些Pod用来承载系统中复制控制器的对象（也就是复制的服务）？； . | Endpoint Controller：负责将Endpoint对象，加入到一个指定的服务或者Pod中； . | Service Account &amp; Token Controllers：管理和创建用于API访问的用户，和用户Token，这些Token用不同的命名空间进行区分； . 命名空间的概念，一个命名空间用来声明一个区域或者范围，该范围内包含该命名空间独一无二的身份验证或者程序变量、方法等； . | . | . | cloud-controller-manager . | 云控制器，用来和底层云环境进行交互； . | 运行 cloud-provider-specific 控制器循环，在启动前，必须disable不适用的controller loops； . –cloud-provider = external . 当前版本的kubernetes核心代码对”云服务提供商“的代码在功能上有所依赖； . 未来版本中，”云服务提供商“将自己管理云厂商的代码段，在运行kubernetes期间和 cloud-controller-manager 进行链接； . | 对于云提供商的代码有所依赖的控制器包括： . | Node Controller . | 通过云供应商来检查已经停止的节点，是否在环境中已经被释放； | . | Route Controller . | 为底层基础设施配置路由 | . | Service Controller . | 用来创建、更新、删除、云供应商提供的负载均衡产品 | . | Volume Controller . | 用来创建、附加、挂在”卷“，和云提供商交互进行”卷“的编排； | . | . | . | . | Node Components . | 节点组件，运行在kubernetes集群的每一个节点上，用来维护运行的Pods并为Kubernetes提供运行时环境 | Kubelet . | 运行在集群中的每个节点上的agent，用于确保容器运行在Pod中； | | . | . | . ",
    "url": "/docs/archives/2020/2020-04-03-kubernetes-curve/#kubernetes--docker",
    
    "relUrl": "/docs/archives/2020/2020-04-03-kubernetes-curve/#kubernetes--docker"
  },"243": {
    "doc": "Kubernetes & Docker",
    "title": "Kubernetes & Docker",
    "content": "TODO . Kubernetes . Docker . 2020-04-10 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-03-kubernetes-curve/",
    
    "relUrl": "/docs/archives/2020/2020-04-03-kubernetes-curve/"
  },"244": {
    "doc": "Golang性能分析和监控",
    "title": "Golang性能分析和监控",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-05-golang-performance-flame-graph/#golang%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%92%8C%E7%9B%91%E6%8E%A7",
    
    "relUrl": "/docs/archives/2020/2020-04-05-golang-performance-flame-graph/#golang性能分析和监控"
  },"245": {
    "doc": "Golang性能分析和监控",
    "title": "tool pprof 和 package pprof",
    "content": "* [pprof](https://golang.org/pkg/runtime/pprof/) * 通过HTTP服务提供运行时的性能分析数据（统计数据） * 通过使用go tool pprof可以对数据进行特殊的格式化，以满足分析需求 * 包导入的方式 * `import \"net/http/pprof\"` * http定位器访问方式 * `/debug/pprof` . ",
    "url": "/docs/archives/2020/2020-04-05-golang-performance-flame-graph/#tool-pprof-%E5%92%8C-package-pprof",
    
    "relUrl": "/docs/archives/2020/2020-04-05-golang-performance-flame-graph/#tool-pprof-和-package-pprof"
  },"246": {
    "doc": "Golang性能分析和监控",
    "title": "实践过程",
    "content": "func main() { //c := make(chan os.Signal) //signal.Notify(c) binaryAbsPath, _ := filepath.Abs(filepath.Dir(os.Args[0])) // @ golang performance test fmt.Printf(\"[monitor-patrol] Performance CPU, %s/cpu_monitor.prof...\\n\", filepath.Dir(binaryAbsPath)) fmt.Printf(\"[monitor-patrol] Performance MEM, %s/mem_monitor.prof...\\n\", filepath.Dir(binaryAbsPath)) fmt.Printf(\"[monitor-patrol] Performance monitor, contect to 127.0.0.1:8080 to check...\\n\") cpuProFile := filepath.Dir(binaryAbsPath) + \"/cpu_monitor.prof\" memProFile := filepath.Dir(binaryAbsPath) + \"/mem_monitor.prof\" // @ Windows debug //cpuProFile := \"./cpu_monitor.prof\" //memProFile := \"./mem_monitor.prof\" f, err := os.Create(cpuProFile) if err != nil { fmt.Printf(\"could not create CPU profile: %s\", err) } if err := pprof.StartCPUProfile(f); err != nil { //监控cpu fmt.Printf(\"could not start CPU profile: %s\", err) } runtime.GOMAXPROCS(runtime.NumCPU()) go func() { http.ListenAndServe(\"0.0.0.0:8080\", nil) }() pg := &amp;program{} if err := svc.Run(pg, syscall.SIGINT, syscall.SIGTERM, syscall.SIGKILL, syscall.SIGQUIT); err != nil { fmt.Printf(\"run exit with err:%s\", err) fmt.Printf(\"Main END\\n\") // pprof.StopCPUProfile() // f, err := os.Create(memProFile) if err != nil { fmt.Printf(\"could not create memory profile: %s\", err) } runtime.GC() // GC，获取最新的数据信息 if err := pprof.WriteHeapProfile(f); err != nil { // 写入内存信息 fmt.Printf(\"could not write memory profile: %s\", err) } f.Close() fmt.Printf(\"Main END\\n\") // os.Exit(2) } else { log.Logger.Info(\"bye :-)\") } } . 方式一 . | 使用方式是通过import直接导入 _ \"net/http/pprof\" | 然后通过http的package直接启动监听服务 http.ListenAndServe() | 通过浏览器可以直接访问 http://ip:port/debug/pprof 来查看当前的性能采样情况 | . 方式二 . | 通过 io package的writer，创建并调用i/o写入性能采样数据 pprof.StartCPUProfile(f) pprof.WriteHeapProfile(f) | 程序结束退出后，可以直接访问生成的cpu和heap文件 | . debug/pprof 内容 . /debug/pprof/ Types of profiles available: Count Profile 4 allocs 0 block 0 cmdline 1054 goroutine 4 heap 0 mutex 0 profile 13 threadcreate 0 trace full goroutine stack dump Profile Descriptions: allocs: A sampling of all past memory allocations block: Stack traces that led to blocking on synchronization primitives cmdline: The command line invocation of the current program goroutine: Stack traces of all current goroutines heap: A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. mutex: Stack traces of holders of contended mutexes profile: CPU profile. You can specify the duration in the seconds GET parameter. After you get the profile file, use the go tool pprof command to investigate the profile. threadcreate: Stack traces that led to the creation of new OS threads trace: A trace of execution of the current program. You can specify the duration in the seconds GET parameter. After you get the trace file, use the go tool trace command to investigate the trace. | allocs . | 对程序声明周期内所有分配的内存的抽样 | . | block . | 因为堆栈跟踪导致对“同步原语”的阻塞 | . | cmdline . | 当前程序的命令行调用 | . | goroutine . | 当前所有的go协程的堆栈追踪 | . | heap . | 当前堆内存中处于“存活”状态的对象的抽样，可以在运行抽样，特别的指定想要垃圾回收的对象 | . | mutex . | 对“互斥锁”的持有对象的堆栈跟踪 | . | profile . | CPU 的性能描述数据 | 如果使用了StartCPUProfile写入文件的方式，在http服务中无法下载该文件，对该文件的查看方式 | 使用 go tool pprof 命令进入交互式环境，使用top命令查看调用时长等； . | 典型的命令 . | top Outputs top entries in text form | web Visualize graph through web browser | call_tree Create a context-sensitive call tree | list Output annotated source for functions matching regexp | . | 使用help命令查看详情 | 使用web命令生成可视化的svg调用树，也可以使用web Func来过滤执行函数相关的调用树； CentOS下必须安装 xdg-utils 和 graphviz . | top+[数量值]，可以查看占用CPU采样时间的函数的行数，例如默认top为top10，就只看占用CPU采样时间最长的10个函数调用； | 组合使用： . | 使用top命令找到占据CPU采样时间最多的函数调用 | 再通过 web 函数名 生成该函数的调用树的图谱，查看调用关系，找到调用该函数的父级函数 | 使用 list 父级函数 查看该函数的具体代码实现，通过对函数内部使用的数据结构和处理判断对CPU发生大量占用的点； | 思路：通过结合top和web命令找到导致占用大量抽样的关键函数，分析函数内部实现，和其涉及到的数据结构和算法；对该函数的优化可以结合go test benchmark的基准测试来测试优化后的性能； [root@CNSZ049589 /]# go tool pprof optcpu_monitor.prof File: libc-2.17.so Build ID: 8b2c421716985b927aa0caf2a05d0b1f452367f7 Type: cpu Time: Nov 11, 2019 at 6:07pm (CST) Duration: 3.89s, Total samples = 22.57s (580.86%) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) top Showing nodes accounting for 12980ms, 57.51% of 22570ms total Dropped 254 nodes (cum &lt;= 112.85ms) Showing top 10 nodes out of 132 flat flat% sum% cum cum% 4470ms 19.81% 19.81% 4500ms 19.94% runtime.chanrecv 2260ms 10.01% 29.82% 6730ms 29.82% runtime.selectnbrecv 1290ms 5.72% 35.53% 1330ms 5.89% encoding/json.stateInString 1060ms 4.70% 40.23% 2190ms 9.70% encoding/json.(*decodeState).scanWhile 930ms 4.12% 44.35% 2020ms 8.95% encoding/json.checkValid 620ms 2.75% 47.10% 7100ms 31.46% encoding/json.(*decodeState).object 600ms 2.66% 49.76% 3810ms 16.88% code.test.com.cn/test-monitor/monitor/monitor-patrol/handler/analyzer.UploadEventToDB 600ms 2.66% 52.41% 1630ms 7.22% runtime.scanobject 580ms 2.57% 54.98% 580ms 2.57% runtime.memmove 570ms 2.53% 57.51% 4090ms 18.12% code.test.com.cn/test-monitor/monitor/monitor-patrol/handler/analyzer.UploadMonitorCoverageData . | . | . | . | threadcreate . | 对于从操作系统创建的新的线程的堆栈堆栈跟踪 | . | 当前程序执行的跟踪。 您可以在秒GET参数中指定持续时间。 获取跟踪文件后，使用go工具trace命令调查跟踪。 . | 内存分析 [root@CNSZ049589 /]# go tool pprof optmem_monitor.prof File: libc-2.17.so Build ID: 8b2c421716985b927aa0caf2a05d0b1f452367f7 Type: inuse_space Time: Nov 11, 2019 at 6:07pm (CST) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) top Showing nodes accounting for 573.38MB, 98.95% of 579.46MB total Dropped 32 nodes (cum &lt;= 2.90MB) Showing top 10 nodes out of 27 flat flat% sum% cum cum% 173.51MB 29.94% 29.94% 184.01MB 31.76% encoding/json.(*decodeState).literalStore 158.42MB 27.34% 57.28% 158.42MB 27.34% reflect.unsafe_NewArray 105.63MB 18.23% 75.51% 105.63MB 18.23% code.test.com.cn/test-monitor/monitor/monitor-patrol/handler/analyzer.(*DataContainer).AppendMetricList 64MB 11.05% 86.56% 201.35MB 34.75% code.test.com.cn/test-monitor/monitor/monitor-patrol/handler/analyzer.(*Analyzer).DataDistribution 23.72MB 4.09% 90.65% 29.72MB 5.13% sync.(*Map).Store 20.76MB 3.58% 94.23% 20.76MB 3.58% code.test.com.cn/test-monitor/monitor/monitor-patrol/vendor/github.com/streadway/amqp.(*Channel).recvContent 10.50MB 1.81% 96.04% 10.50MB 1.81% encoding/json.(*decodeState).convertNumber 8.34MB 1.44% 97.48% 8.34MB 1.44% code.test.com.cn/test-monitor/monitor/monitor-patrol/vendor/github.com/streadway/amqp.(*reader).parseBodyFrame 5.50MB 0.95% 98.43% 5.50MB 0.95% sync.newEntry (inline) 3MB 0.52% 98.95% 3MB 0.52% runtime.malg . | memprofile 就是堆采样数据，使用参数结合 go tool pprof 来查看内存情况 . | –inuse_objects 来显示使用的堆的对象的个数 | –alloc_objects 分配的堆对象个数 | –alloc_space 分配的堆内存大小 | . | 使用web 生成可视化文件，查看内存分配； | . Prometheus . | Prometheus client内置了golang metrics暴露的handler，只需要简单调用即可实现 | 使用metrics即可定位metrics指标的采集数据 | 使用模块“github.com/zsais/go-gin-prometheus” ```golang package main | . import ( “github.com/prometheus/client_golang/prometheus/promhttp” “net/http” ) . func main() { http.Handle(“/metrics”, promhttp.Handler()) panic(http.ListenAndServe(“:9090”, nil)) } ``` . | 访问http://localhost:9090/metrics 即可。 | 同时可以通过Prometheus来采集此Endpoint暴露出来的数据，也可以进行自定义数据的采集 . | prometheus修改yaml配置文件，增加新的job和job指标静态描述 | 进行配置重载 curl -X POST http://ip:port/-/reload | . | 参考文档 . | https://blog.pvincent.io/2017/12/prometheus-blog-series-part-4-instrumenting-code-in-go-and-java/ | . | . ",
    "url": "/docs/archives/2020/2020-04-05-golang-performance-flame-graph/#%E5%AE%9E%E8%B7%B5%E8%BF%87%E7%A8%8B",
    
    "relUrl": "/docs/archives/2020/2020-04-05-golang-performance-flame-graph/#实践过程"
  },"247": {
    "doc": "Golang性能分析和监控",
    "title": "Golang性能分析和监控",
    "content": "Go . Go-pprof . Flamegraph . 2020-04-05 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-05-golang-performance-flame-graph/",
    
    "relUrl": "/docs/archives/2020/2020-04-05-golang-performance-flame-graph/"
  },"248": {
    "doc": "Python性能分析和火焰图",
    "title": "Python性能分析和火焰图",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#python%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%92%8C%E7%81%AB%E7%84%B0%E5%9B%BE",
    
    "relUrl": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#python性能分析和火焰图"
  },"249": {
    "doc": "Python性能分析和火焰图",
    "title": "cProfile和profile为python程序提供的性能分析工具",
    "content": ". | profile提供一组统计信息，用来描述对于一个函数或者一个代码块的被调用次数或者执行次数和执行所花费的时间； | 对于这些统计信息，可以使用python的pstats模块，使用不同类型的参数进行输出，或者使用第三方的模块输入火焰图，例如frameprof； | python2.7-cProfile | . ",
    "url": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#cprofile%E5%92%8Cprofile%E4%B8%BApython%E7%A8%8B%E5%BA%8F%E6%8F%90%E4%BE%9B%E7%9A%84%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7",
    
    "relUrl": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#cprofile和profile为python程序提供的性能分析工具"
  },"250": {
    "doc": "Python性能分析和火焰图",
    "title": "使用方式",
    "content": ". | 运行命令中添加cProfile模块，来生产统计信息 python -m cProfile [-o output_file] [-s sort_order] myscript.py . | -o表示程序生命周期结束后的输出文件 | -s表示指定一个参数来进行排序，例如使用函数被调用次数排序ncalls，或者使用累积时间cumtime | -s参数在有-o输出文件的情况下，不会生效，因为输出文件包含原始的统计数据，需要再次读取和排序 | 当程序终止后才能生成文件，对于循环执行的进程或者服务，需要手动发送前台进程强制终止信号； | . | 在程序中导入cProfile使用 import cProfile import re cProfile.run('re.compile(\"foo|bar\")') . | . ",
    "url": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F",
    
    "relUrl": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#使用方式"
  },"251": {
    "doc": "Python性能分析和火焰图",
    "title": "实践",
    "content": ". | 使用cProfile启动python服务 cd /opt/netmon/debug/monitor-server/monitor/ /home/monitor_server/bin/python -m cProfile -o result.out /opt/netmon/debug/monitor-server/monitor/run_server.py --config-file /opt/netmon/debug/monitor-server/monitor/conf/conf.ini --port 51035 &gt;&gt; /var/log/monitor-server/server_debug.log 2&gt;&amp;1 . | 服务启动后，标准输出和标准错误都会追加到/var/log/monitor-server/server_debug.log | 等待后端服务的进程执行一定的时间，例如10~30分钟，已经处理了相当一部分请求，将进程强制终止，得到result.out文件； | 对result.out文件进行输出，可以直接使用python和pstats模块，或者使用脚本输出； | . #!/usr/bin/python import pstats import sys input_f = sys.argv[1] p = pstats.Stats(input_f) #p.sort_stats(\"cumulative\", \"name\") p.sort_stats(\"ncalls\", \"cumtime\") p.print_stats() . | 支持的排序方式有： . | ncalls | 函数或者代码块被调用的次数 | tottime | 在函数中执行所使用的总时长，但是该时间会排除调用子功能所花费的时间 | percall | tottime 除以 ncalls的商的值 | cumtime | 函数包含其子函数的总累积调用时间，对于递归函数同样适用，为递归函数的全部递归次数的执行总时长 | percall | cumtime 除以 ncalls 的商的值 | Filename | 每个函数所在文件及开始行号 | . | 输出结果： [root@cnsz036678 monitor]# python output_pstats.py cum.out | head -n 100 Tue Apr 7 17:10:32 2020 cum.out 13445271 function calls (13371131 primitive calls) in 436.704 seconds Ordered by: call count, cumulative time ncalls tottime percall cumtime percall filename:lineno(function) 3726996 0.695 0.000 0.716 0.000 {method 'get' of 'dict' objects} 1710220/1710218 0.565 0.000 0.580 0.000 {isinstance} 1525540/1524061 0.191 0.000 0.192 0.000 {len} 959341 1.045 0.000 1.045 0.000 {_codecs.utf_8_decode} 959298 0.454 0.000 1.499 0.000 /home/monitor_server/lib64/python2.7/encodings/utf_8.py:15(decode) 706968 0.595 0.000 0.926 0.000 /home/monitor_server/lib/python2.7/site-packages/oslo_config/cfg.py:2940(_get) 706966 0.476 0.000 1.402 0.000 /home/monitor_server/lib/python2.7/site-packages/oslo_config/cfg.py:2509(__getattr__) 706958 1.753 0.000 2.011 0.000 /opt/netmon/debug/monitor-server/monitor/core/handlers/device_info_handler.py:36(_format_speed) 191741 0.034 0.000 0.034 0.000 {method 'append' of 'list' objects} 176914 0.020 0.000 0.020 0.000 {ord} 136071 0.042 0.000 0.042 0.000 {method 'seek' of 'cStringIO.StringO' objects} 71548 0.034 0.000 0.034 0.000 {method 'endswith' of 'str' objects} 66992 0.024 0.000 0.024 0.000 {method 'readline' of 'cStringIO.StringO' objects} 59707/7204 0.367 0.000 2.729 0.000 /home/monitor_server/lib/python2.7/site-packages/redis/connection.py:283(read_response) 59707 0.192 0.000 1.554 0.000 /home/monitor_server/lib/python2.7/site-packages/redis/connection.py:210(readline) 59707 0.011 0.000 0.011 0.000 /home/monitor_server/lib/python2.7/site-packages/redis/_compat.py:126(byte_to_chr) 53938 0.022 0.000 0.022 0.000 /home/monitor_server/lib/python2.7/site-packages/redis/connection.py:162(length) 52878 0.072 0.000 0.393 0.000 {method 'decode' of 'str' objects} 52564 0.034 0.000 0.034 0.000 {method 'read' of 'cStringIO.StringO' objects} 52490 0.069 0.000 0.466 0.000 /home/monitor_server/lib/python2.7/site-packages/redis/connection.py:122(decode) 52482 0.175 0.000 0.313 0.000 /home/monitor_server/lib/python2.7/site-packages/redis/connection.py:193(read) 51196 0.068 0.000 0.081 0.000 /home/monitor_server/lib64/python2.7/sre_parse.py:183(__next) 46852 0.030 0.000 0.103 0.000 /home/monitor_server/lib64/python2.7/sre_parse.py:202(get) 44246 0.019 0.000 0.019 0.000 /home/monitor_server/lib/python2.7/site-packages/yaml/reader.py:87(peek) 33628 0.020 0.000 0.020 0.000 {getattr} 26234 15.935 0.001 16.355 0.001 {eval} 25679 0.013 0.000 0.018 0.000 /home/monitor_server/lib64/python2.7/sre_parse.py:139(append) 25451/25148 0.030 0.000 0.154 0.000 {method 'join' of 'str' objects} 25357 0.017 0.000 0.017 0.000 {range} . | 该进程接入测试数据进行简单的分析后，初步结论 . | 现在通过一些测试，能看出来一部分问题出现的可能，第一是json解析的操作耗时，第二是 IOString 结构体底层的过多的处理，第三是getattr方式来定位对象函数 | 需要更多实际生产环境导致程序大量接口超时的数据模拟； | . | . ",
    "url": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#%E5%AE%9E%E8%B7%B5",
    
    "relUrl": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#实践"
  },"252": {
    "doc": "Python性能分析和火焰图",
    "title": "火焰图",
    "content": ". | 使用flameprof来生成火焰图 | 安装 . | pip install flameprof | . | 简单使用： . | flameprof result_2.cum.out &gt; cum.svg flameprof --help usage: flameprof.py [-h] [--width WIDTH] [--row-height ROW_HEIGHT] [--font-size FONT_SIZE] [--threshold THRESHOLD] [--format {svg,log}] [--log-mult LOG_MULT] [--version] [-r] [-m] [--cpu] [-o OUT] [--wsgi-out-dir WSGI_OUT_DIR] [--wsgi-format WSGI_FORMAT] stats . | 使用help产看具体用法 . | pypi-flameprof | flamegraphs | . | . | 如何快速看懂火焰图 . | 看懂火焰图 | . | 通常性能分析工具会返回 CPU 正在执行的指令对应的函数名以及调用栈（stack） | 通常，它的执行频率是 99Hz（每秒99次），如果99次都返回同一个函数名，那就说明 CPU 这一秒钟都在执行同一个函数，可能存在性能问题。（CPU每秒执行指令的次数取决于CPU内频和外频以及晶振频率） | y 轴表示调用栈，每一层都是一个函数。调用栈越深，火焰就越高，顶部就是正在执行的函数，下方都是它的父函数。 | x 轴表示抽样数，如果一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长。注意，x 轴不代表时间，而是所有的调用栈合并后，按字母顺序排列的。 | 火焰图就是看顶层的哪个函数占据的宽度最大。只要有”平顶”（plateaus），就表示该函数可能存在性能问题。 | 颜色没有特殊含义，因为火焰图表示的是 CPU 的繁忙程度，所以一般选择暖色调。 | . ",
    "url": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#%E7%81%AB%E7%84%B0%E5%9B%BE",
    
    "relUrl": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/#火焰图"
  },"253": {
    "doc": "Python性能分析和火焰图",
    "title": "Python性能分析和火焰图",
    "content": "Python . Flamegraph . 2020-04-05 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/",
    
    "relUrl": "/docs/archives/2020/2020-04-05-python-performance-flame-graph/"
  },"254": {
    "doc": "Prometheus",
    "title": "Prometheus",
    "content": "prometheus.io . | Prometheus生态系统架构图 ecosystem components architecture | 基本流程： . | Prometheus Server从“采集器” Jobs / Exporters 中收集指标数据 | Server同时会从推送网关“收集” 生命周期较短的任务采集指标 | Server将数据指标存储在本地的，并进行一些规则匹配来对这些data，按照时间序列对数据和记录进行汇总，或者生成告警； | Prometheus可以对接Grafana进行时序数据的界面化展示-Dashboard； | . | . ",
    "url": "/docs/archives/2020/2020-04-06-Prometheus/#prometheus",
    
    "relUrl": "/docs/archives/2020/2020-04-06-Prometheus/#prometheus"
  },"255": {
    "doc": "Prometheus",
    "title": "组件技术栈、源代码分析",
    "content": ". | exporters . | . | . ",
    "url": "/docs/archives/2020/2020-04-06-Prometheus/#%E7%BB%84%E4%BB%B6%E6%8A%80%E6%9C%AF%E6%A0%88%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90",
    
    "relUrl": "/docs/archives/2020/2020-04-06-Prometheus/#组件技术栈源代码分析"
  },"256": {
    "doc": "Prometheus",
    "title": "Prometheus + M3DB + Nginx + LVS 网络监控架构",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-06-Prometheus/#prometheus--m3db--nginx--lvs-%E7%BD%91%E7%BB%9C%E7%9B%91%E6%8E%A7%E6%9E%B6%E6%9E%84",
    
    "relUrl": "/docs/archives/2020/2020-04-06-Prometheus/#prometheus--m3db--nginx--lvs-网络监控架构"
  },"257": {
    "doc": "Prometheus",
    "title": "Prometheus",
    "content": "Prometheus . OpenSource . Go . 2020-04-06 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-06-Prometheus/",
    
    "relUrl": "/docs/archives/2020/2020-04-06-Prometheus/"
  },"258": {
    "doc": "linux signal",
    "title": "linux signal",
    "content": "man-signal . ",
    "url": "/docs/archives/2020/2020-04-09-man-signal/#linux-signal",
    
    "relUrl": "/docs/archives/2020/2020-04-09-man-signal/#linux-signal"
  },"259": {
    "doc": "linux signal",
    "title": "linux signal",
    "content": "TODO . Linux . Man-Signal . 2020-04-09 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-09-man-signal/",
    
    "relUrl": "/docs/archives/2020/2020-04-09-man-signal/"
  },"260": {
    "doc": "C/C++ Syntactic sugar 语法糖",
    "title": "C/C++ Syntactic sugar 语法糖",
    "content": "//Syntactic sugar #include &lt;iostream&gt; using namespace std; int main() { // 语法糖 int a = 0; int b = (a++); cout &lt;&lt; \"a: \" &lt;&lt; a &lt;&lt; \", b: \" &lt;&lt; b &lt;&lt; endl; a = 0; int c = (++a); cout &lt;&lt; \"a: \" &lt;&lt; a &lt;&lt; \", c: \" &lt;&lt; c &lt;&lt; endl; /* a++ 和 ++a 都是对a的单调递增， 但是(a++)和(++a)这两个表达式本身返回值不一样 ++和++i之后都会让i自增 i++这个整体依然是i ++i这个整体是i+1 */ } . ",
    "url": "/docs/archives/2020/2020-04-10-c-cpp-syntactic-sugar/#cc-syntactic-sugar-%E8%AF%AD%E6%B3%95%E7%B3%96",
    
    "relUrl": "/docs/archives/2020/2020-04-10-c-cpp-syntactic-sugar/#cc-syntactic-sugar-语法糖"
  },"261": {
    "doc": "C/C++ Syntactic sugar 语法糖",
    "title": "C/C++ Syntactic sugar 语法糖",
    "content": "C&amp;C++ . Syntactic-Sugar . 2020-04-10 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-10-c-cpp-syntactic-sugar/",
    
    "relUrl": "/docs/archives/2020/2020-04-10-c-cpp-syntactic-sugar/"
  },"262": {
    "doc": "核心知识库",
    "title": "核心知识库",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-12-core-knowledge/#%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E5%BA%93",
    
    "relUrl": "/docs/archives/2020/2020-04-12-core-knowledge/#核心知识库"
  },"263": {
    "doc": "核心知识库",
    "title": "2020核心知识体系，基础知识+上层应用+实践能力，2020年2、3、4月学习复习总结",
    "content": "2020 核心知识体系 . 2020 全年学习计划和路径 . ",
    "url": "/docs/archives/2020/2020-04-12-core-knowledge/#2020%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E4%B8%8A%E5%B1%82%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5%E8%83%BD%E5%8A%9B2020%E5%B9%B4234%E6%9C%88%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93",
    
    "relUrl": "/docs/archives/2020/2020-04-12-core-knowledge/#2020核心知识体系基础知识上层应用实践能力2020年234月学习复习总结"
  },"264": {
    "doc": "核心知识库",
    "title": "目录",
    "content": "I. 计算机基础知识 . | 高级编程语言 . | C/C++ | Golang | Python | Shell编程 | . | 计算机网络 . | 应用层 OSI中7层 | 运输层 OSI中4层 | 网络层 OSI中3层 | 链路层 OSI中2层 | 物理层 OSI中1层 | TCP/IP网络模型/五层网络 | 网络建设：三层网络，二层网络，核心，接入，汇聚 | . | 数据结构和算法 . | 基本数据结构的实现 | 基础排序算法&amp;稳定性 | 算法思想&amp;解题思想 | 数据结构的应用 | . | 操作系统 . | Linux | 内核 | 系统调用 | 进程&amp;线程 | 调度 | . | 体系结构 . | 程序结构 | 信息表示 | 编译器驱动程序 | ECF 异常控制流 | 虚拟内存 | 多线程编程，并发、并行 | 网络编程 | IO并发 | . | . II. 上层应用 . | 数据库 . | 关系型数据库 | 缓存数据库、对象存储 | 时序数据库 | . | 分布式 . | 分布式系统的横向伸缩 | 分布式基础 | 分布式锁，事务单一处理 | 分布式横向扩展 | 负载均衡、转发代理 | 高可用 | 数据库读写分离 | . | 消息队列 . | rabbitmq | Kafka | Redis的消息订阅 | . | 容器 . | Docker基础 | Kubernetes | . | 主流云环境监控系统 . | open falcon | prometheus | . | 云网络 . | 云数据中心网络与SDN | . | 云计算 . | Cloud Native | 虚拟化 | Serverlesss | . | . III. 实践能力 . | IaaS 基础设施研发实践 Python Golang . | Linux运维实践 . | . IV. 题目总结 . | 算法 | 常见题目 | . VI. 开源项目代码研究 . | CPython | Redis | malloc/jemalloc/tcmalloc | . VII. 云计算的未来和趋势 . | 虚拟化 | 容器再 | serverless | . ",
    "url": "/docs/archives/2020/2020-04-12-core-knowledge/#%E7%9B%AE%E5%BD%95",
    
    "relUrl": "/docs/archives/2020/2020-04-12-core-knowledge/#目录"
  },"265": {
    "doc": "核心知识库",
    "title": "核心内容",
    "content": "I. 计算机基础知识 . 1. 高级编程语言 . C/C++ . | C和C++中的指针和引用 . | 编译阶段的符号表 * &amp; 取地址符 间接访问符 | C++中的引用和指针的区别 . | 指针和引用变成了什么？ . | 编译阶段生成符号表，用于链接阶段的重定向 | . | 引用是C++中的新增特性，其作用是为目标变量起一个别名，通过访问别名可以实现对变量和访问其变量名完全一致的效果； | 指针 * type 指针类型 * var 间接访问指针指向变量的值 &amp; var 取地址符，对一个变量取地址； | . | . | C++中 map 库的红黑树实现 | C标准库malloc函数的实现 . | google tcmalloc | facebook jemalloc | . | C中static静态存储类修饰符的作用 . | static修饰的全局遍历所分配的内存段 | static修复的局部过程变量所分配的内存段 | . | 内存管理 . | 从低地址到高地址 . | 只读内存段 .init .text .rodata格式串和开关语句跳转表 | 读/写内存段 .data .bss (已初始化全局变量、静态变量，未初始化全局变量和静态变量) | 堆 内存段 由malloc函数调用创建分配 | 共享库的内存映射区域 | 用户栈 运行时创建 | . | . | . Golang . | Golang 中的协程 . | 协程的上下文切换及管理调度 | 协程堆栈内存段的使用 | . | Golang垃圾回收机制 | . Python . | Python协程&amp;协程C底层实现 . | python协程 yeild | 第三方模块 greenlet，gevent的协程实现及原理 | . | Python 基本数据结构的底层实现 . | CPython CPython源代码分析&amp;虚拟机原理 . | CPython执行过程的高度概括： . | 读取和检查py文件，并进行解释器和线程状态的初始化； . | 解释器 . | 解释器状态是一个简单的结构体，结构体中的字段 | *next 引用进程中的另一个解释器状态结构体； | *tstate_head 引用正在执行的线程状态，多线程下引用全局解释器锁； | 其余字段有解释器状态所有合作线程共享； | . | 线程 . | 线程结构体包括 next 和 previous 指针，指向该线程之前和之后创建的线程状态； . | interp字段指向线程状态所属于的解释器状态 . | frame字段为当前执行的栈帧 . | 本质： . | 线程状态只是一个数据结构，封装了正在执行的线程的某些状态； . | 每个线程都与正在执行的python进程内的操作系统线程关联； . | 关系 . | | Python进程 | 单进程 | . | 解释器状态 | 单进程包含一个或者多个解释器状态 | . | 线程状态 | 每个解释器状态包含一个或多个线程状态 | . | 操作系统管理的线程（控制流） | 每个线程状态的数据结构映射到操作系统的执行线程上 | . | 线程状态和OS线程如何映射：OS线程和线程状态在python的threading模块被实例化时创建 . | 所有线程中，同一时间内持有全局解释器锁的线程才能执行虚拟机中的代码对象； . | 线程由操作系统的线程控制块进行调度和资源分派，但是即使系统调度当前没有持有GIL的线程运行，该线程也必须等待获取GIL； . | 全局解释器锁GIL： . | 为了不在虚拟机内实现细颗粒度的各种锁，更明确精细的互斥锁会一定程序降低线程执行效率，简化了虚拟机的实现而存在； . | 由于引用计数，GIL提供了堆中对象的线程安全，并且CPython链接的部分共享库并非线程安全； . | CPython中GIL的实际工作过程： . GIL 只是一个布尔变量（gil_locked），其访问受到互斥锁（gil_mutex）的保护，并且其更改由条件变量（gil_cond）发出信号。 gil_mutex 的使用时间很短，因此几乎没有竞争。在 GIL 保持线程中，主循环（PyEval_EvalFrameEx）必须能够根据另一个线程的需要释放 GIL。为此使用了一个临时的布尔变量（gil_drop_request），该变量在每次 eval 循环时都会检查。在 gil_cond 上等待间隔微秒后，将设置该变量。 【 实际上，使用了另一个临时的布尔变量（eval_breaker），该变量将多个条件进行或运算。由于 Python 仅在高速缓存相关的体系结构上运行，因此，可变布尔值就足以作为线程间信号传递的手段。】这鼓励了定义的周期性切换，但由于操作码可能需要花费任意时间来执行，因此不强制执行。用户可以使用Python API sys.{get,set}switchinterval() 读取和修改时间间隔值。当一个线程释放 GIL 并设置了 gil_drop_request 时，该线程将确保安排另一个等待 GIL 的线程。它通过等待条件变量（switch_cond）直到 gil_last_holder 的值更改为其自己的线程状态指针以外的值来进行操作，这表明另一个线程能够使用 GIL。这是为了禁止多核计算机上的延迟潜伏行为，在多核计算机上，一个线程会推测性地释放 GIL，但仍然运行并最终成为第一个重新获取 GIL 的对象，这使得“时间片”比预期的长得多。 . | . | . | . | . | . | . | 将一系列python文件中的代码块进行”编译“，生成虚拟机字节码文件（pyc） . | 其中CPython有一套自己的指令集，这些指令不同于x86指令集这样的直接面向x86架构的CPU的指令集合，这些指令面对CPython内部实现的指令处理过程，这个过程的集合就可以看作为一个虚拟的”机器（机器是泛指其实就是机器处理单元）“ . | 这些指令和参数共同组成了字节码文件，可以将这个字节码文件称为Python虚拟机上的”经过汇编器汇编后的可重定向目标文件“ . | 从python源文件到字节码文件的过程包括 . | 生成parse tree | parse tree转化为AST抽象语法树 | 生成符号表 | AST转化为control flow graph | 从control flow graph生成code object | . | . | Python每个文件中的程序代码由代码块构成，如模块、函数、类定义，CPython的整个编译过程就是从代码块生成“代码对象的过程”； . | 代码对象PyCodeObject在CPython中也是一个和PyObject类似也是一个复杂的结构体，结构体中包含co_stacksize，co_flags，co_zombieframe等字段，被初始化的代码对象的结构体被存储在堆中（在PyMem_NEW(type, n)函数中调用PyMem_MALLOC函数在堆中分配内存空间）； . | 此时，完成了PyCodeObject的创建之后，解释器启动，创建单个执行主线程(在python虚拟机的过程调用中如果创建新的线程和线程状态，就会堆GIL产生竞争)； . | 堆中的代码对象的引用被传入解释器循环模块，在执行代码之前，解释器获取到当前代码对象后，会创建一个frame对象 . | frame 对象包含执行代码对象（局部，全局和内置）所需的所有名称空间，对当前执行线程的引用，用于求值字节码的堆栈以及其他对于执行字节码的内部信息； | frame对象的概念类似与C中的过程调用无法全部装载到寄存器中的时候，会在运行时栈中修改rsp指针分配栈帧； | frame对象在运行时栈中创建并保留部分成员的值，保留其他成员的栈空间，局部变量为空； | . | 类似与C的栈中的rip指针执行栈中的指令，Python虚拟机也在栈中进行过程的执行和返回，相应的指令有相应的过程进行处理（如指令：BUILD_LIST， BUILD_MAP， BUILD_CLASS），每个过程执行完成后，会从栈中弹出； . C中的过程：程序开始阶段，运行时栈的rip（程序计数器指针）指针指向入口函数，然后开始执行，例如执行主函数Q的指令，该指令指向主函数内的过程调用的函数P，这是新的函数P在栈中分配了新的栈帧，该栈帧中的过程返回后，rip指针又指向Q中调用P的那条指令，此时这条指令指向P函数的返回值； . | 在指令执行过程中创建的全局变量等PyObject也会在堆中初始化，每个数据结构的底层实现都有与之对应的C代码，如dict底层是一个使用开放寻址法解决冲突的散列表，并且有特殊的因子进行扩容； . | . | 至此，CPython底层虚拟机的运行已经完成了非常简洁的概括式讨论，实际上每个部分的实现都有细节和复杂的思想在其中； . | . 程序的静态和动态存储空间分配： . | 静态：编译器在编译阶段基于源代码就可以确定的数据大小 | 动态：只有在运行时才能确定的数据对象的大小 | . C语言的编译过程中，对于全局或者静态变量这些在编译阶段确定大小的数据结构或为0值的数据结构，会被放入在编译和汇编完成后生成的可重定向目标文件中的.data节和.bss节，链接器会基于符号表中的重定位条目来将这两个节定位到可执行文件的相应的段中；最总装载程序会将这部分数据装载到该程序虚拟内存的读写段（静态区）； . 对于一个被调用的过程，在寄存器无法满足参数存储的情况下，会在运行时栈中分配栈帧； . 而对于调用malloc进行内存分配的变量会在运行时在堆中创建； . 对于CPython程序而言，无法预知将要读取的python文件中的代码段的数量和大小，怎么才能将这些数据读入栈中； . 编译器对栈空间分配的要求是：一个数据对象局限于某个过程，且当过程结束后这个对象不可访问； . C++利用”变长数组“，大小依赖与被调用过程的一个或者多个参数值的数组来将未知大小的对象； . 程序的执行过程在生命周期中讨论 . | dict . | list . | string . | . | CPython对python对象的内存管理与CPython本身的用户栈 . | Python的内回收机制，和底层内存管理 . | Python的动态类型底层实现 . | Python的GIL与线程安全及IO操作 . | Python语法基础 . | 装饰器 | 单例子实现 | __new__, __call__ 方法 | . | Python主流Web框架的实现 . | Tornado | . | Python调优 . | Python&amp;CPython核心 . | I. 虚拟机工作原理&amp;CPython源代码&amp;工作方式 | II. 内存管理和底层数据结构的实现及数据结构的内存分配、回收、扩容 “heap” . | 优化 . | 最小开销的python代码中变量创建和管理 | . | . | III. 生成器和协程 generator &amp; coroutine . | 生成器对象 generator | . | . | . Shell编程 . | shell内置命令 | shell与内核的系统调用，syscall n指令，Linux中上报中系统调用指令，每个指令有唯一正整数标识，对应一个内核中跳转表的偏移量，跳转表对应一系列系统级函数； | . 2. 计算机网络 「计算机网络 自顶向下」 . | 应用层 OSI中7层 | 运输层 OSI中4层 | 网络层 OSI中3层 | 链路层 OSI中2层 . | 链路帧 | 链路层协议 | . | 物理层 OSI中1层 | TCP/IP网络模型/五层网络 . | 协议栈 . | TCP . | TCP报文结构 | TCP连接建立 | TCP连接拆除 | TCP segment 数据报交付方式Socket . | 多路分解 | 多路复用 . | Linux网路编程Socket多路复用算法 | . | . | TCP可靠传输的实现 . | 快速重传 | 选择重传 | . | TCP流量控制 | TCP拥塞控制 . | 三个冗余 | 拥塞避免 | 慢启动 | 快速恢复 | . | 吞吐量/速率 | . | UDP . | 报文结构 | 无连接 | 无拥塞控制、无流量控制 | 多路复用、多路分解 | . | 因特网网际协议 IP . | 数据报结构 | IPv6 | IPv4 | IP数据报分片 . | v4和v6分片方式 | . | DHCP | NAT | UPnP | 分组交换机/路由器 . | 路由器的基本结构 | 路由选择算法 | 层次路由选择 | 自治系统AS | BGP | 广播和多播路由选择 | . | ICMP 网络控制报文协议 | . | . | . | 网络建设：三层网络，二层网络，核心，接入，汇聚 | . 3. 数据结构和算法 「算法导论&amp;Leetcode训练」 . | 基本数据结构的实现 . | 数组（C中的数组） | C++ Java Python 中map/dict 散列表数据结构的实现 . | 散列函数 . | 除法函数 | 乘法函数 | . | 哈稀重叠处理 . | 链表法 | 开放寻址法 | . | . | 堆 . | 堆排序 nlogn | . | bitmap数据结构 | 链表 | 树/二叉树 . | 二叉树的深度遍历 前 中 后 | 二叉树的广度遍历 | 二叉搜索树 | . | 图 . | 图的深度遍历 | 图的广度遍历 | . | 矩阵 | 多维数组 | . | 基础查找算法&amp;数据结构 . | 跳表 | 红黑树 | 二分查找 | | . | 基础排序算法&amp;稳定性 . 算法的稳定性： . 假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，r[i]=r[j]，且r[i]在r[j]之前，而在排序后的序列中，r[i]仍在r[j]之前，则称这种排序算法是稳定的；否则称为不稳定的。 . 对于序列中相同的元素，在排序之后次序与排序之前保持不变； . Sorting algorithm stability . | 非比较排序 . | 桶排序 | . | 比较排序 . | 简单选择排序 . | 基本思想：每一趟从待排序列中选择最小/最大的元素做为首元素，不稳定排序； | 直接插入 | 选择排序 | 冒泡排序 | . | 快速排序 . | 基本思想 . | 基准数元素和其余所有元素做比较，比较完成后，找到自己在有序序列中的位置，这时候比基准小的在左边，比基准元素大的在右边；对基准元素的左右两边分别做相同操作，以此类推，最终得到有序序列； | 排序的时间复杂度完全取决于基准数的选取，使用“三数取中“的方法，可以一定程度降低基准数对时间复杂的影响； | . | 实现方式 . | i，j双指针进行比较和交换，指针相遇交换结束，基准元素找到自己的位置； | 递归对left到i-1，i+1到right做相同操作 | 见Tag: Algorithm | . | 分析 . | 快速排序为不稳定排序，因为在每次比较和交换过程中，对于大小相同的元素，无法保证其顺序在比较和交换之后还能保持一直，例如有可能会将第一个小的元素交换到中间点； | 时间复杂度，需要带入”主定理“求解，基准数选取好的情况下，平均时间复杂为O(nlogn) | 空间复杂度，空间复杂度为O(1)； | . | . | 堆排序 . | 基本思想 . | 堆排序是利用堆这种数据结构而设计的一种排序算法，属于一种比较排序，最坏，最好，平均时间复杂度均为O(nlogn)，属于不稳定排序； | 将待排序序列构造成一个大顶堆，整个序列的最大值就在堆顶的根节点 | 将根节点元素和序列末尾元素交换，末尾就是待排序序列的最大值 | 将剩余的n-1个元素构造成新的堆 | 重复以上步骤，知道无元素在进行堆的构造 | . | 实现方式 . | 大顶堆 arr[i] &gt;= arr[2i+1] &amp;&amp; arr[i] &gt;= arr[2i+2] | 小顶堆 arr[i] &lt;= arr[2i+1] &amp;&amp; arr[i] &lt;= arr[2i+2] | 构造堆的过程 . | 从最后一个非叶子结点开始，与其左右孩子进行调整，先左右，再上下，此处三个节点中权值最大的结点被升到第一个非叶子结点的位置； | 按顺序找到第二个非叶子结点，重复第一步 | 按顺序找完所有的非叶子结点，则第一次构造完成； | . | 构造完成后，将根节点和最后一个叶子结点交换，再对剩下的元素进行构造； | 见algorithm-heap | . | 分析 . | 时间复杂度 . | 初始化建堆的过程需要消耗的时间 . | O(n) | . | 每次交换首位元素后，对堆的重新整理的时间复杂度为 logn，共整理了n-1次，所以整理和交换的时间复杂度为 . | O(nlogn) | . | 所以最终该算法的最差和平均时间复杂度都为O(nlogn) | . | 空间复杂度 . | 原地算法 | . | 基于堆的数据结果的排序算法是时间复杂度为 O(nlogn) 的 原址排序算法 | . | . | 归并排序 . | 分、治思想 | | . | . | 定理 . | 主定理 . | 主定理时间复杂度分析： T(n)=aT(n/b)+f(n) . 其中a≥1和b&gt;1是常数，f(n)是渐近正函数。这个递推式将规模为n的问题分解为a个子问题，每个子问题的规模为n/b，a个子问题递归地求解，每个花费时间T(n/b)。函数f(n)包含了问题分解和子问题解合并的代价。 . | | 条件 | 计算式 | . | 情况1, 若𝑓(𝑛) &lt; 𝑛𝑙𝑜𝑔𝑏𝑎 | 则复杂度为 T(n)=O(n ^ {log_b a}); | . | 情况2, 若f(n) = n ^ {log_b a} | 则复杂度为T(n)= O(n ^ {log_b a} * lgn); | . | 情况3, 若f(n) &gt; n ^ {log_b a} | 则复杂度为T(n)=O(f(n)); | . 例子，对于快速排序，每次递归都将n的问题分解为了2个子问题，所有a=2，每次合并的问题规模是n/2，函数f(n)包含了问题分解的代价，每次对n个问题的递归分解，都需要n次比较，所以问题分解和合并的代价为n，f(n) = n；将a=2，b=2，f(n)=n，带入公式后得到，T(n) = 2T(n/2) + n，符号情况2，所有由情况2可知，时间复杂度T(n) = O(nlogn); . | . | . | 常见排序算法的稳定性分析 . 堆排序、快速排序、希尔排序、直接选择排序是不稳定的排序算法，而基数排序、冒泡排序、直接插入排序、折半插入排序、归并排序是稳定的排序算法。 首先，排序算法的稳定性大家应该都知道，通俗地讲就是能保证排序前2个相等的数其在序列的前后位置顺序和排序后它们两个的前后位置顺序相同。在简单形式化一下，如果Ai = Aj, Ai原来在位置前，排序后Ai还是要在Aj位置前。 其次，说一下稳定性的好处。排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，第一个键排序的结果可以为第二个键排序所用。基数排序就 是这样，先按低位排序，逐次按高位排序，低位相同的元素其顺序再高位也相同时是不会改变的。 回到主题，现在分析一下常见的排序算法的稳定性，每个都给出简单的理由。 (1)冒泡排序 冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改 变，所以冒泡排序是一种稳定排序算法。 (2)选择排序 选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个 元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果当前元素比一个元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么 交换后稳定性就被破坏了。比较拗口，举个例子，序列5 8 5 2 9， 我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。 (3)插入排序 插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开 始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相 等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳 定的。 (4)快速排序 快速排序有两个方向，左边的i下标一直往右走，当a[i] &lt;= a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] &gt; a[center_index]。如果i和j都走不动了，i &lt;= j, 交换a[i]和a[j],重复上面的过程，直到i&gt;j。 交换a[j]和a[center_index]，完成一趟快速排序。在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为 5 3 3 4 3 8 9 10 11， 现在中枢元素5和3(第5个元素，下标从1开始计)交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j] 交换的时刻。 (5)归并排序 归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个元素(1次比较和交换),然后把各个有序的段序列合并成一个有 序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定 性。那么，在短的有序序列合并的过程中，稳定是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结 果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。 (6)基数排序 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优 先级排序，最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以其是稳定的排序算法。 (7)希尔排序(shell) 希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比o(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元 素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。 (8)堆排序 我们知道堆的结构是节点i的孩子为2i和2i+1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n 的序列，堆排序的过程是从第n/2开始和其子节点共3个值选择最大(大顶堆)或者最小(小顶堆),这3个元素之间的选择当然不会破坏稳定性。但当为n /2-1, n/2-2, …1这些个父节点选择元素时，就会破坏稳定性。有可能第n/2个父节点交换把后面一个元素交换过去了，而第n/2-1个父节点把后面一个相同的元素没 有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法。 综上，得出结论: 选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法，而冒泡排序、插入排序、归并排序和基数排序是稳定的排序算法。 . wiki . blog . | . | 算法思想&amp;解题思想 . | 分而治之 分治 divide-conquer | 线性数组双指针 | 滑动窗口法 | 位运算 异或 | 贪心算法 局部最优解 | 动态规划 . | 状态定义 | 状态转移方程 | 边缘条件处理base case | . | 递归/迭代 | 二分查找/二分思想 | . | 数据结构的应用 . | 红黑树 | B/B+树 B树就是B-树 | . | . 4. 操作系统 「现代操作系统&amp;Linux」 . | Linux . | 进程数据结构的实现 | 文件描述符的管理表 | . | 内核 . | 内核组件 | 内核维护的数据结构 | . | 系统调用 . | 进程&amp;线程 . | 进程 . | 核心概念，对当前运行的程序的一个抽象； | 一个 进程 process 表示当前在执行的一个程序的实例； | 程序和进程，程序是存放在磁盘上的可执行目标文件，进程是调用fork，和execve函数后装载虚拟内存空间和init执行入口指令开始后的过程的实例； | 守护进程，后台进程； | 进程由POSIX标准的system call的接口函数fork创建； | execve系统调用函数在fork函数之后调用，目的是允许子进程处理其文件描述符，完成对标准输入，标准输出和标准错误的重定向； | 进程的主动终止，调用 exit system call； | 进程内部错误导致的异常退出，例如sefamentation fault（栈溢出用户栈的大小ulimit查看默认10mb、指针越界），操作系统向进程发送中断信号； | kill命令，直接杀死进程；Linux中由父进程创建的子进程和其更多的子进程组成一个进程组，当系统向进程发送信号，进程组中的每个进程都会捕获信号，并执行动作；Unix中所用进程都是以init为根的一棵树； | 三种状态： . | 运行态 | 就绪态 | 阻塞态 | 运行到就绪，调度算法引起（时间片用完），阻塞到就绪I/O完成进入就绪队列，运行到阻塞I/O等待或者临界区访问等待，就绪到运行调度算法引起； | . | 进程的实现 . | 内核维护了一个结构数组，叫做进程表process table，每个进程占用一个表项，这就是所谓的进程控制块； | 表中字段包括，进程管理，程序计数器，寄存器，程序状态字，堆栈指针，优先级，父进程，进程ID,信号，进程开始时间，使用CPU的时间，子进程使用CPU的时间… | 中断发生的底层操作 . | 硬件压入堆栈程序计数器 | 硬件从中断向量装入新的程序计数器 | 汇编语言过程保存寄存器值 | 汇编语言过程设置新的堆栈 | C中断服务例程运行 | 调度程序决定下一个将要运行的进程 | C过程返回至汇编代码 | 汇编语言过程开始运行新的当前进程 | . | . | . | 线程 . | 进程就是一个地址空间和一个控制线程的组合； | 线程的意义： . | 并行的实体共享同一个地址空间和所有可能的数据； | 相比进程线程更加的轻量级，线程的创建和上下文切换都要更快； | 对于I/O密集型的应用，多个线程允许多个活动重叠进行，从而加快了应用程序的执行速度； | . | 并发和并行 . | 并发是指进程或线程执行的过程或控制流在同一时间段内发生了重叠； | 并行是指进程或线程在多CPU系统中的同时执行，有完全不同的物理寄存器和程序计数器； | . | 线程 thread 是操作系统内核资源分派和调度的最小单位，是调度算法执行的实体； . | 每个线程都有自己的 “寄存器”，”用户栈帧“，栈帧保存着当前程序执行的过程的局部变量及返回地址及机器指令； . | 线程没有层次关系，所有线程都是平等的； | 基本过程调用 . | 调用库函数 thread_create 创建线程，创建成功后返回线程标示符； | 调用库过程 thread_exit 退出线程； | 调用库过程 thread_join 一个线程会等待另一个线程，知道所等待的线程退出，阻塞才会结束退出； | 调用过程 thread_yield 自动放弃CPU从而让另一个线程运行； | . | POSIX . | POSIX，Protable System Interface 是IEEE为各种Unix操作系统上运行的软件定义的API和其关联的标准的总称； | POSIX定义的线程相关的函数的package是Pthread；定义了60个函数调用； . | Pthread_create 创建新线程 | Pthread_exit 结束一个线程 | Pthread_join 等待一个特定的线程退出 | Pthread_yield 主动释放当前分配的CPU时间片，内核会调度新的线程运行 | Pthread_attr_init 创建并初始化一个线程的属性结构 | Pthread_attr_destory 删除一个线程的属性结构 | . | Pthread特性 . | 一个标示符 调用Pthread_create函数返回 起到PID的作用 | 一组寄存器和程序计数器 | 一组存储在结构中的属性，堆栈大小，调度参数，使用线程需要的其他项目 | . | . | 用户空间实现线程，操作系统内核对线程的存在没有任何感知，内核对进程的调度，可以理解为，内核只调度单线程进程；用户空间的内的运行时系统来对线程进程管理，且运行时系统中会管理线程表（thread table），线程的调度实现在运行时系统中，运行时系统的过程进行线程的上下文切换，比内核级别的线程上下文切换要快一个数量级；这个过程不需要陷阱（如系统调用），不需要内核控制的上下文切换，不需要对高速缓存进行刷新；并且允许每个进程中有自己实现的调度算法； . | 内核级线程，所有的调度都发生在内核的调度中； | . | 竞争 （互斥 mutual exclusion）mutex . | 临界区 . | 共享内存进行访问的程序片段为临界区域（critical region），或临界区（critical section） . | 用于解决多个进程竞争访问共享资源：共享内存、共享文件 | . | 并发进程共享数据且高效运行，对临界区访问的必须条件 . | 任何两个进程不能同时处于临界区 | 不对CPU的速度和数量做任何限制 | 临界区外运行的进程不得阻塞其他进程（由于其他进程导致进程阻塞，只能是因为阻塞等待访问临界区） | 进程不能无限期的进入临界区 | . | . | . | . | 调度 . | 操作系统的 调度程序 scheduler 进行对当前多个处就绪状态的线程或者进程选择谁去运行当前的时间分片； . | 调度程序 scheduler 使用的算法是 调度算法 scheduling algorithm . | 进程的切换会消耗大量的CPU时间 . | 用户态切换到内核态，将当前进程的状态及程序计数器保存到当前进程的数据结构中（表） | 运行调度算法选择一个新的进程 | 将新进程的内存映像装入MMU （Memory management Unit） | 进程的切换会使得高速缓存失效，缓存需要重装两次，进入内核一次，离开内核一次 | . | I/O活动 . | 当一个进程等待外部设备完成工作而被“阻塞” | 当前进程发出一个系统调用进行I/O的读写 | CPU的突发使用和等待I/O的时期交替出现 | . | compute-bound . | CPU密集型进程，长的CPU突发，较少的等待I/O | . | I/O-bound . | I/O密集型，短的CPU突发，较多发生的I/O等待 | CPU性能的增长，大多数应用倾向于I/O密集型，CPU密集型例如特效渲染等，建模大量浮点运算等； | . | 调度的简单归纳 . | 对于创建的新进程，策略为合法选择先运行父进程或者先运行子进程 | 进程退出，从就绪进程集中选择某个进程，没有就绪进程则运行一个系统提供的空闲进程 | 当一个进程阻塞在I/O和信号量上或者其他原因阻塞，必须选择另一个进程； | 进程发生I/O中断时，系统必须作出调度决策，对于完成了I/O工作的进程，又会进入就绪状态，对于这个进程的调度，取决与调度算法； | . | 调度算法的分类 . | 时钟中断，调度策略发生在每个时钟中断或者每k个时钟中断（硬件提供50HZ或者60HZ的周期性中断） | 非抢占式调度算法 . | 挑选一个进程，让该进程运行直至被阻塞（I/O或临界区等待），或者直到该进程自动释放CPU；在这种算法下，进程运行了数个小时没有发生I/O或者阻塞，都不会被强制挂起； | . | 抢占式调度算法 . | 挑选一个进程，让该进程运行某个固定时段最大值（最大运行时间片），时段结束，关起进程，在调度下一个就绪进程运行； | 抢占式的调度算法，需要在时间间隔的末端发生时钟中断，用来将CPU控制返回给调度程序（程序计数器）； | . | 在没有可用的时钟的条件下，非抢占式的调度式唯一的选择； | . | 不同的领域和环境需要不同的调度算法 . | 批处理：非抢占式调度算法，或者每个进程都有长时间周期的抢占式； | 交互式环境&amp;服务器：抢占式调度算法，避免程序无限期的霸占CPU； | 实时系统：非抢占式，程序很快完成工作并进入阻塞； | . | 调度算法的目标 . | 所有系统 . | 公平 - 每个进程公平的CPU时间片 | 策略强制执行 | 平衡 - 保持系统所有部分都忙碌 | . | 批处理系统 . | 吞吐量 - 每小时最大作业数 | 周转时间 - 从提交到终止间的最小时间 | CPU利用率 - 保持CPU忙碌 | . | 交互式系统 . | 响应时间 - 快速响应请求 | 均衡性 - 满足用户的期望 | . | 实时系统 . | 满足截至时间 - 避免丢失数据 | 可预测性 - 在多媒体系统中避免品质降低 | . | 必须保障 . | 强制执行公平相关的体系策略 | 保持系统的所有部分尽可能忙碌 | . | . | 调度算法 . | 非抢占式的 先到先服务 first-come first-serverd . | 进程按照请求CPU的顺序使用CPU | 就绪进程的单一队列，新的进程和发生阻塞的进程再次处于就绪状态都将更新到队列尾部； | . | 非抢占式的 最短作业优先 shortest job first . | 对于同时进入就绪队列的进程，从 运行时间 最短的进程依次执行，总体上所有进程的周转时间（执行时间+阻塞时间）的平均值最小； | . | 非抢占式的 最短剩余时间优先 shortest remaining time next . | 总是选择运行时间最短的进程运行； | . | 抢占式 轮转调度 round robin . 古老、最简单、最公平、使用最广的算法 . | 每个进程被分配一个时间片（quantum），允许该进程在该时间段中运行； | 时间片结束后，程序依然没有发生阻塞而在继续运行，算法将剥夺CPU并分配给其他进程； | 如果在时间片之内，程序发生了I/O阻塞或者访问临界区阻塞，则直接发生CPU切换； | 保持一个就绪队列，当一个进程的时间片用完就将其移动到队列尾部； | 进程的控制切换（context switch）开销非常大，保存当前寄存器、内存映像、重载内核映像、清除和重新子啊如高速缓存，载入新进程的内核映像… | 时间片取值，太短降低CPU效率，太长引起响应时间变长，折中为20ms~50ms | . | 优先级调度 . | 操作系统动态的确定进程的优先级；操作系统将进程的优先级分为4类，并使用轮转调度； | 调度算法实现 . | 轮转算法将给第4类优先级进程分配时间片，并云子能够； | 第4类为空的情况下，轮转第3类； | 依次类推； | 并且系统会定期对进程的优先级进行调整； | . | . | 多级队列 . | 最短进程优先 . | 保证调度 . | 彩票调度 . | 公平分享调度 . | . | 调度策略与调度机制分离（scheduling policy &amp; scheduling mechanism) . | 算法参数化，由用户进程填写； | . | 线程调度 . | 进程和线程并存的系统中的调度 | 用户级线程 . | 没有内核级别的线程，内核不知道线程的存在，内核还是对进程进行基于时间片的轮转调度，而线程的调度由进程内部自己实现，进程内一个或多个线程运行完当前的时间片之后，内核会将控制转移给队列首部的进程； | 缺少时钟周期对线程进行中断； | . | 内核级线程 . | 操作系统内核以线程为最小调度单位，用轮转调度和优先级调度算法对线程分配时间片，并在时间片完成后，挂起该线程，在运行其他线程； | 对于线程的I/O阻塞，同样可以将线程挂起，调度运行其他线程； | . | 线程调度的比较 . | 用户级线程调度发生在用户程序内部，开销更小，速度更快； | 用户级线程，可以让应用程序定制自己的线程调度算法； | 内核级线程调度，需要用户态和内核态的切换，开销更大，上下文切换时间更长； | 操作系统在线程调度时候，更加倾向与调度运行上下文切换开销较小的线程，例如同一个进程中的多个线程，在运行线程阻塞的情况下，内核更加倾向于调度执行该进程中的其他线程而不是其他进程中的线程； | . | . | . | 软中断&amp;硬中断 . | . 5. 体系结构 「CSAPP-深入理解计算机系统」 . | 程序结构 . | CPU寄存器和系统字长 | . | 信息表示 . | 补码表示 | 浮点数的表示 | . | Intel指令集架构 . | y86指令集 | 复杂指令集、精简指令集 | . | 编译器驱动程序 . | 预处理 | 编译 | 汇编 | 链接 | . | ECF 异常控制流 . | 控制流 . | 程序计数器中指令地址的过度称为控制转移 control transfer | 程序计数器指令地址的过度的序列为处理器的控制流（control flow） . | 平滑的控制流序列，其中每个指令的地址都是相邻的； | 平滑流的突变，通常由跳转， 调用、返回等指令造成 | . | 控制流突变 . | 异常控制流 Exceptional Control Flow ECF | 发生在计算机系统的各个层次 . | 硬件事件触发控制突然转移到异常处理程序 | 内核通过上下文切换将控制从一个用户进程转移到另一个用户进程 | 应用层，进程之间使用信号通信，接受者会将控制转移到信号处理程序； | 程序通过回避通常的栈规则，执行到其他函数任意位置的非本地跳转来对错误作出反应； | . | . | ECF . | ECF是OS用来实现I/O，进程、虚拟内存的基本机制； | 应用程序使用系统调用 （system call）的ECF形式，向系统请求服务； . | 磁盘写入数据 | 网络读取数据 | 创建新进程 | 终止当前进程 | 通过系统调用实现 | . | ECF是计算机系统实现并发的基本机制； . | 中断应用程序执行的异常处理程序 | 时间上重叠执行的进程和线程 | 中断应用程序执行的信号处理程序； | . | ECF软件异常 . | C++ try catch throw | 软件异常允许程序进行非本地跳转，来响应错误； . | 非本地跳转是一种应用层ECF，C中通过setjmp和longjmp函数提供 | . | . | 各种形式的ECF | . | . | 过程 . | | 用户栈 | - | . | 参数 |   | . | 返回地址 |   | . | 被保存的寄存器 |   | . | 局部变量 |   | . | 参数构造区 | &lt;-%rsp | . | 过程是一种软件中的抽象，提供一种封装代码的方式，用一组指定的参数和一个可选的返回值来实现某种功能 . | 过程的属性包括 . | 传递控制 . | 程序开始阶段，运行时栈的rip（程序计数器指针）指针指向入口函数，然后开始执行，例如执行主函数Q的指令，该指令指向主函数内的过程调用的函数P，这是新的函数P在栈中分配了新的栈帧，该栈帧中的过程返回后，rip指针又指向Q中调用P的那条指令，此时这条指令指向P函数的返回值； | . | 传递数据 | 分配和释放内存 | . | 使用栈数据结构的提供的先进后出的内存管理原则 . | 过程在被调用时候，才会在栈中为局部变量分配空间，而过程结束后分配的局部存储空间都会被释放掉； . | 栈和程序寄存器存放着传递控制和数据、分配内存所需要的信息； . X86_64 栈向底地址增长，栈指针%rsp指向栈顶元素，pushq指令入栈，popq指令出栈，将指针减小一个适当的量可以为没有指定初始值的数据在栈上分配空间 （指针偏移量，变长数组），增加栈指针来释放空间 . | 栈帧 （stack frame） . X86_64 过程所需要的存储空间超出寄存器能够存放的大小，就会在栈上分配空间 . 栈通过增加和减小%rsp的大小来释放空间和分配栈帧； . 当前正在执行的过程的栈总是在栈顶 . 定长栈帧 . 变长栈帧 . 栈帧的实质就是过程因为所需要的寄存器空间不足而在栈顶分配的新的内存空间；内存中一个过程所包含的过程调用和数据及返回； . | 6个或者更少的参数可以直接通过寄存器传递 （6个参数：可以通过寄存器最多传递6个参数，例如整数和指针参数，寄存器只用有特殊的顺序，名字取决于传递的参数的大小） | 叶子过程：所有局部变量都保存在寄存器中，而且不会调用其他函数的过程 | X86_64 只分配自己所需要的栈帧部分 | . | . | 异常 . | 事件发生 – 处理器通过异常表 exception table 跳转表，进行一个间接的过程调用 – 异常处理程序 exception handler – 处理完成后 . | 处理程序将控制返回给当前指令，事件发生时正在执行的指令 | 处理程序将控制返回给当前指令的下一条指令，没有发生异常就会执行下一条指令 | 处理程序终止被中断的程序 | . | . | 陷阱 . | 有意的异常，执行一条指令的结果，像中断处理程序一样； . | 用途 . | 用户程序和内核之间提供一个像过程一样的接口，系统调用 | 用户程序向系统内核请求服务： . | read | fork （创建新进程） | execve | exit | . | 为了允许对内核服务的受控的访问，处理器提供一条特殊的“syscall n”指令； | 用户程序想要请求服务n时，执行指令 syscall n，就会导致一个异常处理程序的陷阱； . | 这个处理程序解析参数，并调用适当的内核程序； | . | . | . | . | . | 虚拟内存 . | 多线程编程 . | 网络编程 . | 磁盘读写 . | I/O . | Linux I/O模式 . 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) . epoll的优点主要是一下几个方面： . | 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 | IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。 | 如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。 | . | . | . II. 上层应用 . 数据库 . | 关系型数据库 . | 索引实现 . | B+tree Mysql的两种可选索引引擎的异同 | 数据库并发和锁 | . | . | 缓存数据库 . | redis | . | 时序数据库 . | M3DB/InfluxDB | etcd | . | . 分布式系统 . | 什么是分布式 | 分布式基础 . | zookeeper | redis | . | 分布式锁，事务单一处理 | 分布式横向扩展 | 负载均衡、转发代理 | 高可用 | 数据库读写分离 . | 容器 . | Docker基础 . | Docker隔离的基本原理和机制 | Docker swarm | Docker compose 配置管理标准 | . | Kubernetes . | serverless架构中Kubernetes的角色 | 基本组件和使用 | . | . | . 主流云环境监控系统 . | open falcon | prometheus | . 云网络 . | LVS | Nginx | iptable | NFV | SDN | . 云计算 . | Cloud Native | 虚拟化 . | hypervisor | KVM . | . | Openstack | Quem | . | Serverlesss | . III. 实践能力 . | IaaS 基础设施研发实践 Python Golang . | Linux运维实践 . | . IV. 题目总结 . 算法 . | Algorithm-curve | . 八皇后问题，火车接龙， 高考分数线，5人抢答题概率，丢手绢问题 . 常见题目 . | 基本排序算法的实现思路和时间空间复杂度 . | 快速排序，经典的比较排序，基准数与其他逐个比较，找到自己在序列中的位置，二分对两边做同样地操作，基准数选择至关重要，可以用三数取中法； . | 时间复杂度，带入“主定理”求解，为nlogn | . | . | . 个人题目总结 . 1. 算法与数据结构 . | 树形结构的同步 . A和B两台计算机，分别跑着同一个程序m，A和B用一根网线相连接，现在A中有一个树形数据结构，有根节点也子节点，且这些子节点都保存着一个二进制数小于256位的二进制数，但是每个节点的子节点最大数量为2^10 256个，且树的深度可能很大，要求描述一个算法将A上的树备份到B上，不能使用json等序列化方式，设计一个算法，实现这个数据传输； . Merkle Tree（默克尔树）算法解析 . 不能离开数据结构谈算法，实际的生产应用中，数据结构和算法应该是怎么样去实践的 . 分析 . | 网线连接，首先说明AB的链路时直接相连中间没有任何分组交换，直接使用socket接口，先在单线程内解决该问题，再思考用socket线程池进行同步，数据的一致性要求，选择TCP | 树形结构，树的深度为n，对于此数据的同步需要进行实时同步，不能一次性同步 | . 方案 . | . | 哈希表的原理及实现方式，扩容、冲突解决 . | 将n个有序数组进行合并 . | 堆排序 nklogk | 归并排序，分治 nklogk | . | 链表，在算法训练中有讨论，下面两题属于非常简单的题型 . | 链表反转，递归反转 | 检测链表成环，快慢指针 | . | . 2. 并发编程 . | 多线程编程 . A线程 ————C1————-C2————– B线程 ——————–C3——————— . 分析 . | 对于这样的两个线程，要求实现 C1 C3 C2 的执行顺序 重点：线程的执行顺序和代码顺序无关，线程也不是同时执行的，线程是由操作系统内核的调度算法进行调度执行的； | . Solution . | 单CPU的并发 . | 维护两个堆中的全局变量的布尔值为 did_e_c1, did_e_c3 . | 创建一个互斥锁 . | 实现 . | 对于两个布尔值的修改，使用一个互斥锁，保证线程安全； | 此处可以不使用yeild函数，但是会浪费调度算法分配的时间片； | . | A线程中实现三个过程（两个控制流） . | 第一个控制流判断两个布尔值是否都为 False，如果符合条件则执行C1，并将did_e_c1置为True，不符合条件则当前帧出栈也就是继续执行 | 控制流继续执行，判断是否当前两个布尔值都为 True，如果符合条件就继续执行，如果不符号条件，则调用 Pthread_yeild 过程主动让出当前线程的时间片，此处的判断条件可以使用while循环； | 第三个控制流直接执行代码块C2，执行完成后将did_e_c1, did_e_c3都置为False | . | B线程中实现两个过程 . | 第一个过程判断当前是否符合 did_e_c1 == True, did_e_c3 == False；如果符合则直接运行过程C3，如果不符合则Pthread_yeild 过程主动让出当前线程的时间片，此处的判断条件可以使用while循环； | 执行完成后将did_e_c3置为True | . | . | . | . | 数据库更新A记录和B记录的加锁和死锁问题 . 数据库，数据库更新A记录和B记录的加锁和死锁问题，表中管理账户信息，A账户给B账户转账，更新A和B，考虑行锁和死锁出现的解决 . | KMP算法，搜索单词数量； . | 磁盘存取原理 . | . 3. 网络 . | 链路层 | TCP连接拆除的过程，三次握手，四次分手，为什么是三次，和TCP配置相关的linux参数； | TCP 连接拆除 大量TIME_WAIT问题，TIME_WAIT分析和解决方案； | 网络工程 | . 4. 操作系统 . | 基础问题 . cpu 占用率到底代表什么，linuxload代表什么，linux中各种内存又代表了什么，linux的网络是如何工作的 . | . 5. 其他问题 . 2019年4月16日 记录 . | 时序数据库底层的实现 时序数据库和关系型数据库的区别 . | 协程到底是什么，协程如何“并发”，io密集型，GIL如何避免 . | 并发&amp;并行 python的并发 并行的概念是 multiprocessing 如何实现并行 . | KVM QUEM Openstack . | 自动化的横向扩展 . | rabbitmq和Kafka . | 长短链接 . | 跳表 . | tcp tw socket recycle reuse 底层实现 / tcp 为什么三次 为什么四次 . | malloc tcmalloc jemalloc . | 长短连接的保持，应用层协议探查连接状态 . | 内核 及 内核组件 模块 操作系统 . | socket在内核中保持的table . | 微服务 容错 容灾 远程调用方案 追踪 . | . 异常 控制流 中断 陷阱 系统调用 . socket 底层原理 linux 内核部分 . 时序 数据库和关系型 数据库 对象存储 redis . 4月19日 . | 线程 进程 切换/控制转移/时间片 操作系统 . | 数据结构 跳表 . | 查找算法，查找算法的时间复杂度，查找算法的稳定性如何衡量 . | 小白鼠问题 . | 调试 循环引用 . | redis 中间件 . | 问什么回答什么，加快节奏，总是打断？ . | 集中式/分布式 . | epoll poll select 区别是什么 . | . V. 2020年2、3、4月学习复习总结 . VI. 开源项目代码研究 . | CPython | Redis | malloc/jemalloc/tcmalloc | . VII. 云计算的未来和趋势 . | 云计算从虚拟化到容器再到现在的serverless的发展趋势， 我个人理解云计算的未来在客户的层面来讲是要看到产品的使用更加简单、开发成本更低，用户编写测试完核心业务代码或者函数，剩下的自动化部署、高可用、快速伸缩、负载均衡这些都扔给服务的provider去做，这也是现在FaaS的概念，这样的serverless架构就要求云服务的提供者有一套完善的容器编排和调度策略，及准确的流量和数据监控系统，保证快速的横向伸缩和计费的准确，例如像AWS的lambda，我看到的统计资料全球有30%的企业都有使用AWS的lamdba服务；所以serverless是一个大的发展趋势； | 从宏观上来讲，云计算的未来是网络和数据的未来，我们需要更加安全和可靠的网络去承载新的业务，像IOT和车联网，也需要准确的，也需要更可靠的分布式的数据存储系统去承载更多业务类型的数据； | . VII. 其他 . Intro . 项目背景和挑战 . 亮点及成果 . 个人规划 . 自我提问 . 简历问题： . | 数据库优化具体是指什么 | Linux的基本操作 | Docker原理 | LXC RabbitMQ 原理 | 基本的网络知识，协议在哪一层 | . TCP的状态都有哪些 . 数据库优化： 数据库优化的问题，我来举两个例子吧： . | redis替代率全表查询到服务缓存问题 例如redis这样的非关系数据库和关系库的区别 . | 数据持久化方式：redis是一个内存数据库，对于我们实时访问的数据都是直接存储在内存中以k-v方式存储，很大程度上提高了读写效率，redis会将更新的数据周期性的同步到磁盘中，并且进行master slave的同步；而关系型数据数据还是索引都存放在硬盘中。到要使用的时候才交换到内存中。能够处理远超过内存总量的数据。 | 存储方式：关系型数据库可以存储多种不同的表关系，而且每个表都有自己的行和列，主键外键、索引等； Redis的外围由一个键、值映射的字典构成。与其他非关系型数据库主要不同在于：Redis中值的类型 [1] 不仅限于字符串，还支持如下抽象数据类型： 字符串列表 无序不重复的字符串集合 有序不重复的字符串集合 键、值都为字符串的哈希表 [1] | 查询方式：redis以k-v形式查询和存储，而且传统的关系型数据库提供了一整套的SQL语句进行各种查询和读写； | . | 增加了索引，对数据量基本确定的表增加了btree的索引，对数据量较大的数据库增加了Brin索引，为什么，分别是什么 | . | RIN索引和BTREE索引相比，在存储空间占用上具备巨大优势。本例中达到6848倍！对于数据仓库或者VLDB应用可以节省大量的存储成本。 本文给出并分析了7中不同的数据分布，在等值查询情况下，所有的场景BTREE的性能都优于BRIN索引。但在不同数据分布情况下，BTREE在性能上的领先优势差别非常大，从不到1倍到265倍。在选择创建BRIN还是BTREE索引时，需要权衡性能和空间使用两方面的影响。根据数据量、数据分布和SQL选择最适合的索引类型。在性能相差不大的情况下，选择BRIN可能是更加经济的选择。总体来说，当实际匹配数据量较少时，BTREE索引更加适合；反之，BRIN更加适合。 . | BRIN 索引（块范围索引，Block Range Indexes） 该索引维护每一定范围内数据块的最大最小值和其他一些统计数据，当数据库查询时可根据索引的统计信息筛选出不符合查询条件的数据块，以避免全表扫描，提高性能和减少 IO。和 BTree 索引比较所占用的空间足够小[1]，因此 BRIN 索引一般用于线性相关较强字段的精确和范围查询，如在一张很大的日志表中通过 id 或时间查询。 BRIN 索引页的存储顺序依次是 meta page、revmap pages 和 regular pages . | B-TREE btree是一个多路的树形结构，内存节点不存储data，只存储key；叶子节点不存储指针,叶子节点存储数据，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree，这个优化的目的是为了提高区间访问的性能。 检索原理：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或未找到节点返回null指针。 缺点：1.插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。造成IO操作频繁。2.区间查找可能需要返回上层节点重复遍历，IO操作繁琐。 . | . B-tree和二叉树的一个显著的区别就是，B-tree是从下往上生长，而二叉树是从上往下生长的。 . | 增加了查询函数和view视图，view视图的主要作用是减小前后端工作量，将较为复杂的SQL查询直接放在可视化的视图上，前端通过中间件直接获取数据；例如 . | 查询函数的优化，主要是以rpc的方式更新数据库中比较固定的字段； 使用了pg函数的方式，将统一的数据访问方式全都放在了中间件上； . | . agent心跳逻辑的更新 旧逻辑： . 每个agent自己通过中间件连接数据库，调用rpc函数，更新它当前所要监控的设备上的update_timestamp和region上的update_time字段为最新时间； 一共440个agent每分钟都在调用rpc函数，导致了严重的对锁的竞争，因为pg会为操作自动加上行锁也就是rowexclusivelock，又因为大量进程的同时修改，导致了两个进程会互相等待对方释放锁，从而导致了死锁； . 完成重构了agent的更新的逻辑，每个agent在表agent_heartbeat中有一条单独的记录，agent还是每分钟更新update_time, 新的agent distribution的服务会将每分钟检查是否有agent down掉，如果有则将设备表中agent的分配update为null，并且将这些无人认领的设备平均分配给其他活着的agent . 这里将多个服务的大量写入更新操作放在了一个服务统一进行； 将rpc函数更新为了简单的agent心跳更新；将原来数据库端的rpc压力降低了； . 主键 外键 主键是一张表里的一个unique的字段，该字段的记录在表中只有一个 外键，是用来约束两张表之间数据关系的，外键的参考键必须是库中其他表的主键或者说必须是uniqe的，外键关联的字段可以是本表的任意字段 表1设置了表2的id和自己的id为外键，表1如果新增数据时，表2中必须已经包含了该数据，表2删除数据时，所删除的ID不能存在于表1中； . | 给数据量较大的表，比如3000条数据的表，加入了btree的索引 | metric_event表的并发BRIN 索引 | 配置一个表的外键，需要选取参考模式参考表和参考值， | . Linux Load Average: 1min 5min 15min 一个逻辑核心的Load为1.0，表示当前n分钟的时间内，CPU核心一直处于工作状态, 当小于1.0的情况下例如0.7，表示CPU在n分钟内有0.3n分钟的时间内是idle的状态；如果为1.3的情况下，表示CPU在n分钟内一直处于工作状态，且有进程处于阻塞等待调度和执行的时间为0.3n分钟； n个逻辑核心的load average为n.0 将CPU的逻辑核心数*0.7 到0.8 就是最好的运行状态 . Linux的堆和栈 内存从高地址到底地址分为 栈区 剩余内存区 bss段 data段 text段 text段存放代码，data段和bss段存放全局变量和静态变量 data存已经初始化的 bss存未初始化的 栈的作用就是在寄存器紧张的情况下，临时存放一些数据，push和pop的方式进行访问，当寄存器空闲的情况下，栈中的数据会被pop出来以供使用，比如存放局部变量，函数参数和上下文环境这些临时数据，栈的顶部是向底内存方向增加的，栈顶由ESP堆栈指针寄存器来标记； . Linux中的内存 . 所谓的malloc和free进行分配和释放的内存区域为中间的剩余内存段，也就是常说的堆； . | 首先，栈是一个后进先出(LIFO)结构。当把数据放入栈时，我们把数据push进入；当从栈取出数据时，我们把数据pop出来。 在x86体系中，栈顶由堆栈指针寄存器ESP来标记，它是一个32位寄存器，里面存放着最后一个压入栈顶的项的内存地址，栈顶是朝着底内存方向增长的。 栈经常可以用来在寄存器紧张的情况下，临时存储一些数据，并且十分安全。当寄存器空闲后，我们可以从栈中弹出该数据，供寄存器使用。这种临时存放数据的特性，使得它经常用来存储局部变量，函数参数，上下文环境等。 . | 堆相对于栈，更加强调需要进行控制。常见的就是我们手动申请，手动释放。因此可以分配更大的空间，但开销也会更多。 . | . 数据格式： { “endpoint”: “metric”: “timestamp”: “step”: “value”: “counterType”: “tags”: } . TCP/IP协议 OSI 应用层 表示层 会话层 传输层 TCP协议族 网络层 IP协议 + Internet协议 IP包：[] 数据链路层 物理层 . Linux中TCP状态： . SYN:(同步序列编号,Synchronize Sequence Numbers)该标志仅在三次握手建立TCP连接时有效。表示一个新的TCP连接请求。 . ACK:(确认编号,Acknowledgement Number)是对TCP请求的确认标志,同时提示对端系统已经成功接收所有数据。 . FIN:(结束标志,FINish)用来结束一个TCP回话.但对应端口仍处于开放状态,准备接收后续数据。 . 1)、LISTEN:首先服务端需要打开一个socket进行监听，状态为LISTEN. The socket is listening for incoming connections. 侦听来自远方TCP端口的连接请求 . 2)、SYN_SENT:客户端通过应用程序调用connect进行active open.于是客户端tcp发送一个SYN以请求建立一个连接.之后状态置为SYN_SENT. The socket is actively attempting to establish a connection. 在发送连接请求后等待匹配的连接请求 . 3)、SYN_RECV:服务端应发出ACK确认客户端的SYN,同时自己向客户端发送一个SYN. 之后状态置为SYN_RECV A connection request has been received from the network. 在收到和发送一个连接请求后等待对连接请求的确认 . 4)、ESTABLISHED: 代表一个打开的连接，双方可以进行或已经在数据交互了。 The socket has an established connection. 代表一个打开的连接，数据可以传送给用户 . 5)、FIN_WAIT1:主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态. The socket is closed, and the connection is shutting down. 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 . 6)、CLOSE_WAIT:被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求(它的接收也作为文件结束符传递给上层应用程序),并进入CLOSE_WAIT. The remote end has shut down, waiting for the socket to close. 等待从本地用户发来的连接中断请求 . 7)、FIN_WAIT2:主动关闭端接到ACK后，就进入了FIN-WAIT-2 . Connection is closed, and the socket is waiting for a shutdown from the remote end. 从远程TCP等待连接中断请求 . 8) 、LAST_ACK:被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个 FIN,等待对方的ACK.就进入了LAST-ACK . The remote end has shut down, and the socket is closed. Waiting for acknowledgement. 等待原来发向远程TCP的连接中断请求的确认 . 9)、TIME_WAIT:在主动关闭端接收到FIN后，TCP就发送ACK包，并进入TIME-WAIT状态。 The socket is waiting after close to handle packets still in the network.等待足够的时间以确保远程TCP接收到连接中断请求的确认 . 10)、CLOSING: 比较少见. Both sockets are shut down but we still don’t have all our data sent. 等待远程TCP对连接中断的确认 . 11)、CLOSED: 被动关闭端在接受到ACK包后，就进入了closed的状态。连接结束. The socket is not being used. 没有任何连接状态 . TIME_WAIT状态的形成只发生在主动关闭连接的一方。 . 主动关闭方在接收到被动关闭方的FIN请求后，发送成功给对方一个ACK后,将自己的状态由FIN_WAIT2修改为TIME_WAIT，而必须再等2倍的MSL(Maximum Segment Lifetime,MSL是一个数据报在internetwork中能存在的时间)时间之后双方才能把状态 都改为CLOSED以关闭连接。目前RHEL里保持TIME_WAIT状态的时间为60秒。 . 当然上述很多TCP状态在系统里都有对应的解释或设置,可见man tcp . 二、关于长连接和短连接: . 通俗点讲:短连接就是一次TCP请求得到结果后,连接马上结束.而长连接并不马上断开,而一直保持着,直到长连接TIMEOUT(具体程序都有相关参数说明).长连接可以避免不断的进行TCP三次握手和四次挥手. 长连接(keepalive)是需要靠双方不断的发送探测包来维持的,keepalive期间服务端和客户端的TCP连接状态是ESTABLISHED.目前http 1.1版本里默认都是keepalive(1.0版本默认是不keepalive的)，ie6/7/8和firefox都默认用的是http 1.1版本了(如何查看当前浏览器用的是哪个版本，这里不再赘述)。Apache,java . 一个应用至于到底是该使用短连接还是长连接，应该视具体情况而定。一般的应用应该使用长连接。 . TCP 主动端-被动端 . 主机1发送完自己要发送的所有数据，决定断开连接 主机1使用close发送fin|ack（附带对主机2前面数据的ack），断开连接的过程开始，此时主机1的发送窗口关闭，接受窗口还在工作； 主机2接受到主机1的fin后，发送ack告知主机1对方的fin已收到； 主机2继续发送数据，直到主机2发送完所有数据 主机2使用close发送fin，表示自己的数据也发送完毕 主机1接受fin，发送ack，告知主机2对方的fin已收到 . time-wait开始的时间为tcp四次挥手中主动关闭连接方发送完最后一次挥手，也就是ACK=1的信号结束后，主动关闭连接方所处的状态。 . 然后time-wait的的持续时间为2MSL. MSL是Maximum Segment Lifetime,译为“报文最大生存时间”，可为30s，1min或2min。2msl就是2倍的这个时间。工程上为2min，2msl就是4min。但一般根据实际的网络情况进行确定。 . 然后，为什么要持续这么长的时间呢？ . 原因1：为了保证客户端发送的最后一个ack报文段能够到达服务器。因为这最后一个ack确认包可能会丢失，然后服务器就会超时重传第三次挥手的fin信息报，然后客户端再重传一次第四次挥手的ack报文。如果没有这2msl，客户端发送完最后一个ack数据报后直接关闭连接，那么就接收不到服务器超时重传的fin信息报(此处应该是客户端收到一个非法的报文段，而返回一个RST的数据报，表明拒绝此次通信，然后双方就产生异常，而不是收不到。)，那么服务器就不能按正常步骤进入close状态。那么就会耗费服务器的资源。当网络中存在大量的timewait状态，那么服务器的压力可想而知。 . 原因2：在第四次挥手后，经过2msl的时间足以让本次连接产生的所有报文段都从网络中消失，这样下一次新的连接中就肯定不会出现旧连接的报文段了。也就是防止我们上一篇文章 为什么tcp是三次握手而不是两次握手？ 中说的：已经失效的连接请求报文段出现在本次连接中。如果没有的话就可能这样：这次连接一挥手完马上就结束了，没有timewait。这次连接中有个迷失在网络中的syn包，然后下次连接又马上开始，下个连接发送syn包，迷失的syn包忽然又到达了对面，所以对面可能同时收到或者不同时间收到请求连接的syn包，然后就出现问题了。 . 产生原因 通过图上，我们来分析，什么情况下，连接处于CLOSE_WAIT状态呢？ 在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。 通常来讲，CLOSE_WAIT状态的持续时间应该很短，正如SYN_RCVD状态。但是在一些特殊情况下，就会出现连接长时间处于CLOSE_WAIT状态的情况。 . 出现大量close_wait的现象，主要原因是某种情况下对方关闭了socket链接，但是我方忙与读或者写，没有关闭连接。代码需要判断socket，一旦读到0，断开连接，read返回负，检查一下errno，如果不是AGAIN，就断开连接。 . 参考资料4中描述，通过发送SYN-FIN报文来达到产生CLOSE_WAIT状态连接，没有进行具体实验。不过个人认为协议栈会丢弃这种非法报文，感兴趣的同学可以测试一下，然后把结果告诉我;-) . 为了更加清楚的说明这个问题，我们写一个测试程序，注意这个测试程序是有缺陷的。 只要我们构造一种情况，使得对方关闭了socket，我们还在read，或者是直接不关闭socket就会构造这样的情况。 . 交换机和路由器的区别 . 交换机拥有一条很高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条总线上，控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部交换矩阵迅速将数据包传送到目的端口，目的MAC若不存在则广播到所有的端口，接收端口回应后交换机会“学习”新的地址，并把它添加入内部MAC地址表中。 使用交换机也可以把网络“分段”，通过对照MAC地址表，交换机只允许必要的网络流量通过交换机。通过交换机的过滤和转发，可以有效的隔离广播风暴，减少误包和错包的出现，避免共享冲突。 交换机在同一时刻可进行多个端口对之间的数据传输。每一端口都可视为独立的网段，连接在其上的网络设备独自享有全部的带宽，无须同其他设备竞争使用。当节点A向节点D发送数据时，节点B可同时向节点C发送数据，而且这两个传输都享有网络的全部带宽，都有着自己的虚拟连接。假使这里使用的是10Mbps的以太网交换机，那么该交换机这时的总流通量就等于2×10Mbps＝20Mbps，而使用10Mbps的共享式HUB时，一个HUB的总流通量也不会超出10Mbps。 总之，交换机是一种基于MAC地址识别，能完成封装转发数据包功能的网络设备。交换机可以“学习”MAC地址，并把其存放在内部地址表中，通过在数据帧的始发者和目标接收者之间建立临时的交换路径，使数据帧直接由源地址到达目的地址。 . 从过滤网络流量的角度来看，路由器的作用与交换机和网桥非常相似。但是与工作在网络物理层，从物理上划分网段的交换机不同，路由器使用专门的软件协议从逻辑上对整个网络进行划分。例如，一台支持IP协议的路由器可以把网络划分成多个子网段，只有指向特殊IP地址的网络流量才可以通过路由器。对于每一个接收到的数据包，路由器都会重新计算其校验值，并写入新的物理地址。因此，使用路由器转发和过滤数据的速度往往要比只查看数据包物理地址的交换机慢。但是，对于那些结构复杂的网络，使用路由器可以提高网络的整体效率。路由器的另外一个明显优势就是可以自动过滤网络广播。 . SNAT 指的就是在数据包从网卡发送出去时，将数据包里面的源地址这一个部分替换成为一个指定的IP（也就是网络之间互连的协议）。这样子的话，那么接收方就会认为数据包的来源就是被替换的那个IP的主机了。 . 例如：路由器lan口接的电脑访问百度，数据包从路由器出去的时候源地址会被替换成路由器wan口的ip地址，这种行为就是SNAT。 . DNAT 网卡收到数据包的是否，将数据包里面的目的地址这一个部分替换成为一个指定的IP。这样子的话，那么接收方就会认为数据包的目的就是被替换的那个IP的主机了。 . 例如：路由器wan口收到百度返回的数据包的时候，目地址会被替换成路由器lan口下面接的pc的ip地址，这种行为就是DNAT。 . POSTROUTING和REROUTING 在POSTROUTING链后，就传出数据包，该链是整个NAT结构的最末端。执行的是修改数据包的源IP地址，即SNAT。POSTROUTING只能进行SNAT . 在数据包传入时，就进到PREROUTIING链。该链执行的是修改数据包内的目的IP地址，即DNAT（变更目的IP地址）。PREROUTING只能进行DNAT。因为进行了DNAT，才能在路由表中做判断，决定送到本地或其它网口 . 比如一台内网的机器想上internet，这时要用SNAT，将内网地址换成公网的正式IP地址；又比如内网有一台服务器想发布到公网上，让公网上的其它人来访问你，这时要用的就是DNAT。 . ",
    "url": "/docs/archives/2020/2020-04-12-core-knowledge/#%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9",
    
    "relUrl": "/docs/archives/2020/2020-04-12-core-knowledge/#核心内容"
  },"266": {
    "doc": "核心知识库",
    "title": "END",
    "content": ". ",
    "url": "/docs/archives/2020/2020-04-12-core-knowledge/#end",
    
    "relUrl": "/docs/archives/2020/2020-04-12-core-knowledge/#end"
  },"267": {
    "doc": "核心知识库",
    "title": "核心知识库",
    "content": "Core-Knowledge . 2020-04-12 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-12-core-knowledge/",
    
    "relUrl": "/docs/archives/2020/2020-04-12-core-knowledge/"
  },"268": {
    "doc": "CPython源代码分析&虚拟机原理",
    "title": "CPython源代码分析&amp;虚拟机原理",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-13-cpython-implementation/#cpython%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-04-13-cpython-implementation/#cpython源代码分析虚拟机原理"
  },"269": {
    "doc": "CPython源代码分析&虚拟机原理",
    "title": "结合编译原理&amp;CSAPP理解CPython底层实现，分支v3.8及v2.7",
    "content": "本地追踪分支 master / 2.7 / 2.8 . ",
    "url": "/docs/archives/2020/2020-04-13-cpython-implementation/#%E7%BB%93%E5%90%88%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86csapp%E7%90%86%E8%A7%A3cpython%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%88%86%E6%94%AFv38%E5%8F%8Av27",
    
    "relUrl": "/docs/archives/2020/2020-04-13-cpython-implementation/#结合编译原理csapp理解cpython底层实现分支v38及v27"
  },"270": {
    "doc": "CPython源代码分析&虚拟机原理",
    "title": "进入源代码分析之前",
    "content": ". | CPython是python的解释器实现之一 | CPython在广义上讲，就是”执行程序的程序“ | 但是与传统静态语言（C）编译驱动程序不同的是 . | C程序声明周期简介（简单介绍，核心知识点在此处不展开） . | C源代码经过预处理、编译、汇编、链接，最终生成可执行二进制，该二进制包含一系列的节，对应机器代码段、格式串、开关语句跳转表、全局变量、静态变量、符号表、调试信息等； | 可执行二进制经过fork和execve函数调用后，被加载进内存，并在操作系统栈的进程管理数据结构中创建一个 task_struck 任务结构来管理进程的基本信息；execve最终会指向.init初始化函数，也就是该程序的入口点； | 这样一个传统的可执行二进制就从源代码文件成为了一个由操作管理的正在执行的进程； | . | 概括来说，Python程序的执行包括3个阶段 . | 初始化（initialization） . | 进行对python进程所需要的一系列数据结构的初始化，交互模式下不会进行这些数据的初始化 | . | 编译（compling） . | 将py源文件中ASCII代码，生成抽象语法树 AST（Abstract syntax tree），创建AST对象，创建符号表 symbol table以及生成 code objects； | . | 解释运行（interpreting） . | 对栈中的字节码指令（Python Byte Code Instruction）上下文进行执行（code object）； | . | . | 解释器如果管理堆栈，如何创建和回收python源代码中的数据结构； . | https://nanguage.gitbook.io/inside-python-vm-cn/untitled | https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/ | . | 解释器的本质 . | . | 解释器的堆内存段管理 . | 字节码指令、字节码指令的执行过程 . | CPython本质 . | 不讨论处理细节，只考虑核心过程，本质上，CPython是一个 . | CPython执行过程的高度概括： . | 读取和检查py文件，并进行解释器和线程状态的初始化； . | 解释器 . | 解释器状态是一个简单的结构体，结构体中的字段 | *next 引用进程中的另一个解释器状态结构体； | *tstate_head 引用正在执行的线程状态，多线程下引用全局解释器锁； | 其余字段有解释器状态所有合作线程共享； | . | 线程 . | 线程结构体包括 next 和 previous 指针，指向该线程之前和之后创建的线程状态； . | interp字段指向线程状态所属于的解释器状态 . | frame字段为当前执行的栈帧 . | 本质： . | 线程状态只是一个数据结构，封装了正在执行的线程的某些状态； . | 每个线程都与正在执行的python进程内的操作系统线程关联； . | 关系 . | | Python进程 | 单进程 | . | 解释器状态 | 单进程包含一个或者多个解释器状态 | . | 线程状态 | 每个解释器状态包含一个或多个线程状态 | . | 操作系统管理的线程（控制流） | 每个线程状态的数据结构映射到操作系统的执行线程上 | . | 线程状态和OS线程如何映射：OS线程和线程状态在python的threading模块被实例化时创建 . | 所有线程中，同一时间内持有全局解释器锁的线程才能执行虚拟机中的代码对象； . | 线程由操作系统的线程控制块进行调度和资源分派，但是即使系统调度当前没有持有GIL的线程运行，该线程也必须等待获取GIL； . | 全局解释器锁GIL： . | 为了不在虚拟机内实现细颗粒度的各种锁，更明确精细的互斥锁会一定程序降低线程执行效率，简化了虚拟机的实现而存在； . | 由于引用计数，GIL提供了堆中对象的线程安全，并且CPython链接的部分共享库并非线程安全； . | CPython中GIL的实际工作过程： . GIL 只是一个布尔变量（gil_locked），其访问受到互斥锁（gil_mutex）的保护，并且其更改由条件变量（gil_cond）发出信号。 gil_mutex 的使用时间很短，因此几乎没有竞争。在 GIL 保持线程中，主循环（PyEval_EvalFrameEx）必须能够根据另一个线程的需要释放 GIL。为此使用了一个临时的布尔变量（gil_drop_request），该变量在每次 eval 循环时都会检查。在 gil_cond 上等待间隔微秒后，将设置该变量。 【 实际上，使用了另一个临时的布尔变量（eval_breaker），该变量将多个条件进行或运算。由于 Python 仅在高速缓存相关的体系结构上运行，因此，可变布尔值就足以作为线程间信号传递的手段。】这鼓励了定义的周期性切换，但由于操作码可能需要花费任意时间来执行，因此不强制执行。用户可以使用Python API sys.{get,set}switchinterval() 读取和修改时间间隔值。当一个线程释放 GIL 并设置了 gil_drop_request 时，该线程将确保安排另一个等待 GIL 的线程。它通过等待条件变量（switch_cond）直到 gil_last_holder 的值更改为其自己的线程状态指针以外的值来进行操作，这表明另一个线程能够使用 GIL。这是为了禁止多核计算机上的延迟潜伏行为，在多核计算机上，一个线程会推测性地释放 GIL，但仍然运行并最终成为第一个重新获取 GIL 的对象，这使得“时间片”比预期的长得多。 . | . | . | . | . | . | . | 将一系列python文件中的代码块进行”编译“，生成虚拟机字节码文件（pyc） . | 其中CPython有一套自己的指令集，这些指令不同于x86指令集这样的直接面向x86架构的CPU的指令集合，这些指令面对CPython内部实现的指令处理过程，这个过程的集合就可以看作为一个虚拟的”机器（机器是泛指其实就是机器处理单元）“ . | 这些指令和参数共同组成了字节码文件，可以将这个字节码文件称为Python虚拟机上的”经过汇编器汇编后的可重定向目标文件“ . | 从python源文件到字节码文件的过程包括 . | 生成parse tree | parse tree转化为AST抽象语法树 | 生成符号表 | AST转化为control flow graph | 从control flow graph生成code object | . | . | Python每个文件中的程序代码由代码块构成，如模块、函数、类定义，CPython的整个编译过程就是从代码块生成“代码对象的过程”； . | 代码对象PyCodeObject在CPython中也是一个和PyObject类似也是一个复杂的结构体，结构体中包含co_stacksize，co_flags，co_zombieframe等字段，被初始化的代码对象的结构体被存储在堆中（在PyMem_NEW(type, n)函数中调用PyMem_MALLOC函数在堆中分配内存空间）； . | 此时，完成了PyCodeObject的创建之后，解释器启动，创建单个执行主线程(在python虚拟机的过程调用中如果创建新的线程和线程状态，就会堆GIL产生竞争)； . | 堆中的代码对象的引用被传入解释器循环模块，在执行代码之前，解释器获取到当前代码对象后，会创建一个frame对象 . | frame 对象包含执行代码对象（局部，全局和内置）所需的所有名称空间，对当前执行线程的引用，用于求值字节码的堆栈以及其他对于执行字节码的内部信息； | frame对象的概念类似与C中的过程调用无法全部装载到寄存器中的时候，会在运行时栈中修改rsp指针分配栈帧； | frame对象在运行时栈中创建并保留部分成员的值，保留其他成员的栈空间，局部变量为空； | . | 类似与C的栈中的rip指针执行栈中的指令，Python虚拟机也在栈中进行过程的执行和返回，相应的指令有相应的过程进行处理（如指令：BUILD_LIST， BUILD_MAP， BUILD_CLASS），每个过程执行完成后，会从栈中弹出； . C中的过程：程序开始阶段，运行时栈的rip（程序计数器指针）指针指向入口函数，然后开始执行，例如执行主函数Q的指令，该指令指向主函数内的过程调用的函数P，这是新的函数P在栈中分配了新的栈帧，该栈帧中的过程返回后，rip指针又指向Q中调用P的那条指令，此时这条指令指向P函数的返回值； . | 在指令执行过程中创建的全局变量等PyObject也会在堆中初始化，每个数据结构的底层实现都有与之对应的C代码，如dict底层是一个使用开放寻址法解决冲突的散列表，并且有特殊的因子进行扩容； . | . | 至此，CPython底层虚拟机的运行已经完成了非常简洁的概括式讨论，实际上每个部分的实现都有细节和复杂的思想在其中； . | . 程序的静态和动态存储空间分配： . | 静态：编译器在编译阶段基于源代码就可以确定的数据大小 | 动态：只有在运行时才能确定的数据对象的大小 | . C语言的编译过程中，对于全局或者静态变量这些在编译阶段确定大小的数据结构或为0值的数据结构，会被放入在编译和汇编完成后生成的可重定向目标文件中的.data节和.bss节，链接器会基于符号表中的重定位条目来将这两个节定位到可执行文件的相应的段中；最总装载程序会将这部分数据装载到该程序虚拟内存的读写段（静态区）； . 对于一个被调用的过程，在寄存器无法满足参数存储的情况下，会在运行时栈中分配栈帧； . 而对于调用malloc进行内存分配的变量会在运行时在堆中创建； . 对于CPython程序而言，无法预知将要读取的python文件中的代码段的数量和大小，怎么才能将这些数据读入栈中； . 编译器对栈空间分配的要求是：一个数据对象局限于某个过程，且当过程结束后这个对象不可访问； . C++利用”变长数组“，大小依赖与被调用过程的一个或者多个参数值的数组来将未知大小的对象； . 程序的执行过程在生命周期中讨论 . | . | . ",
    "url": "/docs/archives/2020/2020-04-13-cpython-implementation/#%E8%BF%9B%E5%85%A5%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%89%8D",
    
    "relUrl": "/docs/archives/2020/2020-04-13-cpython-implementation/#进入源代码分析之前"
  },"271": {
    "doc": "CPython源代码分析&虚拟机原理",
    "title": "python 底层原理",
    "content": "Doc The official documentation. This is what https://docs.python.org/ uses. See also Building the documentation. Grammar Contains the EBNF grammar file for Python. Include Contains all interpreter-wide header files. Lib The part of the standard library implemented in pure Python. Mac Mac-specific code (e.g., using IDLE as an OS X application). Misc Things that do not belong elsewhere. Typically this is varying kinds of developer-specific documentation. Modules The part of the standard library (plus some other code) that is implemented in C. Objects Code for all built-in types. PC Windows-specific code. PCbuild Build files for the version of MSVC currently used for the Windows installers provided on python.org. Parser Code related to the parser. The definition of the AST nodes is also kept here. Programs Source code for C executables, including the main function for the CPython interpreter (in versions prior to Python 3.5, these files are in the Modules directory). Python The code that makes up the core CPython runtime. This includes the compiler, eval loop and various built-in modules. Tools Various tools that are (or have been) used to maintain Python. python脚本启动分析 . CPython启动流程 . | CPython的.init节包含的entry point为 Programs/python.c main函数，对于不同的平台win和unix/linux会调用不同的Py_Main函数 . | 以python3为例 ```C /* Minimal main program – everything is loaded from the library */ | . | . #include “Python.h” #include “pycore_pylifecycle.h” . #ifdef MS_WINDOWS int wmain(int argc, wchar_t **argv) { return Py_Main(argc, argv); } #else int main(int argc, char **argv) { return Py_BytesMain(argc, argv); } #endif . * 对当前操作系统环境进行判断后，Linux上调用Py_BytesMain函数 * Py_BytesMain 函数将输入文件的结构体引用传入pymain_main(&amp;args) * pymain_main 函数主要会执行一个 pymain_init 和 Py_RunMain * pymain_init主要负责 * _PyRuntime_Initialize(); 初始化python的运行时环境 * Py_InitializeFromConfig(&amp;config); 初始化python配置文件 * _PyStatus_OK(); 返回成功后 * PyConfig_Clear(&amp;config); 清楚配置文件引用 * 返回status状态 * 初始化完成后，运行Py_RunMain函数 * pymain_run_python(int *exitcode), 该函数中比较核心的部分，创建解释器，并获取其结构体指针，配置输入文件路径等； * 运行函数分为5种不同的情况 * pymain_run_command(config-&gt;run_command, &amp;cf); * pymain_run_module(config-&gt;run_module, 1); * pymain_run_module(L\"__main__\", 0); * pymain_run_file(config, &amp;cf); * pymain_run_stdin(config, &amp;cf); * 其中pymain_run_file为运行python文件，对文件进行解释。 * PySys_Audit 检查文件是否有错误，如果有直接输出并打印 * _Py_wfopen fp 打开文件，将文件进行编码，这里会判断文件是否能打开 * PyUnicode_FromWideChar PyUnicode_EncodeFSDefault 将行unicode编码 * 最终对文件的所有检查和格式化完成后 * 调用 int run = PyRun_AnyFileExFlags(fp, filename_str, 1, cf); 对文件进行解释执行 * PyRun_InteractiveLoopFlags(fp, filename, flags); 此处为执行交互模式 * PyRun_SimpleFileExFlags(fp, filename, closeit, flags); 此处为直接开始执行脚本文件 * PyObject *m, *d, *v; 创建模块，字典，执行返回值 * 判断pyc文件是否存在 * v = run_pyc_file(pyc_fp, filename, d, d, flags); 执行pyc文件 * v = PyRun_FileExFlags(fp, filename, Py_file_input, d, d, closeit, flags); 执行当前文件 * 核心代码 * mod = PyParser_ASTFromFileObject(fp, filename, NULL, start, 0, 0,flags, NULL, arena); 将python脚本文件解析为AST文件格式 * ret = run_mod(mod, filename, globals, locals, flags, arena); 将AST编译成字节码然后启动字节码解释器执行编译结果 * ```C PyInterpreterState *interp = _PyInterpreterState_GET_UNSAFE(); /* pymain_run_stdin() modify the config */ PyConfig *config = &amp;interp-&gt;config; if (config-&gt;run_command) { *exitcode = pymain_run_command(config-&gt;run_command, &amp;cf); } else if (config-&gt;run_module) { *exitcode = pymain_run_module(config-&gt;run_module, 1); } else if (main_importer_path != NULL) { *exitcode = pymain_run_module(L\"__main__\", 0); } else if (config-&gt;run_filename != NULL) { *exitcode = pymain_run_file(config, &amp;cf); } else { *exitcode = pymain_run_stdin(config, &amp;cf); } pymain_repl(config, &amp;cf, exitcode); goto done; . devguide.python devguide.python/exploring cpython-source . ",
    "url": "/docs/archives/2020/2020-04-13-cpython-implementation/#python-%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-04-13-cpython-implementation/#python-底层原理"
  },"272": {
    "doc": "CPython源代码分析&虚拟机原理",
    "title": "CPython源代码分析&虚拟机原理",
    "content": "CPython . 2020-04-13 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-13-cpython-implementation/",
    
    "relUrl": "/docs/archives/2020/2020-04-13-cpython-implementation/"
  },"273": {
    "doc": "生产环境TCP网络问题分析",
    "title": "生产环境TCP网络问题分析",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-16-tcp-network-analysis/#%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83tcp%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90",
    
    "relUrl": "/docs/archives/2020/2020-04-16-tcp-network-analysis/#生产环境tcp网络问题分析"
  },"274": {
    "doc": "生产环境TCP网络问题分析",
    "title": "服务集群的TCP网络问题分析，涉及大量TIME_WAIT原因分析及解决方案",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-16-tcp-network-analysis/#%E6%9C%8D%E5%8A%A1%E9%9B%86%E7%BE%A4%E7%9A%84tcp%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%E6%B6%89%E5%8F%8A%E5%A4%A7%E9%87%8Ftime_wait%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88",
    
    "relUrl": "/docs/archives/2020/2020-04-16-tcp-network-analysis/#服务集群的tcp网络问题分析涉及大量time_wait原因分析及解决方案"
  },"275": {
    "doc": "生产环境TCP网络问题分析",
    "title": "网络监控系统集群模型架构图",
    "content": ". 4月9日突发问题原因分析 . | 流量突增导致monitor_server服务端发送到OpenFalcon的请求大量超时 . | 上报OpenFalcon请求超时的情况又导致server端大量socket的fd（连接描述符）指向的文件句柄大量处于close状态，导致server端不断地创建新的TCP连接，又由于短链接的问题导致了TIME_WAIT状态的TCP连接也大量激增； | Socket_used，TCP_alloc，TIME_WAIT，在监控面板中的波动趋势基本相同，因为大量新建的短链接，导致大量的socket都处于使用状态，短链接的断开又导致了大量的TIME_WAIT，但是又由于通过这些连接交付的数据无法快速写回响应，导致http超时断开，这里又导致了server内部处理错误code 500的日志输出； | . | 情况的进一步恶化： . | 当monitor_server 的 tornado web接收来自agent的大量请求时，由于接收agent数据以及处理数据和发送metric在同一条控制流中进行，这就导致tornado无法对创建的socket进行快速写回响应，又导致epoll无法实现连接的多路复用（复用连接写会对本地ng的响应），当本地nginx转发和server的listening端口，能创建的socket达到峰值时（因为端口数量有限65535，又由于一个socket是用{源ip} {源端口} {目的ip} {目的端口} 这个四元组来表示唯一性，所以socekt的创建有端口数量的限制，而且连接发起端占用的65535个端口要对应到30个listen端口上)，这就导致了健康检查发起的新的http请求无法写入socket（因为目的socket没有及时写回导致源端socket处于close，且无法新建TCP连接），这就导致了 看到的hc.do的接口没有任何反应（因为他的上下文在等待文件open的IO事件的调度），这就导致了ngnix自动移除了对当前server的转发； | nginx不断地移除server，只会导致问题更加恶化，因为agent端的数据请求不受后端server的影响，还在源源不断的进行发送； | 最终整个系统会一直处于一个nginx不断移除和加入server实例，且还是有持续大量http请求的超时、TCP新建、TIME_WAIT; | 此时后端的服务实例进入了恶性循环； | . | . 现存问题 . 登陆任意一台server . netstat -npt | grep 127.0.0.1:51005 # agent到server的报文，使用了TCP短链接，经过二层转发后到达server； # 大量新创建的tcp连接和处于被动拆除状态LAST_ACK的连接 netstat -ntp | grep 127.0.0.1 | grep 12057 # 发送到回环地址的报文段，报文从server发送到nginx的12057端口，使用了TCP短连接，大量新创建的tcp连接和TIME_WAIT状态的连接 netstat -npt | grep 127.0.0.1 # OpenFalcon数据上报，使用了TCP短连接，大量新创建的tcp连接和TIME_WAIT状态的连接 netstat -ntp | grep -E \"127.0.0.1|127.0.0.1|127.0.0.1\" # 发送到转存服务的报文段，使用了TCP短连接，大量新创建的tcp连接和TIME_WAIT状态的连接 . ",
    "url": "/docs/archives/2020/2020-04-16-tcp-network-analysis/#%E7%BD%91%E7%BB%9C%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E5%9B%BE",
    
    "relUrl": "/docs/archives/2020/2020-04-16-tcp-network-analysis/#网络监控系统集群模型架构图"
  },"276": {
    "doc": "生产环境TCP网络问题分析",
    "title": "生产环境TCP网络问题分析",
    "content": "TCP&amp;IP . Network . Socket . 2020-04-16 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-16-tcp-network-analysis/",
    
    "relUrl": "/docs/archives/2020/2020-04-16-tcp-network-analysis/"
  },"277": {
    "doc": "现代操作系统",
    "title": "现代操作系统",
    "content": "Unix/Linux 操作系统基本原理和源代码分析 . A namespace in computer science (sometimes also called a name scope), is an abstract container or environment created to hold a logical grouping of unique identifiers or symbols (i.e. names). An identifier defined in a namespace is associated only with that namespace. ",
    "url": "/docs/archives/2020/2020-04-20-operating-system/#%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F",
    
    "relUrl": "/docs/archives/2020/2020-04-20-operating-system/#现代操作系统"
  },"278": {
    "doc": "现代操作系统",
    "title": "现代操作系统",
    "content": "Operating-System . Linux . 2020-04-20 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-20-operating-system/",
    
    "relUrl": "/docs/archives/2020/2020-04-20-operating-system/"
  },"279": {
    "doc": "I/O的多路复用算法",
    "title": "I/O的多路复用算法",
    "content": "io-multiplexing: select/poll/epoll . 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) . epoll的优点主要是一下几个方面： . | 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 . | IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。 如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。 . | . ",
    "url": "/docs/archives/2020/2020-04-20-select-poll-epoll/#io%E7%9A%84%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E7%AE%97%E6%B3%95",
    
    "relUrl": "/docs/archives/2020/2020-04-20-select-poll-epoll/#io的多路复用算法"
  },"280": {
    "doc": "I/O的多路复用算法",
    "title": "I/O的多路复用算法",
    "content": "IO-Multiplexing . Select . Poll . Epoll . 2020-04-20 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-20-select-poll-epoll/",
    
    "relUrl": "/docs/archives/2020/2020-04-20-select-poll-epoll/"
  },"281": {
    "doc": "Python&CPython核心",
    "title": "Python&amp;CPython核心",
    "content": "“生成器与协程、CPython虚拟机原理、CPython解释器原理、内存管理与引用计数与优化、高级第三方库、Python语法魔术” . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#pythoncpython%E6%A0%B8%E5%BF%83",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#pythoncpython核心"
  },"282": {
    "doc": "Python&CPython核心",
    "title": "CPython核心",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#cpython%E6%A0%B8%E5%BF%83",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#cpython核心"
  },"283": {
    "doc": "Python&CPython核心",
    "title": "I. 虚拟机工作原理&amp;CPython源代码&amp;工作方式",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#i-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86cpython%E6%BA%90%E4%BB%A3%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#i-虚拟机工作原理cpython源代码工作方式"
  },"284": {
    "doc": "Python&CPython核心",
    "title": "Evaluation Loop ceval.c",
    "content": ". | Python虚拟机的 核心部分，迭代执行python字节码指令；迭代执行的实现依靠 for 循环； | Python/ceval.c 模块，包含实现执行部分的核心代码，核心函数为 PyEval_EvalFrameEx，该函数中包含执行循环； | ceval.c 模块会针对不同的平台或者操作系统类型，进行对线程和虚拟机有不同的优化； | . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#evaluation-loop-cevalc",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#evaluation-loop-cevalc"
  },"285": {
    "doc": "Python&CPython核心",
    "title": "执行循环的工作原理",
    "content": ". | 执行前的准备工作 initialization &amp; prepare context . | _PyEval_EvalCodeWithName . | 代码对象从代码块创建，在python源代码中，代码块包含函数、模块、类、装饰器等等； | 从代码块创建的代码对象会经过一连串的函数调用 run_mod -&gt; PyEval_EvalCode -&gt; PyEval_EvalCodeEx -&gt; _PyEval_EvalCodeWithName -&gt; PyEval_EvalFrameEx | _PyEval_EvalCodeWithName 的过程包括 . | 初始化“帧对象”，用来提供执行“代码对象”的上下文 | 为“frame fast locals” 添加 dict 关键词 | 为 “fastlocals” 添加位置参数 positional arguments （python函数中的*args类型的参数） | 将 无位置变量序列 non-positional variable sequence 和 无关键词参数 non-keyword arguments 添加到 fastlocals数组，这些变量都被存放在 元组 类型的数据结构中；（python函数中的*args，**kwargs类型的参数） | 检查代码块是否有提供或是否重复提供 kwargs 类型的参数； | 检查是否缺少*args位置参数，如果发现缺少则抛出错误 | 添加默认参数到 fastlocals 数组 | 初始化存储空间和单元变量（storage and cell variables）并拷贝空闲变量数组到当前帧中； | . | . | . | 循环的执行 Evaluation Loop . | 始化过程完成后，PyEval_EvalFrameEx会以参数的形式调用帧（frame object）； . | PyEval_EvalFrameEx 会进行C的优化，例如宏和计算gotos； . | Evaluation Loop中的核心重要变量 （ceval.c） . | **stack_pointer，引用下一个要执行的“执行帧”的空闲槽（free slot）； | *next_instr，引用执行循环需要执行的下一个指令；可以将该变量视为C程序内存中栈帧的程序计数器指针%rip | opcode，引用当前正在执行的opcode或者将要执行的opcode | oparg，引用当前执行或将要执行的opcode所需参数 | why，执行循环 Evaluation Loop 是一个无线循环 - for(;;)，执行循环需要跳出或终止条件，该变量引用当前要跳出循环的原因；例如跳出循环的原因是因为代码快函数的返回，该变量则应用“WHY_RETURN”状态； | fastlocals，引用保存了本地变量的数组 | freevars，引用，变量名称列表，但是这些名称在代码块中并没有被定义； | retval，引用代码快的返回值； | co，引用了代码对象，参考虚拟机原理，该对象保存着执行循环的“字节码指令”和过程变量； | names，引用了“执行帧对象”的代码块中所有值的名称； | consts，引用了代码对象中使用的常量； 回顾虚拟机字节码 python vm bytecode instruction 字节码长度为 16bit，Python虚拟机使用小端法（最低最前，大多数机器都是用小端法表示地址，16进制的最低有效位存储从虚拟内存低地址位开始存储） 字节码包含两个字节，第一个字节存放OPARG，第二个字节存放OPCODE； . | . | 8bit | 8bit | . | OPARG | OPCODE | . | 重要的C宏 . | TARGET(op) 定义#define TARGET(op) ，扩展为case op，将当前要执行的字节码和代码快的实现进行匹配； | DISPATCH，扩展为 continue，和宏 - FAST_DISPATCH，用来处理执行循环执行完该opcode之后的“控制流”； | FAST_DISPATH，扩展为跳入fast_next_opcode标签； | . | 处理字节码相关的C宏 . | INSTR_OFFSET()，这个宏在当前的指令数组中为指令提供“字偏移” | NEXTOPARG()，这个宏用来更新下一个要执行的指令和过程变量的opcode和oparg变量； | . | 执行循环过程分析 | . | . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#%E6%89%A7%E8%A1%8C%E5%BE%AA%E7%8E%AF%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#执行循环的工作原理"
  },"286": {
    "doc": "Python&CPython核心",
    "title": "II. 内存管理和底层数据结构的实现及数据结构的内存分配、回收、扩容 “heap”",
    "content": "优化 . | 最小开销的python代码中变量创建和管理 | Py_INCREF和Py_DECREF了，它们都是内存管理函数。CPython使用引用计数来管理对象的生命周期。一旦新建引用指向对象，那么Py_INCREF会将对象的引用递增，一旦引用超出作用域，Py_INCREF就会递减对象的引用。 | 垃圾回收分析 . | python的垃圾回收发生的条件 . https://docs.python.org/2/library/gc.html 官方文档：The GC classifies objects into three generations depending on how many collection sweeps they have survived. New objects are placed in the youngest generation (generation 0). If an object survives a collection it is moved into the next older generation. Since generation 2 is the oldest generation, objects in that generation remain there after a collection. In order to decide when to run, the collector keeps track of the number object allocations and deallocations since the last collection. When the number of allocations minus the number of deallocations exceeds threshold0, collection starts. Initially only generation 0 is examined. If generation 0 has been examined more than threshold1 times since generation 1 has been examined, then generation 1 is examined as well. Similarly, threshold2 controls the number of collections of generation 1 before collecting generation 2. | python内存管理的三层结构 . | generation 0：新建的对象 . | generation 1：垃圾回收后，任然存在引用，则归入1 . | generation 2：最老的无法被collection函数回收的对象 . | . | 回收机制会在内存分配数量和取消分配数量的差值超过 一个特定的阈值 才会触发 . | 通过gc模块，可以查看默认的阈值，且可以通过调用set_threshold函数，配置定制的阈值 . import gc gc.get_threshold() #gc模块中查看阈值的方法 (700, 10, 10) . | . | 这里的解释是：阈值超过700时才会对g0的对象进行回收，每10次回收g0会发生1次回收g1，每10次回收g1会发生1次回收g2； | gc模块提供主动触发垃圾回收的函数 def collect(generation=None) collect([generation]) -&gt; n . With no arguments, run a full collection. The optional argument may be an integer specifying which generation to collect. A ValueError is raised if the generation number is invalid. | 对于不传入参数的调用来说，会发起g0 g1 g2三代的全部的回收； . | CPython对C运行库提供的free函数的调用，也存在一定的条件 | 第3层：最上层，用户对Python对象的直接操作 | . | 第1层和第2层：内存池，有Python的接口函数PyMem_Malloc实现-----若请求分配的内存在1~256字节之间就使用内存池管理系统进行分配，调用malloc函数分配内存，但是每次只会分配一块大小为256K的大块内存，不会调用free函数释放内存，将该内存块留在内存池中以便下次使用。 . | 第0层：大内存-----若请求分配的内存大于256K，malloc函数分配内存，free函数释放内存； | . | . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#ii-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%92%8C%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%9B%9E%E6%94%B6%E6%89%A9%E5%AE%B9-heap",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#ii-内存管理和底层数据结构的实现及数据结构的内存分配回收扩容-heap"
  },"287": {
    "doc": "Python&CPython核心",
    "title": "III. 生成器和协程 generator &amp; coroutine",
    "content": "生成器对象 generator . /* _PyGenObject_HEAD defines the initial segment of generator and coroutine objects. */ #define _PyGenObject_HEAD(prefix) \\ PyObject_HEAD \\、 /* Note: gi_frame can be NULL if the generator is \"finished\" */ \\ struct _frame *prefix##_frame; \\ /* True if generator is being executed. */ \\ char prefix##_running; \\ /* The code object backing the generator */ \\ PyObject *prefix##_code; \\ /* List of weak reference. */ \\ PyObject *prefix##_weakreflist; \\ /* Name of the generator. */ \\ PyObject *prefix##_name; \\ /* Qualified name of the generator. */ \\ PyObject *prefix##_qualname; \\ _PyErr_StackItem prefix##_exc_state; typedef struct { /* The gi_ prefix is intended to remind of generator-iterator. */ _PyGenObject_HEAD(gi) } PyGenObject; . | 结构底层定义为 _PyGenObject_HEAD, 结构体对象为PyGenObject . | 在生成器对象中包含了 帧对象的引用 和 代码对象的引用，回顾python虚拟机实现可知，代码对象在运行时会生成帧对象，解释器对帧对象进行执行，其中包含了代码对象中的Python虚拟机指令和过程变量； | 运行的生成器提供了 “suspended”阻塞 和 “resumed”就绪 的状态切换的功能； | 定义的属性包括和宏 . | *prefix##_frame . | 帧对象，包含生成器对象的代码对象引用，用来执行该对象 | . | prefix##_running . | 布尔值，用来确定当前的生成器是否还在运行 | . | *prefix##_code . | 代码对象引用，生成器用来执行的对象 | . | *prefix##_name . | 生成器名称 | . | *prefix##_qualname . | “qualified” 的名称，多数情况下和_name相同； | . | . | . | 生成器和协程运行原理 . | 生成器通过对内置next python函数的调用来执行，当遇到yield python内置表达式时，生成器会发生阻塞； | 生成器如何保存和获取执行状态，又是怎样在遇到特定的状态是对当前的执行进行状态的更新的 . | 如何保存执行状态 . | 生成器对象中保存着当前帧对象的引用，该引用中包含了所有生成器需要执行的上下文（代码对象），通过对帧对象的引用，生成器可以捕获执行过程中的所有状态；（状态可以指过程的python虚拟机指令及变量） | . | yield 表达式 . | 生成器的执行过程中，在遇到yield语句时会发生主动放弃或让出当前执行时间片，然后Python虚拟机会对当前的生成器的状态进行保存，时间片发生轮转； | . | 生成器如何完成调度（这里的调度就是生成器的阻塞和就绪的状态切换，且生成器需要主动放弃当前执行的权限，或者说执行的时间片） . | next内置函数，当生成器调用next内置函数，next函数的主要作用是对已经发生阻塞的生成器恢复执行，该函数会完成两个作用 . | 对当前的指针 “tp_iternext” 解除引用，”tp_iternext” 可以理解为python虚拟机的程序计数器指针，每个运行的线程或者生成器对象在执行期间都会引用程序计数器，从而告诉虚拟机下一条要执行的指令； | 随机调用 “tp_iternext” 程序计数器关联的任何其他函数，对于当前线程的其他生成器来说，会调用 gen_iternext -&gt; gen_send_ex，最终通过该函数的调用会重新执行之前被阻塞的生成器； | . | 通过以上两种方式生成器/协程实现了在Python虚拟机内部的时间片轮转； | . | Python的生成器同样支持参数传递； | . | . | . 调度 . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#iii-%E7%94%9F%E6%88%90%E5%99%A8%E5%92%8C%E5%8D%8F%E7%A8%8B-generator--coroutine",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#iii-生成器和协程-generator--coroutine"
  },"288": {
    "doc": "Python&CPython核心",
    "title": "IV. 线程状态对象&amp;CIL结构对象&amp;解释器对象",
    "content": "调度 . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#iv-%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%AF%B9%E8%B1%A1cil%E7%BB%93%E6%9E%84%E5%AF%B9%E8%B1%A1%E8%A7%A3%E9%87%8A%E5%99%A8%E5%AF%B9%E8%B1%A1",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#iv-线程状态对象cil结构对象解释器对象"
  },"289": {
    "doc": "Python&CPython核心",
    "title": "V. 对象&amp;对象管理",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#v-%E5%AF%B9%E8%B1%A1%E5%AF%B9%E8%B1%A1%E7%AE%A1%E7%90%86",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#v-对象对象管理"
  },"290": {
    "doc": "Python&CPython核心",
    "title": "VI. 内置方法的高级用法",
    "content": "数据模型 . | datamodel | 元类 __metaclass__ . | datamodel | python中默认情况下，类型由type()函数构成，类的主体会创建一个新的namespace用于执行，类名会和type(name, bases, namespace)进行绑定； | python可以在类声明行中传递 metaclass keyword argument 实现元类，或者通过对传递了该参数的类进行继承，原来需要继承自type； | 元类就是其父类继承自type的类型（子孙类都可以实现元类）； | 类定义中指定的任何其他关键字参数都将传递到下面描述的所有元类操作； | 当类定义被执行后，发生了以下的步骤： . | MRO 入口处理 | 确定该类型适当的元类 | 准备类型的命名空间 | 执行类型主体 | 类型对象呗创建并返回 | . | . | . class Singleton(type): __instance = {} def __int__(self, *args, **kwargs): super(Singleton, self).__init__(*args, **kwargs) def __call__(cls, *args, **kwargs): if cls not in cls.__instance: cls.__instance[cls] = super(Singleton, cls).__call__(*args, **kwargs) return cls.__instance[cls] class Publisher(): __metaclass__ = Singleton def __init__(self): pass class Meta(type): pass class MyClass(metaclass=Meta): pass class MySubclass(MyClass): pass . | 抽象基类 ABC | __class__ . | 该方法可以访问当前实例的类，通过该函数可以修改一个实例对象对某个类的引用； | . | __new__ . | 静态方法，在python的语法中，一切皆对象，__new__ 方法用来创建新的类的实例，该方法的调用中，cls也就是类对象要作为第一个参数，其他参数用来传递给__new__来构造新的对象，新的对象可能是类的实例，也可能是一个新的类型； | 在 __new__ 实现中，如果需要实现对父类的调用，可以使用 super().__new__(cls[, ...]) 并且需要传入父类所需要的基本参数，获得父类实例后再进行任何其他修改； | 在 __new__ 实现中，如果需要实现对父类的类对象调用，可以使用 super(xxx, cls).__new__(cls[, ...]) ，可以获得新的类型，对于在对象构造期间调用 __new __（） 并返回cls的实例或子类，则将像 __init __（self [，...]） 一样调用新实例的 __init __（） 方法，其中self是新实例，而 其余参数与传递给对象构造函数的参数相同。 | 如果__new__(), 方法调用没有返回任何实例或者子类，那么新实例的__init __（）方法就不会被调用； | __new__ 核心作用 . | 主要是允许 不可变 类型的子类，自定义的创建实例； | 也用来实现自定义的类和其属性的实现； | 通常也被自定义元类覆盖。 | . | . | . def __new__(cls, **kwargs): new_cls = super(DataModel, cls).__new__(cls) for k, v in kwargs.iteritems(): if hasattr(DataModel, k): setattr(new_cls, k, v) return new_cls . | __init__ . | 在实例创建完成后调用（通过__new __（）），但在实例返回给调用方之前被调用。 参数是传递给类构造函数表达式的参数。 如果基类具有__init __（）方法，则派生类的__init __（）方法（如果有）必须显式调用它，以确保实例的基类部分的正确初始化。 例如：super（）.__ init __（[args ...]）。 | 子类中如果想要调用父类的__init __（）方法，必须在__init __（）中通过super（）显示的调用； | 因为__new __（）和__init __（）在构造对象时一起工作（__new __（）来创建它，而__init __（）来对其进行自定义），所以__init __（）不能返回任何非None值； 这样做将导致在运行时引发TypeError。 | . | __call__ . | 该方法会在一个对象被当做函数调用的情况下，调用，object.__call__(self[, args...]), object() | 通过在类中定义__call __（）方法，可以使任意类的实例成为可调用的。 | python的任何对象都可以使用callable()来判断是否可调用，对于不可调用的对象，只需要在对象中实现__call__方法，例如在元类中实现call方法，则继承元类的子类在生成实例时就会调用； | . | 总结 . | 单例的多种实现方式在类中重写__new __（），类继承元类，并在元类中使用__call__() 方法实现，装饰器实现； | There is no fucking magic, all the implementation are from CPython pyobjectclass; | . | . class Singleton(type): __instance = {} def __call__(cls): print \"metaclass __call__\" if cls not in cls.__instance: cls.__instance[cls] = super(Singleton, cls).__call__() return cls.__instance[cls] class BasicSub(object): __metaclass__ = Singleton def __init__(self): print \"__init__\" super(BasicSub, self).__init__() def __new__(cls): print \"__new__\" self = super(cls, BasicSub).__new__(cls) return self def __call__(self): print \"__call__\" a = BasicSub() a() . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#vi-%E5%86%85%E7%BD%AE%E6%96%B9%E6%B3%95%E7%9A%84%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#vi-内置方法的高级用法"
  },"291": {
    "doc": "Python&CPython核心",
    "title": "VII. 高级第三方库的实现",
    "content": "Web框架 . 并发框架 . | futures | Gevent . | 基于C的高性能事件循环模型库libev，实现的基于API和网络相关任务的并发模型； | . | greenlet | . C实现的第三方库 . https://github.com/python/cpython/blob/master/Python/ceval.c . https://www.cnblogs.com/qdhxhz/p/9757390.html . https://redis.io/commands . openstack https://blog.csdn.net/dylloveyou/article/details/80698420 . socket fd https://www.cnblogs.com/DengGao/p/file_symbol.html . mmap https://www.cnblogs.com/huxiao-tee/p/4660352.html . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#vii-%E9%AB%98%E7%BA%A7%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93%E7%9A%84%E5%AE%9E%E7%8E%B0",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#vii-高级第三方库的实现"
  },"292": {
    "doc": "Python&CPython核心",
    "title": "VIII.",
    "content": " ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#viii",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#viii"
  },"293": {
    "doc": "Python&CPython核心",
    "title": "Python Runtime Services",
    "content": "Runtime Services . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/#python-runtime-services",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/#python-runtime-services"
  },"294": {
    "doc": "Python&CPython核心",
    "title": "Python&CPython核心",
    "content": "CPython . Python . 2020-04-26 10:00:00 +0800 . ",
    "url": "/docs/archives/2020/2020-04-26-python-core/",
    
    "relUrl": "/docs/archives/2020/2020-04-26-python-core/"
  },"295": {
    "doc": "时序数据完整性的方法巡检工具",
    "title": "程序设计时序图",
    "content": ". ",
    "url": "/docs/archives/2020/2020-05-13-data-patrol/#%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%97%B6%E5%BA%8F%E5%9B%BE",
    
    "relUrl": "/docs/archives/2020/2020-05-13-data-patrol/#程序设计时序图"
  },"296": {
    "doc": "时序数据完整性的方法巡检工具",
    "title": "如图所示：",
    "content": ". | 将监控数据接入消息队列后，监控数据可以进行多路复用，将监控数据接入审计工具；审计工具的主要功能包括： . | 监控数据每个采集间隔内的完整性； | 监控数据是否发生完全丢失； | 监控对象和其上报的监控指标是否覆盖全部初始配置。 | . | 审计工具的实现方式，将每个监控项的10个单位内的时间戳放在缓存栈内，每经过一个周期，各个栈对应的线程会做数据完整性的检查；检查结果会通过相应的事件存储在数据库中； | 图为审计工具的时序图，图中以Golang的协程为基础单位，展示了数据处理的全部流程和并发情况； | Consumer的协程会连接消息队列，实时接收消息并通过通信管道将消息分发到数量为1000的DataDistribution协程中，DataDistribution会对消息做相对应的拆封，将每个拆封后的数据发送到它对应监控对象的处理协程中，处理协程会做数据缓存并每个周期检测缓存栈，为了防止过多的协程导致阻塞和饥饿，每个协程会设置10分钟的超时，如果十分钟内没有进行数据处理，就会将自己杀掉，数据最终会发给事件上报的协程，从而实现事件的存储和前端展示； | . Source Code . ",
    "url": "/docs/archives/2020/2020-05-13-data-patrol/#%E5%A6%82%E5%9B%BE%E6%89%80%E7%A4%BA",
    
    "relUrl": "/docs/archives/2020/2020-05-13-data-patrol/#如图所示"
  },"297": {
    "doc": "时序数据完整性的方法巡检工具",
    "title": "时序数据完整性的方法巡检工具",
    "content": "Go . RabbitMQ . Data-Patrol . 2020-05-13 17:46:51 +0800 . ",
    "url": "/docs/archives/2020/2020-05-13-data-patrol/",
    
    "relUrl": "/docs/archives/2020/2020-05-13-data-patrol/"
  },"298": {
    "doc": "Linux常用工具&内置命令",
    "title": "Linux常用工具&amp;内置命令",
    "content": " ",
    "url": "/docs/archives/2020/2020-05-13-linux-command-tools/#linux%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4",
    
    "relUrl": "/docs/archives/2020/2020-05-13-linux-command-tools/#linux常用工具内置命令"
  },"299": {
    "doc": "Linux常用工具&内置命令",
    "title": "Linux 工具箱",
    "content": " ",
    "url": "/docs/archives/2020/2020-05-13-linux-command-tools/#linux-%E5%B7%A5%E5%85%B7%E7%AE%B1",
    
    "relUrl": "/docs/archives/2020/2020-05-13-linux-command-tools/#linux-工具箱"
  },"300": {
    "doc": "Linux常用工具&内置命令",
    "title": "I. 常用工具命令",
    "content": "按路径检查磁盘利用率 . NAME du - estimate file space usage USAGE du -h --max-depth 1 | sort -hr . 快速杀掉某程序所有进程 . ps -ef | grep {NAME} | awk -F ' ' '{ print $2}' | xargs kill -9 . 清除DNS缓存 . nscd -g #查看统计信息 nscd -i passwd nscd -i group nscd -i hosts rm -f /var/db/nscd/hosts service nscd restart #修改 /etc/nscd.conf enable-cache hosts yes . sublime 反相匹配 . ^(?!.*InstanceId).+ . python 正则表达式反向 . | 匹配符（…代表匹配内容） | 描述 | . | (?!.*…) | 字符内容不匹配才能匹配成功 | . | […] | 匹配字符集，例如只匹配空格和制表符，不能使用\\s，而是[\\t ] | . find 高级查询 . find ../ -type f -name \"*.py[co]\" -delete find /（查找范围） -name '查找关键字' -type d . ",
    "url": "/docs/archives/2020/2020-05-13-linux-command-tools/#i-%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%91%BD%E4%BB%A4",
    
    "relUrl": "/docs/archives/2020/2020-05-13-linux-command-tools/#i-常用工具命令"
  },"301": {
    "doc": "Linux常用工具&内置命令",
    "title": "Linux常用工具&内置命令",
    "content": "Linux . 2020-05-13 17:17:18 +0800 . ",
    "url": "/docs/archives/2020/2020-05-13-linux-command-tools/",
    
    "relUrl": "/docs/archives/2020/2020-05-13-linux-command-tools/"
  },"302": {
    "doc": "pg数据库过程事务执行的锁竞争导致锁表",
    "title": "pg数据库过程事务执行的锁竞争导致锁表",
    "content": "问题描述：pg数据库200+进程在同一分钟内对过程事务进行访问，事务在执行过程中会先后竞争 exclusive 和 raw exclusive 两个锁，由于持有锁并等待锁导致数据库锁表（t_device）, 被锁数据表无法进行任何操作和访问；且连接无法释放导致数据库访问连接达到pool的max值； . ",
    "url": "/docs/archives/2020/2020-05-13-pg-dead-lock/#pg%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%87%E7%A8%8B%E4%BA%8B%E5%8A%A1%E6%89%A7%E8%A1%8C%E7%9A%84%E9%94%81%E7%AB%9E%E4%BA%89%E5%AF%BC%E8%87%B4%E9%94%81%E8%A1%A8",
    
    "relUrl": "/docs/archives/2020/2020-05-13-pg-dead-lock/#pg数据库过程事务执行的锁竞争导致锁表"
  },"303": {
    "doc": "pg数据库过程事务执行的锁竞争导致锁表",
    "title": "修复方案：",
    "content": ". | 将mark_device的复杂过程事务改为 agent heart beat的心跳上报； | 将监控设备的分配逻辑迁移到监控设备同步的功能上进行； | . 查询SQL . select count(*) from pg_stat_activity where wait_event_type = 'Lock'; select client_addr,client_port,wait_event_type,wait_event,state,query,backend_start,xact_start,query_start,state_change from pg_stat_activity where wait_event_type = 'Lock'; select count(*) from pg_stat_activity where wait_event_type is NULL OR wait_event_type = 'Lock'; select client_addr,client_port,backend_start,xact_start,query_start,state_change,wait_event_type,wait_event,state,query from pg_stat_activity where wait_event_type is NULL OR wait_event_type = 'Lock'; select count(*) from pg_stat_activity; select client_addr,client_port,backend_start,xact_start,query_start,state_change,wait_event_type,wait_event,state,query from pg_stat_activity; select client_addr,client_port,query,backend_start,xact_start,query_start,state_change,wait_event_type,wait_event,state from pg_stat_activity WHERE query NOT LIKE '%mark_device%'; . 锁表连接数 . ",
    "url": "/docs/archives/2020/2020-05-13-pg-dead-lock/#%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%A1%88",
    
    "relUrl": "/docs/archives/2020/2020-05-13-pg-dead-lock/#修复方案"
  },"304": {
    "doc": "pg数据库过程事务执行的锁竞争导致锁表",
    "title": "pg数据库过程事务执行的锁竞争导致锁表",
    "content": "PostgreSQL . 2020-05-13 15:43:29 +0800 . ",
    "url": "/docs/archives/2020/2020-05-13-pg-dead-lock/",
    
    "relUrl": "/docs/archives/2020/2020-05-13-pg-dead-lock/"
  },"305": {
    "doc": "Data Sampling [Redis]",
    "title": "监控覆盖率检查和数据完整性检查【2020-4】",
    "content": " ",
    "url": "/docs/archives/2020/2020-05-13-redis_data_sampling/#%E7%9B%91%E6%8E%A7%E8%A6%86%E7%9B%96%E7%8E%87%E6%A3%80%E6%9F%A5%E5%92%8C%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E6%A3%80%E6%9F%A52020-4",
    
    "relUrl": "/docs/archives/2020/2020-05-13-redis_data_sampling/#监控覆盖率检查和数据完整性检查2020-4"
  },"306": {
    "doc": "Data Sampling [Redis]",
    "title": "方案一，单节点",
    "content": " ",
    "url": "/docs/archives/2020/2020-05-13-redis_data_sampling/#%E6%96%B9%E6%A1%88%E4%B8%80%E5%8D%95%E8%8A%82%E7%82%B9",
    
    "relUrl": "/docs/archives/2020/2020-05-13-redis_data_sampling/#方案一单节点"
  },"307": {
    "doc": "Data Sampling [Redis]",
    "title": "方案二，可横向扩展集群",
    "content": ". 方案： . monitor-torrent负责与redis保持连接，对应key更新当前数据value和最新的timestamp及count进行++，数据模型为 key = {endpoint} + {metric} + {tag} 注：遇到key中tag过长可以进行一定的压缩处理 value 为redis-list 值都为redis-integer 1) {value} 2) {timestamp} 3) {count} monitor-patrol . | 多个实例的情况下，需要考虑如何读取redis中的数据，如何触发读取； a. 问题点 i. 读取过程的耗时问题 ii. 读取数据如何平均分配到多个节点 | 单个实例的情况下，如何快速的读取是比较严重的问题 | . 所有对于数据断点的检查本身还是需要将数据保存在本机内存中，但是需要实现的双机的高可用，可以利用redis做监控覆盖检查； 对于数据的检查方式 . | 固定时段内计点 | 每个map数据中的timestamp相见 利用redis完全可以实现第二点，但是第一种方式对于数据的完全丢失有监测作用，使用redis必然要考虑分布式锁； | . 问题的本质： 断点监测的本质，就是在一个超大的哈希表中更新并检查当前一段时间的count值，对于这个检查的单个过程的执行指令并不多且不复杂，但是每次的检查涉及到哈希表的更新和协程的中断和上下文切换，线程安全和大量的上下文切换是需要考虑的主机计算资源压力点； 方案： 需要进行严格的单节点程序的压力测试，以获取程序的瓶颈； . 将比对和计算压力分摊到redis 思路描述： . | 使用redis 的可以设置元素过期的数据结构存储监控项 | 在redis 中使用原生的方法比对获取当前异常的监控 | . ",
    "url": "/docs/archives/2020/2020-05-13-redis_data_sampling/#%E6%96%B9%E6%A1%88%E4%BA%8C%E5%8F%AF%E6%A8%AA%E5%90%91%E6%89%A9%E5%B1%95%E9%9B%86%E7%BE%A4",
    
    "relUrl": "/docs/archives/2020/2020-05-13-redis_data_sampling/#方案二可横向扩展集群"
  },"308": {
    "doc": "Data Sampling [Redis]",
    "title": "方案三，时间戳比对和数据对象未到达超时的开销分摊给redis",
    "content": "方案思路 . | 用monitor-torrent将监控数据对象以key-value形式写入redis集群 数据模型 key = {endpoint} + {metric} + {tag} 注：遇到key中tag过长可以进行一定的压缩处理 value {timestamp} | redis中初始创建数据对象时，对每个key设置一定的超时，并配置超时通知事件，如180s，当数据对象的value在超时事件内没有发生更新时，表示当前数据发生了断点，当再次新建该key时，表示数据恢复，如果无新建表示数据丢失； a. 需要订阅的通知事件 i. key超时通知 ii. key新建通知 | 单独使用新的进程订阅redis的事件通知，对事件进行聚合和录入关系库； 横向扩展：只需要考虑redis集群的横向扩展； | 当前进度，redis写入测试阶段 | . ",
    "url": "/docs/archives/2020/2020-05-13-redis_data_sampling/#%E6%96%B9%E6%A1%88%E4%B8%89%E6%97%B6%E9%97%B4%E6%88%B3%E6%AF%94%E5%AF%B9%E5%92%8C%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E6%9C%AA%E5%88%B0%E8%BE%BE%E8%B6%85%E6%97%B6%E7%9A%84%E5%BC%80%E9%94%80%E5%88%86%E6%91%8A%E7%BB%99redis",
    
    "relUrl": "/docs/archives/2020/2020-05-13-redis_data_sampling/#方案三时间戳比对和数据对象未到达超时的开销分摊给redis"
  },"309": {
    "doc": "Data Sampling [Redis]",
    "title": "方案四，监控覆盖率",
    "content": "方案描述 . | 用monitor-torrent将监控数据对象以key-value形式写入redis集群 . | 数据模型 . | key: {endpoint} + {metric} | value: {timestamp} | . | . | 写入方式是，monitor-torrent在一个时间段内（例如20分钟）的timer内将收到的endpoint和metric写入本地map，如果已经存在，则无需更新，这样就完成了20内对数据对象的取样； | timer结束后，将该map全量写入redis集群 | redis批量写入测试 | . | benchmark结果 . | 一百四十万个数据对象完全的传输和写入耗时为6 ~12秒 | 连续5次基准测试的耗时在6 ~12秒 | . | 实现方式 . | 创建连接池，并且保持TCP连接，此处可以自定义一个空闲的TCP连接保持时间，和最小空闲连接数据，及连接池最大连接数； | 初始化pipeline对象，go-redis通过将redis命令从多条TCP连接一次性发送到redis集群或者服务节点，大大减小了I/O开销； | . | . 基准测试源代码 . package benchmark import ( \"code.test.com.cn/test-monitor/monitor/monitor-patrol/sdk/httputil\" \"encoding/json\" \"fmt\" \"github.com/go-redis/redis\" \"time\" ) type d_dev struct { Sysname string `json:\"sysname\"` } type metric struct { Metrics []string `json:\"metric\"` } func RedisBenchmark() { // get all data1 queryDevUrl := \"http://127.0.0.1:2345/data1?select=name\" SysnameAll := GetSomething(queryDevUrl, []d_dev{}) //fmt.Printf(\"SYSNAME: %s\", SysnameAll) // get all data2 queryTaskUrl := \"http://127.0.0.1:2345/data2?select=metric\" MetricAll := GetSomething(queryTaskUrl, []metric{}) //fmt.Printf(\"Metric: %s\", MetricAll) c := redis.NewClient(&amp;redis.Options{ Addr: \"127.0.0.1:6380\", Password: \"\", DB: 0, MinIdleConns: 10, IdleTimeout: 30 * time.Second, PoolSize: 120, }) var AllData = make(map[string] int64) // generate key for _, sys := range (* SysnameAll).([]interface{}){ sysnamemap := sys.(map[string]interface {}) for _, sysname := range sysnamemap { for _, ml := range (* MetricAll).([]interface{}) { for _, m := range ml.(map[string]interface{}) { if m != nil { for _, v := range m.([]interface{}) { AllData[sysname.(string) + \"&amp;\" + v.(string)] = time.Now().Unix() } } } } } } fmt.Printf(\"LEN: %d\\n\", len(AllData)) pong, err := c.Ping().Result() if err != nil { fmt.Print(\"no pong\") } fmt.Printf(\"Connection: %s\\n\", pong) // 初始化pipeline对象，go-redis通过将redis命令从多条TCP连接一次性发送到redis集群或者服务节点，大大减小了I/O开销； p := c.Pipeline() err = p.Set(\"endpoint+metric\", time.Now().Unix(), 60*time.Second).Err() for k, v := range AllData { err = p.Set(k, v, 60*time.Second).Err() if err != nil { fmt.Print(err) } //val, getErr := c.Get(\"endpoint+metric\").Result() // //if getErr != redis.Nil { // val, getErr = c.Get(\"endpoint+metric\").Result() // fmt.Printf(\"VALUE: %d\", val) //} // //fmt.Printf(\"VALUE: %d\", val) } p.Exec() fmt.Printf(\"------END------\\n\") } func GetSomething(url string, arr interface{}) (* interface{}) { // get all monitor device and metric resultByte , resultStatus , errj , _ := httputil.GetRequest(url, 60, nil , nil) if errj != nil &amp;&amp; resultStatus != 200 { fmt.Printf(\"select failed, error=%s, response=%s\", errj, resultByte) }else{ //fmt.Printf(\"select succeed, response=%s\", resultByte) } errj = json.Unmarshal(resultByte, &amp;arr) if errj != nil { fmt.Print(errj) } return &amp;arr } . ",
    "url": "/docs/archives/2020/2020-05-13-redis_data_sampling/#%E6%96%B9%E6%A1%88%E5%9B%9B%E7%9B%91%E6%8E%A7%E8%A6%86%E7%9B%96%E7%8E%87",
    
    "relUrl": "/docs/archives/2020/2020-05-13-redis_data_sampling/#方案四监控覆盖率"
  },"310": {
    "doc": "Data Sampling [Redis]",
    "title": "Data Sampling [Redis]",
    "content": "Go . Redis . Data-Sampling . 2020-05-13 14:54:35 +0800 . ",
    "url": "/docs/archives/2020/2020-05-13-redis_data_sampling/",
    
    "relUrl": "/docs/archives/2020/2020-05-13-redis_data_sampling/"
  },"311": {
    "doc": "Ansible自动化",
    "title": "Ansible自动化",
    "content": " ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#ansible%E8%87%AA%E5%8A%A8%E5%8C%96",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#ansible自动化"
  },"312": {
    "doc": "Ansible自动化",
    "title": "学习路径",
    "content": ". | 理解Ansible架构 | 安装配置Ansible, Inventory | 理解playbook的原理 | Ansible Ad-Hoc Commands | Ansible 强大的模块 | Ansible playbook编写 | 掌握编写自己的 Roles | 使用Ansible管理集群 | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#学习路径"
  },"313": {
    "doc": "Ansible自动化",
    "title": "Ansible Architecture",
    "content": ". | 核心：ansible | 核心模块（Core Modules）：这些都是ansible自带的模块  | 扩展模块（Custom Modules）：如果核心模块不足以完成某种功能，可以添加扩展模块 | 插件（Plugins）：完成模块功能的补充 | 剧本（Playbooks）：ansible的任务配置文件，将多个任务定义在剧本中，由ansible自动执行 | 连接插件（Connection Plugins）：ansible基于连接插件连接到各个主机上，虽然ansible是使用ssh连接到各个主机的，但是它还支持其他的连接方法，所以需要有连接插件（centos下必须要安装sshpass） | 主机群（Host Inventory）：定义ansible管理的主机 | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#ansible-architecture",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#ansible-architecture"
  },"314": {
    "doc": "Ansible自动化",
    "title": "Installation",
    "content": "Ansible安装 . yum -y install ansible pip install ansible . Ansible配置 . inventory = /etc/ansible/hosts roles_path = /etc/ansible/roles log_path = /var/log/ansible.log remote_tmp = ~/.ansible/tmp local_tmp = ~/.ansible/tmp forks = 5 sudo_user = root remote_port = 22 timeout = 10 remote_user = root . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#installation",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#installation"
  },"315": {
    "doc": "Ansible自动化",
    "title": "Ansible Usage",
    "content": "Ansible命令 . ansible一共为我们提供了七个指令：ansible、ansible-doc、ansible-galaxy、ansible-lint、ansible-playbook、ansible-pull、ansible-vault . | ansible  ansible是指令核心部分，其主要用于执行ad-hoc命令，即单条命令。默认后面需要跟主机和选项部分，默认不指定模块时，使用的是command模块。 . | ansible-doc 该指令用于查看模块文档信息，常用参数有两个-l 和 -s . | ansible-galaxy ansible-galaxy 指令用于方便的从https://galaxy.ansible.com/ 站点下载第三方扩展模块 . | ansible-lint ansible-lint是对playbook的语法进行检查的一个工具。用法是ansible-lintplaybook.yml . | ansible-playbook 调用playbook，通过读取playbook 文件后，执行相应的动作，最常用最核心的命令 . | ansible-pull 通过ansible-pull结合Git和crontab一并实现对大批量机器配置，其原理是通过crontab定期拉取指定的Git版本到本地，并以指定模式自动运行预先制订好的指令。 . | ansible-vault ansible-vault主要应用于配置文件中含有敏感信息，又不希望他能被人看到，vault可以帮你加密/解密这个配置文件。主要对于playbooks里比如涉及到配置密码或其他变量时，可以通过该指令加密，这样我们通过cat看到的会是一个密码串类的文件，编辑的时候需要输入事先设定的密码才能打开。这种playbook文件在执行时，需要加上 –ask-vault-pass参数，同样需要输入密码后才能正常执行。 . | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#ansible-usage",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#ansible-usage"
  },"316": {
    "doc": "Ansible自动化",
    "title": "Usage &amp; Ad-Hoc",
    "content": ". Ad-Hoc命令集, 由 /usr/bin/ansible实现，其命令用法如下： . ansible &lt;host-parttern&gt; [options] # 查看可用选项： ansible -h . 常用选项： . -f forks：启动的并发线程数（默认值为5） -m module_name: 指定要使用的模块 -a –args module_args: 模块特有的参数 -v verbose: 详情模式，显示所有debug信息 . Ad-Hoc Commands . ansible host -m service -a “name=pacemaker.service state=restarted ansible host -m shell -a “systemctl status pacemaker.service” . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#usage--ad-hoc",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#usage--ad-hoc"
  },"317": {
    "doc": "Ansible自动化",
    "title": "Working with module",
    "content": "ansible内置模块 . ansible-doc --list #列出所有可用模块 ansible-doc shell #查看模块说明 . 常用模块 . | command | shell | ping | yum | pip | service | template | copy | fetch | file | cron | synchronize | unarchive | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#working-with-module",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#working-with-module"
  },"318": {
    "doc": "Ansible自动化",
    "title": "Module",
    "content": "Module调用方式 . [root@controller]# ansible [group_name] -m service -a \"name=httpd state=started“ [root@controller]# ansible [group_name] -m ping - name: reboot the servers command: /sbin/reboot -t now . | 模块是在 Ansible 中实际在执行的.它们就是在每个 playbook 任务中被调用执行的.你也可以仅仅通过 ‘ansible’ 命令来运行它们. | 每个模块都能接收参数. 几乎所有的模块都接受键值对(key=value)参数,空格分隔.一些模块不接收参数,只需在命令行输入相关的命令就能调用. | 用ansible-doc [module]命令来查看你要使用的模块的文档 . | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#module",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#module"
  },"319": {
    "doc": "Ansible自动化",
    "title": "Woking with Inventory",
    "content": "[group names] ip_1 ansible_ssh_user=‘’ ansible_ssh_pass=‘’ ip_2 ansible_ssh_user=‘’ ansible_ssh_pass=‘’ Hostname_1 ansible_ssh_host=${ip} ansible_ssh_user=‘’ ansible_ssh_pass=‘’ Hostname_2 ansible_ssh_host=${ip} ansible_ssh_user=‘’ ansible_ssh_pass=‘’ Example: [nsp] szd-l0100875 ansible_ssh_host=127.0.0.1 ansible_ssh_user=root ansible_ssh_pass=‘root' . | Ansible 可同时操作属于一个组的多台主机,组和主机之间的关系通过 inventory 文件配置, 默认的文件路径为 /etc/ansible/hosts. | 除默认文件外,你还可以同时使用多个 inventory 文件(-i 选项), 也可以从动态源, 或云上拉取 inventory 配置信息. | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#woking-with-inventory",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#woking-with-inventory"
  },"320": {
    "doc": "Ansible自动化",
    "title": "playbooks",
    "content": ". 调用命令 . ansible-playbook playbook.yml -f 10 （-f参数表示ansible主机并非进程数） . | 简单来说,playbooks 是一种简单的配置管理系统与多机器部署系统的基础.与现有的其他系统有不同之处,且非常适合于复杂应用的部署. | Playbooks 可用于声明配置,更强大的地方在于,在 playbooks 中可以编排有序的执行过程,甚至于做到在多组机器间,来回有序的执行特别指定的步骤.并且可以同步或异步的发起任务. | Playbooks 的格式是YAML, 语法做到最小化, 避免 playbooks 成为一种编程语言或是脚本,但它也并不是一个配置模型或过程的模型. | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#playbooks",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#playbooks"
  },"321": {
    "doc": "Ansible自动化",
    "title": "YAML &amp; Jinja2",
    "content": "YAML 像 XML 或 JSON 是一种利于读写的数据格式，Ansible使用YAML 语法来描述一个 playbooks . | 所有的 YAML 文件(无论和 Ansible 有没有关系)开始行都应该是 —. 这是 YAML 格式的一部分, 表明一个文件的开始. | 对于 Ansible, 每一个 YAML 文件都是从一个列表开始. 列表中的每一项都是一个键值对, 通常它们被称为一个 “哈希” 或 “字典”. | 列表中的所有成员都开始于相同的缩进级别, 并且使用一个 “- “ 作为开头(一个横杠和一个空格) | 个字典是由一个简单的 键: 值 的形式组成(这个冒号后面必须是一个空格) | . --- - hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted . jinja2是Flask作者开发的一个模板系统，起初是仿django模板的一个模板引擎，为Flask提供模板支持，由于其灵活，快速和安全等优点被广泛使用。 . 作为一个模板系统，它还提供了特殊的语法，在jinja2中，存在三种语法： . | 控制结构 | . \\{\\% \\%\\} #\\用于markdown表示的转义 . | 变量取值 | . \\{\\{ \\}\\} #\\用于markdown表示的转义 . | 注释 | . \\{\\# \\#\\} #\\用于markdown表示的转义 . [keystone_authtoken] auth_uri = http://keystone.mgt.domain:\\{\\{ keystone_mgt_port1 \\}\\} auth_url = http://keystone.mgt.domain:\\{\\{ keystone_mgt_port2 \\}\\} auth_plugin = password project_domain_id = default user_domain_id = default project_name = service username = neutron password = neutron identity_uri = http://127.0.0.1:5000 . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#yaml--jinja2",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#yaml--jinja2"
  },"322": {
    "doc": "Ansible自动化",
    "title": "Roles&amp;Include",
    "content": ". | 使用 include 语句引用 task 文件的方法，可允许你将一个配置策略分解到更小的文件中，方便文件复用. | Role：通过 include 包含文件并将它们组合在一起，组织成一个简洁、可重用的抽象的对象. | 在playbook中通过 roles: 来包含多个角色，然后顺序执行. | . foo.yml roles/ role_foo/ files/ templates/ tasks/ handlers/ vars/ defaults/ meta/ . | 如果 roles/x/tasks/main.yml 存在, 其中列出的 tasks 将被添加到 play 中 | 如果 roles/x/handlers/main.yml 存在, 其中列出的 handlers 将被添加到 play 中 | 如果 roles/x/vars/main.yml 存在, 其中列出的 variables 将被添加到 play 中 | 如果 roles/x/meta/main.yml 存在, 其中列出的 “角色依赖” 将被添加到 roles 列表中 | 所有 copy tasks 可以引用 roles/x/files/ 中的文件，不需要指明文件的路径。 | 所有 script tasks 可以引用 roles/x/files/ 中的脚本，不需要指明文件的路径。 | 所有 template tasks 可以引用 roles/x/templates/ 中的文件，不需要指明文件的路径。 | 所有 include tasks 可以引用 roles/x/tasks/ 中的文件，不需要指明文件的路径。 | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#rolesinclude",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#rolesinclude"
  },"323": {
    "doc": "Ansible自动化",
    "title": "Tags",
    "content": "[root@controller]# ansible-playbook example.yml --tags \"step_1,step_2\" [root@controller]# ansible-playbook example.yml --skip-tags \"step_11,step_12\" . | Ansible 允许给playbook里面的资源通过自定义的关键字打上标签，然后只运行与标签部分的代码。 | Tags允许用户在一个playbook中，只运行部分task或跳过部分task。 | always, never, 是两个特殊的tag，always表示task总会执行，除非–skip-tags always；never表示总会跳过never下的task执行，如果此task还有其他tag，并且在—tags中包含，才会执行never的task。 | tags: tagged, untagged, all, 这三个tag在执行命令中可以使用，默认情况下ansible是默认运行 –tags all | . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#tags",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#tags"
  },"324": {
    "doc": "Ansible自动化",
    "title": "Var&amp;Condition&amp;Loop",
    "content": "--- tasks: - name: \"shutdown Debian systems\" command: /sbin/shutdown -t now when: ansible_os_family == \"Debian\" --- tasks: - name: run script shell: python script.py when: \"'\\{\\{ node1_ip \\}\\}' in ansible_all_ipv4_addresses or '\\{\\{ node2_ip \\}\\}' in ansible_all_ipv4_addresses\" register: output - name: print output debug: msg=\"\\{\\{ output.stdout \\}\\}\" . | Ansible使用 When 语句来控制执行流. | When 语句也可以应用于role 或 task 中的incloud语句 | 变量文件在playbook中指定，变量用“{{ }}”的形式导入，并且括号外要加引号 | 使用resigter将执行动作的输出，赋值给定义的变量 | . - name: add several users user: name=\\{\\{ item \\}\\} state=present groups=wheel with_items: - testuser1 - testuser2 - name: enable services service: name=\\{\\{ item.name \\}\\} state=\\{\\{ item.state \\}\\} enabled=\\{\\{ item.enabled \\}\\} with_items: - \\{name: ntpd, state: restarted, enabled: yes\\} - \\{name: httpd, state: restarted, enabled: yes\\} Loop： with_list with_items with_indexed_items with_flattened with_together with_dict with_sequence with_subelements with_nested/with_cartesian with_random_choice . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#varconditionloop",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#varconditionloop"
  },"325": {
    "doc": "Ansible自动化",
    "title": "END",
    "content": " ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/#end",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/#end"
  },"326": {
    "doc": "Ansible自动化",
    "title": "Ansible自动化",
    "content": "Ansible . Yaml . Python . 2020-05-14 15:24:57 +0800 . ",
    "url": "/docs/archives/2020/2020-05-14-ansible-automation/",
    
    "relUrl": "/docs/archives/2020/2020-05-14-ansible-automation/"
  },"327": {
    "doc": "Monitor System",
    "title": "监控系统1.5版本项目重组",
    "content": ". | 采集数据处理接口添加逻辑： | . \"\"\" DES: 监控项目数据处理入口 @API API = { \"/monitor_upload/snmp/\": MonitorUploadAPI, } Key: 父级路由 Value: 父级路由对应的子路由 @MonitorUploadAPI MonitorUploadAPI = { \"xxx\": {\"metric\": \"x.xx\", \"handler\": metric.xx.xxx} } Key: 子路由 Value: 监控项及处理函数 metric: 监控项名称 handler: 数据处理函数, 处理函数如参必须包含： metric 和 data \"\"\" . ├── monitor │ ├── api │ API管理 │ │ ├── OpenFalcon_access_api │ 与OpenFalcon进行交互的API, 告警联系组管理, 告警模版管理, 告警名称翻译, 告警联系人组管理, 采集数据查询, 告警解除及屏蔽, 告警视图查询 │ │ ├── monitor_manage_api │ 对monitor采集系统进行管理的API, 承载对monitor-pg的访问, 包括监控agent增删改查, 包括监控设备增删改查, 包括监控任务增删改查 │ │ ├── metric_process_api │ Agent原始采集数据上报API, 包括各厂商的netconf协议下的数据上报，API以.do结尾, 包括各厂商的snmp协议下的数据上报，API以.do结尾 │ │ └── third_access_api │ 第三方系统管理API, 包括zabbix线路添加相关API │ ├── conf │ 配置文件, 配置项注册 │ ├── core │ 监控数据处理核心 │ │ ├── OpenFalcon │ 核心OpenFalcon访问模块, 告警核心配置功能，接收OpenFalcon_access_api调用 │ │ ├── handlers │ 核心处理模块, 包括设备信息缓存加载功能，server服务启动前预加载数据到缓存，并定时更新，由metric数据处理单元调用 │ │ ├── metric │ 监控metric数据处理模块, 原始采集数据基础处理模块，由.do数据接收API直接调用，或由vendor protocol数据处理模块基础 │ │ │ ├── vendor │ 设备类采集任务的原始采集数据处理模块 │ │ │ └── wrapper │ Falcon数据封装模块 │ │ └── model │ 数据模型, OpenFalcon数据模型, monitor数据模型 │ ├── db │ db访问模块 │ ├── inventory │ 监控OID，监控项管理仓库 │ ├── pkg │ 功能模块管理 │ │ ├── amqp │ amqp模块，包括rabbitmq生成和消费 │ │ ├── redis │ redis模块，包括redis写入和读取 │ │ ├── security │ 数据加密模块 │ │ └── utils │ 工具组件模块 │ ├── run_agent_manager.py │ 运行入口：agent状态检查设备分配服务 │ ├── run_cmdb_manager.py │ 运行入口：CMDB设备监控同步服务 │ ├── run_server.py │ 运行入口：Web Server服务 │ ├── run_service_debug.py │ 运行入口：所有服务debug │ ├── run_task_scheduler.py │ 运行入口：其他同步服务的统一入口 │ └── service │ 定时同步服务管理模块 │ ├── alarm_sync_service.py │ 告警翻译同步服务 │ ├── cmdb_sync_service.py │ CMDB设备监控同步服务 │ ├── device_distribution_service.py │ agent状态检查设备分配服务 │ ├── device_manager_service.py │ 设备基础信息管理服务 │ ├── monitor_oper_service.py │ 监控设备同步服务，移除下线设备等 │ └── monitor_task_service.py │ Agent执行任务生成及同步服务 ├── docs │ 文档 Project Structure: ├── monitor │ ├── __init__.py │ ├── api │ │ ├── __init__.py │ │ ├── OpenFalcon_access_api │ 与OpenFalcon进行交互的API │ │ │ ├── __init__.py │ │ │ │ ├── alarm_group_manage_api.py │ 告警联系组管理 │ │ │ ├── alarm_manage_api.py │ │ │ │ ├── alarm_template_manage_api.py │ 告警模版管理, 告警名称翻译 │ │ │ ├── alarm_user_manage_api.py │ 告警联系人组管理 │ │ │ ├── const.py │ │ │ │ └── falcon_handler_api.py │ 采集数据查询, 告警解除及屏蔽, 告警视图查询 │ │ ├── monitor_manage_api │ 对monitor采集系统进行管理的API, 承载对monitor-pg的访问 │ │ │ ├── __init__.py │ │ │ │ ├── agent_manage_api.py │ 包括监控agent增删改查 │ │ │ ├── device_manage_api.py │ 包括监控设备增删改查 │ │ │ └── task_manage_api.py │ 包括监控任务增删改查 │ │ ├── metric_process_api │ Agent原始采集数据上报API │ │ │ ├── __init__.py │ │ │ │ ├── netconf_metric_api.py │ 包括各厂商的netconf协议下的数据上报，API以.do结尾 │ │ │ └── snmp_metric_api.py │ 包括各厂商的snmp协议下的数据上报，API以.do结尾 │ │ └── third_access_api │ 第三方系统管理API │ │ ├── __init__.py │ │ │ └── zabbix_manage_api.py │ 包括zabbix线路添加相关API │ ├── conf │ 配置文件 │ │ ├── __init__.py │ 配置项注册 │ │ ├── conf.ini │ 内部云配置文件 │ │ ├── conf_debug.ini │ 测试环境配置文件 │ │ ├── conf_efa.ini │ 金融云配置文件 │ │ ├── conf_pub.ini │ 公有云配置文件 │ ├── core │ 监控数据处理核心 │ │ ├── __init__.py │ │ │ ├── OpenFalcon │ 核心OpenFalcon访问模块 │ │ │ ├── __init__.py │ │ │ │ ├── alarm_setting.py │ 告警核心配置功能，接收OpenFalcon_access_api调用 │ │ ├── handlers │ 核心处理模块 │ │ │ ├── __init__.py │ │ │ │ ├── device_info_handler.py │ 包括设备信息缓存加载功能，server服务启动前预加载数据到缓存，并定时更新，由metric数据处理单元调用 │ │ ├── metric │ 监控metric数据处理模块 │ │ │ ├── __init__.py │ │ │ │ ├── base.py │ 原始采集数据基础处理模块，由.do数据接收API直接调用，或由vendor protocol数据处理模块基础 │ │ │ ├── driver │ │ │ │ │ ├── __init__.py │ │ │ │ │ ├── cisco_firewall.py │ │ │ │ │ ├── cisco_router.py │ │ │ │ │ ├── cisco_switch.py │ │ │ │ │ ├── h3c_switch.py │ │ │ │ │ ├── huawei_switch.py │ │ │ │ │ └── juniper_firewall.py │ │ │ │ ├── protocol │ 协议类采集任务的原始采集数据处理模块，该任务为用户自定义任务 │ │ │ │ ├── __init__.py │ │ │ │ │ ├── http.py │ http协议任务原始采集数据处理模块 │ │ │ │ ├── ping.py │ ping监控任务原始采集数据处理模块 │ │ │ │ ├── process.py │ 进程监控任务原始采集数据处理模块 │ │ │ │ ├── snmp.py │ snmp协议任务原始采集数据处理模块 │ │ │ │ └── tcp.py │ tcp协议任务原始采集数据处理模块 │ │ │ ├── publisher.py │ 已完成封装的Falcon数据推送模块，包括对OpenFalcon的http上报和rabbitmq的发布 │ │ │ ├── vendor │ 设备类采集任务的原始采集数据处理模块 │ │ │ │ ├── __init__.py │ │ │ │ │ ├── cisco.py │ cisco 思科原始采集数据处理模块 │ │ │ │ ├── f5.py │ f5 原始采集数据处理模块 │ │ │ │ ├── h3c.py │ h3c 华三原始采集数据处理模块 │ │ │ │ ├── hillstone.py │ hillstone 山石原始采集数据处理模块 │ │ │ │ ├── huawei.py │ huawei 华为原始采集数据处理模块 │ │ │ │ ├── infoblox.py │ infoblox 原始采集数据处理模块 │ │ │ │ ├── juniper.py │ juniper 原始采集数据处理模块 │ │ │ │ ├── nexus.py │ nexus 原始采集数据处理模块 │ │ │ │ └── riverbed.py │ riverbed 原始采集数据处理模块 │ │ │ └── wrapper │ Falcon数据封装模块 │ │ │ ├── __init__.py │ │ │ │ ├── common_metric.py │ 通用数据封装模块 │ │ │ ├── interface_metric.py │ 设备子接口数据封装模块 │ │ │ ├── protocol_metric.py │ 协议类数据封装模块 │ │ │ └── vendor_wrapper │ 厂商设备数据封装模块 │ │ │ ├── __init__.py │ │ │ │ ├── cisco_metric.py │ cisco 设备数据封装模块 │ │ │ ├── f5_metric.py │ f5 设备数据封装模块 │ │ │ ├── h3c_metric.py │ h3c 设备数据封装模块 │ │ │ ├── hillstone_metric.py │ hillstone 设备数据封装模块 │ │ │ ├── huawei_metric.py │ huawei 设备数据封装模块 │ │ │ ├── infoblox_metric.py │ infoblox 设备数据封装模块 │ │ │ ├── juniper_metric.py │ juniper 设备数据封装模块 │ │ │ ├── nexus_metric.py │ nexus 设备数据封装模块 │ │ │ └── riverbed_metric.py │ riverbed 设备数据封装模块 │ │ └── model │ 数据模型 │ │ ├── __init__.py │ │ │ ├── OpenFalcon_data_model.py │ OpenFalcon数据模型 │ │ └── monitorf_data_model.py │ monitor数据模型 │ ├── db │ db访问模块 │ │ ├── __init__.py │ db访问API，包括增删改查及合并 │ │ ├── api.py │ │ │ ├── device_manager_dao.py │ │ │ ├── device_topo_dao.py │ │ │ ├── monitor_data_dao.py │ │ │ ├── monitor_oper_dao.py │ │ │ ├── monitor_task_dao.py │ │ │ └── monitor_user_view_dao.py │ │ ├── inventory │ 监控OID，监控项管理仓库 │ │ ├── __init__.py │ │ │ ├── cisico_snmp.json │ │ │ ├── huawei_snmp.json │ │ │ ├── NetconfRule.py │ │ │ ├── SnmpRule.py │ │ │ └── TaskSupported.py │ │ ├── pkg │ 功能模块管理 │ │ ├── __init__.py │ │ │ ├── amqp │ amqp模块，包括rabbitmq生成和消费 │ │ │ ├── __init__.py │ │ │ │ ├── const.py │ │ │ │ ├── metric_publisher.py │ │ │ │ ├── pika_util.py │ │ │ ├── redis │ redis模块，包括redis写入和读取 │ │ │ ├── __init__.py │ │ │ │ ├── redis.py │ │ │ ├── security │ 数据加密模块 │ │ │ ├── __init__.py │ │ │ │ ├── key │ │ │ │ │ ├── rsa.key │ │ │ │ │ └── rsa.pub │ │ │ │ └── rsa_secure.py │ │ │ └── utils │ 工具组件模块 │ │ ├── __init__.py │ │ │ ├── async.py │ │ │ ├── daemon.py │ │ │ ├── date_util.py │ │ │ ├── encrypt_util.py │ │ │ ├── file_util.py │ │ │ ├── flow_util.py │ │ │ ├── global_variable.py │ │ │ ├── http_util.py │ │ │ ├── import_util.py │ │ │ ├── lock_util.py │ │ │ ├── logger.py │ │ │ ├── os_util.py │ │ │ ├── request_util.py │ │ │ ├── result.py │ │ │ ├── temp.py │ │ │ ├── temp.txt │ │ │ ├── temp2.py │ │ │ ├── thread_helper.py │ │ │ ├── time_helper.py │ │ ├── run_agent_manager.py │ 运行入口：agent状态检查设备分配服务 │ ├── run_cmdb_manager.py │ 运行入口：CMDB设备监控同步服务 │ ├── run_server.py │ 运行入口：Web Server服务 │ ├── run_service_debug.py │ 运行入口：所有服务debug │ ├── run_task_scheduler.py │ 运行入口：其他同步服务的统一入口 │ └── service │ 定时同步服务管理模块 │ ├── __init__.py │ │ ├── alarm_sync_service.py │ 告警翻译同步服务 │ ├── cmdb_sync_service.py │ CMDB设备监控同步服务 │ ├── device_distribution_service.py │ agent状态检查设备分配服务 │ ├── device_manager_service.py │ 设备基础信息管理服务 │ ├── monitor_oper_service.py │ 监控设备同步服务，移除下线设备等 │ └── monitor_task_service.py │ Agent执行任务生成及同步服务 ├── docs │ │ ├── api_docs │ │ │ └── restful_api.yml │ │ └── README.md │ ├── etc │ │ └── bin │ │ ├── monitor-log.service │ │ ├── monitor-monitor.service │ │ ├── monitor-scheduler.service │ │ └── monitor-server.service │ ├── README │ . ",
    "url": "/docs/archives/2020/2020-05-14-monitor_system_restructure/#%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F15%E7%89%88%E6%9C%AC%E9%A1%B9%E7%9B%AE%E9%87%8D%E7%BB%84",
    
    "relUrl": "/docs/archives/2020/2020-05-14-monitor_system_restructure/#监控系统15版本项目重组"
  },"328": {
    "doc": "Monitor System",
    "title": "Monitor System",
    "content": "2020-05-14 14:52:45 +0800 . ",
    "url": "/docs/archives/2020/2020-05-14-monitor_system_restructure/",
    
    "relUrl": "/docs/archives/2020/2020-05-14-monitor_system_restructure/"
  },"329": {
    "doc": "Python服务容器化部署",
    "title": "监控容器微服务部署",
    "content": "新增节点初始化操作 . | . | 下载Docker环境部署文件，上传到物理机 | . | 将以上文件上传至同一目录下，执行如下： | . | 准备日志 | . | . | 准备应用文件 | . | Step0：获取监控物理机信息 | Step1：初始化配置监控主机 | Step2：部署+验证 | . nmsagent镜像部署 . | . | 下载Docker环境部署文件，上传到物理机 | . | . | 安装docker | . | . | 导入镜像, 必须在两台物理机上都执行 | . | . | 准备日志 | . | . | 准备应用文件 | . | . | 部署nspmonitor-xxx.tar.gz,准备docker服务所需文件及虚环境安装lvxmonitor-engine到nginx物理机,以EFA为例子 | . | . | 部署服务 - 部署nspmonitor和lvxmonitor-porxy的Docker服务 | . | 更新yunzhi环境信息 | Debug | 采用docker三节点HA部署 | . 新增节点初始化操作 . #允许root ssh登录修改： vi /etc/ssh/sshd_config PermitRootLogin no修改为：PermitRootLogin yes #重启sshd服务 service sshd restart . | nspmonitor验证配置文件所有IP:PORT是否能够访问,alphaops验证hillstone防火墙snmpwalk和22端口 | . snmp安装： yum install -y net-snmp net-snmp-utils alphaops验证 . | 执行以下步骤：Step1 | 上传镜像文件，初始化docker环境 . | 下载Docker环境部署文件，上传到物理机 | . init_docker_node.sh 镜像包net_monitor_add_ssh.tar.tar 下载最新版本的nspmonitor-xxx.tar.gz docker-package.tar.gz . 将以上文件上传至同一目录下，执行如下： . bash init_docker_node.sh 注意：如果执行以上脚本出错，把内容复制出来，命令逐行执行 #检查镜像是否导入 docker images . | 准备日志 | . mkdir -p /var/log/nspmonitor vim /etc/logrotate.d/nspmonitor # 将下面的文本粘贴到 /etc/logrotate.d/nspmonitor 该文件中 /var/log/nspmonitor/*.log { rotate 10 size 50M missingok compress copytruncate } mkdir -p /var/log/lvxmonitor vim /etc/logrotate.d/lvxmonitor # 将下面的文本粘贴到 /etc/logrotate.d/lvxmonitor 该文件中 /var/log/lvxmonitor/*.log { rotate 10 size 50M missingok compress copytruncate } . | 准备应用文件 . | 创建目录 | . | . mkdir -p /opt/netmon/agent . | 解压agent_updater文件并移动到agent下 | . tar -zxvf nspmonitor-xxx.tar.gz -C /opt/netmon/agent cp /opt/netmon/agentnspmonitor-xxx/nspmonitor /opt/netmon/agent -r . Step0：获取监控物理机信息 . | 监控主机为双机高可用模式 | . Step1：初始化配置监控主机 . | 修改ulimit linux系统对用户态程序限制 | . # 查看 open files 的限制数量 ulimit -a # 永久修改： vim /etc/security/limits.conf * - nproc 102400 * - nofile 102400 # 修改max-file vim /etc/sysctl.conf fs.file-max = 6815744 # 最好对系统进行reboot reboot . | 配置NTP服务器，并启动NTP时间同步服务，检查时间是否为UTC+8（不同地域可用区不同） | . systemctl status ntpd ntptime # 参考AZ NSP的 /etc/ntp.conf ntp配置，拷贝到监控物理机 systemctl restart ntpd ntptime #检查时间是否同步UTC+8（不同地域可用区不同） # 如果服务没有启动或者时间不对，需要修改/etc/ntp.conf 配置文件，将server修改为该区域可用的ntp server，并启动服务 . | 配置域名解析服务 | . cat /etc/resolv.conf search cloud.pub nameserver 127.0.0.1 nameserver 127.0.0.1 # 检查域名是否解析，网络是否可达 ping gateway-OpenFalcon.cloud.pub telnet gateway-OpenFalcon.cloud.pub 12057 . | 检查Open-Falcon的agent是否安装，端口是否监听 | . # 检查端口是否监听 netstat -antl | grep 12050 # 检查应用是否部署并启动 ps -aux | grep falcon ps -aux | grep ops_updater # falcon-agent进程不存在，或目录/opt/pamon/不存在 # 进入 http://fcloud.test.com.cn/d/9a0876f347/ 联系文件提供人，下载并安装 # 若OpenFalcon-agent未安装，请根据主机类型（传统环境/内部云/公有云）按照以下流程安装： # http://yunzhi.test.com.cn/pages/viewpage.action?pageId=24564124 . | YUM配置 | yum clean all &amp;&amp; yum makecache # 如果不发生报错，则YUM配置可用，报错请继续 | 配置路径：/etc/yum.repos.d/ 对应.repo文件可以到AZ NSP物理机相同路径复制到本机目录 | 完成/etc/yum.repos.d/*.repo 文件配置后 yum clean all &amp;&amp; yum makecache 进行验证 | 修改主机密码 | passwd root 改为网络组新密码 | . Step2：部署+验证 . nmsagent镜像部署 说明： 下面的安装步骤中 0,1,2,3 必须在两台物理机都进行操作 下面的安装步骤中 4,5,6 只需要在一台物理机都进行操作 . | 下载Docker环境部署文件，上传到物理机 | . add_manager.sh install.sh docker-package.tar.gz net_monitor_add_ssh.tar . 下载最新版本的nspmonitor-xxx.tar.gz 下载最新版本的agent_updater-xxx.tar.gz . | 安装docker . | 将下面三个文件放置在同一级目录下 | . | . add_manager.sh install.sh docker-package.tar.gz . | 安装主节点 | . bash install.sh &lt;ip&gt; #此ip为两台物理机中任意一台, 安装完成后会显示 --token xxxx ip:port, 复制--token后面的内容 . | 添加管理节点 | . bash add_manager.sh xxxx ip:port #将复制的--token之后的内容加在add_manager.sh后 . | 检查集群状态 | . docker node ls . | 导入镜像, 必须在两台物理机上都执行 . | 将上传的net_monitor_add_ssh.tar文件导入为docker image, 命名为netmonitor，版本为1.0 | . | . docker import net_monitor_add_ssh.tar netmonitor:v1.0 . | 准备日志 | . mkdir -p /var/log/nspmonitor vim /etc/logrotate.d/nspmonitor # 将下面的文本粘贴到 /etc/logrotate.d/nspmonitor 该文件中 /var/log/nspmonitor/*.log { rotate 10 size 50M missingok compress copytruncate } mkdir -p /var/log/lvxmonitor vim /etc/logrotate.d/lvxmonitor # 将下面的文本粘贴到 /etc/logrotate.d/lvxmonitor 该文件中 /var/log/lvxmonitor/*.log { rotate 10 size 50M missingok compress copytruncate } . | 准备应用文件 | . | 创建目录 | . mkdir -p /opt/netmon/agent . | 解压agent_updater文件并移动到agent下 | . tar -zxvf agent_updater-xxx.tar.gz -C /opt/netmon/agent . | 到agent_updater内创建新的{可用区名称}配置文件夹, 以EFA为例子 | . mkdir /opt/netmon/agent/agent_updater/updater/config/EFA/ cp /opt/netmon/agent/agent_updater/updater/config/SCA/config.json /opt/netmon/agent/agent_updater/updater/config/EFA/ #拷贝SCA的配置文件为模版 vim /opt/netmon/agent/agent_updater/updater/config/EFA/config.json # 修改监控物理机ip，nginx物理机ip，密码也需要统一 . | 部署nspmonitor-xxx.tar.gz,准备docker服务所需文件及虚环境安装lvxmonitor-engine到nginx物理机,以EFA为例子 | . cp &lt;上传路径&gt;/nspmonitor-xxx.tar.gz /opt/netmon/agent/agent_updater/package cd /opt/netmon/agent/agent_updater/updater # ansible command not found 的情况下，需要安装ansible cd /opt/netmon/agent/agent_updater/ansible/playbooks/init python init.py python updater.py EFA ansible # 以EFA为例子,检查部署结果 . | 部署服务 - 部署nspmonitor和lvxmonitor-porxy的Docker服务 . | 修改服务compose文件, 修改文件中的可用区名称，例如：把所有的”SCA”替换为”EFA” | . | . cd /opt/netmon/agent/agent_updater/package/nspmonitor-{1.2.5.dev57}/docker-compose/ # File use vim 修改可用区 line：20 -rwxr-xr-x 1 root root 691 Jul 31 00:59 lvxmonitor-proxy-compose.yml -rwxr-xr-x 1 root root 687 Jul 31 01:07 nspmonitor-compose.yml -rwxr-xr-x 1 root root 689 Jul 31 01:08 pagwmonitor-compose.yml . | config 文件配置，如果不存在下面两个配置文件或路径，请联系监控开发在代码仓库中添加，并提供最新的nspmonitor的包 | . /opt/netmon/agent/nspmonitor/etc/&lt;可用区&gt;/nspmonitor.ini # 参考TEMPLATE中做修改 /opt/netmon/agent/nspmonitor/etc/&lt;可用区&gt;/lvxmonitor_proxy.conf # 找到scan_ips， 将scan_ips后的ip改为Nginx物理机ip，以逗号分隔； . | 配置修改完成，重新同步代码 | . cd /opt/netmon/agent/ scp -r nspmonitor &lt;agent_ip&gt;:/opt/netmon/agent # 以EFA为例子,检查部署结果,这里的agentip为另一台没有进行操作的主机ip . | Deploy | . cd /opt/netmon/agent/agent_updater/package/nspmonitor-{1.2.5.dev57}/docker-compose/ docker stack deploy -c &lt;compose_file&gt;.yml &lt;service_name&gt; #　对应名称 # compose_file: lvxmonitor-proxy-compose.yml service_name: lvxmonitor_proxy_EFA # compose_file: nspmonitor-compose.yml service_name: nspmonitor_EFA # compose_file: pagwmonitor-compose.yml service_name: pagwmonitor_EFA # 对于没有PAGW（vpp）产品的可用区请不要部署该微服务 . | 检查服务情况，查看当前服务是否成功启动，是否处于running状态 | . ansible lvx_monitor_engine -m shell -a \"systemctl status lvxmonitor-engine.service\" --inventory-file=/opt/netmon/agent/agent_updater/ansible/hosts docker service ls docker service ps &lt;service_name&gt; . | 检查日志 | . /var/log/nspmonitor # 在此目录下tail -f和tail -f | grep ERROR 检查日志是否有打印，检查是否有大量报错 更新yunzhi环境信息 NFV环境信息 Debug # run a test container as TESTPOD docker run -i -t -d --network=host -v /opt/netmon/:/app -v /var/log/:/var/log/ -v /etc/localtime:/etc/localtime --name TESTPOD netmonitor:v1.0 /bin/bash # start debug process # removing --log-file config app will output log directly to console # add the '&amp;' to the end of execute command will run this process as linux deamon /usr/bin/python /app/agent/nspmonitor/agent/nginx/proxy.py --config-file=/app/agent/nspmonitor/etc/SCA/lvxmonitor_proxy.conf --log-file=/var/log/nspmonitor/proxy.log /usr/bin/python /app/agent/nspmonitor/agent/nsp/entry.py --config-file=/app/agent/nspmonitor/etc/SCA/nspmonitor.ini --log-file=/var/log/nspmonitor/nspmonitor.log /usr/bin/python /app/agent/nspmonitor/agent/pagw/entry.py --config-file=/app/agent/nspmonitor/etc/EFA/nspmonitor.ini --log-file=/var/log/nspmonitor/pagwmonitor.log . nspmonitor版本更新操作 . | 将nspmonitor_xxxx.tar.gz 拷贝至 /opt/netmon/agent/下 | 解压：tar -xvf nspmonitor_xxxx.tar.gz ,cp nspmonitor_xxxx/nspmonitor /opt/netmon/agent/ -r | 重启服务 docker service update nspmonitor_agent –force | 验证进程是否拉起 docker service ps nspmonitor_agent –no-trunc 以及查看日志：tail /var/log/nspmonitor/nspmonitor.log 采用docker三节点HA部署 | 新节点环境配置 | . #根据以上step 0，1，2步骤将新节点配置好 # step0 全部执行 # step1 全部执行 # step2 执行1，2，3步骤 . # 准备应用文件 ## 创建目录 mkdir -p /opt/netmon/agent ## 解压nspmonitor-xxx.tar.gz 文件并移动到agent下 tar -zxvf nspmonitor-xxx.tar.gz -C /opt/netmon/agent cp /opt/netmon/agent/nspmonitor-xxx/nspmonitor /opt/netmon/agent 2.删除原二节点集群 # 删除服务，其中一个节点执行即可 dockers service ls docker service rm （服务名称） --force # 删除集群，两个节点 docker node ls docker node rm --force （节点名称） 3.创建三节点新集群 #找其中一个节点先作为manager docker swarm init --advertise-addr (ip) #另外两个节点加入集群 docker swarm join --token (token) ip:port #manager节点上执行，将两个worker节点升级为manager docker node ls docker promode (节点名称) 变更文档 #原节点执行，复制token docker swarm join-token manager #新加节点执行复制token内容 docker swarm join --token （token str）ip:port 其它方案 # 1.1 删除服务，其中一个节点执行即可 dockers service ls docker service rm （服务名称） --force # 1.2 删除集群，两个节点 docker node ls docker node demote （节点名称） docker node rm --force （节点名称） # 2.1 找其中一个节点先作为manager docker swarm init --advertise-addr (ip) # 2.2另外两个节点加入集群 docker swarm join --token (token) ip:port # 2.3manager节点上执行，将两个worker节点升级为manager docker node ls docker promode (节点名称) # 回滚 docker node ls docker node rm --force （节点名称） docker swarm init --advertise-addr (ip) docker swarm join --token (token) ip:port docker stack deploy -c nspmonitor-compose.yml nspmonitor . ",
    "url": "/docs/archives/2020/2020-05-14-python-service-deployment/#%E7%9B%91%E6%8E%A7%E5%AE%B9%E5%99%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2",
    
    "relUrl": "/docs/archives/2020/2020-05-14-python-service-deployment/#监控容器微服务部署"
  },"330": {
    "doc": "Python服务容器化部署",
    "title": "Python服务容器化部署",
    "content": "Python . Docker . 2020-05-14 15:03:28 +0800 . ",
    "url": "/docs/archives/2020/2020-05-14-python-service-deployment/",
    
    "relUrl": "/docs/archives/2020/2020-05-14-python-service-deployment/"
  },"331": {
    "doc": "Red Hat Enterprise Linux Kernel Version 2.6.32 3.8.13 python依赖环境手动部署",
    "title": "Red Hat Enterprise Linux Kernel Version 2.6.32 3.8.13",
    "content": "步骤 . | Download pkg files from test code | Install needed pkg for redhat linux | Upgrade Python interpreter to Version 2.7.5 | Install pip and setuptools | Install supervisor | Install needed pip pkg | . 0.Download pkg files from test code . | file_path: /opt/netmon/pip_pkg | docker-images/master/tree/redhat_kernel_3.8_pip | . | Install needed pkg for redhat linux yum install -y gcc yum install -y supervisor yum install -y libpng-devel yum install -y gcc yum install -y python-devel.x86_64 yum install MySQL-python yum install libffi yum install libffi-dev yum install -y openssl-devel . | . rpm -ivh libffi-devel-3.0.5-3.2.el6.x86_64.rpm . | Upgrade Python interpreter to Version 2.7.5 | . tar -zxvf Python-2.7.5.tgz cd Python-2.7.5 ./configure --prefix=/usr/local/python2.7 make make install . | Install pip and setuptools | . cd /opt/netmon/pkg unzip setuptools-41.2.0.zip cd setuptools-41.2.0 python setup.py install cd .. tar -zxvf pip-19.2.3.tar.gz cd pip-19.2.3 python setup.py install . | Install supervisor | . cd /opt/netmon/pkg pip install supervisor-4.0.4.tar.gz --no-index --find-links file:///opt/netmon/pkg /usr/local/python2.7/bin/supervisor /usr/local/python2.7/bin/supervisorctl ln -s /usr/local/python2.7/bin/supervisorctl /usr/bin/supervisorctl ln -s /usr/local/python2.7/bin/supervisord /usr/bin/supervisord supervisord -c /etc/supervisord.conf supervisorctl status supervisorctl reload . | Install needed pip pkg | . pip install oslo.config-6.8.1-py2.py3-none-any.whl --no-index --find-links file:///opt/netmon/pip_pkg pip install msgpack-python-0.5.6.tar.gz --no-index --find-links file:///opt/netmon/pip_pkg/ pip install oslo.log-3.42.3-py2.py3-none-any.whl --no-index --find-links file:///opt/netmon/pip_pkg/ pip install greenlet-0.4.15.tar.gz --no-index --find-links file:///opt/netmon/pip_pkg/ pip install prettytable-0.7.2.tar.bz2 --no-index --find-links file:///opt/netmon/pip_pkg/ pip install oslo.messaging-9.5.0-py2.py3-none-any.whl --no-index --find-links file:///opt/netmon/pkg/ pip install passlib-1.7.1-py2.py3-none-any.whl --no-index --find-links file:///opt/netmon/pkg pip install MySQL-python-1.2.5.zip --no-index --find-links file:///opt/netmon/pkg pip install flask --no-index --find-links file:///opt/netmon/pkg pip install oslo.db-4.44.0-py2.py3-none-any.whl --no-index --find-links file:///opt/netmon/pkg pip install supervisor-4.0.4.tar.gz --no-index --find-links file:///opt/netmon/pkg pip install APScheduler-3.6.1-py2.py3-none-any.whl --no-index --find-links file:///opt/netmon/pkg pip install gevent-1.4.0.tar.gz --no-index --find-links file:///opt/netmon/pkg pip install bcrypt-3.1.3.tar.gz --no-index --find-links file:///opt/netmon/pkg pip install cffi-1.10.0.tar.gz --no-index --find-links file:///opt/netmon/pkg pip install cryptography-1.5.tar.gz --no-index --find-links file:///opt/netmon/pkg pip install paramiko-2.4.2-py2.py3-none-any.whl --no-index --find-links file:///opt/netmon/pkg pip install ncclient-0.6.3.tar.gz --no-index --find-links file:///opt/netmon/pkg pip install easysnmp-0.2.5.tar.gz --no-index --find-links file:///opt/netmon/pkg . | Create Link | . ln -s /usr/local/python2.7/bin/python /usr/bin/python ln -s /usr/local/python2.7/bin/python /usr/bin/python ln -s /usr/local/python2.7/bin/pip /usr/bin/pip ln -s /usr/local/python2.7/bin/supervisorctl /usr/bin/supervisorctl ln -s /usr/local/python2.7/bin/supervisord /usr/bin/supervisord . | Make install snmp version5.7 | . make install snmp 5.7 tar -zxvf net-snmp-5.7.3.tar.gz cd net-snmp-5.7.3 ./configure make make install snmpd --version export LD_LIBRARY_PATH = /usr/local/lib . | Other | . # easy snmp pip install easysnmp-0.2.5.tar.gz --no-index --find-links file:///opt/netmon/pkg # config environment variable vim /etc/ld.so.conf &gt; /usr/local/lib ldconfig . ",
    "url": "/docs/archives/2020/2020-05-14-redhat-6.5-python-dependency/#red-hat-enterprise-linux-kernel-version-2632-3813",
    
    "relUrl": "/docs/archives/2020/2020-05-14-redhat-6.5-python-dependency/#red-hat-enterprise-linux-kernel-version-2632-3813"
  },"332": {
    "doc": "Red Hat Enterprise Linux Kernel Version 2.6.32 3.8.13 python依赖环境手动部署",
    "title": "Red Hat Enterprise Linux Kernel Version 2.6.32 3.8.13 python依赖环境手动部署",
    "content": "Red-Hat . Python . 2020-05-14 14:56:51 +0800 . ",
    "url": "/docs/archives/2020/2020-05-14-redhat-6.5-python-dependency/",
    
    "relUrl": "/docs/archives/2020/2020-05-14-redhat-6.5-python-dependency/"
  },"333": {
    "doc": "技术栈提升规划 [2020]",
    "title": "技术栈提升规划 [2020]",
    "content": "体系结构 . 2020-05-18 15:56:38 +0800 . ",
    "url": "/docs/archives/2020/2020-05-18-tech-stack-planning-2020/",
    
    "relUrl": "/docs/archives/2020/2020-05-18-tech-stack-planning-2020/"
  },"334": {
    "doc": "Git进阶",
    "title": "Git 进阶用法",
    "content": " ",
    "url": "/docs/archives/2020/2020-07-12-git-advanced/#git-%E8%BF%9B%E9%98%B6%E7%94%A8%E6%B3%95",
    
    "relUrl": "/docs/archives/2020/2020-07-12-git-advanced/#git-进阶用法"
  },"335": {
    "doc": "Git进阶",
    "title": "I. Git CLI 高级用法",
    "content": "1. 重置头部指针 . git reset {commitHash}/HEAD~{number} --hard . | 可以使用此命令重置当前提交的指针，将指针放在一个特定的提交上，如果想要远端达到相同的效果则需要 --force 强制推送远端，此命令生效后，会导致重置的哈稀值之前的提交都不在提交记录中 | --hard表示强制重置 | . git reflog . | 使用reflog命令可以再次看到reset之前的提交的哈稀值，再次使用git reset可以重新回到之前的提交点 | . 2. 合并多次已同步远端的提交 . git rebase -i {commitHash}/HEAD~{number} . | 使用rebase -i指定到你想要合并的提交的前一个提交的哈稀值上，完成后会进入vim模式 | . pick 2f2fcb4d2 \"{commit message}\" pick 3f4a9e8e6 \"{commit message}\" pick 5f4a7e8e6 \"{commit message}\" . | 提交顺序为倒序，最下面的是最新的提交，此处有两种方式可以合并下面两个提交到第一行的最老的提交上 . | 使用关键词 squash 或者 s （s是缩写形式）替换掉第二行和第三行的 pick，完成之后ESC: w保存修改，然后退出，此时在查看 git log 可以发现出现了一个新的提交，并且描述信息和第一行的相同，而且原本的三个提交记录仍然存在 . | 使用关键词 fixup 替换掉第二行和第三行的 pick，完成之后ESC: w保存修改，然后退出，此时在查看 git log 可以发现出现了一个新的提交，并且描述信息和第一行的相同，而且原本的三个提交记录已经不存在了 . pick：保留该commit（缩写:p） reword：保留该commit，但我需要修改该commit的注释（缩写:r） edit：保留该commit, 但我要停下来修改该提交(不仅仅修改注释)（缩写:e） squash：将该commit和前一个commit合并（缩写:s） fixup：将该commit和前一个commit合并，但我不要保留该提交的注释信息（缩写:f） exec：执行shell命令（缩写:x） drop：我要丢弃该commit（缩写:d） . | . | . git push -f origin {branch_name}:{branch_name} . | 强制推到远端仓库，与远端仓库同步此次修改 | . 3. 清除工作区域和暂存区所有修改和文件 . git clean -df . 4. 只将同一文件中的部分修改移动到暂存区 . git add --patch . | 使用 git add --patch （或者简称 -p），git 会开始把你的文件分解成它认为合理的”大块”(文件的一部分)。然后，它将提示以下问题： | . Stage this hunk [y,n,q,a,d,/,g,s,e,?]? . | 以下是每个选项的说明： | . Y 为下一次提交准备这个模块 n不为下一次提交准备此块 q 退出；不要将此块或任何剩余块放入阶段 a 将此块和文件中的所有后续块放入阶段 d 不准备此块或文件中的任何后期块 g 选择要转到的块 / 搜索与给定regex匹配的块 s 将当前的大块拆分为较小的大块 e 手动编辑当前hunk ? 打印Hunk帮助 . | 如果文件还不在存储库中，可以先执行 git add -N 。然后你可以继续使用 git add -p | . git diff --staged . | 检查是否进行了正确的更改 | . git reset -p . | reset 到 unstage 错误地添加了大块 | . git commit -v . | 在编辑提交消息时查看提交 | 注 git format-patch ，该命令的目的是将提交数据解析为.patch文件。 | . 5. 撤销一次非merge的Commit . git revert {commitHash} . 6. 强制拉取当前HEAD的新增修改 . git pull --rebase . | 对于，使用 git add --amend 和 git push -f 强制提交到同一commit的提交，如果需要在另一个本地仓库拉取同步使用 git pull 会要求解决冲突并重新提交，使用 git pull --rebase 可以直接强制拉取并重新将HEAD 指向远端最新修改； | . 7. 文件从暂存区回退到工作区 . git reset HEAD {file_name} . 8. 单独挑选任意一个提交到当前分支 . git cherry-pick {commitHash} . | 有冲突的情况下，需要单独处理冲突 | . 9. 将多个提交并入当前分支 . git rebase [startpoint] [endpoint] --onto [branchName] git checkout [branchName] git reset --hard [endpoint] . | (startpoint, endpoint] 从开始 commitHash 到结束 commitHash 是一个前开后闭的区间，需要考虑当前要并入那些提交 | 完成 rebase 后，需要reset当前分支的 HEAD 指针 | . 10. 将当前开发分支的Base同步为最新的master或CI . git rebase master . | 将当前分支的Base分支更新为最新的master | . ",
    "url": "/docs/archives/2020/2020-07-12-git-advanced/#i-git-cli-%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95",
    
    "relUrl": "/docs/archives/2020/2020-07-12-git-advanced/#i-git-cli-高级用法"
  },"336": {
    "doc": "Git进阶",
    "title": "II. Git 思维方法论 - 底层代码分析",
    "content": " ",
    "url": "/docs/archives/2020/2020-07-12-git-advanced/#ii-git-%E6%80%9D%E7%BB%B4%E6%96%B9%E6%B3%95%E8%AE%BA---%E5%BA%95%E5%B1%82%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90",
    
    "relUrl": "/docs/archives/2020/2020-07-12-git-advanced/#ii-git-思维方法论---底层代码分析"
  },"337": {
    "doc": "Git进阶",
    "title": "Git进阶",
    "content": "Git . 2020-07-12 12:30:48 +0800 . ",
    "url": "/docs/archives/2020/2020-07-12-git-advanced/",
    
    "relUrl": "/docs/archives/2020/2020-07-12-git-advanced/"
  },"338": {
    "doc": "Cloud Qualification",
    "title": "云认证",
    "content": "学习&amp;考试准备 . | 学习路径 . | 云计算基础 | 云服务器产品 | 云网络产品 | CDN加速产品 | 云存储产品 | 数据库产品 | 安全产品 | 视频与通信服务 | . | . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#%E4%BA%91%E8%AE%A4%E8%AF%81",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#云认证"
  },"339": {
    "doc": "Cloud Qualification",
    "title": "I. 云计算基础",
    "content": " ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#i-%E4%BA%91%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#i-云计算基础"
  },"340": {
    "doc": "Cloud Qualification",
    "title": "1.1 数据中心",
    "content": "1.1.1 EDC . | TCO = CapEx + OpeEx + OppCost | TVO = IT带来的业务价值与收益 | . | L4 | 业务应用层 各种应用系统 | . | L3 | 应用支撑层 中间件、消息、开发环境、API / 数据分析层 数据库 | . | L2 | IT基础设施 服务器、网络、存储、安全 | . | L1 | 机房设施层 电源、机柜 | . | L0 | 楼宇系统层 机房、传输 | . | 中心等级、云DC在T3级以上，并行维护+99.982%+1.6H年宕机时间 . | IDC资源出租，托管型、租用型，成本低，上线块，标准化，电信级可靠、运维管理； . | 托管，企业要购买硬件+管理维护+业务 | 租用，运营商要硬件投入、电力公园、管理维护 | . | . 1.1.2 云计算 . | 按需服务，按量付费的服务模式，按需可配置的计算资源共享池 | 2006 Google CEO提出云计算 Cloud Computing . | 独立自建 &gt; 部分租用 &gt; 按需使用 | 成本低，上线时间很快，运维管理简单、弹性扩展、范围L0-L4，自主公有云、私有云 | . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#11-%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#11-数据中心"
  },"341": {
    "doc": "Cloud Qualification",
    "title": "1.2 核心特征",
    "content": "1.2.1 模型 . | 公有云 | 私有云 | 混合云 | 行业云 | . | 服务目录 |   | 服务生命周期管理 | 运维管理系统 | . | SaaS 软件即服务 | 服务编排调度 | 服务生命周期管理 | 运维管理系统 | . | PaaS 平台即服务 | 服务编排调度 | 服务生命周期管理 | 运维管理系统 | . | IaaS 基础设施即服务 | 服务编排调度 | 服务生命周期管理 | 运维管理系统 | . | 虚拟基础设施 |   |   | 运维管理系统 | . | 物理基础设施 |   |   | 运维管理系统 | . | 资源池化 提升利用率/可用性 | 弹性扩展 业务需求/成本均衡 | 按需服务 资源/时间 | 泛网络访问 随时随地/高质量 | 服务可度量 服务计费/精细化运营 | . 1.2.2 服务模式 . | 服务使用/应用层/中间层/基础设施 | 租户维护如下 | . | Iaas | PaaS | SaaS | . | 服务使用/应用层/中间层 | 服务使用/应用层 | 服务使用 | . 技术架构 . | SaaS | . | 应用层 |   |   |   |   | . | Portal | CRM | ERP | OA | 其他 | . | PaaS | . | 中间层 |   |   |   |   | . |   | 访问控制 | 负载均衡 | 开发工具 | 服务总线 | . | 中间件 |   |   |   |   | . | 数据库 |   |   |   |   | . | IaaS | . | 基础架构层 |   |   |   |   | . |   | 计算资源池 | 存储资源池 | 网络资源池 | 其他资源池 | . | 虚拟化 |   |   |   |   | . |   | 主机 | 存储 | 网络 | 其他基础设施 | . | 管理层 | . | 云计算管理 |   |   |   |   |   |   |   |   | . |   | 帐号管理 | 配置管理 | 计费管理 | 安全管理 | 流程管理 | 运维管理 | SLA监控 | API | . 1.2.3 部署方式 . | 公、私、混、行业 . | 公、私区别 . | 多租户、不同组织；同组织、单租户 | 使用权属于客户、所有权属于服务商；使用权、所有权都属于客户 | 成本低；成本高 | 运维较简单；较为复杂 | 较低的自主可控；较高的自主可控 | . | 混合 . | 公+私，核心为私，非核心为公 | 多云统一，多云网关统一管理多个服务商的云服务，高质量议价权、多灾备 | . | 行业 . | 针对行业或者互联网产品深度优化； | . | . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#12-%E6%A0%B8%E5%BF%83%E7%89%B9%E5%BE%81",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#12-核心特征"
  },"342": {
    "doc": "Cloud Qualification",
    "title": "1.3 关键技术",
    "content": "1.3.1 计算虚拟化 . | 虚拟化前，单一OS，软件和硬件强耦合，利用率低，扩展性和容错性差 | 裸金属架构，虚拟化层运行在硬件上，提供CPU和内存资源池、VM、软硬解耦，故障迁移、弹性扩展 | 分类 . | 全虚拟化，OS直接运行在虚拟化层上 . | ESXi . | User App | GuestOS | 虚拟化层，OS特权指令通过BT转换执行 | 硬件 | . | KVM . | User App | GusetOS | 虚拟化层，OS特权指令切换到根模式执行 | 硬件 | . | . | 半虚拟化，OS需要修改安装额外的驱动 . | Xen . | User APP | PV GuestOS | 虚拟化，OS特权指令超级调用Hypercall | 硬件 | . | . | . | 对比 . | KVM . | 全虚拟化 | KVM内核完成CPU和内存虚拟化 | QEMU完成磁盘和网络的虚拟化 | Linux进程进行虚拟化调度和管理 | . | Xen . | 全/半 | Xen内核完成CPU、内存 | Dom0完成磁盘和网络 | Dom0完成虚拟化调度和管理 | . | ESXi . | 全 | ESXi内核完成CPU、内存 | 虚拟化内核完成磁盘和网络IO | 虚拟化内核完成虚拟化调度和管理 | . | . | KVM . | VM是Linux进程，有进程管理模块进行管理 | KVM内核负责CPU和内存虚拟化，QEMU负责I/O虚拟化 | 硬件支持Intel-VT，AMD-V | . | KVM优势 . | 高性能 | 易扩展 | 易管理 | . | . 1.3.2 分布式数据存储 ServerSAN . | 原理 . | 将server上分散的本地盘整合为资源池 | 读写元 . | 承接应用IO | . | 控制元 . | Hash算法确保I/O分布到各个节点 | . | 存储元 . | 负责写入数据到存储块 | . | . | 优势 . | 高性价比，普通盘高性能 | 易扩展，线性增删节点 | 高可靠：保存3副本，快速修改和迁移 | . | . 1.3.3 网络虚拟化 SDN . | 应用层 |   |   | 业务应用 | . | 控制层 | SDN控制软件 | 网络服务 | ^API | . | 基础设施 | 网络设备 | 路由器、交换机、防火墙 | ^控制数据接口（OpenFlow） | . | DSN/NFV . | SDN software define network . | 核心 . | 控制面和数据面分离 | 通用路由器和交换机 | 控制面可编程 | . | 场景 . | 数据中心网络 | . | 优点 . | 处理OSI 2-3层（链路，网络），优化交换机、路由器、无线 | . | . | NFV network function virtulization . | 核心 . | 功能和硬件解耦 | 商业化硬件替代专用 | 数据面可编程 | . | 场景 . | 运营商基础网络 | . | 优点 . | 处理4-7层（传输、会话、表示、应用），优化网络功能、LB、FW、WAN | . | . | . | . 1.3.4 OpenStack . | SERVICE | DESC | . | Nova | 计算 | . | Neutron | 网络 | . | Keystone | 认证和授权 | . | Glance | 镜像 | . | Swift | 对象存储服务 | . | Cinder | 块存储服务 | . | Horizon | 图形化管理界面 | . | Ceilometer | 监控 | . | Heat | 编排调度 | . | 开源 | 标准 | 部署、运维、升级复杂 | 性能和扩展性差 | 容灾能力不足 | . 1.3.4 VStation . | 自主研发的云计算管理平台 | 设计原则 . | 平行扩展、简洁高效、异步 | Fail-fast、无状态、高可用 | 共享信道（以太网） | 事务处理（SQL） | 逻辑抽离（CGI） | 易于追溯（git） | . | 架构 . | [dispatcher] &lt;==&gt; API =&gt; . | [TaskCmen] MQ &lt;==&gt; . | &lt;==&gt; . | [Volume / cbs] | [dfw] | . | Compute Access &lt;==&gt; . | Compute | . | Image Access &lt;==&gt; . | Image | . | NetWork &lt;==&gt; . | IP | VPC | . | Scheduler | Resource | Error | Debug | . | . | . | OpenStack vs VStation . | 集群：千台 / 十万 | 容灾：需开源组件支持 / 任一模块跨机房容灾 | 运维：需开发 / 监控、可视化运维 | 人员：百 / 十 | 性能：不支持100台同时创建 / 支持数万台同时创建 | . | . 1.3.5 容器 . | 轻量级虚拟化，进程隔离，应用和依赖环境、配置共同打包封装，提供独立可移植的运行环境 . | | 虚拟化 | 容器化 | . | APP1 | APP2 | APP1 | APP2 | . | Bins/Libs | Bins/Libs | Bins/Libs | Bins/Libs | . | GuestOS | GuestOS | 容器引擎 | . | 虚拟化层 | 虚拟化层/操作系统 | . | 硬件 | 硬件 | . | . | . Docker . | 标准化，移植性强，Build, Ship and Run Anywhere | 管理 . | K8S（Kubernetes）开源容器编排管理调度 | . | 优势 . | 轻量 | 秒级部署 | 易于移植 | 弹性伸缩 | . | . 1.3.6 大数据 &amp; AI . | 未来互联网就是利用人工智能在云端处理大数据。—Pony Ma | 大数据 . | 数据量大 | 价值密度低 | 多样化 | 高速产生 | . | AI . | 大数据 | 算法 | 算力 | 边界清晰 | . | . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#13-%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#13-关键技术"
  },"343": {
    "doc": "Cloud Qualification",
    "title": "1.4 行业",
    "content": ". | 互联网：C2C / B2C | 互联网+：B2B2C | 产业互联网：C2B2B2C | . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#14-%E8%A1%8C%E4%B8%9A",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#14-行业"
  },"344": {
    "doc": "Cloud Qualification",
    "title": "II. 云服务器V2.0",
    "content": " ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#ii-%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8v20",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#ii-云服务器v20"
  },"345": {
    "doc": "Cloud Qualification",
    "title": "2.1 基础",
    "content": "2.1.1 地域和可用区 . | 可用区 Zone . | 统一地域内电力和网络互相独立的物理数据中心，命名=城市 + 编号 | . | 地域 region . | 一个独立的地理去域名，命名=覆盖范围+机房所在城市 | . | 云：25个地域+53个可用区 | 部署多地域多可用区 . | 就近接入 | 隔离故障 | LB | HA | . | . 2.1.2 实例 . | 实例 . | 完整的云服务器（VM），CPU、内存、磁盘、网络、OS | 命名=系列.机型.规格（vCPU核心数和内存大小） | S4.MEDIUM4 | . | 管理 . | 控制台或者API管理 | 在线调整实例配置，重启生效 | . | 安全 . | 策略 | 安全组 | 登录控制 | . | 规格 . | | 标准型 | S1 | S2 | S3 | S4 | . | CPU | Intel Xeon | Xeon Broadwell V4 | Skylake 6133 | Skylake 6148 | . | 内存 | DDR3 | DDR4 | 最新DDR4 | 最新DDR4 | . | 内网带宽 | 10Gbps | 10Gbps | 10Gbps | 25Gbps | . | Max规格 | 48C96G | 56C224G | 80C320G | 72C228G | . | . | 实例类型 . | 不同配置实现不同的IO、计算、网络、存储能力 | 选择CVM实例 | . | 实例族 . | 某一类实例类型集合 | . | 实例类型 . | | 类型 | 特点 | 场景 | . | 标准 | 均衡计算、内存和网络 | 中小Web应用、数据库、企业官网 | . | 内存 | 大内存 | 大量的内存操作、查找和计算、分布式内存缓存 | . | 高IO | 高IO、高吞吐量、低时延 | NoSQL、集群化数据库、OLTP系统 | . | 计算 | 高主频CPU、最高性价比 | 高流量Web、MMO游戏、HPC | . | . | . 2.1.3 云服务器镜像 . | 定义 . | 创建云服务器的模板，提供操作系统和软件配置 | . | 作用 . | 批量部署 | 特定软件部署 | 运行环境备份 | . | 镜像类型 . | 公有 | 服务市场 | 自定义 | 共享 | . | 镜像优势 . | 部署时长： 3 -5 min | 过程：快速创建合适和云服务器 | 安全性：测试审核、安全加固 | 适用情况：四种镜像 | . | . 2.1.4 云服务器存储 . | 介质 . | 普通云硬盘 | 高性能云硬盘 | SSD云硬盘 | . | 场景 . | 系统盘 | 数据盘 | . | 架构 . | 本地盘 | 云硬盘 | 对象存储 | . | . 2.1.5 . | 虚拟主机 &gt; 独立主机 &gt; VPS &gt; 云服务器 | . 2.2.1 CVM (Cloud Virtual Machine) . | 弹性伸缩的计算服务 . | 弹性伸缩，分钟 | 灵活配置，CPU、内存、带宽 | 稳定可靠，3副本 | 管理简单，API/CLI/控制台 | 安全网络，VPC/ACL/安全组 | 全面防护，木马/漏洞/破解 | . | 业务，电商 . | 需求 . | 突发流量井喷 | 业务保障、成本控制 | . | 方案 . | 标准CVM、镜像，S2 1C1G | 弹性伸缩组：闲时减实例，忙时增实例 | . | . | . 2.2.2 GPU . | 高速并行计算和浮点计算 | 高并行、高吞吐、低时延，科学计算性能比传统架构高50倍 | CPU：几十个核心、复杂逻辑控制单元、强大的算术逻辑单元、逻辑控制、串行运算 | GPU：数千个加速核心，众多ALU、多线程超大并行，计算密集，并行计算 . | 计算型GPU . | 深度学习：训练和推理、图像、语音识别 | 科学计算：建模、基因组、金融 | 视频编码：高清视频编码 | . | 渲染型GPU . | 图形工作站：动画、游戏、建模 | 非线性编辑：电源特效 | . | 需求 . | AI算法建模 | 高计算能力 | . | 方案 . | GPU实例 Tesla M40 GDDR5 24GB | 缩短深度学习和训练时间 | 避免采购昂贵硬件 | . | . 2.2.3 FPGA (Field Programmable Gate Array) . | 现场可编程阵列的计算服务 | FPGA 镜像在几min内部署实例，实现硬件加速 | 3种类型 . | FX2.7xlarge60 1 14C60GB | FX2.14xlarge120 2 28C120GB | FX2.28xlarge240 4 56C240GB | . | 优势 . | 硬件加速，协同执行，运行速度比CPU快20倍 | 硬件可编程，FPGA可重复编程，自定义硬件加速 | 产权交易平台，统一规范和安全可靠的FPGA硬件平台和服务市场 | . | 场景 . | 深度学习 | 实时图像压缩处理 | . | . 2.2.4 专用宿主机CDH CVM Dedicated Host . | 独享主机资源、搭建平台、创建主机 | 优势 . | 物理隔离 | 资源独享 | 安全合规 | 灵活配置 | . | 场景 . | 金融业务：安全合规 | 高性能业务：资源独享 | . | . 2.2.5 黑石 CPM . | 黑石物理服务器 Cloud Physical Machine . | 按需购买、按量付费的物理服务器租赁服务 | 云端专用、高性能、安全隔离的物理集群 | . | 黑石 Stack-V，深度整合VMware . | 混合云 | 深度整合VMware套件，包括vSphere6.5、vSAN6.6、NSX6.3等，VMware许可 | 通过互联网，整合云产品 | . | 黑石 ARM，CPM for ARM . | 需求：移动端游戏真机测试 | 方案：黑石ARM实例，运行android模拟器，测试 | . | 黑石 OpenPOWER，CPM for OpenPOWER . | 需求：大数据处理、高并发IO，大内存、高速传输 | 黑石OpenOPWER，高主频、并发线程多、内存带宽大、缓存大 | . | . 2.3.1 云服务计费模式 . | 购买渠道 . | 官网Portal购买，控制台 | API购买 | . | 模式 . | 包年包月 PrePaid | 按量付费 PostPaid | 阶梯计价、越多越省，量越大、时间越长、单价越低 | . | 价格计算器 . | 产品选型配置，价格计算，直接购买，导出清单 | . | 包年包月 . | 一次支付一个月或多月、多年的费用 | 退款，五天无理由 | 场景，低成本、长期、稳定 | 流程 . | 选购 - 订单 - 账单 - 到期处理 - 续费 | . | 停服回收 . | 到期预警，前7-前1天，续费通知，自动续费不足通知 | 欠费预警，到期当天，断网关机保留数据，系统通知 | 资源停服，当期当天-后7天，联系客服续费恢复 | 资源销毁，到期后8天，清除数据销毁资源，不可恢复 | . | . | 按量付费 . | 后付费，一定结算周期 | 业务波动大，资源使用临时性、突发性 | 流程 . | 充值 - 开通 - 冻结 - 解冻 - 账单 - 欠费 &lt; | . | 冻结机制 . | 系统根据结算周期和历史使用情况，预估冻结一定的余额，下次结算或资源释放时解冻 | 月结 . | 每月计算日，解冻之前的费用，并扣费 | 再次计算冻结费用 . | 设备资源：上月底Last day实际使用云服务量 X 30 X 单价 | 流量类资源：上月费用的X1或X1.2 | . | 调整配置，先解冻，在按照新配置冻结 | 资源释放，下月结算日3号，解冻 | . | 时结/日结 . | 购买，冻结1~2个结算周期的费用 | 调整配置，先解冻，在按照新配置单价冻结 | 资源释放，下月结算日3号，解冻 | . | 回收机制 . | 生成账单，结算周期，生成账单进行扣费，余额不足进入欠费状态； | 欠费保护，时：2小时，天：1天，推送欠费提醒，继续使用；冲正前，不能新开通服务 | 欠费停服，时：24小时，天：30天，系统推送停服通知，资源被强制关停；充值后，控制台重新启动；冲正前，不能新开通服务 | 欠费回收，超过欠费停服期，销毁回收，不可恢复；冲正前，不能新开通服务 | . | 限制 . | 不支持代理商代父 | 不支持代金券 | 不支持5天无理由 | 不支持切换包年包月 | . | . | . | . 2.3.4 计费方案 . | CVM 费用 = 实例费用（CPU+Mem）+ 存储费用 + 带宽费用 | 模式 . | 包年包月 . | 预付 | . | 按量计费 . | 后付费，按秒，按小时 | 阶梯：0 &lt; T1 &lt;= 96H &lt;= T2 &lt;= 360H &lt; T3 | 部分不支持关机不收费 | . | . | 方案 . | 包年包月 . | 元/月 | 单价低 | 使用一个月 | 升配无限制，降配5次 | . | 按量计费 . | 元/秒 | 初始单价高，阶梯降价，96小时，360小时，使用15天后，单价基本接近包年包月 | 按秒计费，按小时结算 | 随时升降配置，无限制 | . | . | 实例购买限额 . | 包年包月150，100（新加坡1，多伦多1，硅谷1） | 按量付费30，20（香港1，多伦多1，硅谷1） | . | 云服务器计费方案 . | CVM，包年包月、按秒、按时 | GPU，包年包月、按秒、按时 | FPGA，内测 | CDH，包年包月 | CPM黑石，包年包月、按秒、按时 | . | . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#21-%E5%9F%BA%E7%A1%80",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#21-基础"
  },"346": {
    "doc": "Cloud Qualification",
    "title": "III. 网络产品",
    "content": "3.1.1 私有网络VPC . | Virtual Private Cloud, 是用户自定义的，逻辑隔离的专属云上网络空间 . | 不同VPC完全逻辑隔离 | SDN的方式管理VPC、实现IP地址，子网、路由表、网络ACL、流日志 | 多种连接，弹性IP，NAT网关，VPN | . | 私有网络连接 . | 每个私有网络内的服务资源内网互通 | 不同VPC之间内网默认不通 | 用 ”对等连接“ 和 ”云联网“ 实现同一个账户下的VPC子网互通 | . | VPC内部 . | 自有定义网段划分、IP、路由策略，部署云服务器、LB、云数据库 | 对等连接和基础网络互通功能，连接内网资源，实现同服和两地三中心容灾 | ACL和安全组，保证网络安全性 | . | VPC . | 自定义网络 . | 自定义 网段、子网、路由策略，部署服务 | . | 灵活、高性能访问 . | 性IP、NAT网关和公网网关 访问Internet | . | 稳定可靠的数据中心连接 . | 混合云，连接云上计算资源和本地数据中心，使用 公网VPN or 专线 接入 | . | 灵活互通 . | 对等连接和基础网络互通 实现私有网络的资源互通 | . | 多维度安全 . | 网络ACL和安全组 实现端口和实例维度的资源访问控制 | . | . | . 3.1.2 VPC网段 . | 私有网段 . | 10.0.0.0 - 10.255.255.255 [掩码16-28] | 172.16.0.0 - 172.31.255.255 [掩码16-28] | 192.168.0.0 - 192.168.255.255 [掩码16-28] | . | 子网 . | 云资源部署在子网内，CVM和CDB | 通过DHCP获取私有IP，不能在公网路由 | 每个子网可用IP数量，2^n - 3 （n为主机位的位数） | . | CIDR (Classless Inter-Domain Routing) . | 支持「私有网段」中的任意一个 | . | 子网 . | 一个VPC至少有一个子网组成，子网的CIDR必须在VPC的CIDR内，VPC的所有云资源必须部署在子网内 | VPC具有地域（Region）属性 | 子网具有可用区（Zone）属性 | 一个私有网络下的子网属于该地域的不同可用区 | 同一VPC下各子网内资源默认互通 | . | 默认私有网络和子网 . | 默认私有网络和自行创建的私有网络功能完全一致 | 默认VPC不会占用某个地域下的VPC配额，不需要默认VPC和子网可自行删除 | . | 子网划分 . | | xxxx xxxx. | xxxx xxxx. | xxxx xxxx. | xxxx xxxx. | xxxx xxxx. | . | 子 | 网 | 掩 | 码 [24] | 主机位 | . | 子网划分 . | 通过设置子网的位数，来决定可用的子网数和主机IP数 . | 子网位数为m，主机位数为2^(32-m) - 3 | 10.3.5.7/24 . | 主机数量=2^(32-24) - 3 | 网络地址10.3.5.0，广播10.3.5.255 | . | . | . | . | . 3.1.3 VPC路由表 . | VPC内互通，不同VPC内网不通，通过路由表实现子网间、子网与外部的路由通信 | 路由表 . | 每个私有网络有一个默认路由，用户可以创建自定义路由表； | 由多条路由策略组成 | 用于控制VPC内子网的出流量方向 | 每个子网只能关联一个路由表，一个路由表可以关联多个子网 | 分类 . | 默认路由表 . | 创建VPC自动生成 | 新建子网自动关联默认路由表 | 添加删除修改路由策略，无法删除默认路由 | . | 自定义路由表 . | 可以删除 | 为相同策略的子网，创建一个路由表，将路由协议与所有子网关联 | 创建时关联、创建后关联 | . | . | . | 路由策略 . | 目的端 . | 目的网段 | 不能为路由表所在VPC的IP段，Local路由已经表示过此VPC内网默认互通 | . | 下一跳类型 . | 数据包出口，支持类型：NAT网关、云服务器等 | . | 下一跳 . | 指定具体跳转的下一跳实例，ID标识 | . | . | 路由策略优先级 . | 多条策略，由高到低 . | 私有网络内流量 | 最精确路由（最长前缀匹配，优先匹配掩码最长的路由策略并确定下一跳） | 公网IP | . | . | . 3.1.4 VPC 访问控制 . | ACL (Access Control List) . | 控制进出子网的数据流 | 子网级别无状态的可选安全层 | 协议和端口 | . | 安全组 . | 配置放通和拒绝的端口/协议 | 有状态的包过滤功能的虚拟防火墙，用于设置云服务器的实例级别的网络访问控制 | 安全隔离手段 | . | | 安全组 | ACL | . | CVM实例级别的流量控制 【第一层】 | 子网级别的流量控制 【第二层】 | . | 放通和拒绝的端口/协议 | 放通和拒绝的端口/协议 | . | 有状态：返回数据被自动允许 | 无状态：返回数据必须明确规则 | . | 启动CVM，指定安全组，关联实例 | 自动应用到子网内的所有CVM实例，可以做备份安全层 | . | . 3.1.5 弹性网卡 . | ENI [Elastic Network Interface] | 绑定私有网络云服务器的弹性网络接口，可以自有迁移 | 优势 . | 多网卡 | 网络隔离 | 灵活迁移 | . | 绑定多个ENI，实现HA | 单个ENI绑定多个IP，实现单机多IP | 多网卡 . | 创建时自动生成的网卡 | 主持绑定多个辅助弹性网卡 | 弹性网卡可以属于同一个VPC下的不同子网 | 支持独立的安全组 | 配置独立的路由和转发策略 | . | 灵活迁移 . | 自由地在同VPC和同可用区下的云服务器之间自由迁移 | 绑定，保留内网IP、弹性公网IP，安全组策略 | 迁移后无需重新配置关联关系 | . | 网络隔离 . | 绑定同VPC可可用区的不同子网的弹性网卡，设定独立的路由转发策略，实现隔离 | 云服务器内设定策略，失信特定目的端的流量指向不同的网卡 | . | . 3.2.1 网络连接 . | 对等连接 . | 不同VPC之间内网互通 | . | 云联网 . | 不同VPC之间内网互通 | 私有网络接入私有数据中心 | . | 弹性IP、NAT网关、公网网关 . | 访问公网 | . | VPN . | 私有网络接入私有数据中心 | . | 专线 . | 私有网络接入私有数据中心 | . | 基础网络互通 . | 基础网络和私有网络内网通信 | . | 安全组和ACL . | 多维度网络安全 | . | . 3.2.2 公网接入 . | VPC里的服务器，绑定公网IP来实现 . | 普通公网IP，CVM上申请绑定，解绑后释放，无法找回 | 弹性公网IP，EIP . | 关联帐号，解绑保留，重新绑定 | 提供外网访问能力 | EIP，独立申请，支持CVM/NAT网关实例动态绑定和解绑 | 释放 . | 用户控制台/API释放 | 欠费释放，余额小于0且超过2小时，免费保留24H，24+2H后释放 | . | . | . | 公网网关 . | 是开启了转发功能的主机 | 通过不同子网的公网网关访问Internet | 做源地址转换 | 购买是没有勾选，则购买后无法切换 | 有公网流量转发功能，为其他云主机转发，公网IP的主机没有转发能力 | . | 公网网关所在子网 . | 只能转发 非所在子网 的路由转发请求，不能与使用网关的服务在一个子网下 | . | NAT网关 . | 通过IP地址转换提供Internet访问 | SNAT，源地址转换 | DNAT，目的地址转换 | 网关流量、流量高级、共享带宽包 | . | NAT [NAT Gateway] . | IP地址转换的网络云服务 | 访问Internet | 不暴露公网 | IP流量管理，异常流量定位 | 海量并发 | SNAT [Source Network Address Translation] . | 同一公网IP访问，支持5GB | . | DNAT [Destination Network Address Translation] . | 将内网IP、协议、端口映射成外网IP、协议、端口，是云服务器能被外网访问 | . | 网关监控 . | 限制内IP和NAT带宽 | . | 流量告警 . | 阈值告警 | . | 共享带宽包 . | 多个IP共享公网带宽，不同流量错峰 | . | 安全高仿 . | BGP做DDoS和CC防护，最高310Gbps防护 | . | 自动容灾 . | 双机热备、自动容灾 | 单机故障自动切换，业务无感知 | 可用性高达99.99% | . | . | 公网接入的对比 . | NAT vs 公网网关 的优势 . | 大容量 | 双机热备高可用 | 省成本 | 使用约束 . | 公网网关最大100Mbps，可以购买形成出口集群 | 通过路由表汇总配置目的端路由，转发流量可以在网关间LB | 公网网关不支持NAT接入 | 专线网关、VPN网关不支持NAT接入 | 网关子网和普通子网不能关联到同一张路由表，需要新建 | . | . | NAT | 公网网关 | . | 双机热备、自动热切换 | 手动故障切换 | . | 带宽最大5G | 取决于与服务器带宽 | . | 最多绑定10个弹性IP | 1个弹性IP或普通公网IP | . | 无限速 | 云服务器限速 | . | 最大1000万连接 | 50万 | . | 不占VPC内网IP | 内用内网IP | . | 不支持安全组 | 支持安全组 | . | . | . 3.2.3 DC连接 . | Direct Connect 专线 . | 物理专线 | 专用通道 | 专线网关 | 多地域 | 多端口协议，100Base-T,1000Base-T, 1000Base-LX, 10GBase-LR 四种端口，MSTP，SDH，OTN，DWDM多种协议 | 双线接入 | NAT | . | VPN . | 安全加密网络隧道 | IKE，IPsec数据加密 | 监控告警 . | 无需额外收费 | . | . | . 3.2.4 对等连接 . | 大带宽、高质量互通服务 . | 多VPC，多地域，多账户异构 | 5GB以上 | . | . 3.2.5 云联网 . | 内网互联、全网互联、学习调度、路由自动下发 | . 3.3.1 CLB . | Cloud Load Balancer | . 3.3.2 流量分发算法 . | 四层负载均衡 . | TCP、UDP，端口+VIP转发 | . | 七层 . | HTTP和HTTPS，基于内容转发 | . | 算法 . | 加权轮训算法 | 加权最小连接数算法 | 源地址散列算法 | . | 公网负载均衡 | 内网负载均衡 | 流量分发 . | 接入层服务器，配置一致的Docker容器承载 | . | 横向扩展，Autoscaling动态伸缩组 | . 3.3.4 CLB+CDN . | 通过CLB+CDN将不同的流量分发到对应集群 | 业务分离 | . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#iii-%E7%BD%91%E7%BB%9C%E4%BA%A7%E5%93%81",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#iii-网络产品"
  },"347": {
    "doc": "Cloud Qualification",
    "title": "3.4 网络计费",
    "content": ". | 免费 . | 内网同地域免费，不同子网通信，同地域连接免费； | 普通公网IP免费 | 帮定CVM或NAT的弹性IP | . | 收费 . | 为绑定CVM和NAT的弹性IP | 闲置的EIP，计算到S，闲置费用 0.2 * (xs/3600) | . | 公网网关本质是云服务器实例 | NAT . | 网关费用+Internet流量费用 | 共享带宽包，按照整体结算，出带宽产生高额费用 | BGP线路 | 带宽计费 . | 公网传输速率 Mbps 计费 | 包年包月、按带宽使用时长计费 | . | 流量计费，总流量GB | . | . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/#34-%E7%BD%91%E7%BB%9C%E8%AE%A1%E8%B4%B9",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/#34-网络计费"
  },"348": {
    "doc": "Cloud Qualification",
    "title": "Cloud Qualification",
    "content": "CloudComputing . 2020-07-26 13:30:07 +0800 . ",
    "url": "/docs/archives/2020/2020-07-26-cloud-qualification/",
    
    "relUrl": "/docs/archives/2020/2020-07-26-cloud-qualification/"
  },"349": {
    "doc": "MacOS Configure",
    "title": "MacOS 配置",
    "content": " ",
    "url": "/docs/archives/2020/2020-08-05-macos-configuration/#macos-%E9%85%8D%E7%BD%AE",
    
    "relUrl": "/docs/archives/2020/2020-08-05-macos-configuration/#macos-配置"
  },"350": {
    "doc": "MacOS Configure",
    "title": "I. 自动化组件部署",
    "content": "1.1 ZSH . 1.1.1 zshrc . | .zshrc | . 1.1.2 Oh My Zsh . download . | Oh My Zsh | . via curl . sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" . via wget . sh -c \"$(wget -O- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" . Manual inspection . curl -Lo install.sh https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh sh install.sh . 1.1.3 Font . | nerd-fonts . | Hack Regular Nerd Font Complete . | . 1.1.4 Color . | iTerm2-Color-Schemes | . 1.2 Brew . download . | Homebrew | . install . /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\" . ",
    "url": "/docs/archives/2020/2020-08-05-macos-configuration/#i-%E8%87%AA%E5%8A%A8%E5%8C%96%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2",
    
    "relUrl": "/docs/archives/2020/2020-08-05-macos-configuration/#i-自动化组件部署"
  },"351": {
    "doc": "MacOS Configure",
    "title": "II. 应用程序",
    "content": "2.1 开发 . | Beyond Compare | CLion | Dash | Docker | GoLand | iTerm | MacDown | MindNode | Office | Navicat Premium | OmniGraffle | PhpStorm | Postman | PyCharm | Sublime Text | Typora | Visual Studio Code | XMind ZEN | . 2.2 网络 . | OneDrive | Proxifier | ShadowsocksX-NG-R8 | . 2.3 工具 . | Blackmagic Disk Speed Test | Alfred 3 | Android File Transfer | CleanMyMac X | DaisyDisk | Firefox | gfxCardStatus - video card switcher | Google Chrome | HandShaker | iHosts | IINA | iStat Menus | Karabiner-Elements | Karabiner-EventViewer | Kindle | Magnet | NightOwl | Parallels Desktop | Speedtest | TG Pro | Typeeto | VLC | . 2.4 开源 . | AirBar | . 2.5 墙内 . | QQ | WeChat | WeChat Work | . 2.6 试用软件下载站点 . | nmac.to | xclient.info | . ",
    "url": "/docs/archives/2020/2020-08-05-macos-configuration/#ii-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F",
    
    "relUrl": "/docs/archives/2020/2020-08-05-macos-configuration/#ii-应用程序"
  },"352": {
    "doc": "MacOS Configure",
    "title": "III. 高级配置",
    "content": "3.1 关闭”不明身份开发者”检查 . sudo spctl --master-disable . 3.2 Dock中增加空格图标做分隔符 . defaults write com.apple.dock persistent-apps -array-add '{\"tile-type\"=\"spacer-tile\";}' killall Dock . 3.3 CLI启动sublime . sudo ln -s /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl /usr/local/bin/subl cd /usr/local/bin echo $PATH . 3.4 高效的中文输入法 . | 【鼠鬚管】輸入法 | . ",
    "url": "/docs/archives/2020/2020-08-05-macos-configuration/#iii-%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE",
    
    "relUrl": "/docs/archives/2020/2020-08-05-macos-configuration/#iii-高级配置"
  },"353": {
    "doc": "MacOS Configure",
    "title": "IV. 问题修复",
    "content": "4.1 修复MacOS音频无声音的问题 . sudo launchctl stop com.apple.audio.coreaudiod &amp;&amp; sudo launchctl start com.apple.audio.coreaudiod . 4.2 清除当前dns缓存 . sudo killall -HUP mDNSResponder sudo killall mDNSResponderHelper sudo dscacheutil -flushcache . 4.3 蓝牙信道优化、连接修复 . | 下载 Additional_Tools_for_Xcode Tools_for_Xcode | 打开 Additional_Tools_for_Xcode.dmg 选择 Hardware &gt; Bluetooth Explorer ，进入 Bluetooth Explorer 的 menu bar 选择 Tools &gt; RSSI Sweeper | start 后蓝牙会暂时端口，蓝牙模块在扫描到其他蓝牙连接的信道后，会优化当前连接的信道，保证最优质的连接 | . ",
    "url": "/docs/archives/2020/2020-08-05-macos-configuration/#iv-%E9%97%AE%E9%A2%98%E4%BF%AE%E5%A4%8D",
    
    "relUrl": "/docs/archives/2020/2020-08-05-macos-configuration/#iv-问题修复"
  },"354": {
    "doc": "MacOS Configure",
    "title": "MacOS Configure",
    "content": "MacOS . 2020-08-05 08:40:51 +0800 . ",
    "url": "/docs/archives/2020/2020-08-05-macos-configuration/",
    
    "relUrl": "/docs/archives/2020/2020-08-05-macos-configuration/"
  },"355": {
    "doc": "Agile",
    "title": "敏捷开发",
    "content": " ",
    "url": "/docs/archives/2020/2020-09-22-roles-of-agile-team/#%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91",
    
    "relUrl": "/docs/archives/2020/2020-09-22-roles-of-agile-team/#敏捷开发"
  },"356": {
    "doc": "Agile",
    "title": "敏捷团队中的角色",
    "content": "Business owner . | 行业客户，需求提出方 | . Developer . | 开发工程师，开发需求并交付产品 | . End user . | 端用户，产品面向用户 | . BA . | Business Analyst - 业务分析员 | 负责理解并挖掘客户的需求，然后将需求转化为具体的 AC（Acceptance criteria, 验收标准） | 作为 Business owner 和 Developer 直接的桥梁，将业务知识最大化的传递给 Developer ，保证工程师对业务准确的理解 | . QA . | Quality Analyst - 质量分析师 | Quality Assurance - 质量保证 | tester 的职责是按照 AC ，对系统功能进行测试，包括功能性、安全性、性能等维度保证系统的健壮性及所开发功能符合 AC | QA 的职责不仅仅只是一个 tester， QA 的职责不是单纯的在开发完成后，接收 AC 并测试。为了解决开发过程中参与度不足导致的需求衰减问题，QA 应尽早接入用户故事的前期工作，在BA分析 user story 及细分任务时就应该准备开发环境、测试策略、测试数据。 | tester可以从测试的角度给开发人员提供一些建议。而在开发人员开发卡的时候，tester可以和开发人员一起pair编写自动化的测试用例。开发人员开发完毕后，tester可以在开发人员的本地环境中快速验证其是否满足所有验收条件，必要的自动化测试是否已经完成等。在UAT环节，tester又可以帮助business owner进行sign off | QA 作为连接器把需求过程中的每个环节的参与者串联起来，他的职责已经超出了开发所理解的单纯的 tester，所以将这个角色定义为质量分析师，在整个产品的生命周期中保证产品的质量，最终高质量交付 | . ",
    "url": "/docs/archives/2020/2020-09-22-roles-of-agile-team/#%E6%95%8F%E6%8D%B7%E5%9B%A2%E9%98%9F%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2",
    
    "relUrl": "/docs/archives/2020/2020-09-22-roles-of-agile-team/#敏捷团队中的角色"
  },"357": {
    "doc": "Agile",
    "title": "敏捷开发中的重要概念",
    "content": ". | TODO | . ",
    "url": "/docs/archives/2020/2020-09-22-roles-of-agile-team/#%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%E4%B8%AD%E7%9A%84%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5",
    
    "relUrl": "/docs/archives/2020/2020-09-22-roles-of-agile-team/#敏捷开发中的重要概念"
  },"358": {
    "doc": "Agile",
    "title": "Agile",
    "content": "Agile . 2020-09-22 20:05:23 +0800 . ",
    "url": "/docs/archives/2020/2020-09-22-roles-of-agile-team/",
    
    "relUrl": "/docs/archives/2020/2020-09-22-roles-of-agile-team/"
  },"359": {
    "doc": 2020,
    "title": "2020",
    "content": " ",
    "url": "/docs/archives/2020/2020/#2020",
    
    "relUrl": "/docs/archives/2020/2020/#2020"
  },"360": {
    "doc": 2020,
    "title": 2020,
    "content": " ",
    "url": "/docs/archives/2020/2020/",
    
    "relUrl": "/docs/archives/2020/2020/"
  },"361": {
    "doc": "Mac Reset Smc Nvram",
    "title": "Mac 重置 SMC 和 NVRAM",
    "content": " ",
    "url": "/docs/archives/2021/2021-02-15-mac-reset-smc-nvram/#mac-%E9%87%8D%E7%BD%AE-smc-%E5%92%8C-nvram",
    
    "relUrl": "/docs/archives/2021/2021-02-15-mac-reset-smc-nvram/#mac-重置-smc-和-nvram"
  },"362": {
    "doc": "Mac Reset Smc Nvram",
    "title": "第一步 重置系统管理控制器(SMC)",
    "content": ". | 将 Mac 关机。 . | 将 MagSafe 或 USB-C 电源适配器连接到电源和 Mac。 . | 在内建键盘上，按下键盘左侧的 Shift-Control-Option 键，然后同时按下电源按钮。 . | 松开所有按键，然后再次按下电源按钮以开启 Mac。 . | . 第二步 重置非易失的随机访问存储器(NVRAM) . | 关闭 Mac。 . | 在键盘上找到以下按键：Command (⌘)、Option、P 和 R。 . | 打开 Mac。 . | 听到启动声后立即按住 Command-Option-P-R 键。 . | 按住这些按键直到电脑重新启动，然后您会再次听到启动声。 . | . （如果使用 MacBook Pro 2016，您将不会听到启动声，请按住这些按键至少 20 秒钟，确保 Mac 正确完成该过程。） . | 松开这些按键。 | . ",
    "url": "/docs/archives/2021/2021-02-15-mac-reset-smc-nvram/#%E7%AC%AC%E4%B8%80%E6%AD%A5-%E9%87%8D%E7%BD%AE%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E6%8E%A7%E5%88%B6%E5%99%A8smc",
    
    "relUrl": "/docs/archives/2021/2021-02-15-mac-reset-smc-nvram/#第一步-重置系统管理控制器smc"
  },"363": {
    "doc": "Mac Reset Smc Nvram",
    "title": "Mac Reset Smc Nvram",
    "content": "mac . 2021-02-15 16:15:52 +0800 . ",
    "url": "/docs/archives/2021/2021-02-15-mac-reset-smc-nvram/",
    
    "relUrl": "/docs/archives/2021/2021-02-15-mac-reset-smc-nvram/"
  },"364": {
    "doc": "Research of Ergonomics",
    "title": "健康的办公坐姿研究",
    "content": " ",
    "url": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#%E5%81%A5%E5%BA%B7%E7%9A%84%E5%8A%9E%E5%85%AC%E5%9D%90%E5%A7%BF%E7%A0%94%E7%A9%B6",
    
    "relUrl": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#健康的办公坐姿研究"
  },"365": {
    "doc": "Research of Ergonomics",
    "title": "正确坐姿",
    "content": ". | 脚面轻松接触地面，完全平放地面 check | 小腿与大腿之间夹角大于等于90度 check | 大腿超出椅面3公分到5公分 check | 腰部下背部有支撑 cehck | 颈椎有头枕支撑 check | 身体与大腿角度 90~110度之间，越大腰部颈部压力越小 check | 平视显示器，视线处于显示器中上段 | 手托不能太高，让大臂和小臂自然成90 ~ 110度之间的夹角，使肩部不要感受到压力和酸胀感 | 适当倾斜键盘托盘，让鼠标手和键盘更容易控制 | . ",
    "url": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#%E6%AD%A3%E7%A1%AE%E5%9D%90%E5%A7%BF",
    
    "relUrl": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#正确坐姿"
  },"366": {
    "doc": "Research of Ergonomics",
    "title": "久坐有害健康",
    "content": ". | 保持健康正确的坐姿，每次如果发现身体不自觉的改变为不健康的姿势，那么就证明需要其他活动，没40分钟坐姿办公，活动5min或交替站立办公20min，对身体更加有益； | . ",
    "url": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#%E4%B9%85%E5%9D%90%E6%9C%89%E5%AE%B3%E5%81%A5%E5%BA%B7",
    
    "relUrl": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#久坐有害健康"
  },"367": {
    "doc": "Research of Ergonomics",
    "title": "办公室解决方案",
    "content": "问题 . 未添加辅助品的工学椅 . | 座椅面面积较大，导致大腿压迫； | 腰部支撑完全不够； | 扶手调节问题导致肩膀不适； | 扶手高度没有调整到最佳，加之鼠标过平，导致右臂和右肩压迫较大； | 右边肩膀不适主要来自于健身房锻炼时，大重量深蹲压迫了肩部神经，长期积累导致右肩神经痛，改进方法为，不再用深蹲的方式进行腿部肌肉锻炼，换用其他器材，并且要注意休息，长期健康的锻炼和休息有助于肩部恢复； | 鼠标，当坐姿靠后时，鼠标无法垫高导致，小臂和大臂之间的角度超过了一个舒适的角度，所以鼠标控制移动的距离越大，对右边肩部有越大的损伤，解决方案是垫高鼠标，让鼠标和桌面成一定的夹角，或者更换直立的人体工学鼠标； | . 试错 . | 升降台，缺陷，升降台升高了桌子高度导致椅子升高扶手升高，导致肩膀受力，一天办公下来，肩膀发生异常酸痛，站立时间并不多； | 硬质座椅靠背，缺陷，办公椅椅面有限，导致大腿离开椅面面积过大，5~10cm，硬质靠背无法躺靠坐姿，长时间导致肩颈眼里过大，躺靠坐姿下，硬质靠背对后背肌肉有挤压，导致疼痛； | . 改进 . | 选用建议便携笔记本升降支架，即可以坐姿下调至笔记本高度到最佳，又可以站立使用，通常一次站立办公只有15~20分，期间可以还会有一些拉升动作，使用笔记本完全满足需求； | 选用12cm左右的乳胶靠背，第一保证大腿离开椅面的距离控制在3到5厘米，第二保证不接触头枕的坐姿和接触头枕的坐姿，腰部等能有足够多且舒适的支撑； | 键盘垫高，键盘与桌面有一定夹角，硬质鼠标垫 + 小角度垫高 | 新增座椅头枕，垫高头部，以用来防止由于背部支撑后，颈部支撑太过靠后导致的不适 | . 办公室必备 . | 笔记本电脑升级支架，便携易用 | 显示器升高支架，升高台 | 客制化键盘+手托 | 人体工学鼠标 | 增强工学椅贴合度的乳胶靠背 | 颈枕+折叠床 | 拖鞋+水杯+茶” 遵循 . | 便携 | 易用 | 低成本 | . ",
    "url": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#%E5%8A%9E%E5%85%AC%E5%AE%A4%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88",
    
    "relUrl": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#办公室解决方案"
  },"368": {
    "doc": "Research of Ergonomics",
    "title": "不适",
    "content": "后肩神经痛 . 第二次发作，初步怀疑原因为深蹲姿势非百分之百正确，导致颈部受到压迫，最终导致右肩传递的神经痛 . 解决方案 . | 停止练腿方式中会给颈部肩颈压力的动作，不再进行深蹲训练，换用其他的器械训练 | 药物和物理治疗，使颈部压迫恢复，神经恢复 | 继续观察，是否与坐姿，使用鼠标等条件有必然联系，如果有关系就再次进行调整，观察并记录情况，最终进行分析 | . 初步判断 . | 之前第一次右肩下神经痛时，遇到的情况是多次的硬拉和深蹲，不舒适的工学座椅和办公姿势，包括用鼠标的姿势，不自觉抬手等 | 第二次右肩下神经痛，又一次是多次的硬拉和深蹲以及更换工位后，新的办公座椅和办公姿势，包括使用鼠标的姿势和使用鼠标的重量 | 经过第一次物理治疗时，医师建议原因是颈部问题，由于颈部受到的压力和长时间压迫，导致了右肩的神经性疼痛，根因还是颈部的压力，此次分析情况为第一次出现较为明显的不适大概时间就是上一次深蹲，颈部受到锻炼杠铃的压力，回家前又练过一次腿，在家中，右边肩膀也有不适，回到工作环境后，每次用键盘和鼠标都会有明显的不适，分析原因大概率是因为颈部问题，所以颈部不能再承受压力，包括长期低头看手机，懒人坐姿压迫颈部，大重量深蹲，杠铃压迫颈部，需要后期养成良好的坐姿+良好的使用电子产品的习惯和少低头的习惯，良好的健身习惯，其他练腿的动作还很多，有很多可以替代深蹲的，1. 深蹲给肩颈和腰部带来巨大的压力，2 深蹲给长期酸胀的脚踝带来的巨大压力，放弃深蹲，使用其他练腿器械 | . ",
    "url": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#%E4%B8%8D%E9%80%82",
    
    "relUrl": "/docs/archives/2021/2021-02-15-research-of-ergonomics/#不适"
  },"369": {
    "doc": "Research of Ergonomics",
    "title": "Research of Ergonomics",
    "content": "ergonomics . 2021-02-15 16:09:45 +0800 . ",
    "url": "/docs/archives/2021/2021-02-15-research-of-ergonomics/",
    
    "relUrl": "/docs/archives/2021/2021-02-15-research-of-ergonomics/"
  },"370": {
    "doc": "Work Efficiency",
    "title": "如何行之有效的提高工作效率，避免完美主义，为自己保留更多可支配时间",
    "content": ". | 避免完美主义，对于已经能够达成目标的任务，不再花过多时间将其 ”完美化“； | 重新建立时间观念，对于工作过程中任务进度的变化尽早感知并修改当日计划，越早延期任务效果越好； | 建立严格的节奏和规律，确定好抽离出工作任务的时间结点，不能因为”过于投入“而再次透支当日精力； | 合理规划睡眠、起床、运动时间，尽最大可能保持长期规律性的时间节律； | 使用番茄工作法，合理规划 ”投入时间“ 和 ”休息时间“，尽最大可能避免碎片化的时间分布，达到”一个时间片内“就做一件事的单线程的效果； | . ",
    "url": "/docs/archives/2021/2021-02-15-work-efficiency/#%E5%A6%82%E4%BD%95%E8%A1%8C%E4%B9%8B%E6%9C%89%E6%95%88%E7%9A%84%E6%8F%90%E9%AB%98%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E9%81%BF%E5%85%8D%E5%AE%8C%E7%BE%8E%E4%B8%BB%E4%B9%89%E4%B8%BA%E8%87%AA%E5%B7%B1%E4%BF%9D%E7%95%99%E6%9B%B4%E5%A4%9A%E5%8F%AF%E6%94%AF%E9%85%8D%E6%97%B6%E9%97%B4",
    
    "relUrl": "/docs/archives/2021/2021-02-15-work-efficiency/#如何行之有效的提高工作效率避免完美主义为自己保留更多可支配时间"
  },"371": {
    "doc": "Work Efficiency",
    "title": "三个避免",
    "content": ". | 避免为了达到短期目的而消耗长期精力以及长期的积极性和主观能动性，以可持续发展的态度，保持长期性的，健康高效的精力输出，长期维持一个较高的精力状态，需要每天必须规定合理的休息和睡眠时间，且需要到达确定时间后及时抽离精力的耗费； | 避免将自我生产的时间大量碎片化，例如在一段高质量的精力集中期间，毫无目的性的频繁解锁手机查阅消息或者主动处理其他琐碎问题，等。将 “时间片” 集中化，高质量的时间集中在 “惟一的一个任务” 上； | 避免 “过度投入”，解决问题的过程中经常会出现一个难以定位的问题点导致联锁反应，既影响原本的工作计划又大量耗费精力和注意力，一定要避免在精力和注意力较低迷的情况下 “过度投入” 这样的任务，例如每日18点之后精力较为低迷的时段；应该采取跳过该任务的方式，先去处理同等优先级但是思维优先精力耗费次之的任务，将该任务安排在第二日精力和注意力的峰值时段； | . ",
    "url": "/docs/archives/2021/2021-02-15-work-efficiency/#%E4%B8%89%E4%B8%AA%E9%81%BF%E5%85%8D",
    
    "relUrl": "/docs/archives/2021/2021-02-15-work-efficiency/#三个避免"
  },"372": {
    "doc": "Work Efficiency",
    "title": "总结",
    "content": " ",
    "url": "/docs/archives/2021/2021-02-15-work-efficiency/#%E6%80%BB%E7%BB%93",
    
    "relUrl": "/docs/archives/2021/2021-02-15-work-efficiency/#总结"
  },"373": {
    "doc": "Work Efficiency",
    "title": "方法论",
    "content": ". | 避免完美主义 | 尽早修改当日计划 | 严格节律，及时抽离 | 合理规划睡眠、运动 | 番茄工作法，集中 “时间片” | . ",
    "url": "/docs/archives/2021/2021-02-15-work-efficiency/#%E6%96%B9%E6%B3%95%E8%AE%BA",
    
    "relUrl": "/docs/archives/2021/2021-02-15-work-efficiency/#方法论"
  },"374": {
    "doc": "Work Efficiency",
    "title": "三个避免",
    "content": ". | 避免为短期任务消耗长期精力 | 避免将自我生产的时间大量碎片化 | 避免低迷期 “过度投入” | . ",
    "url": "/docs/archives/2021/2021-02-15-work-efficiency/#%E4%B8%89%E4%B8%AA%E9%81%BF%E5%85%8D-1",
    
    "relUrl": "/docs/archives/2021/2021-02-15-work-efficiency/#三个避免-1"
  },"375": {
    "doc": "Work Efficiency",
    "title": "Work Efficiency",
    "content": "efficiency . 2021-02-15 16:17:50 +0800 . ",
    "url": "/docs/archives/2021/2021-02-15-work-efficiency/",
    
    "relUrl": "/docs/archives/2021/2021-02-15-work-efficiency/"
  },"376": {
    "doc": 2021,
    "title": "2021",
    "content": " ",
    "url": "/docs/archives/2021/2021/#2021",
    
    "relUrl": "/docs/archives/2021/2021/#2021"
  },"377": {
    "doc": 2021,
    "title": 2021,
    "content": " ",
    "url": "/docs/archives/2021/2021/",
    
    "relUrl": "/docs/archives/2021/2021/"
  },"378": {
    "doc": "Criticism of Hegelianism",
    "title": "Criticism of Hegelianism: “All that is real isrational; and all that is rational is real.”",
    "content": " ",
    "url": "/docs/archives/2022/2022-11-19-Criticism-of-Hegelianism/#criticism-of-hegelianism-all-that-is-real-isrational-and-all-that-is-rational-is-real",
    
    "relUrl": "/docs/archives/2022/2022-11-19-Criticism-of-Hegelianism/#criticism-of-hegelianism-all-that-is-real-isrational-and-all-that-is-rational-is-real"
  },"379": {
    "doc": "Criticism of Hegelianism",
    "title": "对于 “存在即合理” 的黑格尔主义的批判",
    "content": "序： 似乎在历史的发展过程中，哪一个哲学命题都没有像黑格尔的命题可以让其成为很大一部分人脱口而出的对现实问题的最终解，与所谓“现代社会”将一切与人相关的矛盾都归一到“人性论”相似，“存在即合理” 成为了人们对待社会现象及个人经历具体事件的最终答复，似乎人们也必须对自己的经历给出一个合理的解释，这就给黑格尔这个著名的哲学命题以生存空间。 . | “凡是存在的都是合理的，凡是合理的都是存在的” | . 引用：《费尔巴哈和德国古典哲学的终结》 费尔德里西-恩格斯 这样一来，黑格尔的这个命题，由于黑格尔辩证法本身，就转化为自己的反面：凡在人类历史领域中是现实的，随着时间的推移，都会成为不合理的，因而按其本性来说已经是不合理的，一开始就包含着不合理性；凡在人们头脑中是合理的，都注定要成为现实的，不管他的现存的、表面的现实多么矛盾； 按照黑格尔的思维方法的一切规则，凡是现实的都是合理的这个命题，就变成另一个命题：凡是现存的，都是应当灭亡的。 . 个人理解： 现实性在其展开的过程中表现为必然性，不能证明其在该过程中的合理性。这个百年前由 费尔德里西-恩格斯 已经批判并且证明是错误的观点，在今天任然具有讨论的必要性。在如今21世纪现代化在人类社会的展开过程中，还存在不少信奉黑格尔主义的人，其中一部分人是彻底的相信黑格尔的观点，另一部分人则是耳濡目染的接受了来自他人灌输的黑格尔主义。这部分人中的一些人稍加思考就会产生对黑格尔主义的怀疑，这种怀疑显然是思辨的产物，是思想上对黑格尔主义排斥； . 历史上的封建等级制度被资本主义制度代替，封建等级制度在其发展的过程中，必然的产生了一股力量推翻了这种社会制度，彻底的否定它，让它成为过去。那么这就证明对于整个人类社会而言封建等级制度并不合理。按照黑格尔主义的提法，封建等级制度的现实性因为其在展开的过程中的必然性，即证明了它的合理性，如果是对于人类社会合理的制度，那么就应该在历史上永存，但是通过对现实情况的考察，并不能证明黑格尔主义的观点； . 存在即合理，凡在人类历史领域中是现实的，其合理性即证明了其在人类社会中不会被新的事物代替，会永远存在，这就意味着发展的停滞，但是事物总是在矛盾中不断变化和发展的，那么黑格尔主义的观点“存在即合理”就变成了某种废话文学： 存在即存在，因为现实性在其展开的过程中表现为必然性仍然可以证明其现实性；那么黑格尔主义的观点“存在即合理”就变成了它自身的反面：存在即灭亡； . 让我们再次引用恩格斯的批判性观点：凡是现存的，都是应当灭亡的。 . ",
    "url": "/docs/archives/2022/2022-11-19-Criticism-of-Hegelianism/#%E5%AF%B9%E4%BA%8E-%E5%AD%98%E5%9C%A8%E5%8D%B3%E5%90%88%E7%90%86-%E7%9A%84%E9%BB%91%E6%A0%BC%E5%B0%94%E4%B8%BB%E4%B9%89%E7%9A%84%E6%89%B9%E5%88%A4",
    
    "relUrl": "/docs/archives/2022/2022-11-19-Criticism-of-Hegelianism/#对于-存在即合理-的黑格尔主义的批判"
  },"380": {
    "doc": "Criticism of Hegelianism",
    "title": "Criticism of Hegelianism",
    "content": "Philosophy . Criticism . Marxism . 2022-11-19 10:00:43 +0800 . ",
    "url": "/docs/archives/2022/2022-11-19-Criticism-of-Hegelianism/",
    
    "relUrl": "/docs/archives/2022/2022-11-19-Criticism-of-Hegelianism/"
  },"381": {
    "doc": 2022,
    "title": "2022",
    "content": " ",
    "url": "/docs/archives/2022/2022/#2022",
    
    "relUrl": "/docs/archives/2022/2022/#2022"
  },"382": {
    "doc": 2022,
    "title": 2022,
    "content": " ",
    "url": "/docs/archives/2022/2022/",
    
    "relUrl": "/docs/archives/2022/2022/"
  },"383": {
    "doc": "Live Migration Precopy Analyze",
    "title": "热迁移原理",
    "content": " ",
    "url": "/docs/archives/2023/2023-01-02-live_migration_precopy/#%E7%83%AD%E8%BF%81%E7%A7%BB%E5%8E%9F%E7%90%86",
    
    "relUrl": "/docs/archives/2023/2023-01-02-live_migration_precopy/#热迁移原理"
  },"384": {
    "doc": "Live Migration Precopy Analyze",
    "title": "热迁移核心步骤",
    "content": "虚拟化层面实现流程和通信方式 . | 通过 python libvirt 接口启动 libvirt 迁移流程 | client（agent compute）连接源端 libvirtd 进程 | client 连接目的端 libvirt 进程 | 调用源端 domainMigrateBegin3 | 调用目的端 domainMigratePrapare3 | 调用源端 domainMigratePerform3 domainMigratePerform3函数主要是执行迁移操作，将源端的数据迁移到目的端。然后等待迁移完成的信号 大致的调用流程： 1. qemuDomainMigratePerform3 → qemuMigrationPerform → qemuMigrationPerformPhase → doNativeMigrate → qemuMigrationRun → qemuMonitorSetMigrationSpeed → qemuMigrationConnect → qemuMonitorMigrateToHost → qemuMonitorJSONMigrate 2. 终会调用到 QEMU中的qmp_migrate 3. setup iterature complete | 源端 libvirtd 进程调用 源端 qemu qmp_migrate tcp_start_outgoing_migration migrate_fd_connect migrate_compress_thread_create migration_thread qemu_savevm_state_begin qemu_savevm_state_pending qemu_savevm_state_iterate migration_completion vm_stop | 目的端 qemu_start_incoming_migration tcp_start_incoming_migration process_incoming_migration_co migrate_decompress_threads_create qemu_loadvm_state cpu_synchronize_all_post_init process_incoming_migration_bin vm_start | . 源端调用流程分析 . | TODO | . 目的端调用流程分析 . | TODO | . qmp_migrate . | tcp_start_outgoing_migration . | 创建和目的端 libvirt 的 tcp 连接 | . | migrate_fd_connect . | qemu接收来自 libvirt 传入的fd (tcp socket)，准备写入数据 | . | 迁移主函数 migration_thread . | 发送header | 建立迁移的准备 | 迭代传输 | 完成迁移 | . | . qemu 内存迁移 - 标脏所有的内存页 . kvm 内存管理简介 . | GVA - Guest虚拟地址 . | GPA - Guest物理地址 . | HVA - Host虚拟地址 . | HPA -Host物理地址 . | . typedef struct KVMSlot { hwaddr start_addr; //Guest物理地址块的起始地址 ram_addr_t memory_size; //大小 void *ram; //QUMU用户空间地址 int slot; //slot id int flags; } KVMSlot; struct kvm_memslots { int nmemslots; //slot number struct kvm_memory_slot memslots[KVM_MEMORY_SLOTS + KVM_PRIVATE_MEM_SLOTS]; }; struct kvm_memory_slot { gfn_t base_gfn; //该块物理内存块所在guest 物理页帧号 unsigned long npages; //该块物理内存块占用的page数 unsigned long flags; unsigned long *rmap; //分配该块物理内存对应的host内核虚拟地址（vmalloc分配） unsigned long *dirty_bitmap; struct { unsigned long rmap_pde; int write_count; } *lpage_info[KVM_NR_PAGE_SIZES - 1]; unsigned long userspace_addr; //用户空间地址（QEMU) int user_alloc; }; . | KVM的虚拟机实际上运行在Qemu的进程上下文中 | 虚拟机的物理内存实际上是Qemu进程的虚拟地址 | KVMSlot 定义了GPA到HVA的映射关系，也就是虚拟机物理地址和宿主机OS虚拟地址之间的关系 | Guest运行过程中，内存访问的过程，根据其所在memslot区域获得其对应的HVA 宿主机os虚拟地址，交给宿主机OS将HVA转化为HPA，得到宿主页帧号，对于缺页有缺页处理函数负责完成GPA-&gt;HPA转化 | . | memory model (info mtree from QEMU monitor console of guest vm) | MemoryRegion 用于描述一个范围内的映射规则 | AddressSpace 用于描述整个地址空间的映射关系 | guest 通过映射关系访问到这些地址 . | 从顶层 MemoryRegion 逐个找其 child MemoryRegion，其中还需要处理 alias 和 priority 的问题 | QEMU 在 MemoryRegion 的属性发生修改 | MemoryRegion 生成 FlatRange，避免逐级查询 MemoryRegion | FlatRange 树形结构查询，查询时间复杂度 O(n) 优化到 O(log(N)) | . | 例如：kvm 处理 io 端口的操作键盘输入，只要给出 AddressSpace 以及地址，最后就可以找到最后的 handler 为 kbd_read_data | . // 调用栈 /* #2 kbd_read_data (opaque=0x555556844d98, addr=&lt;optimized out&gt;, size=&lt;optimized out&gt;) at ../hw/input/pckbd.c:387 #3 0x0000555555cd2092 in memory_region_read_accessor (mr=mr@entry=0x555556844df0, addr=0, value=value@entry=0x7fffd9ff9130, size=size@entry=1, shift=0, mask=mask@entry=255, attrs=...) at ../softmmu/memory.c:440 #4 0x0000555555cceb1e in access_with_adjusted_size (addr=addr@entry=0, value=value@entry=0x7fffd9ff9130, size=size@entry=1, access_size_min=&lt;optimized out&gt;, access_size_max=&lt;optimized out&gt;, access_fn=0x555555cd2050 &lt;memory_region_read_accessor&gt;, mr=0x555556844df0, attrs=...) at ../softmmu/memory.c:554 #5 0x0000555555cd1ac1 in memory_region_dispatch_read1 (attrs=..., size=&lt;optimized out&gt;, pval=0x7fffd9ff9130, addr=0, mr=0x555556844df0) at ../softmmu/memory.c:1424 #6 memory_region_dispatch_read (mr=mr@entry=0x555556844df0, addr=0, pval=pval@entry=0x7fffd9ff9130, op=MO_8, attrs=attrs@entry=...) at ../softmmu/memory.c:1452 #7 0x0000555555c9eb89 in flatview_read_continue (fv=fv@entry=0x7ffe4402d230, addr=addr@entry=96, attrs=..., ptr=ptr@entry=0x7fffeb17d000, len=len@entry=1, addr1=&lt;optimized out&gt;, l=&lt;optimized out&gt;, mr=0x555556844df0) at /home/maritns3/core/kvmqemu/include/qemu/host-utils.h:165 #8 0x0000555555c9ed43 in flatview_read (fv=0x7ffe4402d230, addr=addr@entry=96, attrs=attrs@entry=..., buf=buf@entry=0x7fffeb17d000, len=len@entry=1) at ../softmmu/physmem.c:2881 #9 0x0000555555c9ee96 in address_space_read_full (as=0x555556606880 &lt;address_space_io&gt;, addr=96, attrs=..., buf=0x7fffeb17d000, len=1) at ../softmmu/physmem.c:2894 #10 0x0000555555c9f015 in address_space_rw (as=&lt;optimized out&gt;, addr=addr@entry=96, attrs=..., attrs@entry=..., buf=&lt;optimized out&gt;, len=len@entry=1, is_write=is_write@entry=false) at ../softmmu/physmem.c:2922 #11 0x0000555555c8ece9 in kvm_handle_io (count=1, size=1, direction=&lt;optimized out&gt;, data=&lt;optimized out&gt;, attrs=..., port=96) at ../accel/kvm/kvm-all.c:2635 #12 kvm_cpu_exec (cpu=cpu@entry=0x555556af4410) at ../accel/kvm/kvm-all.c:2886 #13 0x0000555555cf1825 in kvm_vcpu_thread_fn (arg=arg@entry=0x555556af4410) at ../accel/kvm/kvm-accel-ops.c:49 #14 0x0000555555e55983 in qemu_thread_start (args=&lt;optimized out&gt;) at ../util/qemu-thread-posix.c:541 #15 0x00007ffff628d609 in start_thread (arg=&lt;optimized out&gt;) at pthread_create.c:477 #16 0x00007ffff61b4293 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95 */ . //┌──────────► 这是一个 AddressSpace，AddressSpace 用于描述整个地址空间的映射关系。 // │ ┌───────────────────────► MemoryRegion 的优先级，如果一个范围两个 MemoryRegion 出现重叠，优先级高的压制优先级低的 // │ │ // │ │ ┌───────────────────► 表示这个空间的类型，一般划分为 io 和 RAM // │ │ │ ┌──────────────► 这是一个 MemoryRegion，这是 Address Space 中最核心的概念，MemoryRegion 用于描述一个范围内的映射规则 //address-space: memory │ │ │ 0000000000000000-ffffffffffffffff (prio 0, i/o): system 0000000000000000-ffffffffffffffff (prio 0, i/o): system 0000000000000000-00000000bfffffff (prio 0, ram): alias ram-below-4g @pc.ram 0000000000000000-00000000bfffffff ──────────────┐ 0000000000000000-ffffffffffffffff (prio -1, i/o): pci │ 00000000000a0000-00000000000bffff (prio 1, i/o): vga-lowmem │ 00000000000c0000-00000000000dffff (prio 1, rom): pc.rom │ 00000000000e0000-00000000000fffff (prio 1, rom): alias isa-bios @pc.bios 0000000000020000-000000000003ffff │ 00000000fd000000-00000000fdffffff (prio 1, ram): vga.vram │ 00000000fe000000-00000000fe003fff (prio 1, i/o): virtio-pci │ 00000000fe000000-00000000fe000fff (prio 0, i/o): virtio-pci-common-virtio-9p │ 00000000fe001000-00000000fe001fff (prio 0, i/o): virtio-pci-isr-virtio-9p │ 00000000fe002000-00000000fe002fff (prio 0, i/o): virtio-pci-device-virtio-9p │ 00000000fe003000-00000000fe003fff (prio 0, i/o): virtio-pci-notify-virtio-9p │ 00000000febc0000-00000000febdffff (prio 1, i/o): e1000-mmio │ 00000000febf0000-00000000febf3fff (prio 1, i/o): nvme-bar0 │ 00000000febf0000-00000000febf1fff (prio 0, i/o): nvme │ 00000000febf2000-00000000febf240f (prio 0, i/o): msix-table │ 00000000febf3000-00000000febf300f (prio 0, i/o): msix-pba │ 00000000febf4000-00000000febf7fff (prio 1, i/o): nvme-bar0 │ 00000000febf4000-00000000febf5fff (prio 0, i/o): nvme │ 00000000febf6000-00000000febf640f (prio 0, i/o): msix-table │ 00000000febf7000-00000000febf700f (prio 0, i/o): msix-pba │ 00000000febf8000-00000000febf8fff (prio 1, i/o): vga.mmio │ 00000000febf8000-00000000febf817f (prio 0, i/o): edid └── ram-below-4g 是 pc.ram 的一个 alias 00000000febf8400-00000000febf841f (prio 0, i/o): vga ioports remapped 00000000febf8500-00000000febf8515 (prio 0, i/o): bochs dispi interface ┌── ram-above-4g 也是 pc.ram 的一个 alias, 两者都被放到 system 这个 MemoryRegion 上 00000000febf8600-00000000febf8607 (prio 0, i/o): qemu extended regs │ 00000000febf9000-00000000febf9fff (prio 1, i/o): virtio-9p-pci-msix │ 00000000febf9000-00000000febf901f (prio 0, i/o): msix-table │ 00000000febf9800-00000000febf9807 (prio 0, i/o): msix-pba │ 00000000fffc0000-00000000ffffffff (prio 0, rom): pc.bios │ 00000000000a0000-00000000000bffff (prio 1, i/o): alias smram-region @pci 00000000000a0000-00000000000bffff │ 00000000000c0000-00000000000c3fff (prio 1, ram): alias pam-rom @pc.ram 00000000000c0000-00000000000c3fff │ 00000000000c4000-00000000000c7fff (prio 1, ram): alias pam-rom @pc.ram 00000000000c4000-00000000000c7fff │ 00000000000c8000-00000000000cbfff (prio 1, ram): alias pam-rom @pc.ram 00000000000c8000-00000000000cbfff │ 00000000000cb000-00000000000cdfff (prio 1000, ram): alias kvmvapic-rom @pc.ram 00000000000cb000-00000000000cdfff │ 00000000000cc000-00000000000cffff (prio 1, ram): alias pam-rom @pc.ram 00000000000cc000-00000000000cffff │ 00000000000d0000-00000000000d3fff (prio 1, ram): alias pam-rom @pc.ram 00000000000d0000-00000000000d3fff │ 00000000000d4000-00000000000d7fff (prio 1, ram): alias pam-rom @pc.ram 00000000000d4000-00000000000d7fff │ 00000000000d8000-00000000000dbfff (prio 1, ram): alias pam-rom @pc.ram 00000000000d8000-00000000000dbfff │ 00000000000dc000-00000000000dffff (prio 1, ram): alias pam-rom @pc.ram 00000000000dc000-00000000000dffff │ 00000000000e0000-00000000000e3fff (prio 1, ram): alias pam-rom @pc.ram 00000000000e0000-00000000000e3fff │ 00000000000e4000-00000000000e7fff (prio 1, ram): alias pam-ram @pc.ram 00000000000e4000-00000000000e7fff │ 00000000000e8000-00000000000ebfff (prio 1, ram): alias pam-ram @pc.ram 00000000000e8000-00000000000ebfff │ 00000000000ec000-00000000000effff (prio 1, ram): alias pam-ram @pc.ram 00000000000ec000-00000000000effff │ 00000000000f0000-00000000000fffff (prio 1, ram): alias pam-rom @pc.ram 00000000000f0000-00000000000fffff │ 00000000fec00000-00000000fec00fff (prio 0, i/o): ioapic │ 00000000fed00000-00000000fed003ff (prio 0, i/o): hpet │ 00000000fee00000-00000000feefffff (prio 4096, i/o): apic-msi │ 0000000100000000-00000001bfffffff (prio 0, ram): alias ram-above-4g @pc.ram 00000000c0000000-000000017fffffff ──────────────┘ . dirty page tracking 脏页标记 . dirty bitmap . | bitmap是将原本需要占用1个字节或者多个字节的整数，转化成对一个字节单位中的一个确定位置的比特的占用 | Bitmaps are bit vectors where each ‘1’ bit in the vector indicates a modified (“dirty”) segment of the corresponding block device. The size of the segment that is tracked is the granularity of the bitmap. If the granularity of a bitmap is 64K, each ‘1’ bit means that a 64K region as a whole may have changed in some way, possibly by as little as one byte.、 | 将向量上的每个“1”表示为对应块的脏页，bitmap的增量每增加“1”，就是每个内存脏页大小（4kByte）变更了 | 核心：使用 bitmap 上每一个 solt 槽位来表示一个固定大小的脏页是否变更 . | https://qemu-project.gitlab.io/qemu/interop/bitmaps.html | . dirty ring . * https://blog.csdn.net/huang987246510/article/details/112293303 . +-------------+ +----------+ +--------------+ +---------------------+ | | ram_list +-----&gt; | dirty_memory +--------&gt; | migration_bitmap_rcu| | +----------+ +------+-------+ +---------------------+ | Guest | ^ | | | | |用户态 | +--------------------------------+ |----- | |内核态 | | | | | v | | | +---------+ +-------+--------+ | | memslot +-----&gt; | dirty_bitmap | +-------------+ +---------+ +----------------+ . 用户态 . | 用户态与脏页统计有关的数据结构：RAMList和RAMBlock | RAMList用在从内核获取脏页的时候，它表示脏页的粒度是kvm中的一个slot . | 如前所述：KVMSlot 定义了GPA到HVA的映射关系，也就是虚拟机物理地址和宿主机OS虚拟地址之间的关系 | . | RAMBlock中的位图用来描述一个RAMBlock的脏页使用情况，它表示的脏页粒度是Qemu中的一个RAMBlock | 在内存迁移统计脏页过程中，会依次使用这两个数据结构统计剩余内存的脏页数量 | . 内核态 . | kvm_userspace_memory_region | kvm_dirty_log | kvm_memory_slot | 为了让用于态统计虚机的脏页，内核提供了两个接口，分别是KVM_SET_USER_MEMORY_REGION、KVM_GET_DIRTY_LOG，这两个接口 | 内核提供了两个命令供用户态统计虚机的脏页，KVM_SET_USER_MEMORY_REGION、KVM_GET_DIRTY_LOG，KVM_SET_USER_MEMORY_REGION命令字作用在vm的fd，用来通知kvm开启对某段内存区域的脏页跟踪，结构体kvm_userspace_memory_region 是用户态传入的参数，用来描述kvm应该跟踪的内存区域 | KVM_GET_DIRTY_LOG命令字作用在vm的fd，用来获取内核跟踪的脏页信息，结构体kvm_dirty_log作为参数用来指定要查询的内存slot，同时保存内核的脏页查询结果 | . 交互过程简介 . | 根据PML的硬件特性，每当CPU在Guest态根据EPT转换地址后，写数据到物理页，这时如果PML特性开启，在设置EPT页表项的Dirty位之后，还会将GPA地址写入PML Buffer。 | . 清零Dirty位 . | KVM的实现中，在创建slot时，如果不想记录某个slot包含的所有物理页的是否为脏，需要默认将这些物理页对应的页表项的Dirty页置位，因为如果Dirty位是0，Guest态CPU写物理页时会将其置1并且填充GPA到PML Buffer，如果PML Buffer满了，就会触发VMExit，增加不必要的开销。反之，要记录脏页，首先需要将指向slot包含的所有物理页的spte的Dirty位清零，这里需要根据gfn找到指向该gfn对应页的spte，反向映射数组rmap就派上了用场。 物理页开启写保护：除了清零页表项的Dirty位，记录脏页还需要开启页的写保护，在脏页记录的过程中，所有slot包含的物理页变成只读，当CPU写访问这个页时，发生缺页异常，kvm会重新分配一个新的页给CPU。在脏页记录关闭后，才能将写保护去掉，slot包含的所有页变成可读写。 | . 步骤 . | qemu 初始化一个 bitmap 结构体 migration_bitmap_rcu 并set所有的solt 为1 | qemu 将对内存页的标脏提交给 kvm 并调用 address_space_update_topology_pass | address_space_update_topology_pass 调用 log_start 将已经定义的 memory slot 增加 KVM_MEM_LOG_DIRTY_PAGES 的 flag，这一步就是内核标脏 | kvm_create_dirty_bitmap kvm 初始化内存脏页 bitmap kvm_create_dirty_bitmap | qemu kvm 通过 migration_bitmap_sync 将内核脏页的 usersSpace 同步到 ram_list 结构体中 | migration_bitmap_sync 将当前 ram_list 中的脏页 bitmap 拷贝到 migration_bitmap_rcu，这一步主要就是将kernal中的脏页同步回 qemu bitmap 结构体中 | 通过对 migration_bitmap_rcu-&gt;bmap 的迭代，qemu将通过调用 ram_find_and_save_block 找到脏页并将脏页写入初始化的 fd | . 简化步骤 . | qemu 初始化一个处于用户态的 bitmap 用于记录脏页，并set所有的solt 为1 | qemu 初始化 RAMList 和 RAMBlock，分别用于存储虚拟机整个地址空间 kvmslot 和 用于表示单个脏页的 RAMBlock | qemu 将对内存页的标脏提交给 kvm | kvm 将已经定义的 memory slot 增加标脏的 flag，这一步就是内核标脏 | qemu kvm中通过 kvm_vm_ioctl 获取内存脏页并同步到 RAMList和RAMBlock | 将当前 ram_list 中的脏页 bitmap 拷贝到 migration_bitmap_rcu，这一步主要就是将kernal中的脏页同步回 qemu bitmap 结构体中 | 通过对 migration_bitmap_rcu-&gt;bmap 的迭代，qemu将通过调用 ram_find_and_save_block 找到脏页并将脏页写入初始化的 fd | 对已经完成拷贝的 block 进行清脏 KVM_CLEAR_DIRTY_LOG（一次拷贝完成，对端返回脏页数量） | 计算内存脏页率 | 进行第二次拷贝 | . | 执行栈帧 (gdb) bt #0 kvm_set_user_memory_region (kml=0x55ab8fc502c0, slot=0x55ab8fc50500) at /home/liqiang02/qemu0711/qemu-2.8/kvm-all.c:236 #1 0x000055ab8df10a92 in kvm_slot_update_flags (kml=0x55ab8fc502c0, mem=0x55ab8fc50500, mr=0x55ab8fd36f70) at /home/liqiang02/qemu0711/qemu-2.8/kvm-all.c:376 #2 0x000055ab8df10b1f in kvm_section_update_flags (kml=0x55ab8fc502c0, section=0x7f0ab37fb4c0) at /home/liqiang02/qemu0711/qemu-2.8/kvm-all.c:389 #3 0x000055ab8df10b65 in kvm_log_start (listener=0x55ab8fc502c0, section=0x7f0ab37fb4c0, old=0, new=4) at /home/liqiang02/qemu0711/qemu-2.8/kvm-all.c:404 #4 0x000055ab8df18b33 in address_space_update_topology_pass (as=0x55ab8ea21880 &lt;address_space_memory&gt;, old_view=0x7f0cc4118ca0, new_view=0x7f0aa804d380, adding=true) at /home/liqiang02/qemu0711/qemu-2.8/memory.c:854 #5 0x000055ab8df18d9b in address_space_update_topology (as=0x55ab8ea21880 &lt;address_space_memory&gt;) at /home/liqiang02/qemu0711/qemu-2.8/memory.c:886 #6 0x000055ab8df18ed6 in memory_region_transaction_commit () at /home/liqiang02/qemu0711/qemu-2.8/memory.c:926 #7 0x000055ab8df1c9ef in memory_global_dirty_log_start () at /home/liqiang02/qemu0711/qemu-2.8/memory.c:2276 #8 0x000055ab8df30ce6 in ram_save_init_globals () at /home/liqiang02/qemu0711/qemu-2.8/migration/ram.c:1939 #9 0x000055ab8df30d36 in ram_save_setup (f=0x55ab90d874c0, opaque=0x0) at /home/liqiang02/qemu0711/qemu-2.8/migration/ram.c:1960 #10 0x000055ab8df3609a in qemu_savevm_state_begin (f=0x55ab90d874c0, params=0x55ab8ea0178c &lt;current_migration+204&gt;) at /home/liqiang02/qemu0711/qemu-2.8/migration/savevm.c:956 #11 0x000055ab8e25d9b8 in migration_thread (opaque=0x55ab8ea016c0 &lt;current_migration&gt;) at migration/migration.c:1829 #12 0x00007f0cda1fd494 in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0 #13 0x00007f0cd9f3facf in clone () from /lib/x86_64-linux-gnu/libc.so.6 . | . 4 - qemu 向 tcp sockets 中写入内存数据（迁移的控制层和实现层完全分开） . | 开始迁移内存，将内存数据拷贝到目的端（defaultpage size 4k） | 发送内存数据到目的端，返回发送的内存页个数 | qemu每拷贝一次内存之前，会统计一次剩余的脏页数量，对比域值后决定是否一次性迁移 . | 脏页统计方法：dirtyrate = increased_memory / meaurement_time | 脏页速率越大，虚机内存变化越快，迁移时花费的时间就越多 | 脏页统计率的统计过程和 dirty page tracking 类似，也是通过对内核中的脏页和qemu bitmap 之间的同步来计算增量 | https://blog.csdn.net/huang987246510/article/details/118424717 | . | 内存发送和接收 | . source destination +------------------------+ +-------------------------+ | | SETUP | ram_save_setup | ram_load_setup | | | +------------------------+ +-------------------------+ sync dirty bit to Setup RAMBlock-&gt;receivedmap RAMBlock-&gt;bmap +------------------------+ +-------------------------+ | | ITER | ram_save_pending | ram_load | ram_save_iterate | | | | +------------------------+ +-------------------------+ sync dirty bit Receive page and send page +------------------------+ +-------------------------+ | | COMP | ram_save_pending | ram_load | ram_save_complete | | | | +------------------------+ +-------------------------+ sync dirty bit Receive page and send page . 5 - 迭代所有脏页，脏页达到一定的水平线 . | TODO | . 6 - 暂停虚拟机（默认值30ms），一次性迁移剩余脏页 . 7 - 启动目的端vm . ",
    "url": "/docs/archives/2023/2023-01-02-live_migration_precopy/#%E7%83%AD%E8%BF%81%E7%A7%BB%E6%A0%B8%E5%BF%83%E6%AD%A5%E9%AA%A4",
    
    "relUrl": "/docs/archives/2023/2023-01-02-live_migration_precopy/#热迁移核心步骤"
  },"385": {
    "doc": "Live Migration Precopy Analyze",
    "title": "热迁移 downtime",
    "content": " ",
    "url": "/docs/archives/2023/2023-01-02-live_migration_precopy/#%E7%83%AD%E8%BF%81%E7%A7%BB-downtime",
    
    "relUrl": "/docs/archives/2023/2023-01-02-live_migration_precopy/#热迁移-downtime"
  },"386": {
    "doc": "Live Migration Precopy Analyze",
    "title": "什么是 downtime",
    "content": ". | 脏页率达到指定阈值之后，暂停虚拟机，一次性迁移剩余脏页，并启动目的虚拟机的过程耗时 | 热迁移的停机时间（downtime）不是简单设置一个数字 | 迁移过程中的停机时间是变化的 | 不断增加，在一段时间后停机时间达到最终的最大值（用户态给定的最大值），这个值就是 live_migration_downtime | . ",
    "url": "/docs/archives/2023/2023-01-02-live_migration_precopy/#%E4%BB%80%E4%B9%88%E6%98%AF-downtime",
    
    "relUrl": "/docs/archives/2023/2023-01-02-live_migration_precopy/#什么是-downtime"
  },"387": {
    "doc": "Live Migration Precopy Analyze",
    "title": "影响参数",
    "content": ". | CONF.libvirt.live_migration_downtime . | 最大值，手动配置、配置读取 | downtime_steps 每个 Step 的 max downtime 都在递增直到真正用户设定的最大可容忍 downtime， 这是因为 Nova 在不断的试探实际最小的 max downtime，尽可能早的进入退出状态。 | . | CONF.libvirt.live_migration_downtime_steps . | 最大值，手动配置、配置读取 | 一个元组表示一个 Step，分 Steps 次给 libvirtd 传输 | . | CONF.libvirt.live_migration_downtime_delay . | 最大值，手动配置、配置读取 | 下一次传递时间间隔 | . | downtime 通过上面一个算法得出：每次迭代都会重新计算虚拟机新的脏内存以及每次迭代所花掉的时间来估算带宽，再根据带宽和当前迭代的脏页数计算出传输剩余数据的时间 | 如果最后一次 libvirtd 迭代计算出来的 downtime 在传递的 downtime 范围内，则满足退出条件 | 自动收敛模式：如果虚拟机持续处于高业务状态，那么 libvirtd 会自动调整 vCPU 参数以减轻负载，达到降低脏内存的增长速度，从而保证 downtime 进入退出范围 | compute 中通过 migrateSetMaxDowntime 实现 | . ",
    "url": "/docs/archives/2023/2023-01-02-live_migration_precopy/#%E5%BD%B1%E5%93%8D%E5%8F%82%E6%95%B0",
    
    "relUrl": "/docs/archives/2023/2023-01-02-live_migration_precopy/#影响参数"
  },"388": {
    "doc": "Live Migration Precopy Analyze",
    "title": "Live Migration Precopy Analyze",
    "content": "live_migration . qemu . libvirt . kvm . precopy . ",
    "url": "/docs/archives/2023/2023-01-02-live_migration_precopy/",
    
    "relUrl": "/docs/archives/2023/2023-01-02-live_migration_precopy/"
  },"389": {
    "doc": 2023,
    "title": "2023",
    "content": " ",
    "url": "/docs/archives/2023/2023/#2023",
    
    "relUrl": "/docs/archives/2023/2023/#2023"
  },"390": {
    "doc": 2023,
    "title": 2023,
    "content": " ",
    "url": "/docs/archives/2023/2023/",
    
    "relUrl": "/docs/archives/2023/2023/"
  },"391": {
    "doc": "1.1 Algorithm",
    "title": "1.1 Algorithm",
    "content": " ",
    "url": "/docs/engineering/foundament/algorithm/algorithm/",
    
    "relUrl": "/docs/engineering/foundament/algorithm/algorithm/"
  },"392": {
    "doc": "Archives",
    "title": "Archives",
    "content": " ",
    "url": "/docs/archives/archives/",
    
    "relUrl": "/docs/archives/archives/"
  },"393": {
    "doc": "Arrays & Hashing",
    "title": "Arrays &amp; Hashing",
    "content": "Übung macht den Meister . Roadmap . ",
    "url": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/#arrays--hashing",
    
    "relUrl": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/#arrays--hashing"
  },"394": {
    "doc": "Arrays & Hashing",
    "title": "1. Contains Duplicate",
    "content": "Given an integer array nums, return true if any value appears at least twice in the array . using hash . Python . class Solution: def containsDuplicate(self, nums: list[int]) -&gt; bool: hashset = set() for n in nums: if n in hashset: return True hashset.add(n) return False if __name__ == '__main__': result = Solution().containsDuplicate([1,2,3,4,555,6,222,89,689435,12498,96783,123488,9098,6]) print(\"=&gt; %s\" % result) . Golang . without using hash . Python . # 1. loop initial nums and save value to another list # 2. use binary search to find the same value # 3. if has same value return true # 4. if not just insert to binary search result index, between i &amp; j # 5. looping until last value, return False when finish all # this is sorting problem, time =&gt; Nlogn . Golang . ",
    "url": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/#1-contains-duplicate",
    
    "relUrl": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/#1-contains-duplicate"
  },"395": {
    "doc": "Arrays & Hashing",
    "title": "2. Two Sum",
    "content": "Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target. Python . Golang . ",
    "url": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/#2-two-sum",
    
    "relUrl": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/#2-two-sum"
  },"396": {
    "doc": "Arrays & Hashing",
    "title": "3.",
    "content": "{desc} . Python . Golang . ",
    "url": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/#3",
    
    "relUrl": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/#3"
  },"397": {
    "doc": "Arrays & Hashing",
    "title": "Arrays & Hashing",
    "content": " ",
    "url": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/",
    
    "relUrl": "/docs/engineering/foundament/algorithm/arrays_and_hashing_231115151706/"
  },"398": {
    "doc": "Cloud Native Automation",
    "title": "Cloud Native Automation",
    "content": " ",
    "url": "/docs/jq/cloud_native_automation/cloud_native_automation/",
    
    "relUrl": "/docs/jq/cloud_native_automation/cloud_native_automation/"
  },"399": {
    "doc": "Engineering",
    "title": "Engineering",
    "content": " ",
    "url": "/docs/engineering/engineering/",
    
    "relUrl": "/docs/engineering/engineering/"
  },"400": {
    "doc": "III. Experience",
    "title": "III. Experience",
    "content": " ",
    "url": "/docs/engineering/experience/experience/",
    
    "relUrl": "/docs/engineering/experience/experience/"
  },"401": {
    "doc": "I. Foundament",
    "title": "I. Foundament",
    "content": " ",
    "url": "/docs/engineering/foundament/foundament/",
    
    "relUrl": "/docs/engineering/foundament/foundament/"
  },"402": {
    "doc": "Home",
    "title": "Home",
    "content": "露と落ち露と消えにし我が身かな浪速のことも夢のまた夢 . As dew appears, As dew vanishes, Such is my life, Everything in this world, Is but a dream within a dream. - A motorcycle rider and loving husband. ",
    "url": "/",
    
    "relUrl": "/"
  },"403": {
    "doc": "Jq",
    "title": "Jq",
    "content": " ",
    "url": "/docs/jq/jq/",
    
    "relUrl": "/docs/jq/jq/"
  },"404": {
    "doc": "Kickstart & Recap",
    "title": "Kickstart &amp; Recap",
    "content": "Kickstart next phase of Engineering life &amp; Recap past 7 years experience . The key is connecting the dots! . ",
    "url": "/docs/engineering/kickstart_and_recap_231112205754/#kickstart--recap",
    
    "relUrl": "/docs/engineering/kickstart_and_recap_231112205754/#kickstart--recap"
  },"405": {
    "doc": "Kickstart & Recap",
    "title": "Section 1: Three foundamental aspect",
    "content": "1. Foundament &amp; Basics . | Linux | Programming language | Algorithm . | 75 leetcode questions | Learning roadmap | My algorithm training | . | Networking | . 2. System Design . Transfer a complicated problem into technical requirement . | Design pattern | Design detail | Solution Selection | System elements | Problem Solving | . 3. Experience . Recap &amp; Reexplore all technical solution and architecture . | Projects | . ",
    "url": "/docs/engineering/kickstart_and_recap_231112205754/#section-1-three-foundamental-aspect",
    
    "relUrl": "/docs/engineering/kickstart_and_recap_231112205754/#section-1-three-foundamental-aspect"
  },"406": {
    "doc": "Kickstart & Recap",
    "title": "Section2: Be a PRO",
    "content": " ",
    "url": "/docs/engineering/kickstart_and_recap_231112205754/#section2-be-a-pro",
    
    "relUrl": "/docs/engineering/kickstart_and_recap_231112205754/#section2-be-a-pro"
  },"407": {
    "doc": "Kickstart & Recap",
    "title": "Section3: Explore cognitive boundaries",
    "content": " ",
    "url": "/docs/engineering/kickstart_and_recap_231112205754/#section3-explore-cognitive-boundaries",
    
    "relUrl": "/docs/engineering/kickstart_and_recap_231112205754/#section3-explore-cognitive-boundaries"
  },"408": {
    "doc": "Kickstart & Recap",
    "title": "Kickstart & Recap",
    "content": "Engineering . SystemDesign . Foundament . Experience . ConnectTheDots . ",
    "url": "/docs/engineering/kickstart_and_recap_231112205754/",
    
    "relUrl": "/docs/engineering/kickstart_and_recap_231112205754/"
  },"409": {
    "doc": "Python automation",
    "title": "Python automation",
    "content": " ",
    "url": "/docs/jq/cloud_native_automation/python_automation/",
    
    "relUrl": "/docs/jq/cloud_native_automation/python_automation/"
  },"410": {
    "doc": "Python automation",
    "title": "Basic",
    "content": "What is Python . | object-oriented | interpreter code at run time, no compile | multiple platforms support | also support use as procedural | . 面相对象 &amp; 解释器无需编译 &amp; 实时运行结果 &amp; 可以当作过程语言使用，例如非过程脚本 . | Deep Dive: Understand the CPython interpreter implementation | . Syntax . 1. Dot notation [object we want to access][dot][attribute or method] . Dot notation is a feature in object-oriented programming languages like Python that allows you to search an extensive database for an object’s attributes and methods. In Python, dot notation is written as: [object we want to access][dot][attribute or method] . 点计法语法 . 每一个模块，通过点后加变量名来获取变量值，例如 os.name . 每一个模块，通过点后加函数名称（必须加括号，无入参的情况下括号内为空）来获取函数结果，例如：os.getcwd() . # get value from variable object.var # call method object.this_is_a_method() . Python Indentation Python uses indentation to indicate a block of code. Tabs or Spaces? Spaces are the preferred indentation method. Tabs should be used solely to remain consistent with code that is already indented with tabs. Python disallows mixing tabs and spaces for indentation. 冒号 + tab / 四个空行，来标识代码区块，如果使用 tab 需要全部项目内保持一直，一般建议使用 tab 输出四个空格的编辑器 . if 10 &gt; 1: print(\"Hello\") . Object-oriented . Class: A Class is like an object constructor or template, or a “blueprint” for creating objects. Object: Almost everything in Python is an object, with its properties and methods. (including Class) . Instance: A implementation of Class, with all class properties but has specific values. Self: The self parameter is a reference to the current instance of the class, and is used to access variables that belongs to the class. Method: Give input values to output result, with a Class, used by all instances. Variable: Hold a specific type of value; . 类：class HelloWorld . 实例（类的实例）：定义一个类型表示定义了一种抽象，将这种抽象具体成一个可访问的内存对象的过程就是类的实例化：ob = HelloWorld() . 对象：object 任何类的实例，以及实例的方法、变量都可以被称作对象，python 根类就是 object，通常无需继承 . 方法 method：在类中 def 的一种接收入参和输出参数的函数，将其称为方法：method . 函数 function：直接在 py 文件中定义的 def 函数，不属于任何类型和对象，直接就叫做 function . # This is a Class definition class ThisIsMyClass(): def __init__(self, first_input_var): \"\"\" three quota is Doc string for document purpose init: default method for Class to init a specific instance self: current instance itself first_var: initial variable from instance init self.first_var: class property \"\"\" self.first_var = first_input_var def get_sum(self, second_var): \"\"\" This is a method, with an input return: sum of current instance property first_var and new input \"\"\" return self.first_var + second_var ins = ThisIsMyClass(10) result = ins.get_sum(100) print(\"=&gt; %d\" % result) . | Deep Dive: Python Classes and Objects | . ",
    "url": "/docs/jq/cloud_native_automation/python_automation/#basic",
    
    "relUrl": "/docs/jq/cloud_native_automation/python_automation/#basic"
  },"411": {
    "doc": "Python automation",
    "title": "The Python Standard Library",
    "content": "https://docs.python.org/3/library/index.html . | os - Miscellaneous operating system interfaces . | Often use: . | os.name | os.getcwd() | | . | . | . ",
    "url": "/docs/jq/cloud_native_automation/python_automation/#the-python-standard-library",
    
    "relUrl": "/docs/jq/cloud_native_automation/python_automation/#the-python-standard-library"
  },"412": {
    "doc": "Python automation",
    "title": "Automation 3rd part Library",
    "content": ". | requests - API test | flash - lightweight API server | json - json serializer (convert byte flow to json object) | pymongo - mongoDB (ORM) | . ",
    "url": "/docs/jq/cloud_native_automation/python_automation/#automation-3rd-part-library",
    
    "relUrl": "/docs/jq/cloud_native_automation/python_automation/#automation-3rd-part-library"
  },"413": {
    "doc": "Python automation",
    "title": "Used For",
    "content": ". | Web Server &amp; Restful API | RPC | DataBase Access . | ORM: Object–relational mapping, convert database relational data to objects of python | . | Linux Command Access | Cacheing System Access | . ",
    "url": "/docs/jq/cloud_native_automation/python_automation/#used-for",
    
    "relUrl": "/docs/jq/cloud_native_automation/python_automation/#used-for"
  },"414": {
    "doc": "Roadmap",
    "title": "Roadmap",
    "content": "Übung macht den Meister Roadmap . ",
    "url": "/docs/engineering/foundament/algorithm/roadmap_231115151330/",
    
    "relUrl": "/docs/engineering/foundament/algorithm/roadmap_231115151330/"
  },"415": {
    "doc": "Roadmap",
    "title": "Arrays &amp; Hashing",
    "content": "1. Contains Duplicate . Given an integer array nums, return true if any value appears at least twice in the array . | using hash . | python | golang | . | without using hash . | python | golang | . | . 2. Valid Anagram . | python | golang 3. Two Sum . | python | golang 4. Group Anagrams . | python | golang 5. Top K Frequent Elements . | python | golang 6. Product of Array Except Self . | python | golang 7. Valid Sudoku . | python | golang 8. Encode and Decode Strings . | python | golang 9. Longest Consecutive Sequence . | python | golang | . ",
    "url": "/docs/engineering/foundament/algorithm/roadmap_231115151330/#arrays--hashing",
    
    "relUrl": "/docs/engineering/foundament/algorithm/roadmap_231115151330/#arrays--hashing"
  },"416": {
    "doc": "II. System Design",
    "title": "II. System Design",
    "content": " ",
    "url": "/docs/engineering/system_design/system_design/",
    
    "relUrl": "/docs/engineering/system_design/system_design/"
  }
}
